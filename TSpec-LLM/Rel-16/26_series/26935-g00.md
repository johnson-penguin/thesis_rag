![](media/image1.jpeg){width="7.086111111111111in"
height="1.136111111111111in"}

Contents {#contents .TT}
========

[7](#foreword)

[8](#scope)

[8](#references)

[9](#abbreviations)

[9](#abbreviations-1)

[10](#general-overview)

[10](#introduction)

[10](#tests-over-dch-radio-channels)

[11](#tests-over-hsdpaeul-radio-channels)

[11](#test-bed-and-test-plan-for-phase-1)

[12](#test-methodology)

[12](#test-arrangement)

[12](#description-of-the-testing-system)

[13](#network-simulator)

[14](#umts-simulator-choices)

[14](#rab-and-protocols)

[15](#description-of-the-rlc-implementation)

[16](#physical-layer-implementation)

[18](#headsets-and-sound-card)

[18](#test-environment)

[18](#calibration-and-test-conditions-monitoring)

[18](#speech-level)

[18](#delay)

[19](#test-conditions-for-amr-nb-codec)

[20](#test-conditions-for-amr-wb-codec)

[21](#test-bed-and-test-plan-for-phase-2)

[22](#test-arrangement-1)

[22](#description-of-the-proposed-testing-system)

[23](#network-simulator-1)

[23](#calibration-and-test-conditions-monitoring-1)

[24](#test-conditions)

[24](#analysis-of-test-results-for-dch-channels-for-phase-1-and-2)

[24](#conversation-tests)

[25](#experimental-design-and-statistical-procedures)

[26](#narrowband-test---symmetric-conditions-set-1)

[32](#narrowband-test-asymmetric-conditions-set-2)

[34](#wideband-test-symmetric-conditions-set-3)

[39](#wideband-test-asymmetric-conditions-set-4)

[42](#phase-2---itu-t-codec-tests-set-5)

[45](#summary-of-test-result-analysis)

[45](#performance-characterisation-of-voims-over-hsdpaeul-channels)

[45](#a-listening-only-tests)

[45](#a.1-test-methodology-for-listening-only-tests)

[45](#a.2-test-arrangement)

[46](#a.3-jitter-buffer-implementations)

[46](#a.3.1-fixed-jbm)

[46](#a.3.2-adaptive-jbm)

[46](#a.4-network-conditions)

[47](#a.5-listening-experiments)

[48](#a.6-test-results)

[53](#a.7-delay-analysis)

[59](#a.8-listening-only-test-conclusions)

[59](#b-conversation-tests)

[59](#b.1-introduction)

[59](#b.2-the-test-plan)

[61](#b.3-cross-check-of-test-lab-results)

[61](#b.4-test-results)

[61](#b.4.1-mean-scores-by-experiment-and-by-test-lab)

[65](#b.4.2-subject-consistency-measures-for-test-labs)

[65](#b.4.3-multivariate-analysis-of-variance-manova)

[66](#b.4.3.1-manova-results-and-statistics)

[68](#b.4.3.2-composite-scores-conversational-quality)

[70](#b.4.3.3-conversational-quality-by-experimental-factors)

[74](#b.5-conversation-tests-conclusions)

[74](#conclusions)

[74](#tests-over-dch-radio-channels-1)

[74](#tests-over-hsdpaeul-radio-channels-listening-only-tests)

[74](#tests-over-hsdpaeul-radio-channels-conversation-tests)

[74](#general-consideration)

[75](#annex-a-conversation-test-composite-dependent-variable-scores-by-condition-and-lab)

[77](#annex-b-instructions-to-subjects)

[78](#annex-c-example-scenarios-for-the-conversation-test)

[80](#annex-d-test-plan-for-the-amr-narrow-band-packet-switched-conversation-test)

[97](#annex-e-test-plan-for-the-amr-wide-band-packet-switched-conversation-test)

[114](#annex-f-test-plan-for-packet-switched-conversation-tests-for-comparison-of-quality-offered-by-different-speech-coders)

[126](#annex-g-test-plan-for-global-analysis-of-pss-conversation-tests)

[132](#annex-h-test-plan-for-performance-characterisation-of-voims-over-hsdpaeul-channels-listening-only-tests)

[132](#h.1-introduction)

[132](#h.2-listening-only-test-conditions)

[133](#h.3-end-to-end-delay-analysis)

[133](#h.4-listening-only-experiments)

[134](#h.5-test-material-processing)

[136](#annex-i-illustrative-scheme-for-jitter-buffer-management)

[136](#i.1-pseudo-code)

[141](#i.2-verification-against-the-minimum-performance-requirements)

[142](#i.2.1-delay-performance)

[145](#i.2.2-jbm-induced-error-concealment-operations)

[146](#annex-j-test-processing-for-listening-only-tests)

[146](#j.1-speech-preparation)

[146](#j.2-pre-processing)

[146](#j.3-processing-of-speechbackground-noise-signal)

[147](#j.4-up-and-down-sampling-rounding-and-scaling)

[148](#j.5-processing-for-direct-conditions)

[148](#j.6-processing-for-mnru-conditions)

[148](#j.7-processing-of-voice-over-ims-over-hspa)

[149](#j.8-post-processing)

[149](#j.9-test-conditions)

[152](#annex-k-radio-network-simulation-for-hsdpaeul-performance-characterization)

[156](#annex-l-test-plan-for-the-amr-nbwb-conversation-test-in-umts-over-hsdpaeul)

[156](#l.1-introduction)

[156](#l.2-general-information)

[156](#l.2.1-permanent-documents)

[156](#l.2.2-key-acronyms)

[157](#l.2.3-contacts)

[157](#l.2.4-participants)

[158](#l.3-test-methodology)

[158](#l.3.1-introduction)

[159](#l.3.2-test-design)

[159](#l.3.2.1-description-of-the-test-bed)

[160](#l.3.2.2-transmission-system)

[160](#l.3.2.3-radio-access-bearers)

[161](#l.3.2.4-test-environment)

[161](#l.3.3-test-conditions)

[166](#l.4-test-procedure)

[166](#l.4.1-time-projection)

[167](#l.4.2-instructions-to-the-subjects)

[168](#l.4.3-test-materials)

[168](#l.4.4-deliverables)

[168](#l.4.5-data-analysis)

[169](#l.5-working-document-for-the-performance-characterization-of-voims-over-hsdpaedch)

[169](#l.5.1-introduction)

[169](#l.5.2-system-overview)

[170](#l.5.3-radio-access-bearers)

[173](#l.5.4-delay)

[175](#l.5.5-rn-simulator)

[176](#l.5.6-core-network)

[176](#l.5.7-voip-client)

[178](#l.5.8-interfaces)

[179](#l.5.8.1-interface-1)

[179](#l.5.8.2-interface-2)

[179](#l.5.8.3-interface-3)

[180](#l.5.9-simulated-hspa-air-interface)

[180](#l.5.9.1-general-description)

[180](#l.5.9.2-error-delay-profiles)

[184](#l.5.a.1-network-parameters)

[185](#l.5.a.2-traffic-assumptions-example-amr-7.95)

[186](#l.5.a.3-other-assumptions)

[187](#l.5.a.4-simulation-methodology)

[187](#bibliography)

[188](#annex-m-change-history)Foreword 1 Scope 2 References 3
Abbreviations 3.1 Abbreviations 4 General Overview 4.1 Introduction 4.2
Tests over DCH radio channels 4.3 Tests over HSDPA/EUL radio channels 5
Test bed and test plan for Phase 1 5.1 Test methodology 5.2 Test
arrangement 5.2.1 Description of the testing system 5.2.2 Network
simulator 5.2.3 UMTS simulator choices 5.2.3.1 RAB and protocols 5.2.3.2
Description of the RLC implementation 5.2.3.3 Physical Layer
Implementation 5.2.4 Headsets and Sound Card 5.2.5 Test environment
5.2.6 Calibration and test conditions monitoring 5.2.6.1 Speech level
5.2.6.2 Delay 5.3 Test conditions for AMR-NB codec 5.4 Test conditions
for AMR-WB codec 6 Test bed and test plan for Phase 2 6.1 Test
arrangement 6.1.1 Description of the proposed testing system 6.1.2
Network simulator 6.1.3 Calibration and test conditions monitoring 6.2
Test Conditions 7 Analysis of test results for DCH channels for Phase 1
and 2 7.1 Conversation Tests 7.2 Experimental Design and Statistical
Procedures 7.3 Narrowband Test - Symmetric conditions (*Set 1*) 7.4
Narrowband Test -- Asymmetric Conditions (*Set 2*) 7.5 Wideband Test --
Symmetric Conditions (*Set 3*) 7.6 Wideband Test -- Asymmetric
Conditions (*Set 4*) 7.7 Phase 2 - ITU-T Codec Tests (*Set 5*) 7.8
Summary of Test Result Analysis 8 Performance characterisation of VoIMS
over HSDPA/EUL channels 8.A Listening only tests 8.A.1 Test methodology
for listening only tests 8.A.2 Test arrangement 8.A.3 Jitter buffer
implementations 8.A.3.1 Fixed JBM 8.A.3.2 Adaptive JBM 8.A.4 Network
conditions 8.A.5 Listening experiments 8.A.6 Test Results 8.A.7 Delay
analysis 8.A.8 Listening only test conclusions 8.B Conversation Tests
8.B.1 Introduction 8.B.2 The Test Plan 8.B.3 Cross-check of Test Lab
Results 8.B.4 Test Results 8.B.4.1 Mean Scores by Experiment and by Test
Lab 8.B.4.2 Subject Consistency Measures for Test Labs 8.B.4.3
Multivariate Analysis of Variance (MANOVA) 8.B.4.3.1 MANOVA Results and
Statistics 8.B.4.3.2 Composite Scores -- Conversational Quality
8.B.4.3.3 Conversational Quality by Experimental Factors 8.B.5
Conversation tests conclusions 9 Conclusions 9.1 Tests over DCH radio
channels 9.2 Tests over HSDPA/EUL radio channels; listening only tests
9.3 Tests over HSDPA/EUL radio channels; conversation tests 9.4 General
consideration Annex A: Conversation test composite dependent variable
scores by condition and Lab Annex B: Instructions to subjects Annex C:
Example Scenarios for the conversation test Annex D: Test Plan for the
AMR Narrow-Band Packet Switched Conversation Test Annex E: Test Plan for
the AMR Wide-Band Packet Switched Conversation Test Annex F: Test plan
for Packet Switched Conversation Tests for Comparison of Quality Offered
by Different Speech Coders Annex G: Test Plan for Global Analysis of PSS
Conversation Tests Annex H: Test Plan for Performance characterisation
of VoIMS over HSDPA/EUL channels; listening only tests H.1 Introduction
H.2 Listening only test conditions H.3 End-to-end delay analysis H.4
Listening only experiments H.5 Test material processing Annex I:
Illustrative scheme for jitter buffer management I.1 Pseudo code I.2
Verification against the minimum performance requirements I.2.1 Delay
performance I.2.2 JBM induced error concealment operations Annex J: Test
processing for listening only tests J.1 Speech preparation J.2
Pre-processing J.3 Processing of speech/background noise signal J.4 Up
and Down-Sampling, Rounding and Scaling J.5 Processing for Direct
Conditions J.6 Processing for MNRU conditions J.7 Processing of voice
over IMS over HSPA J.8 Post-processing J.9 Test conditions Annex K:
Radio network simulation for HSDPA/EUL performance characterization
Annex L: Test Plan for the AMR NB/WB Conversation Test in UMTS over
HSDPA/EUL L.1 Introduction L.2 General Information L.2.1 Permanent
Documents L.2.2 Key Acronyms L.2.3 Contacts L.2.4 Participants L.3 Test
Methodology L.3.1 Introduction L.3.2 Test Design L.3.2.1 Description of
the Test Bed L.3.2.2 Transmission System L.3.2.3 Radio Access Bearers
L.3.2.4 Test environment L.3.3 Test Conditions L.4 Test Procedure L.4.1
Time Projection L.4.2 Instructions to the Subjects L.4.3 Test Materials
L.4.4 Deliverables L.4.5 Data Analysis L.5 Working Document for the
Performance Characterization of VoIMS over HSDPA/EDCH L.5.1 Introduction
L.5.2 System Overview L.5.3 Radio Access Bearers L.5.4 Delay L.5.5 RN
Simulator L.5.6 Core Network L.5.7 VoIP Client L.5.8 Interfaces L.5.8.1
Interface 1 L.5.8.2 Interface 2 L.5.8.3 Interface 3 L.5.9 Simulated HSPA
Air-Interface L.5.9.1 General Description L.5.9.2 Error-Delay Profiles
L.5.A.1 Network Parameters L.5.A.2 Traffic Assumptions (example: AMR
7.95) L.5.A.3 Other Assumptions L.5.A.4 Simulation Methodology
Bibliography Annex M: Change history

Foreword
========

This Technical Report has been produced by the 3rd Generation
Partnership Project (3GPP).

The contents of the present document are subject to continuing work
within the TSG and may change following formal TSG approval. Should the
TSG modify the contents of the present document, it will be re-released
by the TSG with an identifying change of release date and an increase in
version number as follows:

Version x.y.z

where:

x the first digit:

1 presented to TSG for information;

2 presented to TSG for approval;

3 or greater indicates TSG approved document under change control.

y the second digit is incremented for all changes of substance, i.e.
technical enhancements, corrections, updates, etc.

z the third digit is incremented when editorial only changes have been
incorporated in the document.

1 Scope
=======

The present document provides information on the performances of default
speech codecs in packet switched conversational multimedia applications.
The codecs under test are AMR-NB (Adaptive Multi-Rate Narrowband) and
AMR-WB (Adaptive Multi-Rate Wideband). In addition, several ITU-T codecs
(G.723.1, G.729, G.722 and G.711) are included in the testing.
Experimental test results from the speech quality testing are reported
to illustrate the behaviour of these codecs.

The results give information of the performance of PS conversational
multimedia applications under various operating and transmission
conditions (e.g., considering radio transmission errors, IP packet
losses, end-to-end delays, and several types of background noise). The
performance results can be used e.g. as guidance for network planning
and to appropriately adjust the radio network parameters.

2 References
============

The following documents contain provisions which, through reference in
this text, constitute provisions of the present document.

\- References are either specific (identified by date of publication,
edition number, version number, etc.) or non‑specific.

\- For a specific reference, subsequent revisions do not apply.

\- For a non-specific reference, the latest version applies. In the case
of a reference to a 3GPP document (including a GSM document), a
non-specific reference implicitly refers to the latest version of that
document *in the same Release as the present document*

\[1\] ITU-T Recommendation P.800: \"Methods for Subjective Determination
of Transmission Quality\".

\[2\] ITU-T Recommendation P.831: \"Subjective performance evaluation of
network echo cancellers\".

\[3\] ITU-T Recommendation G.711: \"Pulse code modulation (PCM) of voice
frequencies\".

\[4\] ITU-T Recommendation G.729: \"Coding of speech at 8 kbit/s using
conjugate-structure algebraic-code-excited linear-prediction
(CS-ACELP)\".

\[5\] ITU-T Recommendation G.723.1: \"Dual rate speech coder for
multimedia communications transmitting at 5.3 and 6.3 kbit/s\".

\[6\] ITU-T Recommendation G.722: \"7 kHz audio-coding within 64
kbit/s\".

\[7\] IETF RFC 1889: \"RTP: A Transport Protocol for Real-Time
Applications\".

\[8\] IETF RFC 3267: \"Real-Time Transport Protocol (RTP) Payload Format
and File Storage Format for the Adaptive Multi-Rate (AMR) Adaptive
Multi-Rate Wideband (AMR-WB) Audio Codecs\".

\[9\] 3GPP TS 34.121: \"Terminal Conformance Specification, Radio
Transmission and Reception (FDD)\" (downlink).

\[10\] 3GPP TS 25.141: \" Base Station (BS) conformance testing (FDD)\"
(uplink).

\[11\] 3GPP TR 25.853 \"Delay budget within the access stratum\".

\[12\] 3GPP TS 26.235: \"Packet switched conversational multimedia
applications; Default codecs\".

\[13\] 3GPP TS 26.071: \"AMR speech Codec; General description\".

\[14\] 3GPP TS 26.171: \"AMR speech codec, wideband; General
description\".

\[15\] 3GPP TS 25.322: \"Radio Link Control (RLC) protocol
specification\".

\[16\] IETF RFC 3095: \"RObust Header Compression (ROHC): Framework and
four profiles: RTP, UDP, ESP, and uncompressed\".

\[17\] 3GPP TS 34.108: \"Common test environments for User Equipment
(UE) conformance testing\".

\[18\] ETSI TR 101 112: \"Universal Mobile Telecommunications System
(UMTS); Selection procedures for the choice of radio transmission
technologies of the UMTS\" (UMTS 30.03 v3.1.0).

\[19\] 3GPP TS 26.114 : \"IP Multimedia Subsystem (IMS); Multimedia
Telephony; Media handling and interaction\"

\[20\] ITU-T Recommendation P.805 (P.CONV): \"Subjective evaluation of
conversational quality\"

3 Abbreviations
===============

3.1 Abbreviations
-----------------

For the purposes of the present document, the following abbreviations
apply:

> AMR-NB (or AMR) Adaptive Multi-Rate Narrowband Speech Codec
>
> AMR-WB Adaptive Multi-Rate Wideband Speech Codec
>
> ANOVA Analysis of Variance
>
> ASY ASYmmetric conditions
>
> BLER Block Error Rate
>
> CDF Cumulative Distribution Function
>
> CMR Codec Mode Request
>
> COND Test CONDitions
>
> CN Core Network
>
> CQ Conversational Quality
>
> CRC Cyclic Redundancy Check
>
> DCH Dedicated Channel
>
> DL Downlink
>
> DMOS Degradation Mean Opinion Score
>
> DPCH Dedicated Physical Channel
>
> DTCH Dedicated Traffic Channel
>
> Eb/No Ratio of energy per modulating bit to the noise spectral density
>
> EID Error Insertion Device
>
> FER Frame Erasure Rate, Frame Error Rate
>
> GAL Global Analysis Laboratory
>
> GQ Global Quality (of the conversation)
>
> HM High Mobility
>
> HT High Traffic
>
> HSDPA/EUL High Speed Downlink Packet Access/Enhanced UpLink
>
> IA InterAction (with your partner)
>
> IP Internet Protocol
>
> ITU-T International Telecommunication Union - Telecommunications
> Standardization Sector
>
> JBM Jitter Buffer Management
>
> LAB Listening LABoratory
>
> LM Low Mobility
>
> LT LowTraffic
>
> MAC Medium access control
>
> MANOVA Multivariate Analysis of Variance
>
> Log-MAP Logarithmic Maximum A Posteriori
>
> MOS Mean Opinion Score
>
> NB Narrowband
>
> PC PerCeption of impairments (also: Personal Computer)
>
> PDCP Packet Data Convergence Protocol
>
> PDU Protocol Data Unit
>
> Pa Sound Pressure Level (in Pascal)
>
> PL Packet Loss
>
> plc Packet Loss Concealment
>
> RC Radio Conditions
>
> PS Packet Switched
>
> RB Radio Bearer
>
> RAB Radio Access Bearer
>
> RCV Receive
>
> RLC Radio Link Control
>
> ROHC Robust Header Compression
>
> RRM Radio Resource Management
>
> RTCP Real-Time Control Protocol
>
> RTP Real-time Transport Protocol
>
> SYM SYMmetric conditions
>
> TB size Transport Block size
>
> TF Transport Format
>
> ToC Table of Content
>
> TrCH Transmission Channel
>
> TTI Transmission Time Interval
>
> UDP User Datagram Protocol
>
> UE User Equipment
>
> UL Uplink
>
> UM Unacknowledged Mode
>
> UMD Unacknowledged Mode Data
>
> US difficulty UnderStanding (your partner)
>
> VOIP Voice over IP
>
> VQ Voice Quality (of your partner)
>
> WB Wideband
>
> XMIT Transmit

4 General Overview
==================

4.1 Introduction
----------------

The performance of default speech codecs (AMR-NB and AMR-WB) for packet
switched conversational multimedia \[12, 19\] was characterised over DCH
channels and over HSDPA/EUL radio channels.

The testing over DCH channels was carried out from October 2003 until
February 2004. Further subjective testing was carried out from June
until October 2007 in order to characterize the performance over
HSDPA/EUL radio channels. The main purpose of the latter testing was to
evaluate and verify adequate performance of the AMR-NB and AMR-WB speech
codecs used as defined in IMS Multimedia Telephony TS 26.114 \[19\] with
a specific focus on jitter buffer management.

4.2 Tests over DCH radio channels
---------------------------------

The tests over DCH channels were separated into two phases: Phase 1
considered the default speech codecs AMR-NB \[13\] and AMR-WB \[14\] in
various operating conditions. Phase 2 considered also several other
codecs including ITU-T codecs G.723.1 \[5\], G.729 \[4\], G.722 \[6\]
and G.711 \[3\].

In Phase 1, France Telecom R&D acted as host laboratory. The subjective
testing laboratories were ARCON for the North American English language,
France Telecom R&D for the French language and NTT-AT for the Japanese
language. Phase 1 tests consisted of 24 test conditions both for the AMR
codec (modes 6.7 and 12.2 kbit/s) and the AMR-WB codec (modes 12.65 and
15.85 kbit/s) with error conditions covering both IP packet loss of 0%
and 3% and radio conditions with 10--2, 10--3 and 5 10-4 BLER (Block
Error Rate). End-to-end delays of 300 and 500 ms were covered. Robust
Header Compression (ROHC), an optional UMTS functionality, was included
for some test cases for AMR-WB. Three types of background noise were
used: car, street and cafeteria.

In Phase 2, France Telecom R&D acted as host and listening laboratory.
Two languages were used (French and Arabic). The following codecs were
tested: AMR-NB (modes 6.7 and 12.2 kbit/s), AMR-WB (modes 12.65 and
15.85 kbit/s), ITU-T G.723.1 (mode 6.4 kbit/s), ITU-T G.729 (mode 8
kbit/s), ITU-T G.722 (mode 64 kbit/s) and ITU-T G.711 (64 kbit/s).
Transmission error conditions covered IP packet loss of 0% and 3%.

Siemens provided the real time air interface simulator for the Phase 1.
France Telecom provided the IP core network simulator and terminal
simulator used in both experiments Phase 1 and Phase 2. IPv6 was
employed in the testing. (IPv6 is fully simulated over the radio
interface. The CN simulator employs IPv4 but since the only impact is a
marginal difference in the end-to-end delay - of the order of \~16 ìs -
the use of a particular IP-version in CN part has no impact on the
performance results.)

These tests were the first ever conversational tests conducted in any
standardization body. Performance evaluation consisted of assessment of
5 aspects: 1) voice quality, 2) difficulty of understanding words, 3)
quality of interaction, 4) degree of impairments, and 5) global
communication quality. A 5-category rating scale was used for each
aspect.

Dynastat performed the global analysis for Phases 1 and 2. The results
are contained in Clause 7.

4.3 Tests over HSDPA/EUL radio channels
---------------------------------------

These listening-only tests characterized the performance of AMR-NB and
AMR-WB speech codecs over HSDPA/EUL channels when conducting buffer
adaptation to the network delay variations using a simple jitter buffer
management (JBM) algorithm. The tests focused on the effect of channel
errors and channel jitter to speech quality instead of the impact of
overall end-to-end delay in speech conversation. The end-to-end delay
impact was considered separately by conducting a delay analysis on the
whole processed test material.

The subjective listening-only tests were conducted in Finnish and
Swedish languages at Nokia and Ericsson, respectively. The tests
consisted of eight different channel conditions in clean speech and in
background noise conditions. AMR-NB was tested in 12.2 and 5.9 kbit/s
modes, and AMR-WB at 12.65 kbit/s. The outstanding issue was to evaluate
the performance of adaptive JBM operation in HSDPA/EUL channel
conditions. The applied adaptive jitter buffer was a simple
implementation conducting buffer adaptation mainly during discontinuous
transmission, i.e. speech pauses, and not using any time scaling
operation. A non-implementable fixed jitter buffer with the full a
priori knowledge on the channel characteristics was used as a reference.
Although the average end-to-end delays of both adaptive and fixed jitter
buffers were the same, the number and locations of jitter buffer induced
frame losses were different depending on the channel conditions.

The results are contained in Clause 8A.

A program of Conversation Tests was organized to evaluate the
performance of AMR-NB and AMR-WB for UMTS over HSDPA/EUL. Three test
labs were contracted to conduct the conversation tests and deliver raw
voting data to Dynastat, the Global Analysis Lab (GAL), for processing
and statistical analysis.

Three conversation tests were conducted in each of three test labs. The
test labs were FTRD, testing in the French language, BIT, testing in the
Chinese language, and Dynastat, testing in North American English. Each
of the three conversation tests involved a different speech codec:

\- Exp.1 - AMR operating at 5.9k bps

\- Exp.2 - AMR operating at 12.2k bps

\- Exp.3 - AMR-WB operating at 12.65k bps

The experiments were conducted according to specifications contained in
the ITU-T Recommendation for Conversation Testing, P.805 \[20\].
Alcatel-Lucent provided the network impairment simulation test-bed. The
raw voting data for each test lab and each Experiment was delivered to
the GAL. The GAL conducted statistical analyses on the raw voting data
and the results of those analyses are contained in Clause 8B.

5 Test bed and test plan for Phase 1
====================================

This section describes the test plan for the Phase 1 of the conversation
test of the AMR-NB (AMR) and AMR-WB in PS networks. All the laboratories
participating to this conversation test phase used the same test plan,
just the language of the conversation changed. Even if the test rooms or
the test equipments are not exactly the same in all the laboratories,
the calibration procedures and the tests equipment characteristics and
performance guaranteed the similarity of the test conditions.

Annex B contains the instructions for the subjects participating to the
conversation tests.

5.1 Test methodology
--------------------

The protocol described below evaluates the effect of degradation such as
delay and dropped packets on the quality of the communications. It
corresponds to the conversation-opinion tests recommended by the ITU-T
P.800 \[1\]. First of all, conversation--opinion tests allow subjects
passing the test to be in a more realistic situation, close to the
actual service conditions experienced by telephone customers. In
addition, conversation-opinion tests are suited to assess the effects of
impairments that can cause difficulty while conversing (such as delay).

Subjects participate to the test by couple; they are seated in separate
sound-proof rooms and are asked to hold a conversation through the
transmission chain performed by means of UMTS simulators, and
communications are impaired by means of an IP impairments simulator part
of the CN simulator and by the air interface simulator, as Figure 1
describes it.

The network configurations (including the terminal equipments) are
symmetrical (in the two transmission paths). The only dissymmetry will
be due to presence of background noise in one of the test rooms.

5.2 Test arrangement
--------------------

### 5.2.1 Description of the testing system

Figure 1 describes the simulation system.

![](media/image3.wmf){width="6.309722222222222in"
height="3.4583333333333335in"}

Figure 1: Packet switch audio communication simulator

The PS audio communication has been simulated using 5 PCs as shown in
Figure 2.

![](media/image4.png){width="6.354861111111111in"
height="2.9159722222222224in"}

Figure 2: Simulation Platform

PC 1 and PC 5 are running under Windows OS with the VOIP Terminal
Simulator Software of France Telecom R&D. PC 2 and PC 4 run under Linux
OS with the Air Interface Simulator coming from Siemens AG. And PC 3
runs under WinNT OS with Network Simulator Software (NetDisturb).

The platform simulates a PS interactive communication between two users
using PC 1 and PC 5 as their relative VOIP terminals. PC 1 sends AMR (or
AMR-WB) encoded packets that are encapsulated using IP/UDP/RTP headers
to PC 5. PC 1 receives IP/UDP/RTP audio packets from PC 5.

In fact, the packets created in PC 1 are sent to PC 2. PC 2 simulates
the air interface uplink (UL) transmission and then forwards the
transmitted packets to PC 4.

In the same way, PC 4 simulates the air interface downlink (DL)
transmission and then forwards the packets to PC 5. PC 5 decodes and
plays the speech back to the listener.

### 5.2.2 Network simulator

The core network simulator, as implemented, works under IPv4. However,
as the core network simulator acts only on packets (loss, delay,...) the
use of IPv4 or IPv6 is equivalent for this test conversation context.
Considering the networks perturbations introduced by the simulator and
the context of the interactive communications, the simulation using IPv4
perturbation network simulator is adapted to manage and simulate the
behaviours of an IPv6 core network.

Figure 3 shows the possible network simulator parameters that can be
modified.

![](media/image5.png){width="6.574305555555555in"
height="3.9138888888888888in"}

Figure 3: IP simulator interface

On both links, one can choose delay and loss laws. Both links can be
treated separately or in the same way. For example, delay can be set to
a fixed value but can also be set to another law such as exponential
law.

Only loss law and delay law were given values, for delay law the values
are 0 or 200 ms and for loss law the possible values: 0% or 3% under
bursty law. Both links were treated in the same way.

### 5.2.3 UMTS simulator choices

The transmission of IP/UDP/RTP/AMR (or AMR-WB) packets over the UMTS air
interface is simulated using the RAB described in Section 5.2.3.1. The
required functions of the RLC layer are implemented according to \[15\]
and work in real-time. The underlying Physical Layer is simulated
offline. Error patterns of block errors (i.e. discarded RLC PDUs) are
inserted in the real-time simulation as described in Section 5.2.3.2.
For more details on the parameter settings of the Physical Layer
simulations see Section 5.2.3.3.

#### 5.2.3.1 RAB and protocols

For the narrowband conversational tests, the AMR is encoded with a
maximum of 12.2 kbit/s. The bitstream is encapsulated using IP/UDP/RTP
protocols. The air interface simulator receives IPv4 packets from the CN
simulator. The RTP packets are extracted and before transmission over
the air interface, IPv6/UDP headers are inserted. Finally real IPv6
packets are transmitted over the air interface simulator.

The payload format is the following:

− RTP payload format for AMR-NB (cf. \[8\]) is used;

− Bandwidth efficient mode is used;

− One speech frame is encapsulated in each RTP packet;

− Interleaving is not used;

The payload header consists of the 4 bits of the CMR (Codec Mode
Request). Then 6 bits are added for the ToC (Table of Content). For
IPv4, this corresponds to a maximum of 72 bytes per frame that is to say
28.8 kbit/s. This goes up to 92 bytes (36.8 kbit/s) when using IPv6
protocol on the air interface.

RTCP packets are sent. However, in the test conditions defined in the
conversation test plans, RTCP is not mandatory, as it is not in a
multicast environment (cf. \[7\]). RTCP reports were sent but not used.

ROHC is an optional functionality in UMTS. In order to reduce the size
of the tests and the number of conditions, the ROHC algorithm is not
used for the AMR-NB conversation test. This functionality is only tested
in the wideband condition.

For the WB conversational tests, the AMR-WB encodes speech at a maximum
of 15.85 kbit/s. The bitstream is also encapsulated and transmitted in
the same way as for the NB case. For IPv4 a maximum of 81 bytes (41
bytes for the AMR and its payload header plus the 40 bytes of the
IP/UDP/RTP headers) per frame are transmitted that is to say 32.4
kbit/s, this goes up to 101 bytes (40.4 kbit/s) when using IPv6 protocol
on the air interface.

ROHC algorithm is supported in the AMR-WB conversation test, for the
12.65 kbit/s mode and the 15.85 modes. Header compression is done on the
IP/UDP/RTP headers (profile 1). ROHC starts in the unidirectional mode
and switches to bi-directional mode as soon as a packet has reached the
decompressor and replied with a feedback packet indicating that a mode
transition is desired.

The Conversational / Speech / UL:46 DL:46 kbps / PS RAB coming from
\[17\] was used. It is not an optimal RAB for PS conversational test but
it was the only one available at the time the test bed and the air
interface simulator were designed. The RAB description is given in Table
1.

Table 1: RAB description

  -------------- ------------------------------------------------------------- --------------- -------
  Higher layer   RAB/Signalling RB                                             RAB             
  PDCP           PDCP header size, bit                                         8               
  RLC            Logical channel type                                          DTCH            
                 RLC mode                                                      UM              
                 Payload sizes, bit                                            920, 304, 96    
                 Max data rate, bps                                            46000           
                 UMD PDU header, bit                                           8               
  MAC            MAC header, bit                                               0               
                 MAC multiplexing                                              N/A             
  Layer 1        TrCH type                                                     DCH             
                 TB sizes, bit                                                 928, 312, 104   
                 TFS                                                           TF0, bits       0x928
                                                                               TF1, bits       1x104
                                                                               TF2, bits       1x312
                                                                               TF3, bits       1x928
                 TTI, ms                                                       20              
                 Coding type                                                   TC              
                 CRC, bit                                                      16              
                 Max number of bits/TTI after channel coding                   2844            
                 Uplink: Max number of bits/radio frame before rate matching   1422            
                 RM attribute                                                  180-220         
  -------------- ------------------------------------------------------------- --------------- -------

#### 5.2.3.2 Description of the RLC implementation

The UMTS air interface simulator (implemented in PC 2 and 4) receives
IP/UDP/RTP/AMR (or AMR-WB) packets on a specified port of the network
card (see Figure 4). The IP/UDP/RTP/AMR (or AMR-WB) packets are given to
the transmission buffer of the RLC layer, which works in Unacknowledged
Mode (UM). The RLC segments or concatenates the IP bitstream in RLC
PDUs, adding appropriate RLC headers (sequence number and length
indicators). It is assumed that always Transport Format TF 3 is chosen
on the physical layer, providing an RLC PDU length including header of
928 bits. In the regular case, one IP packet is placed into an RLC PDU
that is filled up with padding bits. Due to delayed packets from the
network simulator it may also occur that there are none or no more than
one IP packet in the RLC transmission buffer to transmit in the current
TTI.

Each TTI of 20ms, an RLC PDU is formed. It is then given to the error
insertion block that decides if the RLC PDU is transmitted successfully
over the air interface or if it is discarded due to a block error after
channel decoding. The physical layer is not simulated in real time, but
error pattern files are provided. The error patterns of the air
interface transmission are simulated offline according to the settings
given in Section 5.2.3.1. They consist of binary decisions for each
transmitted RLC PDU, resulting in a certain BLER.

After the error pattern insertion, the RLC of the air interface receiver
site receives RLC PDUs in the reception buffer. The sequence numbers of
the RLC headers are checked to detect when RLC PDUs have been discarded
due to block errors. A discarded RLC PDU can result in one or more lost
IP packets, resulting in a certain packet loss rate of the IP packets
and thereby in a certain FER of the AMR (or AMR-WB) frames. The
IP/UDP/RTP/AMR (or AMR-WB) packets are reassembled and transmitted to
the next PC. This PC is either the network simulator (PC 3) in case of
uplink transmission, or is one of the terminals (PC 1 or PC 5) in case
of downlink transmission.

![](media/image6.wmf){width="6.615277777777778in"
height="4.749305555555556in"}

Figure 4: UMTS air interface simulation

#### 5.2.3.3 Physical Layer Implementation

The parameters of the physical layer simulation were set according to
the parameters for a DCH in multipath fading conditions given in \[9\]
for the downlink and \[10\] for the uplink. The TB size is 928 bits and
the Turbo decoder uses the Log-MAP algorithm with 4 iterations. The rake
receiver has 6 fingers at 60 possible positions.

The different channel conditions given in Tables 2, 3 and 4 were
extracted from \[18\] (Selection procedures for the choice of radio
transmission technologies of the UMTS).

Table 2: Indoor Office Test Environment Tapped-Delay-Line Parameters

  ----- ------------------- ----------------- ----------
  Tap   Channel A           Doppler           
        Rel. Delay (nsec)   Avg. Power (dB)   Spectrum
  1     0                   0                 FLAT
  2     50                  -3.0              FLAT
  3     110                 -10.0             FLAT
  4     170                 -18.0             FLAT
  5     290                 -26.0             FLAT
  6     310                 -32.0             FLAT
  ----- ------------------- ----------------- ----------

Table 3: Vehicular Test Environment, High Antenna, Tapped-Delay-Line
Parameters

  ----- ------------------- ----------------- ----------
  Tap   Channel A           Doppler           
        Rel. Delay (nsec)   Avg. Power (dB)   Spectrum
  1     0                   0.0               CLASSIC
  2     310                 -1.0              CLASSIC
  3     710                 -9.0              CLASSIC
  4     1090                -10.0             CLASSIC
  5     1730                -15.0             CLASSIC
  6     2510                -20.0             CLASSIC
  ----- ------------------- ----------------- ----------

Table 4: Outdoor to Indoor and Pedestrian Test Environment
Tapped-Delay-Line Parameters

  ----- ------------------- ----------------- ----------
  Tap   Channel A           Doppler           
        Rel. Delay (nsec)   Avg. Power (dB)   Spectrum
  1     0                   0                 CLASSIC
  2     110                 -9.7              CLASSIC
  3     190                 -19.2             CLASSIC
  4     410                 -22.8             CLASSIC
  5     \-                  \-                CLASSIC
  6     \-                  \-                CLASSIC
  ----- ------------------- ----------------- ----------

Table 5 (DL) and Table 6 (UL) show approximate results of the air
interface simulation for $\frac{\text{DPCH}_{}}{I_{\text{or}}}$ and
Eb/N0 corresponding to the considered BLERs.

Table 5: Downlink performance - approximate
$\frac{\text{DPCH}_{}}{I_{\text{or}}}$ for the different channels and
BLER

  ------------------------------------ ---------- ---------- ---------- ----------
                                       BLER                             
  Channel                              5\*10-2    1\*10-2    1\*10-3    5\*10-4
  Indoor, 3 km/h (= 9 dB)              -13.1 dB   -8.9 dB    -3.4 dB    -2.4 dB
  Outdoor to Indoor, 3 km/h (= 9 dB)   -13.2 dB   -9.7 dB    -5.9 dB    -5.2 dB
  Vehicular, 50 km/h (= -3 dB)         -9.35 dB   -8.2 dB    -6.9 dB    -6.55 dB
  Vehicular, 120 km/h (= -3 dB)        -9.7 dB    -8.95 dB   -7.95 dB   -7.55 dB
  ------------------------------------ ---------- ---------- ---------- ----------

Table 6: Uplink performance - approximate Eb/N0 for the different
channels and BLER

  --------------------------- --------- ---------- --------- ---------
  Channel                     BLER                           
                              5\*10-2   1\*10-2    1\*10-3   5\*10-4
  Indoor, 3 km/h              3.9 dB    6.4 dB     9.2 dB    9.8 dB
  Outdoor to Indoor, 3 km/h   3.7 dB    6.1 dB     8.6 dB    9.2 dB
  Vehicular, 50 km/h          -0.9 dB   -0.15 dB   0.55 dB   0.75 dB
  Vehicular, 120 km/h         0.2 dB    0.6 dB     1.1 dB    1.3 dB
  --------------------------- --------- ---------- --------- ---------

Outdoor to Indoor channel was used for uplink and downlink in the
simulations.

### 5.2.4 Headsets and Sound Card

To avoid echo problems headsets were used instead of handsets. The
monaural headsets are connected to the sound cards of the PCs supporting
the speech codec simulators.

The sound level in the earphones can be adjusted, if needed, by the
users. But, in practice, the original settings, defined during the
preliminary tests, and producing a comfortable listening level, are not
modified. The microphones are protected by a foam ball in order to
reduce the \"pop\" effect. It is also suggested to the user to avoid
placing the acoustic opening of the microphone in front of the mouth.

### 5.2.5 Test environment

Each of the two subjects participating to the conversations are
installed in a test room. They sit on an armchair, in front of a table.
The test rooms are acoustically insulated. All the test equipments are
installed in a third room, connected to the test rooms. When needed, the
background noise is generated in the appropriate test room through a set
of 4 loudspeakers. The background noise level is adjusted and controlled
by a sound level meter. The measurement microphone, connected to the
Sound level meter is located at the equivalent of the center of the
subject\'s head. The noise level is A weighted.

### 5.2.6 Calibration and test conditions monitoring

#### 5.2.6.1 Speech level

Before the beginning of a set of experiment, the end-to-end transmission
level is checked subjectively, to ensure that there is no problem. If it
is necessary to check the speech level following procedure is applied.
An artificial mouth placed in front of the microphone of the Headset A,
in the LRGP position (see ITU-T Rec. P.64), generates in the artificial
ear (according to ITU-T Rec. P57), coupled to the earphone of the
Headset B, the nominal level. If necessary, the level is adjusted with
the receiving volume control of the headset. Similar calibration is done
by inverting headsets A and B.

#### 5.2.6.2 Delay

The overall delay (from the input of sound card A to the output of sound
card B) is calculated as shown: On the air interface side, the simulator
only receives packets on its network card, processes them and transmits
every 20 ms these packets to the following PC. Only processing delay and
a possible delay due to a jitter can be added (a packet arrives just
after the sending window of the air interface).

The delay is calculated as shown below:

> − Encoder side: delay due to account framing, look-ahead, processing
> and packetization = 45ms
>
> − Uplink delay between UE and Iu: 84.4 ms (see \[11\])
>
> − Core network delay: a few ms
>
> − Routing through IP: depending on the number of routers.
>
> − Downlink delay between Iu and UE: 71.8 ms (see \[11\])
>
> − Decoder side, taking into account jitter buffer, de-packetization
> and processing: 40 ms

The total delay to be considered is at least: 241.2 ms.

5.3 Test conditions for AMR-NB codec
------------------------------------

Tables 7 - 9 summarise the test conditions used for AMR-NB testing.

For both AMR-NB and AMR-WB codecs two representative modes were chosen
for the testing. The lowest codec modes (such as AMR-NB 4.75) were not
included since these are intended to be used mainly temporarily to cope
with poor radio conditions. They were expected to provide insufficient
quality for conversational applications if used throughout the call (as
done in these characterisation tests).

Table 7: Test conditions for AMR-NB

  ------- ---------------------------- ---------------------------- ---------------------- ------------------------------ ----------------------------
  Cond.   Background noise in Room A   Background noise in Room B   Experimental factors                                  
                                                                    Radio cond. (BLER)     IP cond. (Packet loss ratio)   Mode + delay
  1       No                           No                           10 --2                 0%                             6.7 kbit/s (delay 300 ms)
  2       No                           No                           10 --2                 0%                             12.2 kbit/s (delay 500 ms)
  3       No                           No                           10 --2                 0%                             12.2 kbit/s (delay 300 ms)
  4       No                           No                           10 --2                 3%                             6.7 kbit/s (delay 300 ms)
  5       No                           No                           10 --2                 3%                             12.2kbit/s (delay 500 ms)
  6       No                           No                           10 --2                 3%                             12.2 kbit/s (delay 300 ms)
  7       No                           No                           10-3                   0%                             6.7 kbit/s (delay 300 ms)
  8       No                           No                           10-3                   0%                             12.2 kbit/s (delay 500 ms)
  9       No                           No                           10-3                   0%                             12.2 kbit/s (delay 300 ms)
  10      No                           No                           10-3                   3%                             6.7 kbit/s (delay 300 ms)
  11      No                           No                           10-3                   3%                             12.2 kbit/s (delay 500 ms)
  12      No                           No                           10-3                   3%                             12.2 kbit/s (delay 300 ms)
  13      No                           No                           5 10-4                 0%                             6.7kbit/s (delay 300 ms)
  14      No                           No                           5 10-4                 0%                             12.2kbit/s (delay 500 ms)
  15      No                           No                           5 10-4                 0%                             12.2 kbit/s (delay 300 ms)
  16      No                           No                           5 10-4                 3%                             6.7kbit/s (delay 300 ms)
  17      No                           No                           5 10-4                 3%                             12.2 kbit/s (delay 500 ms)
  18      No                           No                           5 10-4                 3%                             12.2 kbit/s (delay 300 ms)
  19      Car                          No                           5 10-4                 3%                             12.2 kbit/s (delay 300 ms)
  20      No                           Car                          5 10-4                 3%                             12,2 kbit/s (delay 300 ms)
  21      Cafeteria                    No                           5 10-4                 0%                             6.7 kbit/s (delay 300 ms)
  22      No                           Cafeteria                    5 10-4                 0%                             6.7 kbit/s (delay 300 ms)
  23      Street                       No                           5 10-4                 0%                             12.2kbit/s (delay 500 ms)
  24      No                           Street                       5 10-4                 0%                             12.2kbit/s (delay 500 ms)
  ------- ---------------------------- ---------------------------- ---------------------- ------------------------------ ----------------------------

Table 8: Noise types for AMR-NB

  ------------ ----------------
  Noise type   Level (dB Pa )
  Car          60
  Street       55
  Cafeteria    50
  ------------ ----------------

Table 9: Test details for AMR-NB

  ----------------------- ---- -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Listening Level         1    79 dBSPL
  Listeners               32   Naïve Listeners
  Groups                  16   2 subjects/group
  Rating Scales           5    
  Languages               3    North American English, French, Japanese
  Listening System        1    Monaural headset (flat response in the audio bandwidth of interest: 50Hz-7kHz). The other ear is open.
  Listening Environment        Room Noise: Hoth Spectrum at 30dBA (as defined by ITU-T Recommendation P.800: Annex A, section A.1.1.2.2.1 Room Noise, with table A.1 and Figure A.1), except when background noise is needed (see Table 8 of this TR).
  ----------------------- ---- -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

5.4 Test conditions for AMR-WB codec
------------------------------------

Tables 10 - 13 summarise the test conditions used for AMR-WB testing.

Table 10: Test conditions for AMR-WB

  ------- ------------------------- ----------------------------------- --------------------
  Cond.   Experimental factors                                          
          Radio conditions (BLER)   IP conditions (Packet loss ratio)   Mode
  1       10--2                     0%                                  12,65 kbit/s, ROHC
  2       10--2                     0%                                  12,65 kbit/s
  3       10--2                     0%                                  15,85 kbit/s, ROHC
  4       10--2                     3%                                  12,65 kbit/s, ROHC
  5       10--2                     3%                                  12,65 kbit/s
  6       10--2                     3%                                  15,85 kbit/s, ROHC
  7       10--3                     0%                                  12,65 kbit/s, ROHC
  8       10--3                     0%                                  12,65 kbit/s
  9       10--3                     0%                                  15,85 kbit/s, ROHC
  10      10--3                     3%                                  12,65 kbit/s, ROHC
  11      10--3                     3%                                  12,65 kbit/s
  12      10--3                     3%                                  15,85 kbit/s, ROHC
  13      5\. 10--4                 0%                                  12,65 kbit/s, ROHC
  14      5\. 10--4                 0%                                  12,65 kbit/s
  15      5\. 10--4                 0%                                  15,85 kbit/s, ROHC
  16      5\. 10--4                 3%                                  12,65 kbit/s, ROHC
  17      5\. 10--4                 3%                                  12,65 kbit/s
  18      5\. 10--4                 3%                                  15,85 kbit/s, ROHC
  ------- ------------------------- ----------------------------------- --------------------

Table 11: Test conditions with noise for AMR-WB

+----------+----------+----------+----------+----------+----------+
| *        | **Ad     | **Ad     | **Expe   |          |          |
| *Cond.** | ditional | ditional | rimental |          |          |
|          | Ba       | Ba       | f        |          |          |
|          | ckground | ckground | actors** |          |          |
|          | noise**  | noise**  |          |          |          |
|          |          |          |          |          |          |
|          | **Room   | **Room   |          |          |          |
|          | A**      | B**      |          |          |          |
+----------+----------+----------+----------+----------+----------+
|          |          |          | Radio    | IP       | Mode     |
|          |          |          | co       | co       |          |
|          |          |          | nditions | nditions |          |
|          |          |          | (BLER)   | (Packet  |          |
|          |          |          |          | loss     |          |
|          |          |          |          | ratio)   |          |
+----------+----------+----------+----------+----------+----------+
| 19       | Car      | No       | 5 10-4   | 3%       | 12,65    |
|          |          |          |          |          | kbit/s,  |
|          |          |          |          |          | ROHC     |
+----------+----------+----------+----------+----------+----------+
| 20       | No       | Car      | 5 10-4   | 3%       | 12,65    |
|          |          |          |          |          | kbit/s,  |
|          |          |          |          |          | ROHC     |
+----------+----------+----------+----------+----------+----------+
| 21       | C        | No       | 5 10-4   | 0%       | 12,65    |
|          | afeteria |          |          |          | kbit/s   |
+----------+----------+----------+----------+----------+----------+
| 22       | No       | C        | 5 10-4   | 0%       | 12,65    |
|          |          | afeteria |          |          | kbit/s   |
+----------+----------+----------+----------+----------+----------+
| 23       | Street   | No       | 5 10-4   | 0%       | 15,85    |
|          |          |          |          |          | kbit/s,  |
|          |          |          |          |          | ROHC     |
+----------+----------+----------+----------+----------+----------+
| 24       | No       | Street   | 5 10-4   | 0%       | 15,85    |
|          |          |          |          |          | kbit/s,  |
|          |          |          |          |          | ROHC     |
+----------+----------+----------+----------+----------+----------+

Table 12: Noise Types for AMR-WB

  ------------ ---------------
  Noise type   Level (dB Pa)
  Car          60
  Street       55
  Cafeteria    50
  ------------ ---------------

Table 13: Test details for AMR-WB

  ----------------------- ---- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Listening Level         1    79 dBSPL
  Listeners               32   Naïve Listeners
  Groups                  16   2 subjects/group
  Rating Scales           5    
  Languages               3    North American English, French, Japanese
  Listening System        1    Monaural headset (flat response in the audio bandwidth of interest: 50Hz-7kHz). The other ear is open.
  Listening Environment        Room Noise: Hoth Spectrum at 30dBA (as defined by ITU-T Recommendation P.800: Annex A, section A.1.1.2.2.1 Room Noise, with table A.1 and Figure A.1),except when background noise is needed (see Table 12 of this TR)
  ----------------------- ---- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

6 Test bed and test plan for Phase 2
====================================

The Phase 2 of the listening test was conducted by one listening test
laboratory (FT R&D). The different speech coders used in this test are:

\- Adaptive Multi-Rate Narrow-Band (AMR-NB), in modes 6.7 kbit/s and
12.2 kbit/s,

\- Adaptive Multi-Rate Wide-Band (AMR-WB), in modes 12.65 kbit/s and
15.85 kbit/s,

\- ITU-T G.723.1, in mode 6.4 kbit/s,

\- ITU-T G.729, in mode 8 kbit/s,

\- ITU-T G.722 (wideband codec), in mode 64 kbit/s, with packet loss
concealment and,

\- ITU-T G.711, with packet loss concealment.

As there is no standardized packet loss concealment for G.711 and G.722,
proprietary packet loss concealment algorithms were used for them. The
simulated network was tested under two values of IP packet loss (0% and
3%). The testing was done in one test laboratory only, but in two
different languages (Arabic and French).

The IP packet contains 20 ms speech frames except for G.723.1 for which
IP packet contains 30 ms speech. For G.729 the 20 ms packet consists of
two 10 ms frames.

The test methodology was the same as the one applied in Phase 1.

Annex B contains the instructions for the subjects participating to the
conversation tests.

6.1 Test arrangement
--------------------

### 6.1.1 Description of the proposed testing system

Figure 5 describes the system that was simulated.

![](media/image11.png){width="6.363888888888889in"
height="3.5097222222222224in"}

Figure 5: Packet Switched audio communication simulator

This was simulated using 3 PCs as shown in Figure 6.

![](media/image12.png){width="6.354861111111111in"
height="2.9069444444444446in"}

Figure 6: Simulation Platform

PC 1 and PC 5 run under Windows OS with VOIP Terminal Simulator Software
of France Telecom R&D. PC 3 run under WinNT OS with Network Simulator
Software (NetDisturb).

The platform simulates a packet switched interactive communication
between two users using PC 1 and PC 5 as their relative VOIP terminals.
PC 1 sends encoded packets that are encapsulated using IP/UDP/RTP
headers to PC 5. PC 1 receives these IP/UDP/RTP audio packets from PC 5.

### 6.1.2 Network simulator

The core network simulator is the same as the one presented in Section
5. The different parameters that can be modified are presented in Figure
3 (Section 5.2.2).

In this test, only \"loss law\" has two values, all the others settings
are fixed. On both links, one can choose delay and loss laws. Both links
can be treated separately or in the same way. For example, delay can be
set to a fixed value but it can also be set to another law such as
exponential law. Only loss law was given values: 0% or 3% under bursty
law. Both links were treated in the same way.

Headsets were here also used to reduce echo problems. The monaural
headsets are connected to the sound cards of the PCs supporting the
different codecs.

The sound level in the earphones can be adjusted, if needed, by the
users. But, in practice, the original settings, defined during the
preliminary tests, and producing a comfortable listening level, are not
modified. The microphones are protected by a foam ball in order to
reduce the \"pop\" effect. It is also suggested to the user to avoid
placing the acoustic opening of the microphone in front of the mouth.

The same test environment as in test Phase 1 is used. Each of the two
subjects participating to the conversations are installed in a test
room. They sit on an armchair, in front of a table. The test rooms are
acoustically insulated. All the test equipments are installed in a third
room, connected to the test rooms. The background noise level is checked
by a sound level meter. The measurement microphone, connected to the
Sound level meter is located at the equivalent of the center of the
subject\'s head. The noise level is A weighted.

### 6.1.3 Calibration and test conditions monitoring

The speech level checking is done in the same way as for Phase 1 (see
Section 5.2.6.1).

The overall delay (from the input of sound card A to the output of sound
card B) is adjusted for each test condition taking into account the
delay of the related codec in order to have a fixed delay around 250ms.
This value of 250ms is close to the hypothetical delay computed for
AMR-NB and AMR-WB through the UMTS network.

6.2 Test Conditions
-------------------

The test conditions and details are described in Tables 14 and 15.

Table 14: Test conditions

  ------- ----------------------------------- -----------------------
  Cond.   Experimental factors                
          IP conditions (Packet loss ratio)   Mode
                                              
  1       0%                                  AMR-NB 6,7kbit/s
  2       0%                                  AMR-NB 12,2 kbit/s
  3       0%                                  AMR-WB 12,65 kbit/s
  4       0%                                  AMR-WB 15,85 kbit/s
  5       0%                                  G. 723.1 6,4 kbit/s
  6       0%                                  G.729 8 kbit/s
  7       0%                                  G.722 64 kbit/s + plc
  8       0%                                  G.711 + plc
  9       3%                                  AMR-NB 6,7kbit/s
  10      3%                                  AMR-NB 12,2 kbit/s
  11      3%                                  AMR-WB 12,65 kbit/s
  12      3%                                  AMR-WB 15,85 kbit/s
  13      3%                                  G. 723.1 6,4 kbit/s
  14      3%                                  G.729 8 kbit/s
  15      3%                                  G.722 64 kbit/s + plc
  16      3%                                  G.711 + plc
  ------- ----------------------------------- -----------------------

Table 15: Test details

  ----------------------- ---- -------------------------------------------------------------------------------------------------------------------------------------------------------
  Listening Level         1    79 dBSPL
  Listeners               32   Naïve Listeners per language
  Groups                  16   2 subjects/group
  Rating Scales           5    
  Languages               2    French, Arabic
  Listening System        1    Monaural headset (flat response in the audio bandwidth of interest: 50Hz-7kHz). The other ear is open.
  Listening Environment        Room Noise: Hoth Spectrum at 30dBA (as defined by ITU-T Recommendation P.800: Annex A, section A.1.1.2.2.1 Room Noise, with table A.1 and Figure A.1)
  ----------------------- ---- -------------------------------------------------------------------------------------------------------------------------------------------------------

7 Analysis of test results for DCH channels for Phase 1 and 2
=============================================================

This section presents the Global Analysis of the results. The analysis
work was performed by Dynastat in its function as the Global Analysis
Laboratory (GAL). Annex G presents the GAL Test Plan for characterizing
the results of the conversation tests. (Detailed test plans are given in
Annexes D and E for Phase 1 and in Annex F for Phase 2).

It should be noted that this is the first instance in any
standardisation body of conversation tests being used to characterize
the performance of standardized speech codecs, and the first instance of
codecs in 3GPP being characterized for packet-switched networks.
Moreover, the analyses reported in this document represent a new
approach to evaluating the results of conversation tests.

7.1 Conversation Tests
----------------------

The Phase 1 test plan describes the methodology for conducting the
conversation tests. In general, the procedure involved a pair of
subjects located in different rooms and communicating over a simulated
packet-switched network. The subjects were involved in a task, which
required them to communicate in order to solve a specific problem. At
the end of their task, each subject was required to rate various aspects
of the quality of their conversation. Each of these ratings involved a
five-point scale with descriptors appropriate to the aspect of the
conversation being rated. Table 16 shows a summary of the five rating
scales. (The first row in each column shows the scale abbreviation that
will be used throughout this report).

Table 16: Summary of Rating Scales used in the Conversation Tests

![](media/image13.wmf){width="6.409027777777778in" height="1.3125in"}

Since each subject makes five ratings for each condition, there are five
dependent variables involved in analyses of the response data. We would
expect the ratings on the scales in Table 16 to show some degree of
inter-correlation across test conditions. If, in fact, all five were
perfectly correlated then we would conclude that they were each
measuring the same underlying variable. In this scenario, we could
combine them into a single measure (e.g., by averaging them) for
purposes of statistical analyses and hypothesis testing. If, on the
other hand, the ratings were uncorrelated, we would conclude that each
scale is measuring a different underlying variable and should be treated
separately in subsequent analyses. In practice, the degree of
intercorrelation among such dependent variables usually falls somewhere
between these two extremes. Multivariate Analysis of Variance (MANOVA)
is a statistical technique designed to evaluate the results of
experiments with multiple dependent variables and determine the nature
and number of underlying variables. MANOVA was proposed in the GAL test
plan for the conversation tests and was used extensively in the analyses
presented in this report.

7.2 Experimental Design and Statistical Procedures
--------------------------------------------------

The two Phase 1 test plans, AMR Narrowband (AMR-NB) and AMR Wideband
(AMR-WB), described similar experimental designs, each experiment
involving 24 test conditions (*COND*) and 16 pairs of subjects. The test
plans also specified that the experiments would be conducted by three
Listening Laboratories (*LAB*), each in a different language: Arcon for
North American English, NTT-AT for Japanese, and France Telecom for
French.

Of the 24 conditions in both the NB and WB experiments, 18 were
described as Symmetrical conditions (SYM), six as Asymmetrical (ASY). In
the SYM conditions all subjects were located in a Quiet room, i.e., with
no introduced background noise. The six ASY conditions were actually
three pairs of conditions where one subject in each conversation-pair
was located in a noisy background and the other subject was in the
quiet. The data from these sets of paired conditions were sorted to
effect a comparison of *sender in noise/receiver in quiet* and s*ender
in quiet/receiver in noise* for the three conditions involving noise in
the rooms.

The Phase 2 test plan described a single experiment involving 16
conditions conducted by one listening lab (France Telecom) but in two
languages, French and Arabic.

For purposes of the GAL, the data from the three experiments, Phase
1-NB, Phase 1-WB, and Phase 2 were separated into five *Sets* of
conditions for statistical analyses:

*Set 1.* Phase 1 - NB/SYM conditions (1-18)

*Set 2.* Phase 1 - NB/ASY conditions (19-24)

*Set 3.* Phase 1 - WB/SYM conditions (1-18)

*Set 4.* Phase 2 - WB/ASY conditions (19-24)

*Set 5.* Phase 2 - Ph2 conditions (1-16)

For each of these five set of conditions, a three-step statistical
process was undertaken to attempt to simplify the final analyses and
arrive at the most parsimonious and unambiguous statistical method for
characterizing the results of the conversation tests. These procedures
involved the following steps:

Step 1) Compute an intercorrelation matrix among the dependent variables
for the *Set* of conditions. Substantial inter-correlation among the
dependent variables (i.e., correlation coefficients \> .50 or \< -.50)
indicates that the number of dependent variables can be reduced - that
there is a reduced set of underlying variables accounting for the
variance in the dependent variables.

Step 2) Conduct a MANOVA on the *Set* of scores for the effects of
conditions (*COND*) in the *Set*, (18 *COND* for *Set 1*, *6 COND* for
*Set 2*, etc.) ignoring other factors. The MANOVA procedure determines
the linear combination of the dependent variables that best separates
the linear combination of the independent variable, i.e., *COND*. The
initial linear combination of dependent variables is the *root* that
accounts for maximum variance in the independent variables - it also
represents the first underlying variable. A Chi-square test is conducted
to determine the significance of the root. Subsequent roots are also
extracted from the residual variance and tested with Chi-square for
significance with each subsequent root being orthogonal to the preceding
root. The number of significant roots indicates the number of
significant underlying variables that account for the variance in the
dependent variables.

Step 3) If there is only one significant root for the *COND* effect, the
*Canonical coefficients* for that root are used to compute a weighted
average of the dependent variables to estimate the underlying variable.
This composite dependent variable is then used in a univariate ANOVA to
test the factors involved in the experiment. Such ANOVA\'s will produce
results that are more parsimonious and less complicated than presenting
the results in the multi-dimensional space which would be necessary with
multiple dependent variables.

7.3 Narrowband Test - Symmetric conditions (*Set 1*)
----------------------------------------------------

Table 18 shows the 1 to 18 test conditions involved in the NB symmetric
condition conversation tests. Also shown in the table are the Mean
scores for each rating scale by condition and by listening lab. Each
score shown in the table is the average of ratings from 32 subjects.

The first step in the process described in the previous section is to
examine the inter-correlations among the dependent variables for
indications of underlying variables. Table 17 shows the
inter-correlation matrix of the five dependent variables for the NB/SYM
conditions. Absolute values of correlation above .50 have been bolded in
the table. The table shows a high degree of inter-correlation among the
dependent variables indicating the presence of a reduced set of
underlying variables.

Table 17: Intercorrelations Among the Dependent Variables for the NB/SYM
Conditions

![](media/image14.wmf){width="4.218055555555556in"
height="1.1354166666666667in"}

The second step in the analysis is designed to determine how many
underlying variables account for the variance in the five dependent
variables. MANOVA for the effects of *COND* was conducted on the NB/SYM
data -- conditions 1-18. Table 19 summarizes the results of the MANOVA
analysis. The table contains two sections. The top section shows the
analysis for the main effect of *COND.* It includes the results of
univariate ANOVA\'s for each of the five dependent variables followed by
results for the Multivariate-ANOVA (i.e., the MANOVA) for the
combination of dependent variables. In Table 19 we can see that the
*COND* main effect is highly significant for each of the five individual
dependent variables in the univariate ANOVA\'s as well as for the
combination of dependent variables

Table 18: Test Conditions and Mean Scores for each Condition and for
each Lab for the Narrowband Experiment

![](media/image15.wmf){width="9.988194444444444in"
height="4.210416666666666in"}

Rm-A/Rm-B (Noise environment) RC (Radio Conditions) PL (% Packet Loss)
Mode (Bit rate in kbps) Del (Delay in msec)

The bottom section of Table 19 shows the Chi-square tests of the MANOVA
roots. It shows only a single significant root (1 through 5), indicating
that a single underlying variable accounts for the significant variation
in the dependent variables for these conditions. The canonical
coefficients for this root are also shown in the table and are used to
compute the composite dependent variable that represents the underlying
variable for the NB/SYM conditions. The composite dependent variable
(**NB/S-CTQ** for **N**arrow**B**and/**S**ymmetric**-C**onversation
**T**est **Q**uality) is used to characterize the ratings in the NB/SYM
conditions. NB/S-CTQ scores for all conditions and all LAB\'s in *Set 1*
are listed in the Annex A. Equation 1 shows the formula used to compute
the composite score for the NB/SYM conditions.

Table 19: Results of MANOVA for *COND* for NB/SYM Conditions

![](media/image16.wmf){width="5.9875in" height="2.5215277777777776in"}

Formula used to compute the Conversation Test Quality Score (NB/S-CTQ)
for the conditions in Set 1:

NB/S-CTQ = .0426\*VQ + .0620\*US - .0015 \* IA + .5664 \* PC + .4470 \*
GQ (1)

The SYM conditions in the NB experiment are categorized by four
experimental factors:

> \- Radio conditions -- 10-2, 10-3, and 5x10-4
>
> \- Packet Loss -- 0% and 3%
>
> \- AMR-NB mode or bit rate -- 6.7 kbps and 12.2 kbps
>
> \- Delay -- 300 msec and 500 msec

These conditions are assigned to two factorial experimental designs for
analysing the effects of three of these factors. Table 20a shows the
allocation of the 12 conditions used to evaluate the effects of Radio
Conditions, Packet Loss, and Mode -- with Delay held constant at 300
msec. Table 20b shows the allocation of the 12 conditions used to
evaluate the effects of Radio Conditions, Packet Loss, and Delay -- with
Mode held constant at 12.2 kbit/s.

Table 20a: NB/SYM: Factorial Design for the Table 20b: NB/SYM: Factorial
Design for the Effects of Radio Cond., Packet Loss, and Mode Effects of
Radio Cond., Packet Loss, and Delay

![](media/image17.wmf){width="6.002083333333333in" height="2.1875in"}

The composite dependent variable, NB/S-CTQ, was computed for the NB/SYM
conditions using the equation shown in Eq.1. These composite scores were
subjected to factorial ANOVA for the two experimental designs shown in
Tables 20a and 20b. The results of those ANOVA\'s are shown in Tables 21
and 22, respectively.

Table 21: Results of ANOVA of NB/S-CTQ for the Effects of Lab, Radio
Conditions (RC), Packet Loss (PL), and Mode

![](media/image18.wmf){width="5.519444444444445in"
height="3.4881944444444444in"}

Table 21 shows that the main effects for *Radio Conditions*, *Packet
Loss*, and *Mode* are significant (p\<.05) for the NB/S-CTQ composite
variable as are the interactions of *LAB x RC* and *LAB x PL*. Figure 7
shows the NB/S-CTQ scores with 95% confidence-interval bars for the
factors tested in Table 21. The significant interactions of *RC x LAB*
and *PL x LAB* indicate that the pattern of scores for the levels of RC
and PL were significantly different across the three LAB\'s. Figure 9
illustrates the interaction of *LAB x RC*, Fig.10 the interaction of
*LAB x PL*.

![](media/image19.wmf){width="4.9875in" height="2.7215277777777778in"}

Figure 7: NB/S-CTQ Scores for the Effects of *LAB*, *Radio Conditions*,
*Packet Loss*, and *Mode*

![](media/image20.wmf){width="4.622916666666667in"
height="3.2777777777777777in"}

Figure 8: NB/S-CTQ Scores showing the Interaction of *LAB x Radio
Conditions*

![](media/image21.wmf){width="4.625in" height="2.9138888888888888in"}

Figure 9: NB/S-CTQ Scores showing the Interaction of *LAB x Packet Loss*

Table 22: Results of ANOVA of NB/S-CTQ for the Effects of *LAB*, *Radio
Conditions* (RC), *Packet Loss* (PL), and *Delay*

![](media/image22.wmf){width="5.519444444444445in"
height="3.3118055555555554in"}

The results in Table 22 show that the main effects for *Radio
Conditions*, *Packet Loss*, and *Delay* are significant while only one
interaction, *LAB x RC*, is significant. Figure 10 shows the NB/S-CTQ
scores with 95% confidence-interval bars for the factors tested in Table
22. Figure 11 illustrates the significant interaction of Lab x RC. The
figure shows that the pattern of scores for RC is significantly
different across LAB\'s.

![](media/image23.wmf){width="5.069444444444445in"
height="3.136111111111111in"}

Figure 10: NB/S-CTQ Scores for the Effects of *LAB*, *Radio Conditions*,
*Packet Loss*, and *Delay*

![](media/image24.wmf){width="4.35in" height="3.2618055555555556in"}

Figure 11: NB/S-CTQ Scores showing the Interaction of *LAB x Radio
Conditions*

7.4 Narrowband Test -- Asymmetric Conditions (*Set 2*)
------------------------------------------------------

Table 18 shows the 6 test conditions involved in the NB asymmetric
condition conversation tests (conditions 19 to 24). Also shown in the
table are the Mean scores for each rating scale by condition and by
listening lab. Each score shown in the table is the average of ratings
from 32 subjects.

Table 23 shows the inter-correlation matrix for the dependent variables
in the NB/ASY conditions. The degree of inter-correlation among the
dependent variables suggests that a reduced set of underlying variables
accounts for their variation.

Table 23: Inter-correlations Among the Dependent Variables for the
NB/ASY Conditions

![](media/image25.wmf){width="4.218055555555556in" height="1.09375in"}

Table 24 shows the results of MANOVA for the effects of *COND* for the
NB/ASY conditions. The analysis shows significant *COND* effects for all
the univariate ANOVA\'s as well as for the MANOVA. The Chi-square tests
of the MANOVA roots shows only a single significant root (1 through 5),
indicating that a single underlying variable accounts for the
significant variation in the dependent variables for these conditions.
The canonical coefficients for this root are used to estimate the
composite dependent variable that represents the underlying variable for
the NB/ASY conditions. The composite dependent variable (**NB/A-CTQ**
for **N**arrow**B**and/**A**symmetric**-C**onversation **T**est
**Q**uality) is used to characterize the ratings in the NB/ASY
conditions. NB/A-CTQ scores for all conditions and all LAB\'s in *Set 2*
are listed in Annex A. Equation 2 shows the formula that was used to
compute the values of the composite variable, NB/A-CTQ, for
characterizing the NB/ASY conditions.

Table 24: Results of MANOVA for *COND* for NB/ASY Conditions

![](media/image26.wmf){width="4.658333333333333in"
height="2.7083333333333335in"}

Formula used to compute the Conversation Test Quality Score (NB/A-CTQ)
for the NB/ASY conditions:

NB/A-CTQ = .0894\*VQ + .3420\*US + .1851 \* IA + .2761 \* PC + .1074 \*
GQ (2)

The six NB/ASY conditions are distinguished by two factors. One factor
has three levels with each level differing along a number of dimensions
-- Noise, Packet Loss, Mode, and Delay. These differences are listed in
Table 18, but the factor will be referred to in the following analyses
by the factor-name, *Noise*, noting that the conditions differ in more
dimensions than noise alone. The second factor relates to the source of
the noise. The noise is either in the room of the transmitting subject
or in the room of the receiving subject. This factor will be referred to
as *Room*. Table 25 shows the results of ANOVA for NB/A for the factors
of *LAB*, *Noise*, and *Room*.

Table 25: Results of ANOVA of NB/A-CTQ for the Effects of *LAB*,
*Noise*, and *Room*

![](media/image27.wmf){width="5.853472222222222in"
height="1.9694444444444446in"}

The results of the ANOVA for NB/A-CTQ show that all three factors,
*LAB*, *Noise*, and *Room*, are significant, but that none of the
interactions are significant. Figure 12 shows the NB/A-CTQ scores with
95% confidence-interval bars for the three factors tested in Table 25.

![](media/image28.wmf){width="4.33125in" height="2.9541666666666666in"}

Figure 12: NB/A-CTQ Scores for the Effects of *LAB*, *Noise*, and *Room*

7.5 Wideband Test -- Symmetric Conditions (*Set 3*)
---------------------------------------------------

Table 27 shows the 18 test conditions involved in the AMR-WB
conversation tests (conditions 1 to 18). Also shown in the table are the
Mean scores for each rating scale by condition and by listening lab.
Each score shown in the table is the average of ratings from 32
subjects.

The initial step in the analysis is to examine the inter-correlation
among the dependent variables for indications of underlying variables.
Table 26 shows the inter-correlation matrix of the dependent variables
for the WB/SYM conditions. Absolute values of correlation above .50 have
been bolded in the table. The table shows a high degree of
inter-correlation among the dependent variables indicating the presence
of a reduced set of significant underlying variables.

Table 26: Intercorrelations Among the Dependent Variables for the WB/SYM
Conditions

![](media/image29.wmf){width="4.218055555555556in"
height="1.1354166666666667in"}

The second step in the analysis is designed to determine how many
underlying variables account for the variance in the five dependent
variables. MANOVA for the effects of *COND* was conducted on the WB/SYM
data -- conditions 1-18. Table 28 summarizes the results of the
analysis. The top section shows the analysis for the main effect of
*COND.* This section includes the results of the univariate ANOVA\'s for
each of the five dependent variables followed by the results of the
MANOVA. In the table we can see that the *COND* main effect is highly
significant for each of the five individual dependent variables in the
univariate ANOVA\'s as well as for the combination of dependent
variables in the MANOVA.

The bottom section of the table shows the Chi-square test of the MANOVA
roots or underlying variables extracted from the five dependent
variables. In Table 28, only the first root (1 through 5) is
significant, indicating that a single underlying variable accounts for
the significant variation in the dependent variables for these
conditions. The canonical coefficients shown in the table are used to
estimate the composite dependent variable that represents this root or
underlying variable. The composite dependent variable (**WB/S-CTQ** for
**W**ide**B**and/**S**ymmetric**-C**onversation **T**est **Q**uality) is
computed and used in the third step -- ANOVA\'s to test and characterize
the factors of interest in the Wideband/SYM conditions. WB/S-CTQ scores
for all conditions and all LAB\'s for *Set 3* are listed in Annex A.
Equation 3 shows the formula that was used to compute the values of the
composite variable, WB/S-CTQ, for characterizing the WB/SYM conditions.

Table 27: Test Conditions and Mean Scores for each LAB for the Wideband
Experiment

![](media/image30.wmf){width="10.096527777777778in" height="4.39375in"}

Rm-A/Rm-B (Noise environment) RC (Radio Conditions) PL (% Packet Loss)
Mode (Bit rate in kbps) RoHC

Table 28: Results of MANOVA for *COND* for WB/SYM Conditions

![](media/image31.wmf){width="5.9875in" height="2.5215277777777776in"}

The following formula is used to compute the Conversation Test Quality
Score (WB/S-CTQ) for the WB/SYM conditions:

WB/S-CTQ = .0685\*VQ + .3519\*US + .1612 \* IA + .2619 \* PC + .1565 \*
GQ (3)

The SYM conditions in the WB experiment are categorized by four
experimental factors:

− Radio conditions -- 10-2, 10-3, and 5x10-4

− Packet Loss -- 0% and 3%

− AMR-WB mode or bit rate -- 12.65 kbps and 15.85 kbps

− ROHC

These conditions are assigned to two factorial experimental designs for
analysing the effects through ANOVA of three of these factors. Table 29a
shows the allocation of the 12 conditions used to evaluate the effects
of Radio Conditions, Packet Loss, and Mode -- with ROHC held constant.
Table 29b shows the allocation of the 12 conditions used to evaluate the
effects of Radio Conditions, Packet Loss, and ROHC -- Mode held constant
at 12.65kbps.

  ------------------------------------------------------------------------------------------- -------------------------------------------------------------------------------------------
  Table 29a: WB/SYM: Factorial Design for the Effects of Radio Cond., Packet Loss, and Mode   Table 29b: WB/SYM: Factorial Design for the Effects of Radio Cond., Packet Loss, and Mode
  ------------------------------------------------------------------------------------------- -------------------------------------------------------------------------------------------

![](media/image32.wmf){width="5.990972222222222in"
height="2.140972222222222in"}

The composite dependent variable, WB/S-CTQ, was computed for the WB/SYM
conditions and subjected to factorial ANOVA for the two experimental
designs shown in Tables 29a and 29b. The results of the ANOVA\'s are
shown in Tables 30 and 31, respectively.

Table 30: Results of ANOVA of WB/S-CTQ for the Effects of *Lab*, *Radio
Conditions* (RC), *Packet Loss* (PL), and *Mode*

![](media/image33.wmf){width="5.519444444444445in"
height="3.498611111111111in"}

Table 30 shows that the main effects for *LAB*, *Radio Conditions*, and
*Packet Loss* are significant for the WB/S-CTQ composite variable. The
factor *Mode* is not significant nor are any of the interactions. Figure
13 shows the WB/S-CTQ scores with 95% confidence-interval bars for the
factors tested in Table 30.

![](media/image34.wmf){width="5.677777777777778in"
height="3.542361111111111in"}

Figure 13: WB/S-CTQ Scores for the Effects of *LAB*, *Radio Conditions*,
*Packet Loss*, and *Mode*

Table 31: Results of ANOVA of WB/S-CTQ for the Effects of *LAB*, *Radio
Conditions* (RC), *Packet Loss* (PL), and ROHC

![](media/image35.wmf){width="5.525in" height="3.3152777777777778in"}

The results in Table 31 show that the main effects for *LAB*, *Radio
Conditions*, and *Packet Loss* are significant. The factor *ROHC* is not
significant nor are any of the interactions. Figure 14 shows the
WB/S-CTQ scores with 95% confidence-interval bars for the factors tested
in Table 31.

These listening tests were conducted using a fixed size RAB available at
this time (size: 46 kbit/s). The test results show that when using ROHC
the quality stays the same and the bitrate can be drastically reduced by
suppressing the IP/UDP/RTP headers. As a result, a smaller RAB could be
used.

![](media/image36.wmf){width="4.799305555555556in"
height="2.9569444444444444in"}

Figure 14: WB/S-CTQ Scores for the Effects of *LAB*, *Radio Conditions*,
*Packet Loss*, and *ROHC*

7.6 Wideband Test -- Asymmetric Conditions (*Set 4*)
----------------------------------------------------

Table 27 shows the 6 test conditions involved in the AMR-WB asymmetric
condition conversation tests (condition 19 to 24). Also shown in the
table are the Mean scores for each rating scale by condition and by
listening lab. Each score shown in the table is the average of ratings
from 32 subjects.

Table 32 shows the inter-correlation matrix for the dependent variables
in the WB/ASY conditions. The high degree of inter-correlation shown in
the table suggests that a reduced set of underlying variables accounts
for the variation in the five dependent variables.

Table 32: Inter-correlations Among the Dependent Variables for the
WB/ASY Conditions

![](media/image37.wmf){width="4.222916666666666in"
height="1.1034722222222222in"}

Table 33 shows the results of MANOVA for the effects of *COND* for the
WB/ASY conditions. The analysis shows significant *COND* effects for all
the univariate ANOVA\'s as well as for the MANOVA. The Chi-square tests
of the MANOVA roots show only a single significant root (1 through 5),
indicating that a single underlying variable accounts for the
significant variation in the dependent variables for these conditions.
The canonical coefficients for this root were used to compute the
composite dependent variable that represents the underlying variable for
the WB/Asymmetric conditions. The composite dependent variable
(**WB/A-CTQ** for **W**ide**B**and/**A**symmetric**-C**onversation
**T**est **Q**uality) is used to characterize the ratings in the WB/ASY
conditions. WB/A-CTQ scores for all conditions and all LAB\'s for *Set
4* are listed Annex A. Equation 4 shows the formula that was used to
compute the values of the composite variable, WB/A-CTQ, for
characterizing the WB/ASY conditions.

Table 33: Results of MANOVA for *COND* for WB/ASY Conditions

![](media/image38.wmf){width="4.646527777777778in"
height="2.7083333333333335in"}

The following formula used to compute the Conversation Test Quality
Score (WB/ACTQ) for the WB/ASY conditions.

WB/A-CTQ = -.0970\*VQ + .8979\*US - .1103 \* IA + .4136 \* PC - .1042 \*
GQ (4)

The six WB/ASY conditions are distinguished by two factors. One factor
has three levels with each level differing along a number of dimensions
-- Noise, Packet Loss, Mode, and ROHC. These differences are listed in
Table 27 but the factor will be referred to in the following analyses by
the factor-name, *Noise*, noting that the conditions differ in more
dimensions than noise alone. The second factor relates to the source of
the noise and has two levels. The noise is either in the room of the
transmitting subject or in the room of the receiving subject. This
factor is referred to as *Room* in the following analyses. Table 34
shows the results of ANOVA for WB/A-CTQ for the factors of *LAB*,
*Noise*, and *Room*.

Table 34: Results of ANOVA of WB/A-CTQ for the Effects of *LAB*,
*Noise*, and *Room*

![](media/image39.wmf){width="5.7131944444444445in"
height="1.9013888888888888in"}

The results of the ANOVA for WB/A-CTQ show that all three factors,
*LAB*, *Noise*, and *Room*, are significant but only one of the
interactions, *LAB x Noise* is significant. Figure 15 shows the WB/A-CTQ
scores with 95% confidence-interval bars for the three factors tested in
Table 34. Figure 16 shows how the pattern of scores for the Noise factor
is different over the three LAB\'s resulting in the significant
interaction of *Lab x Noise*.

![](media/image40.wmf){width="5.101388888888889in"
height="3.316666666666667in"}

Figure 15: WB/A-CTQ Scores for the Effects of *LAB*, *Noise*, and *Room*

![](media/image41.wmf){width="4.896527777777778in"
height="3.9583333333333335in"}

Figure 16: WB/A-CTQ Scores for the Interaction of *LAB x Noise*

7.7 Phase 2 - ITU-T Codec Tests (*Set 5*)
-----------------------------------------

Table 35 shows the test conditions involved in the conversation tests
designed to compare the performance of standardized ITU-T codecs in
packet switched networks. The test involves eight codecs and two levels
of packet loss, 0% and 3%. Scores are shown for each of the five
dependent variables by Condition and by Language (Language is referred
to by factor-name *LAB* in the following analyses). Each score shown in
the table is the average of ratings from 32 listeners.

Table 35: Test Conditions and Scores for each Condition and Lab
(Language) for the Codec (Phase 2) Experiment

![](media/image42.wmf){width="5.543055555555555in"
height="3.1729166666666666in"}

Table 36 shows the inter-correlation matrix for the dependent variables
in the Phase 2 experiment. The moderate degree of inter-correlation
shown in the table suggests that a reduced set of underlying variables
may account for the variation in the five dependent variables.

The following acronyms were used in the tables PL for Packet Loss, FR
for French and AB-Arabic.

Table 36: Inter-correlations Among the Dependent Variables for the Codec
Conditions.

![](media/image43.wmf){width="4.361805555555556in"
height="1.0729166666666667in"}

Table 37 shows the results of MANOVA for the effects of *COND* for the
Phase 2 experiment. The analysis shows significant *COND* effects for
all the univariate ANOVA\'s as well as for the MANOVA. The Chi-square
tests of the MANOVA roots show only a single significant root (1 through
5), indicating that a single underlying variable accounts for the
significant variation in the dependent variables for these conditions.
The canonical coefficients for this root were used to compute the
composite dependent variable that represents the underlying variable for
the Phase 2 conditions. The composite dependent variable (**Ph2-CTQ**
for **Ph**ase**2-C**onversation **T**est **Q**uality) is computed and
used to characterize the ratings in the Phase 2 experiment. Ph2-CTQ
scores for all conditions and all LAB\'s for *Set 5* are listed in the
Appendix. Equation 5 shows the formula that was used to compute the
values of the composite variable, Ph2-CTQ, for characterizing the Phase
2 conditions.

Table 37: Results of MANOVA for *COND* for the Phase 2 Conditions

![](media/image44.wmf){width="4.788194444444445in"
height="2.6381944444444443in"}

The following formula was used to compute the Conversation Test Quality
Score (Ph2-CTQ) for the Phase 2 conditions:

Ph2-CTQ = .5995\*VQ + .0860\*US - .0092 \* IA + .0459 \* PC + .2778 \*
GQ

The 16 Phase 2 conditions are distinguished by two factors, *Codec* and
*Packet Loss*. Table 38 shows the results of ANOVA for Ph2-CTQ for these
factors.

Table 38: Results of ANOVA of Ph2-CTQ for the Effects of *Codec* and
*Packet Loss*

![](media/image45.wmf){width="5.621527777777778in"
height="1.9618055555555556in"}

The results of the ANOVA for Ph2-CTQ show that all three factors, *LAB*,
*Codec*, and *Packet Loss*, are significant as well as the interaction
*Codec x Packet Loss*. Figure 17 shows the Ph2-CTQ scores with 95%
confidence-interval bars for the factors tested in Table 38. Figure 18
illustrates the interaction of *Codec x Packet Loss*.

![](media/image46.wmf){width="6.104861111111111in"
height="3.217361111111111in"}

Figure 17: Ph2-CTQ Scores for the Effects of *LAB*, *Codec*, and *Packet
Loss*

![](media/image47.wmf){width="5.625in" height="2.970833333333333in"}

Figure 18: Ph2-CTQ Scores Showing the Interaction of Factors *Codec* and
*Packet Loss*

7.8 Summary of Test Result Analysis
-----------------------------------

For each of the five sets of conditions in the Packet-Switched
Conversation Tests, analysis by MANOVA revealed a single underlying
variable that accounts for the significant variation in the five opinion
rating scales, VQ, US, IA, PC, and GQ. Conversation Test Quality (CTQ)
scores were computed for each set of conditions. The CTQ scores were
analysed through ANOVA to characterize the conditions involved in the
Conversation Tests.

8 Performance characterisation of VoIMS over HSDPA/EUL channels
===============================================================

8.A Listening only tests
------------------------

### 8.A.1 Test methodology for listening only tests

The HSPDA/EUL listening only characterisation tests were conducted by
two listening test laboratories (Nokia and Ericsson). Tested languages
were Finnish and Swedish.

The tested speech codecs were:

\- Adaptive Multi-Rate narrownand (AMR-NB), in modes 12.2 kbit/s and 5.9
kbit/s,

\- Adaptive Multi-Rate wideband (AMR-WB), in mode 12.65 kbit/s.

The tested jitter buffer implementations were:

\- Fixed reference jitter buffer (as a reference),

\- Adaptive jitter buffer compliant with the functional and performance
requirements in TS 26.114.

Subjective quality score and delay were used as metrics to evaluate the
results. The test was designed based on P.800.Sec.6.2.

### 8.A.2 Test arrangement

The subjective tests evaluated the impact of the HSDPA/EUL radio channel
conditions on the speech quality especially when the channel is subject
to packet losses and jitter. The test items were processed using an
error insertion device (EID) introducing jitter and packet losses into
simulated RTP packet stream. The performance of AMR-NB and AMR-WB was
evaluated with adaptive jitter buffer management (JBM). Description of
the processing of speech material is found in Annex J.

### 8.A.3 Jitter buffer implementations

Two different jitter buffer implementations were used in the tests; a
fixed JBM and an adaptive JBM. Both are briefly described in the
following subsections.

#### 8.A.3.1 Fixed JBM

The fixed jitter buffer -- i.e. a buffer that does not change the
end-to-end delay during a session -- used in the tests was only used
together with the tested codecs as a reference condition. The buffer was
not conducting any buffer adaptation at all. The role of the fixed JBM
reference condition was to show the performance of a fixed JBM, which
was tuned to give the (fixed) end-to-end delay equal to the average
end-to-end delay of the adaptive JBM in the same channel condition. This
was done by setting the initial buffering delay in a value resulting in
the desired end-to-end delay for each channel condition separately. The
initial buffer delay for the fixed jitter buffer was thus set having the
full a priori knowledge of the behaviour of the transmission channel
over the whole session and the transmission delay of the first incoming
packet. Such an approach can not be used in real-life implementations
where both the (future) channel behaviour and the delay of the first
received packet are not known by the receiver. Hence, the fixed JBM was
non-causal and thus impossible to use in a real-life implementation.
Furthermore, due to its nature of non-adaptivity, it does not pass the
minimum performance requirements for JBM schemes set in 3GPP TS 26.114
\[19\].

#### 8.A.3.2 Adaptive JBM

As opposed to the fixed JBM, an adaptive JBM may change the end-to-end
delay during a session with the aim to optmise the trade-off between
buffering delay and buffer induced frame lossess. The adaptive jitter
buffer management algorithm used in the listening only tests was a
simple algorithm conducting buffer adaptation mainly during inactive
speech without any time scale modifications with the option to adapt
during active speech only to avoid excessive frame losses. Thus, the
adaptation was mainly based on insertion and removal of comfort noise
frames. Note, however, that to avoid excessive losses the adaptation may
also have taken place during active speech if a sudden increase in
transmission delay was detected. The algorithm met both the functional
requirements and the minimum performance requirements set in 3GPP TS
26.114. The outline of the operation of this adaptive JBM is described
in Annex I of this document. Contrary to the fixed JBM described in the
previous section, this JBM could be used in real-life implementations
and provides performance according to the test results presented in the
following sections in this report.

### 8.A.4 Network conditions

The network conditions used when the test material was processed were
divided into eight different channels. The conditions were characterized
by low mobility, high mobility, low traffic (LT) and high traffic (HT)
in the uplink and downlink respectively. All conditions were presented
as channel profiles were the transmission end-to-end delay and link
losses could be extracted for test file processing.

The following radio network condition definitions were used.

Table 39: Definition of Radio Network Conditions

+----------------------------+-----------------------+---------------------+
| **Condition Name**         | **Network Load:**     | **Network Load:**   |
|                            |                       |                     |
|                            | **40/45/60 per cell** | **80/100 per cell** |
+----------------------------+-----------------------+---------------------+
| DL:                        | DL-LT                 | DL-HT               |
|                            |                       |                     |
| PedB3\_km+PedA3\_km        |                       |                     |
+----------------------------+-----------------------+---------------------+
| DL:                        | DH-LT                 | DH-HT               |
|                            |                       |                     |
| VehA30km+Veh120km+PedB30km |                       |                     |
+----------------------------+-----------------------+---------------------+
| UL:                        | UL                    |                     |
|                            |                       |                     |
| PedB3\_km+PedA3\_km        |                       |                     |
+----------------------------+-----------------------+---------------------+
| UL:                        | UH                    |                     |
|                            |                       |                     |
| VehA30km+Veh120km+PedB30km |                       |                     |
+----------------------------+-----------------------+---------------------+

Based on the radio network conditions in the table above, eight
different channels were constructed. These network conditions were
composed into channel conditions for the listening tests in the
following way.

Table 40: Definition of Radio Network Channels conditions

  --------- -------------------------
  Channel   Radio Network Condition
  Ch1       DL-LT-UL
  Ch2       DL-LT-UH
  Ch3       DL-HT-UL
  Ch4       DL-HT-UH
  Ch5       DH-LT-UL
  Ch6       DH-LT-UH
  Ch7       DH-HT-UL
  Ch8       DH-HT-UH
  --------- -------------------------

The radio networks conditions were simulated using HSDPA in the downlink
and EUL in the uplink. The actual configurations of the radio network
simulators can be found in Annex K. The 8 resulting channels all showed
a 1% link loss and delay variations in the range of 30-300 msec. The
delay profiles of the conditions are shown together with the adaptive
JBM buffering in section 8.7 in this report.

### 8.A.5 Listening experiments

Tables from 41 to 46 provide a summary of the listening-only test
conditions, and the full test plan is provided in Annex H.

Table 41: Noise types for listening only test

  ------------ ---------------
  Noise type   Level (dBSNR)
  Clean        \-
  Car          15 dB
  Cafeteria    20 dB
  ------------ ---------------

Table 42: Test details for listening only

  ----------------------------------- ---- --------------------------------------------------------------------------------------------------------------
  Listening Level                     1    79 dBSPL
  Reference Conditions (narrowband)   8    MNRU 5, 13, 21, 29, 37 dB, direct, clean 5.9 kbit/s, clean 12.2 kbit/s
  Reference Conditions (wideband)     8    MNRU 5, 13, 21, 29, 37, 45 dB, direct, clean 12.65 kbit/s
  Test Conditions                     2    Fixed buffer (buffer size set to the average of adaptive JBM in the same network condition), adaptive JBM
  Listeners                           32   Naïve Listeners
  Groups                              4    8 subjects/group
  Rating Scales                       1    P.800.2 ACR (clean condition), DCR (background noise)
  Languages                           2    Finnish and Swedish
  Listening System                    1    Monaural headset audio bandwidth 3.4kHz (narrowband) 7.0 kHz (wideband). The other ear is open.
  Listening Environment                    Room Noise: Hoth Spectrum at 30dBA (as defined by ITU-T Recommendation P.800: Annex A, section A.1.1.2.2.1 )
  Number of Talkers                   8    4 males, 4 females
  Number of Samples/Talker            5    4 for the test, 1 for the preliminary items
  ----------------------------------- ---- --------------------------------------------------------------------------------------------------------------

AMR and AMR-WB codecs were tested in both clean and background noise in
various channel conditions.

Table 43: Test conditions for listening-only tests with AMR-NB

  ------- ------------ ----------------- --------- -----------------------------
  Cond.   Noise Type   Frame Loss Rate   Channel   AMR-Modes (fixed RTP delay)
  1-1     Clean        0.01              Ch1       5.9kbit/s (150 ms)
  1-2     Clean        0.01              Ch2       5.9kbit/s (150 ms)
  1-3     Clean        0.01              Ch3       12.2kbit/s (150 ms)
  1-4     Clean        0.01              Ch4       12.2kbit/s (150 ms)
  ------- ------------ ----------------- --------- -----------------------------

Table 44: Test conditions for listening-only tests with AMR-NB in
background noise

  ------- ------------ ----------------- --------- -----------------------------
  Cond.   Noise Type   Frame Loss Rate   Channel   AMR-Modes (fixed RTP delay)
  2-1     Car          0.01              Ch5       5.9kbit/s (150 ms)
  2-2     Cafeteria    0.01              Ch6       5.9kbit/s (150 ms)
  2-3     Car          0.01              Ch7       12.2kbit/s (150 ms)
  2-4     Cafeteria    0.01              Ch8       12.2kbit/s (150 ms)
  ------- ------------ ----------------- --------- -----------------------------

Table 45: Test conditions for listening-only tests with AMR-WB

  ------- ------------ ----------------- --------- --------------------------
  Cond.   Noise Type   Frame Loss Rate   Channel   AMR-WB (fixed RTP delay)
  3-1     Clean        0.01              Ch1       12.65 kbit/s (150 ms)
  3-2     Clean        0.01              Ch2       12.65 kbit/s (150 ms)
  3-3     Clean        0.01              Ch3       12.65 kbit/s (150 ms)
  3-4     Clean        0.01              Ch4       12.65 kbit/s (150 ms)
  ------- ------------ ----------------- --------- --------------------------

Table 46: Test conditions for listening-only tests with AMR-WB in
background noise

  ------- ------------ ----------------- --------- --------------------------
  Cond.   Noise Type   Frame Loss Rate   Channel   AMR-WB (fixed RTP delay)
  4-1     Car          0.01              Ch5       12.65 kbit/s (150 ms)
  4-2     Car          0.01              Ch6       12.65 kbit/s (150 ms)
  4-3     Cafeteria    0.01              Ch7       12.65 kbit/s (150 ms)
  4-4     Cafeteria    0.01              Ch8       12.65 kbit/s (150 ms)
  ------- ------------ ----------------- --------- --------------------------

### 8.A.6 Test Results

Figures from 19 to 26 provide the listening-only test results. For each
test condition the MOS/DMOS score with 95 % confidence intervals is
shown.

![](media/image48.wmf){width="6.6875in" height="4.30625in"}

Figure 19: Experiment 1 (32 listeners, laboratory 1, Finnish)

![](media/image49.wmf){width="6.689583333333333in"
height="3.904861111111111in"}

Figure 20: Experiment 1 (31 listeners, laboratory 2, Swedish)

![](media/image50.wmf){width="6.6875in" height="4.30625in"}

Figure 21: Experiment 2 (32 listeners, laboratory 1, Finnish)

![](media/image51.wmf){width="6.690277777777778in"
height="4.024305555555555in"}

Figure 22: Experiment 2 (30 listeners, laboratory 2, Swedish)

![](media/image52.wmf){width="6.6875in" height="4.30625in"}

Figure 23: Experiment 3 (32 listeners, laboratory 1, Finnish)

![](media/image53.wmf){width="6.690277777777778in"
height="4.024305555555555in"}

Figure 24: Experiment 3 (26 listeners, laboratory 2, Swedish)

![](media/image54.wmf){width="6.6875in" height="4.30625in"}

Figure 25: Experiment 4 (32 listeners, laboratory 1, Finnish)

![](media/image55.wmf){width="6.690277777777778in"
height="4.024305555555555in"}

Figure 26: Experiment 4 (31 listeners, laboratory 2, Swedish)

### 8.A.7 Delay analysis

The delay analysis provided in Table 47 and Figures from 27 to 34 has
only been done on channels 1 through 8 using AMR-NB with the adaptive
JBM for the tests in laboratory 2 using the Swedish language. Including
AMR-WB 12.65 in the analysis does not give any additional information
since the patterns of voice activity is determined to be quite similar
for both codecs. This is also true for including the Finnish language in
the analysis. The voice activity for AMR-NB 5.9 and AMR-NB 12.2 is
identical. The CDF curve is based on the JBM buffering time.

The average end-to-end delay figures in Table 47 indicate that the
achieved delay performance is suitable for speech conversation. In
addition, it can be noted that the error concealment operations caused
by the JBM operation (i.e. frames dropped or inserted by the JBM e.g.
due to late arrival or buffer under/overflow) are below 0.5% for all
test cases restricting the media quality impact to be minor.

The adaptation principle of the tested JBM can be traced back when
comparing average buffering times of all frame and speech frames. Since
the adaptation is conducted mainly during inactive speech, i.e. during
silence periods, the delay values are different. SID frames are
forwarded for decoding typically immediately they arrive to the
receiver, while the jitter buffer target delay is accumulated by
delaying the playback of the first frame of speech burst.

Table 47: Delay analysis of adaptive JBM for AMR-NB 12.2 kbps operation

  ----------------------------------------------------- ---------------------- ---------------------- ---------------------- ---------------------- -------------------- --------------------- -------------------- ---------------------
  ** **                                                 **Condition**          ** **                  ** **                  ** **                  ** **                ** **                 ** **                ** **
  ** **                                                 **Channel 1, clean**   **Channel 2, clean**   **Channel 3, clean**   **Channel 4, clean**   **Channel 5, car**   **Channel 6, café**   **Channel 7, car**   **Channel 8, café**
  **Encoded frames**                                    16000                  16000                  16000                  16000                  16000                16000                 16000                16000
  **Encoded speech frames**                             8746                   8746                   8746                   8746                   8936                 9583                  8935                 9583
  **Encoded SID frames**                                1029                   1029                   1029                   1029                   983                  939                   981                  939
  **Encoded NO\_DATA frames**                           6225                   6225                   6225                   6225                   6081                 5478                  6084                 5478
  **Transmitted frames**                                9775                   9775                   9775                   9775                   9919                 10522                 9916                 10522
  **Received frames**                                   9635                   9636                   9621                   9622                   9820                 10417                 9820                 10410
  **Received speech frames**                            8623                   8621                   8604                   8619                   8846                 9484                  8849                 9479
  **Received SID frames**                               1012                   1015                   1017                   1003                   974                  933                   971                  931
  **Lost frames**                                       140                    139                    154                    153                    99                   105                   96                   112
  **Late frames**                                       6                      2                      39                     26                     23                   13                    40                   17
  **Late speech frames**                                6                      2                      37                     26                     23                   13                    39                   16
  **Late loss rate (speech frames)**                    0,07%                  0,02%                  0,43%                  0,30%                  0,26%                0,14%                 0,44%                0,17%
  **Average buffering time (all frames) \[msec\]**      57,7237                42,4383                71,2345                59,7803                56,294               39,0804               70,4495              56,7029
  **Average buffering time (speech frames) \[msec\]**   62,1496                45,7399                77,0119                64,4522                60,5685              41,5635               76,0796              60,3656
  **Average end-to-end delay (all) \[msec\]**           98,4819                74,6829                127,074                109,9885               104,3152             76,2146               125,1083             103,1506
  **Average end-to-end delay (speech) \[msec\]**        103,0551               77,9534                132,6756               114,6473               108,6259             78,7723               130,4654             106,5322
  **Buffering time (fixed\@startPos) \[msec\]**         85,0551                57,9534                96,6756                66,6473                46,6259              46,7723               64,4654              68,5322
  ----------------------------------------------------- ---------------------- ---------------------- ---------------------- ---------------------- -------------------- --------------------- -------------------- ---------------------

![](media/image56.png){width="5.843055555555556in"
height="4.374305555555556in"}

Figure 27: Performance, adaptive JBM channel 1, clean. The delay spike
at the end of the channel profile was 340 msec. The CDF curve is based
on the JBM buffering time.

![](media/image57.png){width="5.843055555555556in"
height="4.374305555555556in"}

Figure 28: Performance, adaptive JBM channel 2, clean. The delay spikes
of the channel profile were 310, 320 and 300 msec respectively. The CDF
curve is based on the JBM buffering time.

![](media/image58.png){width="5.843055555555556in"
height="4.374305555555556in"}

Figure 29: Performance, adaptive JBM channel 3, clean. The delay spike
of the channel profile was 320 msec. The CDF curve is based on the JBM
buffering time.

![](media/image59.png){width="5.843055555555556in"
height="4.374305555555556in"}

Figure 30: Performance, adaptive JBM channel 4, clean. The CDF curve is
based on the JBM buffering time.
![](media/image60.png){width="5.843055555555556in"
height="4.374305555555556in"}

Figure 31: Performance, adaptive JBM channel 5, car. The CDF curve is
based on the JBM buffering time.

![](media/image61.png){width="5.843055555555556in"
height="4.374305555555556in"}

Figure 32: Performance, adaptive JBM channel 6, café. The CDF curve is
based on the JBM buffering time.

![](media/image62.png){width="5.843055555555556in"
height="4.374305555555556in"}

Figure 33: Performance, adaptive JBM channel 7, car. The CDF curve is
based on the JBM buffering time.

![](media/image63.png){width="5.843055555555556in"
height="4.374305555555556in"}

Figure 34: Performance, adaptive JBM channel 8, café. The CDF curve is
based on the JBM buffering time.

8.A.8 Listening only test conclusions
-------------------------------------

The listening only test results for HSDPA/EUL radio channels indicate
that an adaptive JBM conforming to the MTSI performance requirements is
able to provide consistent voice quality over varying transmission
conditions. The test also showed that the performance of the JBM
directly impacts the voice quality.

Furthermore, the tested adaptive JBM provides equal or better voice
quality than the reference non-causal fixed JBM in all test cases. In
test conditions where the channel delay showed small variations the
adaptive JBM provided performance equal to the fixed reference JBM,
while in the test conditions where the channel behaviour introduced
larger delay variations the adaptive JBM outperformed the fixed
reference JBM. Thus, the results indicate that an adaptive JBM is needed
to cope with the large variations in channel delay.

8.B Conversation Tests
----------------------

### 8.B.1 Introduction

3GPP/SA4 developed a test plan \[see ANNEX L\] designed to evaluate the
performance of AMR and AMR-WB for UMTS over HSDPA/EUL. Three test labs
were contracted to conduct conversation tests according to the test plan
and deliver raw voting data to the Global Analysis Lab (GAL) for
processing and statistical analysis. This document reports the results
for the three test labs and additional statistical analyses conducted by
the GAL.

### 8.B.2 The Test Plan

The test plan described three conversations tests to be conducted in
each of three test labs. The test labs were FTRD, testing in the French
language, BIT, testing in the Chinese language, and Dynastat, testing in
North American English. Each of the three conversation tests involved a
different 3GPP standardized speech codec:

\- Exp.1 - AMR operating at 5.9k bps

\- Exp.2 - AMR operating at 12.2k bps

Exp.3 - AMR-WB operating at 12.65k bpsThe test plan specified that the
experiments should be conducted according to specifications contained in
the ITU-T Recommendation for Conversation Testing, P.805.

Alcatel-Lucent provided the network impairment simulation test-bed,
which was described in the test plan. The test-bed was shipped to each
test lab so that the same test conditions could be reproduced in each
lab. Each conversation test involved the same 16 network test
connections shown in Table 1.

Subjects were paired for the conversation task. Test conditions were
designed such that each condition was evaluated by both members of the
conversation pair. In each test condition, subjects were seated in one
of four simulated noise environments as specified in Table 1: Hoth/Quiet
(labeled **Q** in this document), Cafeteria/Babble (**B**), Car (**C**),
and Street (**S**). In half of the test conditions both subjects in the
pair were in the same noise environment (**QQ**, **BB**, **CC**,
**SS**). In the other half they were in different noise environments
(**QC**, **CQ**, **SB**, **BS**). The noise conditions were also
represented in the network simulation as either High Mobility conditions
(**HM** -- Car and Street) or Low Mobility conditions (**LM** --
Hoth/Quiet and Cafeteria/Babble). In half of the test connections the
test-bed simulated High Traffic network connections (**HT**), in the
other half it simulated Low Traffic (**LT**) network connections.

The test plan specified common testing parameters in order that the
conversation test results would be comparable across test labs. Those
parameters included the test-bed, the experimental design, test
conditions, background noise environments, randomized test-condition
presentation order, and number of subjects (32 subjects in 16
subject-pairs).

Table 8.B.1 --Test Conditions for the Conversation Tests

+-------------+-------------+-------------+-------------+-------------+
| ***Cond.    | ***Noise in | ***Radio    | ***Noise in | ***Des      |
| \#***       | Room A***   | Network     | Room B***   | cription*** |
|             |             | Conditions  |             |             |
|             |             | (RNC)***    |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 1           | Hoth        | A-\>B:      | Hoth        | Lm.LT.LM    |
|             |             | \[1\]       |             |             |
|             |             |             |             | LM.LT.Lm    |
|             |             | B-\>A:      |             |             |
|             |             | \[1\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 2           | Car         | A-\>B:      | Car         | Hm.LT.HM    |
|             |             | \[6\]       |             |             |
|             |             |             |             | HM.LT.Hm    |
|             |             | B-\>A:      |             |             |
|             |             | \[6\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 3           | Car         | A-\>B:      | Hoth        | Hm.LT.LM    |
|             |             | \[5\]       |             |             |
|             |             |             |             | HM.LT.Lm    |
|             |             | B-\>A:      |             |             |
|             |             | \[2\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 4           | Hoth        | A-\>B:      | Car         | Lm.LT.HM    |
|             |             | \[2\]       |             |             |
|             |             |             |             | LM.LT.Hm    |
|             |             | B-\>A:      |             |             |
|             |             | \[5\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 5           | Cafeteria   | A-\>B:      | Cafeteria   | Lm.LT.LM    |
|             |             | \[1\]       |             |             |
|             |             |             |             | LM.LT.Lm    |
|             |             | B-\>A:      |             |             |
|             |             | \[1\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 6           | Cafeteria   | A-\>B:      | Street      | Lm.LT.HM    |
|             |             | \[2\]       |             |             |
|             |             |             |             | LM.LT.Hm    |
|             |             | B-\>A:      |             |             |
|             |             | \[5\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 7           | Street      | A-\>B:      | Cafeteria   | Hm.LT.LM    |
|             |             | \[5\]       |             |             |
|             |             |             |             | HM.LT.Lm    |
|             |             | B-\>A:      |             |             |
|             |             | \[2\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 8           | Street      | A-\>B:      | Street      | Hm.LT.HM    |
|             |             | \[6\]       |             |             |
|             |             |             |             | HM.LT.Hm    |
|             |             | B-\>A:      |             |             |
|             |             | \[6\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 9           | Hoth        | A-\>B:      | Hoth        | Lm.HT.LM    |
|             |             | \[3\]       |             |             |
|             |             |             |             | LM.HT.Lm    |
|             |             | B-\>A:      |             |             |
|             |             | \[3\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 10          | Car         | A-\>B:      | Car         | Hm.HT.HM    |
|             |             | \[8\]       |             |             |
|             |             |             |             | HM.HT.Hm    |
|             |             | B-\>A:      |             |             |
|             |             | \[8\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 11          | Car         | A-\>B:      | Hoth        | Hm.HT.LM    |
|             |             | \[7\]       |             |             |
|             |             |             |             | HM.HT.Lm    |
|             |             | B-\>A:      |             |             |
|             |             | \[4\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 12          | Hoth        | A-\>B:      | Car         | Lm.HT.HM    |
|             |             | \[4\]       |             |             |
|             |             |             |             | LM.HT.Hm    |
|             |             | B-\>A:      |             |             |
|             |             | \[7\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 13          | Cafeteria   | A-\>B:      | Cafeteria   | Lm.HT.LM    |
|             |             | \[3\]       |             |             |
|             |             |             |             | LM.HT.Lm    |
|             |             | B-\>A:      |             |             |
|             |             | \[3\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 14          | Cafeteria   | A-\>B:      | Street      | Lm.HT.HM    |
|             |             | \[4\]       |             |             |
|             |             |             |             | LM.HT.Hm    |
|             |             | B-\>A:      |             |             |
|             |             | \[7\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 15          | Street      | A-\>B:      | Cafeteria   | Hm.HT.LM    |
|             |             | \[7\]       |             |             |
|             |             |             |             | HM.HT.Lm    |
|             |             | B-\>A:      |             |             |
|             |             | \[4\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+
| 16          | Street      | A-\>B:      | Street      | Hm.HT.HM    |
|             |             | \[8\]       |             |             |
|             |             |             |             | HM.HT.Hm    |
|             |             | B-\>A:      |             |             |
|             |             | \[8\]       |             |             |
+-------------+-------------+-------------+-------------+-------------+

On each test trial, the subjects evaluated the test connection using
five rating scales, where each rating scale involved five categories. In
this report the results and analyses for the rating scales are labeled
by the following conventions:

\- Question 1 -- **VQ** -- Rate the **Voice Quality** of your partner.

\- Question 2 -- **UN** -- Rate the difficulty of **Understanding** your
partner.

\- Question 3 -- **LE** -- Rate the **Level of Effort** required to
communicate with your partner.

\- Question 4[^1] -- **DD** -- Did you **Detect Disturbances** in the
conversation? If yes, how annoying were they.

\- Question 5 -- **OQ** -- Rate the **Overall Quality** of the test
connection.

### 8.B.3 Cross-check of Test Lab Results

The three test labs delivered their raw voting data to the GAL in the
Excel spreadsheets provided by the GAL. Each of the test labs also
provided test lab reports containing summary results for the
conversation tests. Dynastat processed the raw voting data from the data
delivery files and cross-checked the resulting scores against those
contained in the test lab reports. In all cases the scores computed by
Dynastat agreed with those reported by the test labs. The GAL therefore
confirms the integrity of the raw data delivery for the three test labs.

### 8.B.4 Test Results

#### 8.B.4.1 Mean Scores by Experiment and by Test Lab

The GAL was instructed by 3GPP/SA4 to treat the results of individual
experiments from the test labs separately rather than making comparisons
across experiments or across labs. This approach is justified by the
experimental design of the conversation tests. Each experiment in each
lab involved a different codec and each used an independent panel of
test subjects. Comparisons of results across experiments within one lab
are confounded by both codecs and subject panels. Comparisons across
labs are further confounded by language and cultural differences in the
subject panels. Finally, there are no common conditions across
experiments and therefore no basis for transforming scores to a common
origin and scale across experiments. The results and analyses contained
in this report are limited to the results from a single experiment in a
single Lab.

Figures 1-9 show the Mean scores for each of the five rating scales by
Experiment and by Test Lab -- Figs. 1-3 for Exp.1, Figs. 4-6 for Exp.2,
and Figs. 7-9 for Exp.3.

![](media/image64.wmf){width="5.002083333333333in"
height="2.790277777777778in"}

Fig. 8.B.1 -- Mean Scores for Exp.1 - AMR-5.9 in Lab BIT

![](media/image65.wmf){width="5.002777777777778in"
height="2.790277777777778in"}

Fig. 8.B.2 -- Mean Scores for Exp.1 - AMR-5.9 in Lab FTRD

![](media/image66.wmf){width="5.002777777777778in"
height="2.813888888888889in"}

Fig. 8.B.3 -- Mean Scores for Exp.1 - AMR-5.9 in Lab Dynastat

![](media/image67.wmf){width="4.997222222222222in"
height="2.779166666666667in"}

Fig. 8.B.4 -- Mean Scores for Exp.2 - AMR-12.2 in Lab BIT

![](media/image68.wmf){width="5.002777777777778in"
height="2.779166666666667in"}

Fig. 8.B.5 -- Mean Scores for Exp.2 - AMR-12.2 in Lab FTRD

![](media/image69.wmf){width="5.002777777777778in"
height="2.779166666666667in"}

Fig. 8.B.6 -- Mean Scores for Exp.2 - AMR-12.2 in Lab Dynastat

![](media/image70.wmf){width="5.002777777777778in"
height="2.790277777777778in"}

Fig. 8.B.7 -- Mean Scores for Exp.3 - AMRWB-12.65 in Lab BIT

![](media/image71.wmf){width="5.002777777777778in"
height="2.779166666666667in"}

Fig. 8.B.8 -- Mean Scores for Exp.3 - AMRWB-12.65 in Lab FTRD

![](media/image72.wmf){width="5.002777777777778in"
height="2.8020833333333335in"}

Fig. 8.B.9 -- Mean Scores for Exp.3 - AMRWB-12.65 in Lab Dynastat

#### 8.B.4.2 Subject Consistency Measures for Test Labs

In most subjective tests there are repeated measures, which may be used
to evaluate the reliability of individual subject\'s performance in the
subjective task relative to that of other subjects in the test panel.
Furthermore, in those tests subjects hear and evaluate the same
materials and there is a basis to compare and evaluate their responses
across trials. For conversation tests, however, subjects don\'t have the
same materials on which to base their responses (i.e., each conversation
is unique) and there are no repeated measurers on which to evaluate
reliability (i.e., there is only one trial per test condition). The only
performance measure available for individual subjects within an
experiment is the correlation of their responses across trials with the
responses of the other subjects in the experiment. Table 2 shows the
average correlation (across subjects and across rating scales) for each
Test Lab and for each experiment within each lab. These values provide
an indication of the consistency of the responses across subjects within
an experiment. In general, the values are relatively low compared to
values typically obtained for other subjective tests --- for MOS tests
conducted by Dynastat, those average correlations are typically around
0.90.

Table 8.B.2 -- Consistency Measures by Lab and Experiment

![](media/image73.wmf){width="3.678472222222222in"
height="0.6770833333333334in"}

Since the same 16 test conditions were tested in each of the three
experiments, though with a different codec, the results across
experiments can be expected to be positively correlated. Table 3 shows
the intercorrelations across experiments for each of the five rating
scales for each of the three Test Labs. The correlations are very high,
especially for Labs Dynastat and FTRD, less so for Lab BIT. This finding
was encouraging but somewhat unexpected considering the relatively
narrow range of mean scores across test conditions, i.e., most mean
scores were between 3.0 and 4.5.

Table 8.B.3 -- Intercorrelations Across Experiments for the Five Rating
Scales for Each Lab

![](media/image74.wmf){width="6.502777777777778in"
height="1.6972222222222222in"}

#### 8.B.4.3 Multivariate Analysis of Variance (MANOVA)

The multiple rating scales used in conversation tests are designed to
capture different aspects of the conversation task, e.g., voice quality,
difficulty of understanding, level of effort, overall quality. In a
previous conversation testing exercise conducted by 3GPP/SA4 \[see
clause 7\] the rating scales were found to be highly intercorrelated and
multivariate analyses (i.e., **M**ultivariate **An**alysis **o**f
**Va**riance or **MANOVA**) revealed that there was only one underlying
variable that accounted for the significant variance in the five rating
scales. The MANOVA procedure also provides coefficients for weighting
the scores on the individual rating scales to produce a composite score
corresponding to the underlying variable. The use of such composite
scores makes it easier to compare test factors since the multiple
criterion variables often give ambiguous or even conflicting results.
Furthermore, the composite scores are more reliable than scores based on
a single criterion variable. For the results reported here, the GAL
conducted a MANOVA for each of the nine experiments involved in the
conversation test, where the independent variable was *Conditions*
(n=16) and the dependent variables were the five rating scales --- VQ,
UN, LE, DD, and OQ. The results of the MANOVA\'s showed that there was
more never than one significant composite variable in any experiment. In
five of the nine experiments (1F, 1D, 2F, 2D, 3D) there was a single
significant underlying variable (criterion = p\<0.05). Furthermore, in
one experiment (1B) the composite variable was close to significant
(p=0.08). In the three remaining experiments (2B, 3B, 3F) there was no
significant composite variable (p\>0.05). Nevertheless, in the interests
of a parsimonious solution, the GAL computed a composite variable for
each of the nine conversation tests based on results from the
appropriate MANOVA. Using the precedent set in the previous 3GPP
conversation tests, the GAL has labeled each composite variable as the
measure of *Conversational Quality* for the appropriate experiment.

##### 8.B.4.3.1 MANOVA Results and Statistics

The raw voting data from Exp.1, conducted at BIT, was subjected to
MANOVA to determine whether the scores for the five rating scales could
be represented by a smaller number of underlying variables. Table 4
shows the results of that MANOVA. The following description of Table 4
also applies to the MANOVA\'s for each of the other eight experiments.

Table 8.B.4 -- Results of MANOVA for Exp.1 -- AMR-5.9 -- Lab BIT

![](media/image75.wmf){width="6.496527777777778in"
height="1.3430555555555554in"}

The first step in the MANOVA process is to examine the intercorrelations
among the dependent variables for indications of underlying variables.
The left-hand side of Table 4 shows the intercorrelation matrix of the
five dependent variables across conditions for Exp.1 for Lab BIT. The
table shows a high degree of intercorrelation, indicating the presence
of a reduced set of underlying variables.

The right-hand side of Table 4 shows the results of the MANOVA for the
effects of *Conditions* (independent variable) x *Rating Scales*
(dependent variables). The top section of the table shows the
statistical test for the significance of the combination of dependent
variables. The Pillai Trace[^2] and the associated F-statistic is not
significant in this MANOVA, though it\'s probability (p=0.0801) is close
to the criterion for significance, p\<0.05. The bottom section of Table
4 shows the Chi-square tests of the MANOVA roots. It shows that only the
first root (1-5) is close to significant, indicating that a single
underlying variable accounts for the (almost) significant variation in
the dependent variables. The canonical coefficients for this root are
also shown in the table and are used to compute the composite dependent
variable that corresponds to the underlying variable. The probability of
the Chi-Square value for the initial root (Chi-square = 93.49, df = 75)
is similar to that of the Pillai Trace (i.e., p = 0.07). The probability
of the second root (2-5) is not even close to significance (p=0.8441).
The same applies to the succeeding roots, 3-5, 4-5, and 5-5. The
Canonical Coefficients for the first root are used to compute a weighted
average of the five dependent variables producing the composite
variable, labeled here as Conversational Quality for Exp.1-Lab BIT. The
same process is applied to the data for each of the other eight
experiments, producing a composite variable, or *Conversational Quality*
measure, for each experiment. Tables 5-12 summarize the results of
MANOVA for each of the other eight conversation tests, respectively.

Table 8.B.5 -- Results of MANOVA for Exp.1 -- AMR-5.9 -- Lab FTRD

![](media/image76.wmf){width="6.496527777777778in"
height="1.3541666666666667in"}

Table 8.B.6 -- Results of MANOVA for Exp.1 -- AMR-5.9 -- Lab Dynastat

![](media/image77.wmf){width="6.496527777777778in"
height="1.3541666666666667in"}

Table 8.B.7 -- Results of MANOVA for Exp.2 -- AMR12.2 -- Lab BIT

![](media/image78.wmf){width="6.496527777777778in"
height="1.3645833333333333in"}

Table 8.B.8 -- Results of MANOVA for Exp.2 -- AMR-12.2 -- Lab FTRD

![](media/image79.wmf){width="6.496527777777778in"
height="1.3645833333333333in"}

Table 8.B.9 -- Results of MANOVA for Exp.2 -- AMR-12.2 -- Lab Dynastat

![](media/image80.wmf){width="6.496527777777778in"
height="1.3645833333333333in"}

Table 8.B.10 -- Results of MANOVA for Exp.3 -- AMRWB-12.65 -- Lab BIT

![](media/image81.wmf){width="6.496527777777778in"
height="1.3645833333333333in"}

Table 8.B.11 -- Results of MANOVA for Exp.3 -- AMRWB-12.65 -- Lab FTRD

![](media/image82.wmf){width="6.496527777777778in"
height="1.3645833333333333in"}

Table 8.B.12 -- Results of MANOVA for Exp.3 -- AMRWB-12.65 -- Lab
Dynastat

![](media/image83.wmf){width="6.496527777777778in"
height="1.3645833333333333in"}

##### 8.B.4.3.2 Composite Scores -- Conversational Quality

The canonical coefficients for the first root were used as weighting
factors for the individual rating scales to compute a composite
variable, labeled here as *Conversational Quality* (CQ)[^3] for each
experiment. The CQ scores present a simplified method for evaluating the
results for each experiment. The validity of the CQ measures is a
function of the reliability of the MANOVA from which it was derived.
More confidence can be afforded to CQ values from those experiments with
a significant underlying variable (1B, 1F, 1D, 2F, 2D, 3D), less
confidence to those experiments with no significant underlying variable
(2B, 3B, 3F).

Table 13 shows Summary CQ results (Means and Standard Deviations) for
Exp.1. Tables 14 and 15 show results for Exp.2 and Exp.3, respectively.

Table 8.B.13 -- Conversational Quality Results for Exp.1 -- AMR-5.9

![](media/image84.wmf){width="4.5in" height="2.5006944444444446in"}

Table 8.B.14 -- Conversational Quality Results for Exp.2 -- AMR-12.2

![](media/image85.wmf){width="4.5in" height="2.495138888888889in"}

Table 8.B.15 -- Conversational Quality Results for Exp.3 -- AMRWB-12.65

![](media/image86.wmf){width="4.5in" height="2.484722222222222in"}

##### 8.B.4.3.3 Conversational Quality by Experimental Factors

The conversation tests were designed primarily to evaluate two
experimental factors, *Traffic* and *Mobility*, for each of three
codecs. The *Traffic* effect had two levels -- Low Traffic and High
Traffic. The *Mobility* effect had four levels -- LMLM, LMHM, HMLM,
and HMHM. In addition, the *Mobility* factor had two test conditions
(i.e., background noise conditions) representing each level of
inter-connection.

The experimental design of the conversation tests does not permit a
direct comparison of the effects of *Codecs,* since each codec was
evaluated in a separate conversation test using independent test panels.
The *Traffic* conditions were simulated by RNC settings in the test-bed.
The *Mobility* conditions were simulated by a combination of test-bed
RNC settings and background noise conditions in the test rooms. Each
mobility connection, e.g., LMHM, involved two different background
noise conditions and therefore the effects of Mobility connection and
background noise were confounded. This confounding means that the
effects of Mobility and background noise cannot be separated. For this
reason the results for the two background noise conditions were often
inconsistent for each level of Mobility.

**Figures 10-18 show the CQ results for each experiment involved in the
conversations tests. Each figure has two parts --- on the left are CQ
scores for every test condition, on the right are average scores for the
*Traffic* and *Mobility* factors. Each figure stands on it\'s own -- the
scale and origin of the CQ scales apply only to the specific experiment.
The caption in each figure indicates whether the CQ variable was
significant in the MANOVA from which it was derived. Figures 10-12 show
CQ scores for Exp.1 for Labs BIT, FTRD, and Dynastat, respectively.
Similarly, Figs. 13-15 show CQ scores for Exp.2, and Figs. 16-18 for
Exp.3.**

![](media/image87.wmf){width="3.1in" height="2.0083333333333333in"}
![](media/image88.wmf){width="3.098611111111111in"
height="2.029166666666667in"}

Fig.8.B.10 -- Conversation Quality Scores for Exp.1-AMR-5.9 for Lab BIT
(CQ was not significant, p=0.08)

![](media/image89.wmf){width="3.1041666666666665in"
height="2.0319444444444446in"}
![](media/image90.wmf){width="3.1055555555555556in"
height="2.0208333333333335in"}

Fig. 8.B.11 -- Conversation Quality Scores for Exp.1-AMR-5.9 for Lab
FTRD (CQ was significant, p\<0.05)

![](media/image91.wmf){width="3.1041666666666665in"
height="2.011111111111111in"}
![](media/image92.wmf){width="3.1013888888888888in"
height="2.0409722222222224in"}

Fig. 8.B.12 -- Conversation Quality Scores for Exp.1-AMR-5.9 for Lab
Dynastat (CQ was significant, p\<0.0001)

![](media/image93.wmf){width="3.1034722222222224in"
height="2.051388888888889in"}
![](media/image94.wmf){width="3.1055555555555556in"
height="2.001388888888889in"}

Fig. 8.B.13 -- Conversation Quality Scores for Exp.2-AMR-12.2 for Lab
BIT (CQ was not significant, p=0.28)

![](media/image95.wmf){width="3.102777777777778in"
height="2.0319444444444446in"}
![](media/image96.wmf){width="3.1055555555555556in"
height="2.0208333333333335in"}

Fig.8.B.14 -- Conversation Quality Scores for Exp.2-AMR-12.2 for Lab
FTRD (CQ was significant, p\<0.05)

![](media/image97.wmf){width="3.0944444444444446in" height="2.0in"}
![](media/image98.wmf){width="3.1034722222222224in"
height="2.020138888888889in"}

Fig. 8.B.15 -- Conversation Quality Scores for Exp.2-AMR-12.2 for Lab
Dynastat (CQ was significant, p\<0.0001)

![](media/image99.wmf){width="3.1041666666666665in"
height="2.0215277777777776in"}
![](media/image100.wmf){width="3.1055555555555556in"
height="2.020138888888889in"}

Fig. 8.B.16 -- Conversation Quality Scores for Exp.3-AMRWB-12.65 for Lab
BIT (CQ was not significant, p=0.55)

![](media/image101.wmf){width="3.1041666666666665in"
height="2.040277777777778in"}
![](media/image102.wmf){width="3.1034722222222224in"
height="2.0416666666666665in"}

Fig. 8.B.17 -- Conversation Quality Scores for Exp.3-AMRWB-12.65 for Lab
FTRD (CQ was not significant, p=0.67)

![](media/image103.wmf){width="3.1041666666666665in"
height="2.0006944444444446in"}
![](media/image104.wmf){width="3.1055555555555556in"
height="2.0409722222222224in"}

Fig. 8.B.18 -- Conversation Quality Scores for Exp.3-AMRWB-12.65 for Lab
Dynastat (CQ was significant, p\<0.0001)

### 8.B.5 Conversation tests conclusions

For the *Traffic* factor, the Conversational Quality results are
consistent and confirm expectations. For all three codecs and in all
three test-labs, CQ is numerically higher in Low Traffic conditions than
in High Traffic conditions. In general, the results of the Conversation
Tests show that the effects of *Traffic* on the performance of AMR and
AMR-WB for UMTS over HSDPA/EUL are relatively small.

For the *Mobility* factor, however, the results are not as consistent.
This is not surprising, since Mobility conditions were confounded with
background noise conditions.

It is important to note that the Conversational Quality scores computed
in this exercise are specific to the particular lab and the experiment
from which they are derived. Scores are not absolute and comparisons
across experiments are not valid. Furthermore, the variables underlying
the CQ scores were not significant in all experiments.

Overall, the performance of AMR and AMR-WB for UMTS over HSDPA/EUL is
robust under conditions of Traffic, Mobility, and Background noise
evaluated in the conversation tests.

9 Conclusions
=============

9.1 Tests over DCH radio channels
---------------------------------

The results from conversational tests on DCH channels confirm that the
default speech codecs (AMR-NB and AMR-WB) operate well for packet
switched conversational multimedia applications over various realistic
operating conditions (i.e. packet loss, delay, background noise, radio
conditions and ROHC).

The quality is somewhat reduced when packet losses occur and the
end-to-end delay is increased, but the overall quality still remains
acceptable even with 3% packet loss rate in the terrestrial IP network
and up to a maximum of 1% BLER on each radio leg. The results also
indicate that users have clear preference for AMR-WB speech over AMR-NB
speech.

9.2 Tests over HSDPA/EUL radio channels; listening only tests
-------------------------------------------------------------

The listening only test results for HSDPA/EUL radio channels indicate
that an adaptive JBM conforming to the MTSI performance requirements is
able to provide consistent voice quality over varying transmission
conditions. The test also shows that the performance of the JBM directly
impacts the voice quality. Furthermore, the test results indicate that
an adaptive JBM is needed to cope with the large variations in channel
delay.

9.3 Tests over HSDPA/EUL radio channels; conversation tests
-----------------------------------------------------------

Overall, the performance of AMR and AMR-WB for UMTS over HSDPA/EUL is
robust under conditions of Traffic, Mobility, and Background noise
evaluated in the conversation tests.

9.4 General consideration
-------------------------

The performance results can be used as guidance for network planning
regarding the QoS parameters for VoIP.

######### Annex A: Conversation test composite dependent variable scores by condition and Lab

![](media/image105.wmf){width="6.555555555555555in"
height="3.1680555555555556in"}

![](media/image106.wmf){width="6.555555555555555in"
height="1.2722222222222221in"}

![](media/image107.wmf){width="6.331944444444445in"
height="3.136111111111111in"}

![](media/image108.wmf){width="6.331944444444445in"
height="1.2152777777777777in"}

![](media/image109.wmf){width="4.883333333333334in"
height="2.8222222222222224in"}

######### Annex B: Instructions to subjects

In this experiment we are evaluating systems that might be used for
telecommunication services.

You are going to have a conversation with another user. The test
situation is simulating communications between two mobile phones. The
most of the situations will correspond to silent environment conditions,
but some other will simulate more specific situations, as in a car, or
in a railway station or in an office environment, when other people are
discussing in the background.

After the completion of each call conversation, you will have to give
your opinions on the quality, by answering to the following questions
that will be displayed on the screen of the black box in front of you.
Your judgment will be stored. You have 8 seconds to answer to each
question. After \"pressing\" the button on the screen, another question
will be displayed. You continue the procedure for the 5 following
questions.

  ------------------------------------------------------------------------ ------ ------ ------ -----
  Question 1: How do you judge the quality of the voice of your partner?                        
  Excellent                                                                Good   Fair   Poor   Bad
  ------------------------------------------------------------------------ ------ ------ ------ -----

  ---------------------------------------------------------------- ------- ----------- -------- -------
  Question 2: Do you have difficulties to understand some words?                                
  All the time                                                     Often   Sometimes   Rarely   Never
  ---------------------------------------------------------------- ------- ----------- -------- -------

  --------------------------------------------------------------------------------------- --------------------------------------------------------------------------------------------------------- ---------------------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------------------ ---------------------------------------------------------------------------
  Question 3: How did you judge the conversation when you interacted with your partner?                                                                                                                                                                                                                                                                                                                   
  Excellent interactivity (similar to face-to-face situation)                             Good interactivity (in few moments, you were talking simultaneously, and you had to interrupt yourself)   Fair interactivity (sometimes, you were talking simultaneously, and you had to interrupt yourself)   Poor interactivity (often, you were talking simultaneously, and you had to interrupt yourself)   Bad interactivity (it was impossible to have an interactive conversation)
  --------------------------------------------------------------------------------------- --------------------------------------------------------------------------------------------------------- ---------------------------------------------------------------------------------------------------- ------------------------------------------------------------------------------------------------ ---------------------------------------------------------------------------

  --------------------------------------------------------------------------------------- --------------------------------------- -------------------------------- ----------------------- ----------------------------
  Question 4: Did you perceive any impairment (noises, cuts,...)? In that case, was it:                                                                                                    
  No impairment                                                                           Slight impairment, but not disturbing   Impairment slightly disturbing   Impairment disturbing   Very disturbing Impairment
  --------------------------------------------------------------------------------------- --------------------------------------- -------------------------------- ----------------------- ----------------------------

  ----------------------------------------------------------------------- ------ ------ ------ -----
  Question 5: How do you judge the global quality of the communication?                        
  Excellent                                                               Good   Fair   Poor   Bad
  ----------------------------------------------------------------------- ------ ------ ------ -----

From then on you will have a break approximately every 30 minutes. The
test will last a total of approximately 60 minutes.

Please do not discuss your opinions with other listeners participating
in the experiment.

######### Annex C: Example Scenarios for the conversation test

The pretexts used for conversation test are those developed by the Ruhr
University (Bochum, Germany) within the context of ITU-T SG12. These
scenarios have been elaborated to allow a well-balanced conversation
within both participants and lasting approximately 2\'30 or 3\', and to
stimulate the discussion between persons that know each other to
facilitate the naturalness of the conversation. They are derived from
typical situations of every day life: railways inquiries, rent a car or
an apartment, etc. Each condition should be given a different scenario.

Examples coming from ITU-T SG 12 COM12-35 \"Development of scenarios for
short conversation test\", 1997

**[Scenario 1: Pizza service]{.underline}**

[Subject 1:]{.underline}

[]{.underline}

+----------------------------------+----------------------------------+
| Your Name:                       | Clemence                         |
+----------------------------------+----------------------------------+
| Reason for the call              | 1 large Pizza                    |
+----------------------------------+----------------------------------+
| Condition which should be        | For 2 people,                    |
| applied to the exchange of       |                                  |
| information                      | Vegetarian pizza preferred       |
+----------------------------------+----------------------------------+
| Information you want to receive  | Topping                          |
| from your partner                |                                  |
|                                  | Price                            |
+----------------------------------+----------------------------------+
| Information that your partner    | Delivery address : 41 industry   |
| requires                         | street, Oxford                   |
|                                  |                                  |
|                                  | Phone : 7 34 20                  |
+----------------------------------+----------------------------------+
| Question to which neither you    | How long will it take?           |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

[Subject 2:]{.underline}

[]{.underline}

+----------------+----------------+----------+-----------+-----------+
| Your Name :    | Pizzeria Roma  |          |           |           |
+----------------+----------------+----------+-----------+-----------+
| Information    | Pizzas         | 1 person | 2 persons | 4 persons |
| from which you |                |          |           |           |
| should select  |                |          |           |           |
| the details    |                |          |           |           |
| which your     |                |          |           |           |
| partner        |                |          |           |           |
| requires       |                |          |           |           |
+----------------+----------------+----------+-----------+-----------+
|                | Toscana (ham,  | 3.2£     | 5.95£     | 10.5£     |
|                | mushrooms,     |          |           |           |
|                | tomatoes,      |          |           |           |
|                | cheese)        |          |           |           |
+----------------+----------------+----------+-----------+-----------+
|                | Tonno (Tuna,   | 3.95£    | 7.5£      | 13.95£    |
|                | onions,        |          |           |           |
|                | tomatoes,      |          |           |           |
|                | cheese)        |          |           |           |
+----------------+----------------+----------+-----------+-----------+
|                | Fabrizio       | 4.2£     | 7.95£     | 14.95£    |
|                | (salami, ham,  |          |           |           |
|                | tomatoes,      |          |           |           |
|                | cheese)        |          |           |           |
+----------------+----------------+----------+-----------+-----------+
|                | Vegetarian     | 4.5£     | 8.5£      | 15.95£    |
|                | (spinach,      |          |           |           |
|                | mushrooms,     |          |           |           |
|                | tomatoes,      |          |           |           |
|                | cheese)        |          |           |           |
+----------------+----------------+----------+-----------+-----------+
| Information    | Name           |          |           |           |
| you want to    |                |          |           |           |
| receive from   | address        |          |           |           |
| your partner   |                |          |           |           |
|                | telephone      |          |           |           |
|                | number         |          |           |           |
+----------------+----------------+----------+-----------+-----------+
| Question to    |                |          |           |           |
| which neither  |                |          |           |           |
| you nor your   |                |          |           |           |
| partner will   |                |          |           |           |
| have           |                |          |           |           |
| information.   |                |          |           |           |
|                |                |          |           |           |
| You should     |                |          |           |           |
| discuss and    |                |          |           |           |
| find a         |                |          |           |           |
| solution that  |                |          |           |           |
| is acceptable  |                |          |           |           |
| to both of     |                |          |           |           |
| you.           |                |          |           |           |
+----------------+----------------+----------+-----------+-----------+

**[Scenario 2 : Information on flights]{.underline}**

[Subject 1:]{.underline}

[]{.underline}

+----------------------------------+----------------------------------+
| Your Name:                       | Parker                           |
+----------------------------------+----------------------------------+
| Reason for the call              | Intended journey: London         |
|                                  | Heathrow àDüsseldorf             |
+----------------------------------+----------------------------------+
| Condition which should be        | On June 23rd,                    |
| applied to the exchange of       |                                  |
| information                      | Morning flight,                  |
|                                  |                                  |
|                                  | Direct flight preferred          |
+----------------------------------+----------------------------------+
| Information you want to receive  | Departure:                       |
| from your partner                |                                  |
|                                  | Arrival                          |
|                                  |                                  |
|                                  | Flight number                    |
+----------------------------------+----------------------------------+
| Information that your partner    | Reservation: 1 seat, Economy     |
| requires                         | class                            |
|                                  |                                  |
|                                  | Address: 66 middle street,       |
|                                  | Sheffield                        |
|                                  |                                  |
|                                  | Phone: 21 08 33                  |
+----------------------------------+----------------------------------+
| Question to which neither you    | From which airport is it easier  |
| nor your partner will have       | to get into Cologne center :     |
| information.                     | Düsseldorf or Cologne/Bonn       |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

[Subject 2:]{.underline}

[]{.underline}

+--------------+--------------+-----------+--------------+-----------+
| Your Name :  | Heathrow     |           |              |           |
|              | flight       |           |              |           |
|              | information  |           |              |           |
+--------------+--------------+-----------+--------------+-----------+
| Information  | Flight       | Lufthansa | British      | Lufthansa |
| from which   | schedule     |           | Airways      |           |
| you should   |              |           |              |           |
| select the   |              |           |              |           |
| details      |              |           |              |           |
| which your   |              |           |              |           |
| partner      |              |           |              |           |
| requires     |              |           |              |           |
+--------------+--------------+-----------+--------------+-----------+
|              | Flight       | LH 2615   | BA 381       | LH 413    |
|              | number       |           |              |           |
+--------------+--------------+-----------+--------------+-----------+
|              | London       | 6:30      | 6:35         | 8:20      |
|              | Heathrow     |           |              |           |
|              | departure    |           |              |           |
+--------------+--------------+-----------+--------------+-----------+
|              | Brussels     |           | 7:35         |           |
|              | arrival      |           |              |           |
|              |              |           | 8:00         |           |
|              | Brussels     |           |              |           |
|              | departure    |           |              |           |
+--------------+--------------+-----------+--------------+-----------+
|              | Düsseldorf   | 7:35      | 9:05         | 9:25      |
|              | arrival      |           |              |           |
+--------------+--------------+-----------+--------------+-----------+
| Information  | Name         |           |              |           |
| you want to  |              |           |              |           |
| receive from | address      |           |              |           |
| your partner |              |           |              |           |
|              | telephone    |           |              |           |
|              | number       |           |              |           |
|              |              |           |              |           |
|              | number of    |           |              |           |
|              | seats        |           |              |           |
|              |              |           |              |           |
|              | Class:       |           |              |           |
|              | Business or  |           |              |           |
|              | Economy      |           |              |           |
+--------------+--------------+-----------+--------------+-----------+
| Question to  |              |           |              |           |
| which        |              |           |              |           |
| neither you  |              |           |              |           |
| nor your     |              |           |              |           |
| partner will |              |           |              |           |
| have         |              |           |              |           |
| information. |              |           |              |           |
|              |              |           |              |           |
| You should   |              |           |              |           |
| discuss and  |              |           |              |           |
| find a       |              |           |              |           |
| solution     |              |           |              |           |
| that is      |              |           |              |           |
| acceptable   |              |           |              |           |
| to both of   |              |           |              |           |
| you.         |              |           |              |           |
+--------------+--------------+-----------+--------------+-----------+

######### Annex D: Test Plan for the AMR Narrow-Band Packet Switched Conversation Test

Source: Siemens[^4], France Telecom[^5]

Title: Test Plan for the AMR Narrow-Band Packet switched Conversation
Test

Document for: Approval

Agenda Item: 14.1

1\. Introduction

This document contains the test plan of one conversation test for the
Adaptive Multi-Rate Narrow-Band (AMR-NB) in Packet Switched networks.

All the laboratories participating to this conversation test phase will
use the same test plan, just the language of the conversation would
change.

Even if the test rooms or the test equipments are not exactly the same
in all the laboratories, the calibration procedures and the tests
equipment characteristics and performance (as defined in this document)
will guarantee the similarity of the test conditions.

Section 2 gives references, conventions and contacts, section 3 details
the test methodology, including test arrangement and test procedure, and
section 4 defines the financial considerations.

Annex A contains the instructions for the subjects participating to the
conversation tests.

Annex B contains the description of results to be provided to the
Analysis Laboratory (if any) by the testing laboratories.

Annex C contains the list of statistical comparisons to be performed.

Considerations about IPV6 versus IPV4 are given in section 3.2.

RoHC is not implemented in AMR-NB conversation test. The effect of RoHC
should be extrapolated from the results observed in AMR-WB conversation
test.

2\. References, Conventions, and Contacts

2.1Permanent Documents

+---+-----------------+--------------------+--------------------+
|   | ITU-T Rec.P.800 | Methods for        |                    |
|   |                 | Subjective         |                    |
|   |                 | Determination of   |                    |
|   |                 | Transmission       |                    |
|   |                 | Quality            |                    |
+---+-----------------+--------------------+--------------------+
|   | ITU-T           | **Subjective       | **This             |
|   |                 | performance**      | Recommendation     |
|   | Rec. P.831      |                    | defines            |
|   |                 | **evaluation of    | conversation test  |
|   |                 | network echo       | procedures based   |
|   |                 | cancellers**       | on handset         |
|   |                 |                    | telephones, and    |
|   |                 |                    | gives inputs for   |
|   |                 |                    | the calibration.** |
+---+-----------------+--------------------+--------------------+

2.2 Key Acronyms

  -------- ---------------------------------------------
  AMR-NB   Adaptive Multi-Rate Narrowband Speech Codec
  AMR-WB   Adaptive Multi-Rate Wide-band Speech Codec
  MOS      Mean Opinion Score
  -------- ---------------------------------------------

2.3 Contact Names

The following persons should be contacted for questions related to the
test plan.

+-------------+-------------+-------------+-------------+-------------+
| **Section** | **Contact   | **Org       | **Address** | **Tele      |
|             | Per         | anisation** |             | phone/Fax** |
|             | son/Email** |             |             |             |
+-------------+-------------+-------------+-------------+-------------+
| Experiments | J-Y Monfort | France      | 2, Avenue   | Tel :       |
| and results |             | Telecom R&D | P. Marzin,  | +           |
| analysis    |             |             |             | 33296053171 |
|             |             |             | 22307       |             |
|             |             |             | Lannion     | Fax :       |
|             |             |             | Cédex       | +           |
|             |             |             |             | 33296051316 |
|             |             |             | France      |             |
+-------------+-------------+-------------+-------------+-------------+
| AOB         | Paolo Usai\ | ETSI MCC    | 650 Route   | Tel: 33     |
|             | paolo.us    |             | des         | (0)4 92 94  |
|             | ai\@etsi.fr |             | Lucioles\   | 42 36\      |
|             |             |             | 06921       | Fax: 33     |
|             |             |             | Sophia      | (0)4 93 65  |
|             |             |             | Antipolis   | 28 17       |
|             |             |             | Cedex\      |             |
|             |             |             | France      |             |
+-------------+-------------+-------------+-------------+-------------+

2.4 Responsibilities

Each test laboratory has the responsibility to organize its conversation
tests.

The list of Test laboratories participating to the conversation test
phase.

  --------- ------------- -------------- -------------------------- ---------------
  **Lab**   **Company**   **Language**   **Statistical analysis**   **Reporting**
  1         LAB1                                                    
  2         LAB2                                                    
  --------- ------------- -------------- -------------------------- ---------------

3\. Test methodology

3.1 Introduction

The protocol described below evaluates the effect of degradation such as
delay and dropped packets on the quality of the communications. It
corresponds to the conversation-opinion tests recommended by the ITU-T
P.800 \[1\]. First of all, conversation--opinion tests allow subjects
passing the test to be in a more realistic situation, close to the
actual service conditions experienced by telephone customers. In
addition, conversation-opinion tests are suited to assess the effects of
impairments that can cause difficulty while conversing (such as delay).

Subjects participate to the test by couple; they are seated in separate
sound-proof rooms and are asked to hold a conversation through the
transmission chain performed by means of UMTS simulators and
communications are impaired by means of an IP impairments simulator part
of the CN simulator and by the air interface simulator, as the figure
below describes it.

The network configurations (including the terminal equipments) will be
symmetrical (in the two transmission paths). The only dissymmetry will
be due to presence of background noise in one of the test rooms.

3.2 Test arrangement

3.2.1 Description of the proposed testing system

This contribution describes a UMTS simulator for the characterization of
the AMR speech codecs when the bitstream is transmitted over a PS
network. The procedure to do the conversational listening test has been
earlier described in \[1\].

Figure 1 describes the system that is going to be simulated:

![](media/image110.png){width="6.354861111111111in"
height="3.4993055555555554in"}

Figure 1: Packet switch audio communication simulator

This will be simulated using 5 PCs as shown in Figure 2.

![](media/image111.png){width="6.343055555555556in"
height="2.9069444444444446in"}

Figure 2: Simulation Platform

PC 1 and PC 5: PCs under Windows OS with VOIP Terminal Simulator
Software of France Telecom R&D.

PC 2 and PC 4: PCs under Linux OS with Air Interface Simulator of
Siemens AG.

PC 3: PCs under WinNT OS with Network Simulator Software (NetDisturb).

[Basic Principles:]{.underline}

The platform simulates a packet switch interactive communication between
two users using PC1 and PC5 as their relatives VOIP terminals. PC1 sends
AMR encoded packets that are encapsulated using IP/UDP/RTP headers to
PC5. PC1 receives these IP/UDP/RTP audio packets from PC5.

In fact, the packets created in PC1 are sent to PC2. PC2 simulates the
air interface Up Link transmission and then forwards the transmitted
packets to PC4.

In the same way, PC4 simulates the air interface Down Link transmission
and then forwards the packets to PC5. PC5 decodes and plays the speech
back to the listener.

3.2.2 France Telecom Network simulator

The core network simulator, as implemented, works under IPv4.

However, as the core network simulator acts only on packets (loss,
delay,...) the use of Ipv4 or Ipv6 is equivalent for this test
conversation context. Considering the networks perturbations introduced
by the simulator and the context of the interactive communications, the
simulation using IPv4 perturbation network simulator is adapted to
manage and simulate the behaviours of an IPv6 core network.

Figure 3 shows the possible parameters that can be modified.

![](media/image5.png){width="6.573611111111111in"
height="3.9180555555555556in"}

Figure 3: IP simulator interface

On both links, one can choose delay and loss laws. Both links can be
treated separately or on the same way. For example, delay can be set to
a fixed value but can also be set to another law such as exponential
law.

3.2.3 UMTS simulator choices

The transmission of IP/UDP/RTP/AMR packets over the UMTS air interface
is simulated using the RAB described in Section 3.2.3.1 The required
functions of the RLC layer are implemented according to TS 25.322 and
work in real-time. The underlying Physical Layer is simulated offline.
Error patterns of block errors (i.e. discarded RLC PDUs) are inserted in
the real-time simulation as described in Section 3.2.3.2 For more
details on the parameter settings of the Physical Layer simulations see
Section3.2.3.3

3.2.3.1 RAB and protocols

For our conversational tests, the AMR will encode speech at a maximum of
12.2 kbit/s. The bitstream will be encapsulated using IP/UDP/RTP
protocols. The air interface simulator will receive IPv4 (or IPv6)
packets from the CN simulator. The RTP packets will be extracted and
before transmission over the air interface, IPv6 headers will be
inserted. Finally real IPv6 packets are transmitted over the air
interface simulator.

The payload Format should be the following:

\- RTP Payload Format for AMR-NB (RFC 3267) will be used;

\- Bandwidth efficient mode will be used;

\- One speech frame shall be encapsulated in each RTP packet;

\- Interleaving will not be used;

The payload header will then consist of the 4 bits of the CMR (Codec
Mode Request). Then 6 bits is added for the ToC (Table of Content). For
IPv4, this corresponds to a maximum of 72 bytes per frame that is to say
28.8 kbit/s, this goes up to 92 bytes (36.8 kbit/s) when using IPv6
protocol on the air interface.

RTCP packets will be sent. However, in the test conditions defined in
the conversation test plans, RTCP is not mandatory, as it is not in a
multicast environment (see IETF rfc 1889) we are not going to make use
of the RTCP reports.

ROHC is an optional functionality in UMTS. In order to reduce the size
of the tests and the number of condition ROHC algorithm will not be used
for AMR-NB conversation test. This functionality will only be tested in
the wideband condition. The Conversational / Speech / UL:42.8 DL:42.8
kbps / PS RAB RAB coming from TS 34.108 v4.7.0 will be used:

Here is the RAB description:

  -------------- ------------------------------------------------------------- --------------- -------
  Higher layer   RAB/Signalling RB                                             **RAB**         
  PDCP           PDCP header size, bit                                         8               
  RLC            Logical channel type                                          DTCH            
                 RLC mode                                                      UM              
                 Payload sizes, bit                                            920, 304, 96    
                 Max data rate, bps                                            46000           
                 UMD PDU header, bit                                           8               
  MAC            MAC header, bit                                               0               
                 MAC multiplexing                                              N/A             
  Layer 1        TrCH type                                                     DCH             
                 TB sizes, bit                                                 928, 312, 104   
                 TFS                                                           TF0, bits       0x928
                                                                               TF1, bits       1x104
                                                                               TF2, bits       1x312
                                                                               TF3, bits       1x928
                 TTI, ms                                                       20              
                 Coding type                                                   TC              
                 CRC, bit                                                      16              
                 Max number of bits/TTI after channel coding                   2844            
                 Uplink: Max number of bits/radio frame before rate matching   1422            
                 RM attribute                                                  180-220         
  -------------- ------------------------------------------------------------- --------------- -------

3.2.3.2 Description of the RLC implementation

The UMTS air interface simulator (PC 2 and 4) receives IP/UDP/RTP/AMR
packets on a specified port of the network card (see Figure 4). The
IP/UDP/RTP/AMR packets are given to the transmission buffer of the RLC
layer, which works in UM. The RLC will segment or concatenate the IP
bitstream in RLC PDUs, adding appropriate RLC headers (sequence number
and length indicators). It is assumed that always Transport Format TF 3
is chosen on the physical layer, providing an RLC PDU length including
header of 928 bits. In the regular case, one IP packet is placed into an
RLC PDU that is filled up with padding bits. Due to delayed packets from
the network simulator it may also occur that there are more than one IP
packets in the RLC transmission buffer to transmit in the current TTI.

Each TTI of 20ms, an RLC PDU is formed. It is then given to the error
insertion block that decides if the RLC PDU is transmitted successfully
over the air interface or if it is discarded due to a block error after
channel decoding. The physical layer will not be simulated in real time,
but error pattern files will be provided. The error patterns of the air
interface transmission will be simulated according to the settings given
in Section 0. They consist of binary decisions for each transmitted RLC
PDU, resulting in a certain BLER.

After the error pattern insertion, the RLC of the air interface receiver
site receives RLC PDUs in the reception buffer. The sequence numbers of
the RLC headers are checked to detect when RLC PDUs have been discarded
due to block errors. A discarded RLC PDU will result in one or more lost
IP packets, resulting in a certain packet loss rate of the IP packets
and thereby in a certain FER of the AMR frames. The IP/UDP/RTP/AMR
packets are reassembled and transmitted to the next PC. This PC is
either the network simulator (PC 3) in case of uplink transmission, or
it is one of the terminals (PC 1 or 5) in case of downlink transmission.

![](media/image112.wmf){width="6.625in" height="4.749305555555556in"}

Figure 4: UMTS air interface simulation

3.2.3.3 Physical Layer Implementation

The parameters of the physical layer simulation were set according to
the parameters for a DCH in multipath fading conditions given in TS
34.121 (downlink) and TS 25.141 (uplink). The TB size is 928 bits and
the Turbo decoder uses the Log-MAP algorithm with 4 iterations. The rake
receiver has 6 fingers at 60 possible positions.

The different channel conditions given in **Table 1**, **Table 2**, and
**Table 3** were extracted from TR 101 112 (Selection procedures for the
choice of radio transmission technologies of the UMTS) and also
mentioned in the annex of the document S4-020680.

  ----- --------------- ------------- ----------
  Tap   Channel A       Doppler       

        Rel~.~ Delay\   Avg. Power\   Spectrum
        (nsec)          (dB)          

  1     0               0             FLAT

  2     50              -3.0          FLAT

  3     110             -10.0         FLAT

  4     170             -18.0         FLAT

  5     290             -26.0         FLAT

  6     310             -32.0         FLAT
  ----- --------------- ------------- ----------

**Table 1:** Indoor Office Test Environment Tapped-Delay-Line Parameters

  ----- ------------------- ----------------- ----------
  Tap   Channel A           Doppler           
        Rel. Delay (nsec)   Avg. Power (dB)   Spectrum
  1     0                   0.0               CLASSIC
  2     310                 -1.0              CLASSIC
  3     710                 -9.0              CLASSIC
  4     1090                -10.0             CLASSIC
  5     1730                -15.0             CLASSIC
  6     2510                -20.0             CLASSIC
  ----- ------------------- ----------------- ----------

**Table 2:** Vehicular Test Environment, High Antenna, Tapped-Delay-Line
Parameters

  ----- ------------------- ----------------- ----------
  Tap   Channel A           Doppler           
        Rel. Delay (nsec)   Avg. Power (dB)   Spectrum
  1     0                   0                 CLASSIC
  2     110                 -9.7              CLASSIC
  3     190                 -19.2             CLASSIC
  4     410                 -22.8             CLASSIC
  5     \-                  \-                CLASSIC
  6     \-                  \-                CLASSIC
  ----- ------------------- ----------------- ----------

**Table 3:** Outdoor to Indoor and Pedestrian Test Environment
Tapped-Delay-Line Parameters

**Table 4** (DL) and **Table 5** (UL) show approximate results of the
air interface simulation for ![](media/image113.wmf){width="0.75625in"
height="0.39861111111111114in"} and E~b~/N~0~ corresponding to the
considered BLERs.

  ----------------------------------------------------------------------------------------------------------------------- --------------- --------------- --------------- ---------------
                                                                                                                          **BLER**                                        
  **Channel**                                                                                                             **5\*10^-2^**   **1\*10^-2^**   **1\*10^-3^**   **5\*10^-4^**
  Indoor, 3 km/h (![](media/image114.wmf){width="0.4861111111111111in" height="0.2361111111111111in"}= 9 dB)              -13.1 dB        -8.9 dB         -3.4 dB         -2.4 dB
  Outdoor to Indoor, 3 km/h (![](media/image114.wmf){width="0.4861111111111111in" height="0.2361111111111111in"}= 9 dB)   -13.2 dB        -9.7 dB         -5.9 dB         -5.2 dB
  Vehicular, 50 km/h (![](media/image114.wmf){width="0.4861111111111111in" height="0.2361111111111111in"}= -3 dB)         -9.35 dB        -8.2 dB         -6.9 dB         -6.55 dB
  Vehicular, 120 km/h (![](media/image114.wmf){width="0.4861111111111111in" height="0.2361111111111111in"}= -3 dB)        -9.7 dB         -8.95 dB        -7.95 dB        -7.55 dB
  ----------------------------------------------------------------------------------------------------------------------- --------------- --------------- --------------- ---------------

**Table 4:** Downlink performance - approximately
![](media/image113.wmf){width="0.75625in"
height="0.39861111111111114in"} for the different channels and BLER

  --------------------------- --------------- --------------- --------------- ---------------
                              **BLER**                                        
  **Channel**                 **5\*10^-2^**   **1\*10^-2^**   **1\*10^-3^**   **5\*10^-4^**
  Indoor, 3 km/h              3.9 dB          6.4 dB          9.2 dB          9.8 dB
  Outdoor to Indoor, 3 km/h   3.7 dB          6.1 dB          8.6 dB          9.2 dB
  Vehicular, 50 km/h          -0.9 dB         -0.15 dB        0.55 dB         0.75 dB
  Vehicular, 120 km/h         0.2 dB          0.6 dB          1.1 dB          1.3 dB
  --------------------------- --------------- --------------- --------------- ---------------

**Table 5:** Uplink performance - approximately E~b~/N~0~ for the
different channels and BLER

3.2.4 Headsets and Sound Card

To avoid echo problems, it has been decided to use headsets, instead of
handsets. The monaural headsets are connected to the sound cards of the
PCs supporting the AMR simulators.

The sound level in the earphones can be adjusted, if needed, by the
users. But, in practice, the original settings, defined during the
preliminary tests, and producing a comfortable listening level, will not
be modified. The microphones are protected by a foam ball in order to
reduce the \"pop\" effect. It is also suggested to the user to avoid to
place the acoustic opening of the microphone in front of the mouth.

3.2.5 Test environment

Each of the two subjects participating to the conversations is installed
in a test room. They sit on an armchair, in front of a table. The test
rooms are acoustically insulated. All the test equipments are installed
in a third room, connected to the test rooms. When needed, the
background noise is generated in the appropriate test room through a set
of 4 loudspeakers. The background noise level is adjusted and controlled
by a sound level meter. The measurement microphone, connected to the
Sound level meter is located at the equivalent of the center of the
subject\'s head. The noise level is A weighted.

3.2.6 Calibration and test conditions monitoring

Speech level

Before the beginning of a set of experiment, the end to end transmission
level is checked subjectively, to ensure that there is no problem. If it
is necessary to check the speech level following procedure will apply.
An artificial mouth placed in front of the microphone of the Headset A,
in the LRGP position -See ITU-T Rec. P.64-, generates in the artificial
ear (according to ITU-T Rec. P57) coupled to the earphone of the Head
set B the nominal level defined in section 4.3. If necessary, the level
is adjusted with the receiving volume control of the headset. The
similar calibration is done by inverting headsets A and B.

Delay

The overall delay (from the input of sound card A to the output of sound
card B) will be evaluated for each test condition.

The hypothetical delay is calculated as shown :

On the air interface side, the simulator only receives packets on its
network card, process them and transmits every 20 ms these packets to
the following PC. Only processing delay and a possible delay due to a
jitter can be added (a packet arrives just after the sending window of
the air interface).

The hypothetical delay is calculated as shown :

On encoder side, delay have to take into account framing, look-ahead,
processing and packetization: 45ms

Uplink delay between UE and Iu: 84.4 ms (see TR25.853)

Core network delay: a few ms

Routing through IP: depending on the number of routers.

Downlink delay between Iu and Ue: 71.8 ms (see TR25.853)

And delay on decoder side, taking into account jitter buffer,
de-packetization and processing, 40 ms

The total delay to be considered is at least: 241.2 ms

3.3 Test Conditions

Based on circuit switched testing experiments, SA4 expects AMR 4.75 kb/s
to provide insufficient quality for conversational applications. SA4
does not recommend testing AMR 4.75kb/s, this mode is considered as fall
back solution in case of poor radio conditions.

+----------+----------+----------+----------+----------+----------+
| **Con    | **Ad     | **Ad     | **Expe   |          |          |
| dition** | ditional | ditional | rimental |          |          |
|          | Ba       | Ba       | actors** |          |          |
|          | ckground | ckground |          |          |          |
|          | noise**  | noise**  |          |          |          |
|          |          |          |          |          |          |
|          | **Room   | **Room   |          |          |          |
|          | A**      | B**      |          |          |          |
+----------+----------+----------+----------+----------+----------+
|          |          |          | Radio    | IP       | Mode     |
|          |          |          | co       | co       |          |
|          |          |          | nditions | nditions | \+       |
|          |          |          |          | (Packet  |          |
|          |          |          |          | loss     | delay    |
|          |          |          |          | ratio)   |          |
+----------+----------+----------+----------+----------+----------+
| 1        | No       | No       | 10 ^--2^ | 0%       | 6        |
|          |          |          |          |          | ,7kbit/s |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 2        | No       | No       | 10 ^--2^ | 0%       | 12.2     |
|          |          |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 500 ms)  |
+----------+----------+----------+----------+----------+----------+
| 3        | No       | No       | 10 ^--2^ | 0%       | 12,2     |
|          |          |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 4        | No       | No       | 10 ^--2^ | 3%       | 6        |
|          |          |          |          |          | ,7kbit/s |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 5        | No       | No       | 10 ^--2^ | 3%       | 12.2kbit |
|          |          |          |          |          | /s(delay |
|          |          |          |          |          | 500 ms)  |
+----------+----------+----------+----------+----------+----------+
| 6        | No       | No       | 10 ^--2^ | 3%       | 12,2     |
|          |          |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 7        | No       | No       | 10^-3^   | 0%       | 6        |
|          |          |          |          |          | ,7kbit/s |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 8        | No       | No       | 10^-3^   | 0%       | 12.2kbit |
|          |          |          |          |          | /s(delay |
|          |          |          |          |          | 500 ms)  |
+----------+----------+----------+----------+----------+----------+
| 9        | No       | No       | 10^-3^   | 0%       | 12,2     |
|          |          |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 10       | No       | No       | 10^-3^   | 3%       | 6        |
|          |          |          |          |          | ,7kbit/s |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 11       | No       | No       | 10^-3^   | 3%       | 12.2kbit |
|          |          |          |          |          | /s(delay |
|          |          |          |          |          | 500 ms)  |
+----------+----------+----------+----------+----------+----------+
| 12       | No       | No       | 10^-3^   | 3%       | 12,2     |
|          |          |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 13       | No       | No       | 5 10^-4^ | 0%       | 6        |
|          |          |          |          |          | ,7kbit/s |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 14       | No       | No       | 5 10^-4^ | 0%       | 12.2kbit |
|          |          |          |          |          | /s(delay |
|          |          |          |          |          | 500 ms)  |
+----------+----------+----------+----------+----------+----------+
| 15       | No       | No       | 5 10^-4^ | 0%       | 12,2     |
|          |          |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 16       | No       | No       | 5 10^-4^ | 3%       | 6        |
|          |          |          |          |          | ,7kbit/s |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 17       | No       | No       | 5 10^-4^ | 3%       | 12.ékbit |
|          |          |          |          |          | /s(delay |
|          |          |          |          |          | 500 ms)  |
+----------+----------+----------+----------+----------+----------+
| 18       | No       | No       | 5 10^-4^ | 3%       | 12,2     |
|          |          |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 19       | Car      | No       | 5 10^-4^ | 3%       | 12,2     |
|          |          |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 20       | No       | Car      | 5 10^-4^ | 3%       | 12,2     |
|          |          |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 21       | C        | No       | 5 10^-4^ | 0%       | 6,7      |
|          | afeteria |          |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 22       | No       | C        | 5 10^-4^ | 0%       | 6,7      |
|          |          | afeteria |          |          | kbit/s   |
|          |          |          |          |          | (delay   |
|          |          |          |          |          | 300 ms)  |
+----------+----------+----------+----------+----------+----------+
| 23       | Street   | No       | 5 10^-4^ | 0%       | 12.2kbit |
|          |          |          |          |          | /s(delay |
|          |          |          |          |          | 500 ms)  |
+----------+----------+----------+----------+----------+----------+
| 24       | No       | Street   | 5 10^-4^ | 0%       | 12.2kbit |
|          |          |          |          |          | /s(delay |
|          |          |          |          |          | 500 ms)  |
+----------+----------+----------+----------+----------+----------+

Noise types

  ---------------- --------------------
  **Noise type**   **Level (dB Pa A**
  Car              60
  Street           55
  Babble           50
  ---------------- --------------------

  ----------------------- ---- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Listening Level         1    79 dBSPL
  Listeners               32   Naïve Listeners
  Groups                  16   2 subjects/group
  Rating Scales           5    
  Languages               1    See table
  Listening System        1    Monaural headset (flat response in the audio bandwidth of interest: 50Hz-7kHz). The other ear is open.
  Listening Environment        Room Noise: Hoth Spectrum at 30dBA (as defined by ITU-T, Recommendation P.800, Annex A, section A.1.1.2.2.1 Room Noise, with table A.1 and Figure A.1), except when background noise is needed (see table)
  ----------------------- ---- ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Annex A Example Instructions for the conversation test

Table : Instructions to subjects.

+----------------------------------------------------------------------+
| **INSTRUCTIONS TO SUBJECTS**                                         |
|                                                                      |
| In this experiment we are evaluating systems that might be used for  |
| telecommunication services.                                          |
|                                                                      |
| You are going to have a conversation with another user. The test     |
| situation is simulating communications between two mobile phones.    |
| The most of the situations will correspond to silent environment     |
| conditions, but some other will simulate more specific situations,   |
| as in a car, or in a railway station or in an office environment,    |
| when other people are discussing in the background.                  |
|                                                                      |
| After the completion of each call conversation, you will have to     |
| give your opinions on the quality, by answering to the following     |
| questions that will be displayed on the screen of the black box in   |
| front of you. Your judgment will be stored. You have 8 seconds to    |
| answer to each question. After \"pressing\" the button on the        |
| screen, another question will be displayed. You continue the         |
| procedure for the 5 following questions.                             |
|                                                                      |
| Question 1: How do you judge the quality of the voice of your        |
| partner?                                                             |
|                                                                      |
|   ----------- ------ ------ ------ -----                             |
|   Excellent   Good   Fair   Poor   Bad                               |
|   ----------- ------ ------ ------ -----                             |
|                                                                      |
| Question 2: Do you have difficulties to understand some words?       |
|                                                                      |
|   -------------- ------- ------------------- -------- -------        |
|   All the time   Often   Some time to time   Rarely   Never          |
|   -------------- ------- ------------------- -------- -------        |
|                                                                      |
| Question 3: How did you judge the conversation when you interacted   |
| with your partner?                                                   |
|                                                                      |
| +------------+------------+------------+------------+------------+   |
| | Excellent  | Good       | Fair       | Poor       | Bad        |   |
| | int        | int        | int        | int        | int        |   |
| | eractivity | eractivity | eractivity | eractivity | eractivity |   |
| |            |            |            |            |            |   |
| | (similar   | (in few    | (          | (often,    | (it was    |   |
| | to         | moments,   | sometimes, | you were   | impossible |   |
| | fa         | you were   | you were   | talking    | to have an |   |
| | ce-to-face | talking    | talking    | simul      | i          |   |
| | situation) | simul      | simul      | taneously, | nteractive |   |
| |            | taneously, | taneously, | and you    | con        |   |
| |            | and you    | and you    | had to     | versation) |   |
| |            | had to     | had to     | interrupt  |            |   |
| |            | interrupt  | interrupt  | yourself)  |            |   |
| |            | yourself)  | yourself)  |            |            |   |
| +------------+------------+------------+------------+------------+   |
|                                                                      |
| Question 4: Did you perceive any impairment (noises, cuts,...)? In   |
| that case, was it:                                                   |
|                                                                      |
|   -----                                                              |
| ---------- --------------------------------------- ----------------- |
| --------------- ----------------------- ---------------------------- |
|   No                                                                 |
| impairment   Slight impairment, but not disturbing   Impairment slig |
| htly disturbing   Impairment disturbing   Very disturbing Impairment |
|   -----                                                              |
| ---------- --------------------------------------- ----------------- |
| --------------- ----------------------- ---------------------------- |
|                                                                      |
| Question 5: How do you judge the global quality of the               |
| communication?                                                       |
|                                                                      |
|   ----------- ------ ------ ------ -----                             |
|   Excellent   Good   Fair   Poor   Bad                               |
|   ----------- ------ ------ ------ -----                             |
|                                                                      |
| From then on you will have a break approximately every 30 minutes.   |
| The test will last a total of approximately 60 minutes.              |
|                                                                      |
| Please do not discuss your opinions with other listeners             |
| participating in the experiment.                                     |
+----------------------------------------------------------------------+

Annex B: Example Scenarios for the conversation test

The pretexts used for conversation test are those developed by the Rurh
University (Bochum, Germany) within the context of ITU-T SG12 . These
scenarios have been elaborated to allow a conversation well balanced
within both participants and lasting approximately 2\'30 or 3\', and to
stimulate the discussion between persons that know each other to
facilitate the naturalness of the conversation. They are derived from
typical situations of every day life: railways inquiries, rent a car or
an apartment, etc. Each condition should be given a different scenario.

Examples coming from ITU-T SG 12 COM12-35 \"Development of scenarios for
short conversation test\", 1997

\- Scenario 1 : Pizza service

Subject 1:

+----------------------------------+----------------------------------+
| Your Name :                      | Clemence                         |
+----------------------------------+----------------------------------+
| Reason for the call              | 1 large Pizza                    |
+----------------------------------+----------------------------------+
| Condition which should be        | For 2 people,                    |
| applied to the exchange of       |                                  |
| information                      | Vegetarian pizza prefered        |
+----------------------------------+----------------------------------+
| Information you want to receive  | Topping                          |
| from your partner                |                                  |
|                                  | Price                            |
+----------------------------------+----------------------------------+
| Information that your partner    | Delivery address : 41 industry   |
| requires                         | street,Oxford                    |
|                                  |                                  |
|                                  | Phone : 7 34 20                  |
+----------------------------------+----------------------------------+
| Question to which neither you    | How long will it take?           |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

Subject 2:

+----------------------------------+----------------------------------+
| Your Name :                      | Pizzeria Roma                    |
+----------------------------------+----------------------------------+
| Information from which you       | <table>                          |
| should select the details which  | <tbody>                          |
| your partner requires            | <tr class="odd">                 |
|                                  | <td>Pizzas</td>                  |
|                                  | <td>1 person</td>                |
|                                  | <td>2 persons</td>               |
|                                  | <td>4 persons</td>               |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td><p>Toscana</p>               |
|                                  | <p>(ham, mush                    |
|                                  | rooms, tomatoes,cheese)</p></td> |
|                                  | <td>3.2£</td>                    |
|                                  | <td>5.95£</td>                   |
|                                  | <td>10.5£</td>                   |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <td><p>Tonno</p>                 |
|                                  | <p>(Tuna, on                     |
|                                  | ions, tomatoes, cheese)</p></td> |
|                                  | <td>3.95£</td>                   |
|                                  | <td>7.5£</td>                    |
|                                  | <td>13.95£</td>                  |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td><p>Fabrizio</p>              |
|                                  | <p>(salami                       |
|                                  | , ham, tomatoes, heese)</p></td> |
|                                  | <td>4.2£</td>                    |
|                                  | <td>7.95£</td>                   |
|                                  | <td>14.95£</td>                  |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <td><p>Vegetaria</p>             |
|                                  | <p>(spinach, mush                |
|                                  | rooms, tomatoes,cheese)</p></td> |
|                                  | <td>4.5£</td>                    |
|                                  | <td>8.5£</td>                    |
|                                  | <td>15.95£</td>                  |
|                                  | </tr>                            |
|                                  | </tbody>                         |
|                                  | </table>                         |
+----------------------------------+----------------------------------+
| Information you want to receive  | Name                             |
| from your partner                |                                  |
|                                  | address                          |
|                                  |                                  |
|                                  | telephone number                 |
+----------------------------------+----------------------------------+
| Question to which neither you    |                                  |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

\- Scenario 2 : Information on flights

Subject 1:

+----------------------------------+----------------------------------+
| Your Name :                      | Parker                           |
+----------------------------------+----------------------------------+
| Reason for the call              | Intended journey: London         |
|                                  | Heathrow  Düsseldorf            |
+----------------------------------+----------------------------------+
| Condition which should be        | On June 23th,                    |
| applied to the exchange of       |                                  |
| information                      | Morning flight,                  |
|                                  |                                  |
|                                  | Direct flight preferred          |
+----------------------------------+----------------------------------+
| Information you want to receive  | Departure :                      |
| from your partner                |                                  |
|                                  | Arrival                          |
|                                  |                                  |
|                                  | Flight number                    |
+----------------------------------+----------------------------------+
| Information that your partner    | Reservation : 1 seat, Economy    |
| requires                         | class                            |
|                                  |                                  |
|                                  | Address: 66 middle street,       |
|                                  | Sheffield                        |
|                                  |                                  |
|                                  | Phone: 21 08 33                  |
+----------------------------------+----------------------------------+
| Question to which neither you    | From which airport is it easier  |
| nor your partner will have       | to get into Cologne center :     |
| information.                     | Düsseldorf or Cologne/Bonn       |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

Subject 2:

+----------------------------------+----------------------------------+
| Your Name :                      | Heathrow flight information      |
+----------------------------------+----------------------------------+
| Information from which you       | <table>                          |
| should select the details which  | <tbody>                          |
| your partner requires            | <tr class="odd">                 |
|                                  | <td>Flight schedule</td>         |
|                                  | <td>Lufthansa</td>               |
|                                  | <td>British Airways</td>         |
|                                  | <td>Lufthansa</td>               |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td>Flight number</td>           |
|                                  | <td>LH 2615</td>                 |
|                                  | <td>BA 381</td>                  |
|                                  | <td>LH 413</td>                  |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <t                               |
|                                  | d>London Heathrow departure</td> |
|                                  | <td>6:30</td>                    |
|                                  | <td>6:35</td>                    |
|                                  | <td>8:20</td>                    |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td><p>Brussels arrival</p>      |
|                                  | <p>Brussels departure</p></td>   |
|                                  | <td></td>                        |
|                                  | <td><p>7:35</p>                  |
|                                  | <p>8:00</p></td>                 |
|                                  | <td></td>                        |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <td>Düsseldorf arrival</td>      |
|                                  | <td>7:35</td>                    |
|                                  | <td>9:05</td>                    |
|                                  | <td>9:25</td>                    |
|                                  | </tr>                            |
|                                  | </tbody>                         |
|                                  | </table>                         |
+----------------------------------+----------------------------------+
| Information you want to receive  | Name                             |
| from your partner                |                                  |
|                                  | address                          |
|                                  |                                  |
|                                  | telephone number                 |
|                                  |                                  |
|                                  | number of seats                  |
|                                  |                                  |
|                                  | Class : Business or Economy      |
+----------------------------------+----------------------------------+
| Question to which neither you    |                                  |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

ITU-T SG 12 COM12-35 \"Development of scenarios for short conversation
test\", 1997

Annex C: Results to be provided

For contractual purposes, the information which needs to be provided is
defined here.

The information required from each test Laboratory is a table containing
the following information for each of the conditions in the experiment:

The \"Mean Opinion Score (MOS)\" obtained for all the subjects.

When the conditions are symmetrical, the mean value is calculated from
all the result for the two test rooms..

For the dissymmetric conditions, the mean is calculated on the two test
conditions, each result cumulating the results obtained in each
condition of background noise.

The Standard Deviation of the \"MOS\" obtained for all the subjects, for
each test condition.

The specific statistical comparisons are specified in Annex C.

Annex D: Data analysis and presentation of results

D.1 Calculation of MOS and Standard Deviation

The (overall) MOS/DMOS for confounded subjects for condition C (Yc) can
then be obtained from:

![](media/image115.wmf){width="0.9118055555555555in"
height="0.4909722222222222in"}

The standard deviation (S) for condition C, denoted as Sc, can be
calculated as:

![](media/image116.wmf){width="0.20833333333333334in"
height="0.20833333333333334in"}=
![](media/image117.wmf){width="2.0277777777777777in"
height="0.5277777777777778in"}

Finally, the confidence interval (CI) at the (1-α) level can be
calculated for![](media/image118.wmf){width="0.5965277777777778in"
height="0.16666666666666666in"} as:

![](media/image119.wmf){width="1.1805555555555556in"
height="0.4166666666666667in"}

D.2 Presentation of Basic Statistical Results

The test results should be reported by the test Laboratory and the
Global Analysis Laboratory as follows:

Calculate and tabulate \"Mean Opinion Scores\" for the (opinion scales,
Standard Deviations and Confidence Intervals as shown in Table E.1.

**Table C.1 - Layout for presentation of test results.**

D.3 Thorough analysis

Two statistical analyses should be conducted on the data obtained with
these subjective scales. The first analysis consists in a Multiple
ANalysis OF VAriance (MANOVA), which globally indicates the possible
effect of the experimental factors (*i.e.*, different conditions). Then,
a specific ANOVA should be run on each dependent variable (the five
scales) to test if there is an effect of a specific experimental factor
for a given subjective variable. In other words, these statistical
analyses indicate if the differences observed between the MOS obtained
for the different conditions are significant, for one given dependant
variable (ANOVA) or for the whole of dependant variables (MANOVA).
Finally, Pearson\'s linear correlations should be computed between the
results of all subjective variables, to see which are those preponderant
or dependent on others.

######### Annex E: Test Plan for the AMR Wide-Band Packet Switched Conversation Test

Source: Siemens[^6], France Telecom[^7]

Title: Test Plan for the AMR Wide-Band Packet Switched Conversation Test

Document for: Approval

Agenda Item: 14.1

1\. Introduction

This document contains the test plan of a conversation test for the
Adaptive Multi-Rate Wide-Band (AMR-WB) in Packet Switched network.

All the laboratories participating to this conversation test phase will
use the same test plan just the language of the conversation would
change.

Even if the test rooms or the test equipments are not exactly the same
in all the laboratories, the calibration procedures and the tests
equipment characteristics and performance (as defined in this document)
will guarantee the similarity of the test conditions.

Section 2 gives references, conventions and contacts, section 3 details
the test methodology, including test arrangement and test procedure, and
section 4 defines the financial considerations.

Annex A contains the instructions for the subjects participating to the
conversation tests.

Annex B contains the description of results to be provided to the
Analysis Laboratory (if any) by the testing laboratories.

Annex C contains the list of statistical comparisons to be performed.

Considerations about IPV6 versus IPV4 are given in section 3.2.

RoHC is implemented for AMR-WB conversation test, but only for the
AMR-WB mode at 12,65 kbit/s

2\. References, Conventions, and Contacts

2.1Permanent Documents

+---+-----------------+--------------------+--------------------+
|   | ITU-T Rec.P.800 | Methods for        |                    |
|   |                 | Subjective         |                    |
|   |                 | Determination of   |                    |
|   |                 | Transmission       |                    |
|   |                 | Quality            |                    |
+---+-----------------+--------------------+--------------------+
|   | ITU-T           | **Subjective       | **This             |
|   |                 | performance**      | Recommendation     |
|   | Rec. P.831      |                    | defines            |
|   |                 | **evaluation of    | conversation test  |
|   |                 | network echo       | procedures based   |
|   |                 | cancellers**       | on handset         |
|   |                 |                    | telephones, and    |
|   |                 |                    | gives inputs for   |
|   |                 |                    | the calibration.** |
+---+-----------------+--------------------+--------------------+

2.2 Key Acronyms

  -------- ---------------------------------------------
  AMR-NB   Adaptive Multi-Rate Narrowband Speech Codec
  AMR WB   Adaptive Multi-Rate Wide-band Speech Codec
  MOS      Mean Opinion Score
  -------- ---------------------------------------------

2.3 Contact Names

The following persons should be contacted for questions related to the
test plan.

+-------------+-------------+-------------+-------------+-------------+
| **Section** | **Contact   | **Org       | **Address** | **Tele      |
|             | Per         | anisation** |             | phone/Fax** |
|             | son/Email** |             |             |             |
+-------------+-------------+-------------+-------------+-------------+
| Experiments | J-Y Monfort | France      | 2, Avenue   | Tel :       |
| and results |             | Telecom R&D | P. Marzin,  | +           |
| analysis    |             |             |             | 33296053171 |
|             |             |             | 22307       |             |
|             |             |             | Lannion     | Fax :       |
|             |             |             | Cédex       | +           |
|             |             |             |             | 33296051316 |
|             |             |             | France      |             |
+-------------+-------------+-------------+-------------+-------------+
| AOB         | Paolo Usai\ | ETSI MCC    | 650 Route   | Tel: 33     |
|             | paolo.us    |             | des         | (0)4 92 94  |
|             | ai\@etsi.fr |             | Lucioles\   | 42 36\      |
|             |             |             | 06921       | Fax: 33     |
|             |             |             | Sophia      | (0)4 93 65  |
|             |             |             | Antipolis   | 28 17       |
|             |             |             | Cedex\      |             |
|             |             |             | France      |             |
+-------------+-------------+-------------+-------------+-------------+

2.4 Responsibilities

Each test laboratory has the responsibility to organize its conversation
tests.

The list of Test laboratories participating to the conversation test
phase.

  --------- ------------- -------------- -------------------------- ---------------
                                                                    
  **Lab**   **Company**   **Language**   **Statistical analysis**   **Reporting**
  1         Lab1                                                    
  2         Lab2                                                    
  --------- ------------- -------------- -------------------------- ---------------

3\. Test methodology

3.1 Introduction

The protocol described below evaluates the effect of degradation such as
delay and dropped packets on the quality of the communications. It
corresponds to the conversation-opinion tests recommended by the ITU-T
P.800 \[1\]. First of all, conversation--opinion tests allow subjects
passing the test to be in a more realistic situation, close to the
actual service conditions experienced by telephone customers. In
addition, conversation-opinion tests are suited to assess the effects of
impairments that can cause difficulty while conversing (such as delay).

Subjects participate to the test by couple; they are seated in separate
sound-proof rooms and are asked to hold a conversation through the
transmission chain of the UMTS simulator Communications are impaired by
means of an IP impairments simulator simulator part of the CN simulator
and by the air interface simulator, as the figure below describes it.

The network configurations (including the terminal equipments) will be
symmetrical (in the two transmission paths). The only dissymmetry will
be due to presence of background noise in one of the test rooms.

3.2 Test arrangement

3.2.1 Description of the proposed testing system

This contribution describes a UMTS simulator for the characterization of
the AMR speech codecs when the bitstream is transmitted over a PS
network. The procedure to do the conversational listening test has been
earlier described in \[1\].

Figure 1 describes the system that is going to be simulated:

![](media/image120.png){width="6.384722222222222in"
height="3.5097222222222224in"}

Figure 1: Packet switch audio communication simulator

This will be simulated using 5 PCs as shown in Figure 2.

![](media/image121.png){width="6.363888888888889in"
height="2.9277777777777776in"}

Figure 2: Simulation Platform

PC 1 and PC 5: PCs under Windows OS with VOIP Terminal Simulator
Software of France Telecom R&D.

PC 2 and PC 4: PCs under Linux OS with Air Interface Simulator of
Siemens AG.

PC 3: PCs under WinNT OS with Network Simulator Software (NetDisturb).

[Basic Principles :]{.underline}

The platform simulates a packet switch interactive communication between
two users using PC1 and PC5 as their relatives VOIP terminals. PC1 sends
AMR encoded packets that are encapsulated using IP/UDP/RTP headers to
PC5. PC1 receives these IP/UDP/RTP audio packets from PC5.

In fact, the packets created in PC1 are sent to PC2. PC2 simulates the
air interface Up Link transmission and then forwards the transmitted
packets to PC4.

In the same way, PC4 simulates the air interface Down Link transmission
and then forwards the packets to PC5. PC5 decodes and plays the speech
back to the listener.

3.2.2 France Telecom Network simulator

The core network simulator, as implemented, works under IPv4.

However, as the core network simulator acts only on packets (loss,
delay,...) the use of IPv4 or IPv6 is equivalent for this test
conversation context. Considering the networks perturbations introduced
by the simulator and the context of the interactive communications, the
simulation using IPv4 perturbation network simulator is adapted to
manage and simulate the behaviours of an IPv6 core network.

. Figure 3 shows the possible parameters that can be modified.

![](media/image5.png){width="6.573611111111111in"
height="3.9131944444444446in"}

Figure 3: IP simulator interface

On both links, one can choose delay and loss laws. Both links can be
treated separately or on the same way. For example, delay can be set to
a fixed value but can also be set to another law such as exponential
law.

3.2.3 UMTS simulator choices

The transmission of IP/UDP/RTP/AMR packets over the UMTS air interface
is simulated using the RAB described in Section 3.2.3.1. The required
functions of the RLC layer are implemented according to TS 25.322 and
work in real-time. The underlying Physical Layer is simulated offline.
Error patterns of block errors (i.e. discarded RLC PDUs) are inserted in
the real-time simulation as described in Section 3.2.3.2. For more
details on the parameter settings of the Physical Layer simulations see
Section 3.2.3.3.

3.2.3.1 RAB and protocols

For our conversational tests, the AMR-WB will encode speech at a maximum
of 15.85 kbit/s. The bitstream will be encapsulated using IP/UDP/RTP
protocols. The air interface simulator will receive IPv4 packets from
the IP network simulator. The RTP packets will be extracted and before
transmission over the air interface, IPv6 headers will be inserted. Then
a new IP/UDP/RTP packet will be transmitted through the air interface
simulator.

The payload Format should be the following:

\- RTP Payload Format for AMR-WB (RFC 3267) will be used;

\- Bandwidth efficient mode will be used;

\- One speech frame shall be encapsulated in each RTP packet;

\- Interleaving will not be used;

The payload header will then consist of the 4 bits of the CMR (Codec
Mode Request). Then 6 bits are added for the ToC (Table of Content). For
IPv4 a maximum of 81 bytes (41 bytes for the AMR and its payload header
plus the 40 bytes of the IP/UDP/RTP headers) per frame will be
transmitted that is to say 32.4 kbit/s, this will go up to 101 bytes
(40.4 kbit/s) when using IPv6 protocol on the air interface.

ROHC algorithm will be supported for AMR-WB conversation test, for the
12.65 kbit/s mode and the 15.85 mode. Header compression will be done on
the IP/UDP/RTP headers. ROHC will start in the unidirectional mode and
switch to bidirectional mode as soon as a packet has reached the
decompressor and it has replied with a feedback packet indicating that a
mode transition is desired.

The Conversational / Speech / UL:42.8 DL:42.8 kbps / PS RAB RAB coming
from TS 34.108 v4.7.0 will be used:

Here is the RAB description:

  -------------- ------------------------------------------------------------- --------------- -------
  Higher layer   RAB/Signalling RB                                             **RAB**         
  PDCP           PDCP header size, bit                                         8               
  RLC            Logical channel type                                          DTCH            
                 RLC mode                                                      UM              
                 Payload sizes, bit                                            920, 304, 96    
                 Max data rate, bps                                            46000           
                 UMD PDU header, bit                                           8               
  MAC            MAC header, bit                                               0               
                 MAC multiplexing                                              N/A             
  Layer 1        TrCH type                                                     DCH             
                 TB sizes, bit                                                 928, 312, 104   
                 TFS                                                           TF0, bits       0x928
                                                                               TF1, bits       1x104
                                                                               TF2, bits       1x312
                                                                               TF3, bits       1x928
                 TTI, ms                                                       20              
                 Coding type                                                   TC              
                 CRC, bit                                                      16              
                 Max number of bits/TTI after channel coding                   2844            
                 Uplink: Max number of bits/radio frame before rate matching   1422            
                 RM attribute                                                  180-220         
  -------------- ------------------------------------------------------------- --------------- -------

3.2.3.2 Description of the RLC implementation

The UMTS air interface simulator (PC 2 and 4) receives IP/UDP/RTP/AMR
packets on a specified port of the network card (see Figure 4). The
IP/UDP/RTP/AMR packets are given to the transmission buffer of the RLC
layer, which works in UM. The RLC will segment or concatenate the IP
bitstream in RLC PDUs, adding appropriate RLC headers (sequence number
and length indicators). It is assumed that always Transport Format TF 3
is chosen on the physical layer, providing an RLC PDU length including
header of 928 bits. In the regular case, one IP packet is placed into an
RLC PDU that is filled up with padding bits. Due to delayed packets from
the network simulator it may also occur that there are more than one IP
packets in the RLC transmission buffer to transmit in the current TTI.

Each TTI of 20ms, an RLC PDU is formed. It is then given to the error
insertion block that decides if the RLC PDU is transmitted successfully
over the air interface or if it is discarded due to a block error after
channel decoding. The physical layer will not be simulated in real time,
but error pattern files will be provided. The error patterns of the air
interface transmission will be simulated according to the settings given
in Section 0. They consist of binary decisions for each transmitted RLC
PDU, resulting in a certain BLER.

After the error pattern insertion, the RLC of the air interface receiver
site receives RLC PDUs in the reception buffer. The sequence numbers of
the RLC headers are checked to detect when RLC PDUs have been discarded
due to block errors. A discarded RLC PDU will result in one or more lost
IP packets, resulting in a certain packet loss rate of the IP packets
and thereby in a certain FER of the AMR frames. The IP/UDP/RTP/AMR
packets are reassembled and transmitted to the next PC. This PC is
either the network simulator (PC 3) in case of uplink transmission, or
it is one of the terminals (PC 1 or 5) in case of downlink transmission.

![](media/image112.wmf){width="6.625in" height="4.749305555555556in"}

Figure 4: UMTS air interface simulation

3.2.3.3 Physical Layer Implementation

The parameters of the physical layer simulation were set according to
the parameters for a DCH in multipath fading conditions given in TS
34.121 (downlink) and TS 25.141 (uplink). The TB size is 928 bits and
the Turbo decoder uses the Log-MAP algorithm with 4 iterations. The rake
receiver has 6 fingers at 60 possible positions.

The different channel conditions given in **Table 1**, **Table 2**, and
**Table 3** were extracted from TR 101 112 (Selection procedures for the
choice of radio transmission technologies of the UMTS) and also
mentioned in the annex of the document S4-020680.

  ----- --------------- ------------- ----------
  Tap   Channel A       Doppler       

        Rel~.~ Delay\   Avg. Power\   Spectrum
        (nsec)          (dB)          

  1     0               0             FLAT

  2     50              -3.0          FLAT

  3     110             -10.0         FLAT

  4     170             -18.0         FLAT

  5     290             -26.0         FLAT

  6     310             -32.0         FLAT
  ----- --------------- ------------- ----------

Table 1: Indoor Office Test Environment Tapped-Delay-Line Parameters

  ----- ------------------- ----------------- ----------
  Tap   Channel A           Doppler           
        Rel. Delay (nsec)   Avg. Power (dB)   Spectrum
  1     0                   0.0               CLASSIC
  2     310                 -1.0              CLASSIC
  3     710                 -9.0              CLASSIC
  4     1090                -10.0             CLASSIC
  5     1730                -15.0             CLASSIC
  6     2510                -20.0             CLASSIC
  ----- ------------------- ----------------- ----------

Table 2: Vehicular Test Environment, High Antenna, Tapped-Delay-Line
Parameters

  ----- ------------------- ----------------- ----------
  Tap   Channel A           Doppler           
        Rel. Delay (nsec)   Avg. Power (dB)   Spectrum
  1     0                   0                 CLASSIC
  2     110                 -9.7              CLASSIC
  3     190                 -19.2             CLASSIC
  4     410                 -22.8             CLASSIC
  5     \-                  \-                CLASSIC
  6     \-                  \-                CLASSIC
  ----- ------------------- ----------------- ----------

Table 3: Outdoor to Indoor and Pedestrian Test Environment
Tapped-Delay-Line Parameters

**Table 4** (DL) and **Table 5** (UL) show approximate results of the
air interface simulation for ![](media/image113.wmf){width="0.75625in"
height="0.39861111111111114in"} and E~b~/N~0~ corresponding to the
considered BLERs.

  ----------------------------------------------------------------------------------------------------------------------- --------------- --------------- --------------- ---------------
                                                                                                                          **BLER**                                        
  **Channel**                                                                                                             **5\*10^-2^**   **1\*10^-2^**   **1\*10^-3^**   **5\*10^-4^**
  Indoor, 3 km/h (![](media/image114.wmf){width="0.4861111111111111in" height="0.2361111111111111in"}= 9 dB)              -13.1 dB        -8.9 dB         -3.4 dB         -2.4 dB
  Outdoor to Indoor, 3 km/h (![](media/image114.wmf){width="0.4861111111111111in" height="0.2361111111111111in"}= 9 dB)   -13.2 dB        -9.7 dB         -5.9 dB         -5.2 dB
  Vehicular, 50 km/h (![](media/image114.wmf){width="0.4861111111111111in" height="0.2361111111111111in"}= -3 dB)         -9.35 dB        -8.2 dB         -6.9 dB         -6.55 dB
  Vehicular, 120 km/h (![](media/image114.wmf){width="0.4861111111111111in" height="0.2361111111111111in"}= -3 dB)        -9.7 dB         -8.95 dB        -7.95 dB        -7.55 dB
  ----------------------------------------------------------------------------------------------------------------------- --------------- --------------- --------------- ---------------

Table 4: **Downlink performance - approximately**
![](media/image113.wmf){width="0.75625in"
height="0.39861111111111114in"} **for the different channels and BLER**

  --------------------------- --------------- --------------- --------------- ---------------
                              **BLER**                                        
  **Channel**                 **5\*10^-2^**   **1\*10^-2^**   **1\*10^-3^**   **5\*10^-4^**
  Indoor, 3 km/h              3.9 dB          6.4 dB          9.2 dB          9.8 dB
  Outdoor to Indoor, 3 km/h   3.7 dB          6.1 dB          8.6 dB          9.2 dB
  Vehicular, 50 km/h          -0.9 dB         -0.15 dB        0.55 dB         0.75 dB
  Vehicular, 120 km/h         0.2 dB          0.6 dB          1.1 dB          1.3 dB
  --------------------------- --------------- --------------- --------------- ---------------

Table 5: **Uplink performance - approximately E~b~/N~0~ for the
different channels and BLER**

3.2.4Headsets and Sound Card

To avoid echo problems, it has been decided to use headsets, instead of
handsets. The monaural headsets are connected to the sound cards of the
PCs supporting the AMR simulators.

The sound level in the earphones can be adjusted, if needed, by the
users. But, in practice, the original settings, defined during the
preliminary tests, and producing a comfortable listening level, will not
be modified. The microphones are protected by a foam ball in order to
reduce the \"pop\" effect. It is also suggested to the user to avoid to
place the acoustic opening of the microphone in front of the mouth.

3.2.5 Test environment

Each of the two subjects participating to the conversations is installed
in a test room. They sit on an armchair, in front of a table. The test
rooms are acoustically insulated. All the test equipments are installed
in a third room, connected to the test rooms. When needed, the
background noise is generated in the appropriate test room through a set
of 4 loudspeakers. The background noise level is adjusted and controlled
by a sound level meter. The measurement microphone, connected to the
Sound level meter is located at the equivalent of the center of the
subject\'s head. The noise level is A weighted.

3.2.6 Calibration and test conditions monitoring

Speech level

Before the beginning of a set of experiment, the end to end transmission
level is checked subjectively, to ensure that there is no problem. If it
is necessary to check the speech level following procedure will apply.
An artificial mouth placed in front of the microphone of the Headset A,
in the LRGP position -See ITU-T Rec. P.64-, generates in the artificial
ear (according to ITU-T Rec. P57) coupled to the earphone of the Head
set B the nominal level defined in section 4.3. If necessary, the level
is adjusted with the receiving volume control of the headset. The
similar calibration is done by inverting headsets A and B.

Delay

The overall delay (from the input of sound card A to the output of sound
card B) will be evaluated for each test condition.

The hypothetical delay is calculated as shown :

On the air interface side, the simulator only receives packets on its
network card, process them and transmits every 20 ms these packets to
the following PC. Only processing delay and a possible delay due to a
jitter can be added (a packet arrives just after the sending window of
the air interface).

The hypothetical delay is calculated as shown :

On encoder side, delay have to take into account framing, look-ahead,
processing and packetization: 45ms

Uplink delay between UE and Iu: 84.4 ms (see TR25.853)

Core network delay: a few ms

Routing through IP: depending on the number of routers.

Downlink delay between Iu and Ue: 71.8 ms (see TR25.853)

And delay on decoder side, taking into account jitter buffer,
de-packetization and processing, 40 ms

The total delay to be considered is at least: 241.2 ms.

Note : The actual delay will be measured on the test equipment.

3.3 Test Conditions

**The 24 test conditions are :**

  --------------- ------------------------- ----------------------------------- --------------------
  **Condition**   **Experimental actors**                                       
                  Radio conditions          IP conditions (Packet loss ratio)   Mode
  1               10 ^--2^                  0%                                  12,65 kbit/s, RoHC
  2               10 ^--2^                  0%                                  12,65 kbit/s
  3               10 ^--2^                  0%                                  15,85 kbit/s, RoHC
  4               10 ^--2^                  3%                                  12,65 kbit/s, RoHC
  5               10 ^--2^                  3%                                  12,65 kbit/s
  6               10 ^--2^                  3%                                  15,85 kbit/s, RoHC
  7               10^-3^                    0%                                  12,65 kbit/s, RoHC
  8               10^-3^                    0%                                  12,65 kbit/s
  9               10^-3^                    0%                                  15,85 kbit/s, RoHC
  10              10^-3^                    3%                                  12,65 kbit/s, RoHC
  11              10^-3^                    3%                                  12,65 kbit/s
  12              10^-3^                    3%                                  15,85 kbit/s, RoHC
  13              5 10^-4^                  0%                                  12,65 kbit/s, RoHC
  14              5 10^-4^                  0%                                  12,65 kbit/s
  15              5 10^-4^                  0%                                  15,85 kbit/s, RoHC
  16              5 10^-4^                  3%                                  12,65 kbit/s, RoHC
  17              5 10^-4^                  3%                                  12,65 kbit/s
  18              5 10^-4^                  3%                                  15,85 kbit/s, RoHC
  --------------- ------------------------- ----------------------------------- --------------------

+----------+----------+----------+----------+----------+----------+
| **Con    | **Ad     | **Ad     | **Expe   |          |          |
| dition** | ditional | ditional | rimental |          |          |
|          | Ba       | Ba       | actors** |          |          |
|          | ckground | ckground |          |          |          |
|          | noise**  | noise**  |          |          |          |
|          |          |          |          |          |          |
|          | **Room   | **Room   |          |          |          |
|          | A**      | B**      |          |          |          |
+----------+----------+----------+----------+----------+----------+
|          |          |          | Radio    | IP       | Mode     |
|          |          |          | co       | co       |          |
|          |          |          | nditions | nditions |          |
|          |          |          |          | (Packet  |          |
|          |          |          |          | loss     |          |
|          |          |          |          | ratio)   |          |
+----------+----------+----------+----------+----------+----------+
| 19       | Car      | No       | 5 10^-4^ | 3%       | 12,65    |
|          |          |          |          |          | kbit/s,  |
|          |          |          |          |          | RoHC     |
+----------+----------+----------+----------+----------+----------+
| 20       | No       | Car      | 5 10^-4^ | 3%       | 12,65    |
|          |          |          |          |          | kbit/s,  |
|          |          |          |          |          | RoHC     |
+----------+----------+----------+----------+----------+----------+
| 21       | C        | No       | 5 10^-4^ | 0%       | 12,65    |
|          | afeteria |          |          |          | kbit/s   |
+----------+----------+----------+----------+----------+----------+
| 22       | No       | C        | 5 10^-4^ | 0%       | 12,65    |
|          |          | afeteria |          |          | kbit/s   |
+----------+----------+----------+----------+----------+----------+
| 23       | Street   | No       | 5 10^-4^ | 0%       | 15,85    |
|          |          |          |          |          | kbit/s,  |
|          |          |          |          |          | RoHC     |
+----------+----------+----------+----------+----------+----------+
| 24       | No       | Street   | 5 10^-4^ | 0%       | 15,85    |
|          |          |          |          |          | kbit/s,  |
|          |          |          |          |          | RoHC     |
+----------+----------+----------+----------+----------+----------+

Noise types

  ---------------- --------------------
  **Noise type**   **Level (dB Pa A**
  Car              60
  Street           55
  Bable            50
  ---------------- --------------------

  ----------------------- ---- -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  Listening Level         1    79 dBSPL
  Listeners               32   Naïve Listeners
  Groups                  16   2 subjects/group
  Rating Scales           5    
  Languages               1    See table
  Listening System        1    Monaural headset (flat response in the audio bandwidth of interest: 50Hz-7kHz). The other ear is open.
  Listening Environment        Room Noise: Hoth Spectrum at 30dBA (as defined by ITU-T, Recommendation P.800, Annex A, section A.1.1.2.2.1 Room Noise, with table A.1 and Figure A.1),except when background noise is needed (see table)
  ----------------------- ---- -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Annex A Example Instructions for the conversation test

**Table :** Instructions to subjects.

+----------------------------------------------------------------------+
| **INSTRUCTIONS TO SUBJECTS**                                         |
|                                                                      |
| In this experiment we are evaluating systems that might be used for  |
| telecommunication services.                                          |
|                                                                      |
| You are going to have a conversation with another user. The test     |
| situation is simulating communications between two mobile phones.    |
| The most of the situations will correspond to silent environment     |
| conditions, but some other will simulate more specific situations,   |
| as in a car, or in a railway station or in an office environment,    |
| when other people are discussing in the background.                  |
|                                                                      |
| After the completion of each call conversation, you will have to     |
| give your opinions on the quality, by answering to the following     |
| questions that will be displayed on the screen of the black box in   |
| front of you. Your judgment will be stored. You have 8 seconds to    |
| answer to each question. After \"pressing\" the button on the        |
| screen, another question will be displayed. You continue the         |
| procedure for the 5 following questions.                             |
|                                                                      |
| Question 1: How do you judge the quality of the voice of your        |
| partner?                                                             |
|                                                                      |
|   ----------- ------ ------ ------ -----                             |
|   Excellent   Good   Fair   Poor   Bad                               |
|   ----------- ------ ------ ------ -----                             |
|                                                                      |
| Question 2: Do you have difficulties to understand some words?       |
|                                                                      |
|   -------------- ------- ------------------- -------- -------        |
|   All the time   Often   Some time to time   Rarely   Never          |
|   -------------- ------- ------------------- -------- -------        |
|                                                                      |
| Question 3: How did you judge the conversation when you interacted   |
| with your partner?                                                   |
|                                                                      |
| +------------+------------+------------+------------+------------+   |
| | Excellent  | Good       | Fair       | Poor       | Bad        |   |
| | int        | int        | int        | int        | int        |   |
| | eractivity | eractivity | eractivity | eractivity | eractivity |   |
| |            |            |            |            |            |   |
| | (similar   | (in few    | (          | (often,    | (it was    |   |
| | to         | moments,   | sometimes, | you were   | impossible |   |
| | fa         | you were   | you were   | talking    | to have an |   |
| | ce-to-face | talking    | talking    | simul      | i          |   |
| | situation) | simul      | simul      | taneously, | nteractive |   |
| |            | taneously, | taneously, | and you    | con        |   |
| |            | and you    | and you    | had to     | versation) |   |
| |            | had to     | had to     | interrupt  |            |   |
| |            | interrupt  | interrupt  | yourself)  |            |   |
| |            | yourself)  | yourself)  |            |            |   |
| +------------+------------+------------+------------+------------+   |
|                                                                      |
| Question 4: Did you perceive any impairment (noises, cuts,...)? In   |
| that case, was it:                                                   |
|                                                                      |
|   -----                                                              |
| ---------- --------------------------------------- ----------------- |
| --------------- ----------------------- ---------------------------- |
|   No                                                                 |
| impairment   Slight impairment, but not disturbing   Impairment slig |
| htly disturbing   Impairment disturbing   Very disturbing Impairment |
|   -----                                                              |
| ---------- --------------------------------------- ----------------- |
| --------------- ----------------------- ---------------------------- |
|                                                                      |
| Question 5: How do you judge the global quality of the               |
| communication?                                                       |
|                                                                      |
|   ----------- ------ ------ ------ -----                             |
|   Excellent   Good   Fair   Poor   Bad                               |
|   ----------- ------ ------ ------ -----                             |
|                                                                      |
| From then on you will have a break approximately every 30 minutes.   |
| The test will last a total of approximately 60 minutes.              |
|                                                                      |
| Please do not discuss your opinions with other listeners             |
| participating in the experiment.                                     |
+----------------------------------------------------------------------+

Annex B: Example Scenarios for the conversation test

The pretexts used for conversation test are those developed by the Rurh
University (Bochum, Germany) within the context of ITU-T SG12 . These
scenarios have been elaborated to allow a conversation well balanced
within both participants and lasting approximately 2\'30 or 3\', and to
stimulate the discussion between persons that know each other to
facilitate the naturalness of the conversation. They are derived from
typical situations of every day life: railways inquiries, rent a car or
an apartment, etc. Each condition should be given a different scenario.

Examples coming from ITU-T SG 12 COM12-35 \"Development of scenarios for
short conversation test\", 1997

\- Scenario 1 : Pizza service

Subject 1:

+----------------------------------+----------------------------------+
| Your Name :                      | Clemence                         |
+----------------------------------+----------------------------------+
| Reason for the call              | 1 large Pizza                    |
+----------------------------------+----------------------------------+
| Condition which should be        | For 2 people,                    |
| applied to the exchange of       |                                  |
| information                      | Vegetarian pizza prefered        |
+----------------------------------+----------------------------------+
| Information you want to receive  | Topping                          |
| from your partner                |                                  |
|                                  | Price                            |
+----------------------------------+----------------------------------+
| Information that your partner    | Delivery address : 41 industry   |
| requires                         | street,Oxford                    |
|                                  |                                  |
|                                  | Phone : 7 34 20                  |
+----------------------------------+----------------------------------+
| Question to which neither you    | How long will it take?           |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

Subject 2:

+----------------------------------+----------------------------------+
| Your Name :                      | Pizzeria Roma                    |
+----------------------------------+----------------------------------+
| Information from which you       | <table>                          |
| should select the details which  | <tbody>                          |
| your partner requires            | <tr class="odd">                 |
|                                  | <td>Pizzas</td>                  |
|                                  | <td>1 person</td>                |
|                                  | <td>2 persons</td>               |
|                                  | <td>4 persons</td>               |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td><p>Toscana</p>               |
|                                  | <p>(ham, mush                    |
|                                  | rooms, tomatoes,cheese)</p></td> |
|                                  | <td>3.2£</td>                    |
|                                  | <td>5.95£</td>                   |
|                                  | <td>10.5£</td>                   |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <td><p>Tonno</p>                 |
|                                  | <p>(Tuna, on                     |
|                                  | ions, tomatoes, cheese)</p></td> |
|                                  | <td>3.95£</td>                   |
|                                  | <td>7.5£</td>                    |
|                                  | <td>13.95£</td>                  |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td><p>Fabrizio</p>              |
|                                  | <p>(salami                       |
|                                  | , ham, tomatoes, heese)</p></td> |
|                                  | <td>4.2£</td>                    |
|                                  | <td>7.95£</td>                   |
|                                  | <td>14.95£</td>                  |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <td><p>Vegetaria</p>             |
|                                  | <p>(spinach, mush                |
|                                  | rooms, tomatoes,cheese)</p></td> |
|                                  | <td>4.5£</td>                    |
|                                  | <td>8.5£</td>                    |
|                                  | <td>15.95£</td>                  |
|                                  | </tr>                            |
|                                  | </tbody>                         |
|                                  | </table>                         |
+----------------------------------+----------------------------------+
| Information you want to receive  | Name                             |
| from your partner                |                                  |
|                                  | address                          |
|                                  |                                  |
|                                  | telephone number                 |
+----------------------------------+----------------------------------+
| Question to which neither you    |                                  |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

\- Scenario 2 : Information on flights

Subject 1:

+----------------------------------+----------------------------------+
| Your Name :                      | Parker                           |
+----------------------------------+----------------------------------+
| Reason for the call              | Intended journey: London         |
|                                  | Heathrow  Düsseldorf            |
+----------------------------------+----------------------------------+
| Condition which should be        | On June 23th,                    |
| applied to the exchange of       |                                  |
| information                      | Morning flight,                  |
|                                  |                                  |
|                                  | Direct flight preferred          |
+----------------------------------+----------------------------------+
| Information you want to receive  | Departure :                      |
| from your partner                |                                  |
|                                  | Arrival                          |
|                                  |                                  |
|                                  | Flight number                    |
+----------------------------------+----------------------------------+
| Information that your partner    | Reservation : 1 seat, Economy    |
| requires                         | class                            |
|                                  |                                  |
|                                  | Address: 66 middle street,       |
|                                  | Sheffield                        |
|                                  |                                  |
|                                  | Phone: 21 08 33                  |
+----------------------------------+----------------------------------+
| Question to which neither you    | From which airport is it easier  |
| nor your partner will have       | to get into Cologne center :     |
| information.                     | Düsseldorf or Cologne/Bonn       |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

Subject 2:

+----------------------------------+----------------------------------+
| Your Name :                      | Heathrow flight information      |
+----------------------------------+----------------------------------+
| Information from which you       | <table>                          |
| should select the details which  | <tbody>                          |
| your partner requires            | <tr class="odd">                 |
|                                  | <td>Flight schedule</td>         |
|                                  | <td>Lufthansa</td>               |
|                                  | <td>British Airways</td>         |
|                                  | <td>Lufthansa</td>               |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td>Flight number</td>           |
|                                  | <td>LH 2615</td>                 |
|                                  | <td>BA 381</td>                  |
|                                  | <td>LH 413</td>                  |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <t                               |
|                                  | d>London Heathrow departure</td> |
|                                  | <td>6:30</td>                    |
|                                  | <td>6:35</td>                    |
|                                  | <td>8:20</td>                    |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td><p>Brussels arrival</p>      |
|                                  | <p>Brussels departure</p></td>   |
|                                  | <td></td>                        |
|                                  | <td><p>7:35</p>                  |
|                                  | <p>8:00</p></td>                 |
|                                  | <td></td>                        |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <td>Düsseldorf arrival</td>      |
|                                  | <td>7:35</td>                    |
|                                  | <td>9:05</td>                    |
|                                  | <td>9:25</td>                    |
|                                  | </tr>                            |
|                                  | </tbody>                         |
|                                  | </table>                         |
+----------------------------------+----------------------------------+
| Information you want to receive  | Name                             |
| from your partner                |                                  |
|                                  | address                          |
|                                  |                                  |
|                                  | telephone number                 |
|                                  |                                  |
|                                  | number of seats                  |
|                                  |                                  |
|                                  | Class : Business or Economy      |
+----------------------------------+----------------------------------+
| Question to which neither you    |                                  |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

Annex C: Results to be provided

For contractual purposes, the information which needs to be provided is
defined here.

The information required from each test Laboratory is a table containing
the following information for each of the conditions in the experiment:

The \"Mean Opinion Score (MOS)\" obtained for all the subjects.

When the conditions are symmetrical, the mean value is calculated from
all the result for the two test rooms..

For the dissymmetric conditions, the mean is calculated on the two test
conditions, each result cumulating the results obtained in each
condition of background noise.

The Standard Deviation of the \"MOS\" obtained for all the subjects, for
each test condition.

The specific statistical comparisons are specified in Annex C.

Annex D: Data analysis and presentation of results

D.1 Calculation of MOS and Standard Deviation

The (overall) MOS/DMOS for confounded subjects for condition C (Yc) can
then be obtained from:

![](media/image115.wmf){width="0.9118055555555555in"
height="0.4909722222222222in"}

The standard deviation (S) for condition C, denoted as Sc, can be
calculated as:

![](media/image116.wmf){width="0.20833333333333334in"
height="0.20833333333333334in"}=
![](media/image117.wmf){width="2.0277777777777777in"
height="0.5277777777777778in"}

Finally, the confidence interval (CI) at the (1-α) level can be
calculated for![](media/image118.wmf){width="0.5965277777777778in"
height="0.16666666666666666in"} as:

![](media/image119.wmf){width="1.1805555555555556in"
height="0.4166666666666667in"}

D.2 Presentation of Basic Statistical Results

The test results should be reported by the test Laboratory and the
Global Analysis Laboratory as follows:

Calculate and tabulate \"Mean Opinion Scores\" for the (opinion scales,
Standard Deviations and Confidence Intervals as shown in Table E.1.

**Table C.1 - Layout for presentation of test results.**

D.3 Thorough analysis

Two statistical analyses should be conducted on the data obtained with
these subjective scales. The first analysis consists in a Multiple
ANalysis OF VAriance (MANOVA), which globally indicates the possible
effect of the experimental factors (*i.e.*, different conditions). Then,
a specific ANOVA should be run on each dependent variable (the five
scales) to test if there is an effect of a specific experimental factor
for a given subjective variable. In other words, these statistical
analyses indicate if the differences observed between the MOS obtained
for the different conditions are significant, for one given dependant
variable (ANOVA) or for the whole of dependant variables (MANOVA).
Finally, Pearson\'s linear correlations should be computed between the
results of all subjective variables, to see which are those preponderant
or dependent on others.

######### Annex F: Test plan for Packet Switched Conversation Tests for Comparison of Quality Offered by Different Speech Coders

Source: France Telecom R&D

Title: Test plan for packet switched conversation test. Comparison of
quality offered by different speech coders.

Document For: Discussion and Approval

Agenda Item:

Introduction

This document proposes a conversation test plan to compare the quality
obtained with several different speech coders, over packet switched
networks.

The different speech coders used in this test are

Adaptive Multi-Rate Narrow-Band (AMR-NB), in modes 6.7 kbit/s and 12.2
kbit/s,

Adaptive Multi-Rate Wide-Band (AMR-WB), in modes 12.65 kbit/s and 15.85
kbit/s,

ITU-T G.723.1, in mode 6.4 kbit/s,

ITU-T G.729, in mode 8 kbit/s,

ITU-T G.722, in mode 64 kbit/s, with packet loss concealment and,

ITU-T G.711, with packet loss concealment.

As there is no standardized packet loss concealment, plc for G.711 and
G.722 are proprietary algorithms.

The simulated network will include two values of IP packet loss.

The test will be done in one test laboratory, only, but in two different
languages.

This discussion gives references, conventions and contacts, section 3
details the test methodology, including test arrangement and test
procedure,

Annex A contains the instructions for the subjects participating to the
conversation tests.

Annex B contains the description of results to be provided to the
Analysis Laboratory (if any) by the testing laboratories.

Annex C contains the list of statistical comparisons to be performed.

2\. References, Conventions, and Contacts

2.1Permanent Documents

+---+--------------------+-------------------------------------------+
|   | ITU-T Rec.P.800    | Methods for Subjective Determination of   |
|   |                    | Transmission Quality                      |
+---+--------------------+-------------------------------------------+
|   | ITU-T              | **Subjective performance**                |
|   |                    |                                           |
|   | Rec. P.831         | **evaluation of network echo cancellers** |
+---+--------------------+-------------------------------------------+
|   | ITU-T Rec. G.711   | Pulse code modulation (PCM) of voice      |
|   |                    | frequencies                               |
+---+--------------------+-------------------------------------------+
|   | ITU-T Rec. G.729   | Coding of speech at8 kbit/s using         |
|   |                    | conjugate-structure                       |
|   |                    | algebraic-code-excited linear-prediction  |
|   |                    | (CS-ACELP)                                |
+---+--------------------+-------------------------------------------+
|   | ITU-T Rec. G.723.1 | Speech coders : Dual rate speech coder    |
|   |                    | for multimedia communications             |
|   |                    | transmitting at 5.3 and 6.3 kbit/s        |
+---+--------------------+-------------------------------------------+
|   | ITU-T Rec. G.722   | 7 kHz audio-coding within 64 kbit/s       |
+---+--------------------+-------------------------------------------+

2.2 Key Acronyms

  -------- ---------------------------------------------
  AMR-NB   Adaptive Multi-Rate Narrowband Speech Codec
  AMR-WB   Adaptive Multi-Rate Wide-band Speech Codec
  MOS      Mean Opinion Score
  -------- ---------------------------------------------

2.3 Contact Names

The following persons should be contacted for questions related to the
test plan.

+-------------+-------------+-------------+-------------+-------------+
| **Section** | **Contact   | **Org       | **Address** | **Tele      |
|             | Per         | anisation** |             | phone/Fax** |
|             | son/Email** |             |             |             |
+-------------+-------------+-------------+-------------+-------------+
| Experiments | L. Gros     | France      | 2, Avenue   | Tel :       |
| and results |             | Telecom R&D | P. Marzin,  | +3329605    |
| analysis    | Laeticia.g  |             |             | 0720        |
|             | ros\@france |             | 22307       |             |
|             | telecom.com |             | Lannion     | Fax :       |
|             |             |             | Cédex       | +           |
|             |             |             |             | 33296051316 |
|             |             |             | France      |             |
+-------------+-------------+-------------+-------------+-------------+
| AOB         | Paolo Usai\ | ETSI MCC    | 650 Route   | Tel: 33     |
|             | paolo.us    |             | des         | (0)4 92 94  |
|             | ai\@etsi.fr |             | Lucioles\   | 42 36\      |
|             |             |             | 06921       | Fax: 33     |
|             |             |             | Sophia      | (0)4 93 65  |
|             |             |             | Antipolis   | 28 17       |
|             |             |             | Cedex\      |             |
|             |             |             | France      |             |
+-------------+-------------+-------------+-------------+-------------+

2.4 Responsibilities

Each test laboratory has the responsibility to organize its conversation
tests.

The list of Test laboratories participating to the conversation test
phase.

  --------- -------------------- --------------
  **Lab**   **Company**          **Language**
  1         France Telecom R&D   French
            France Telecom R&D   Arabic
  --------- -------------------- --------------

3\. Test methodology

3.1 Introduction

The protocol described below evaluates the effect of degradation such as
delay and dropped packets on the quality of the communications. It
corresponds to the conversation-opinion tests recommended by the ITU-T
P.800 \[1\]. First of all, conversation--opinion tests allow subjects
passing the test to be in a more realistic situation, close to the
actual service conditions experienced by telephone customers. In
addition, conversation-opinion tests are suited to assess the effects of
impairments that can cause difficulty while conversing (such as delay).

Subjects participate to the test by couple; they are seated in separate
sound-proof rooms and are asked to hold a conversation through the
transmission chain performed by means of networks simulators and
communications are impaired by means of an IP impairments simulator part
of the CN simulator, as the figure below describes it.

3.2 Test arrangement

3.2.1 Description of the proposed testing system

This contribution describes a networks simulator for the
characterization of the different speech codecs when the bitstream is
transmitted over a PS network. The procedure to do the conversational
listening test has been earlier described in \[1\].

Figure 1 describes the system that is going to be simulated:

![](media/image122.png){width="6.354861111111111in"
height="3.5097222222222224in"}

Figure 1: Packet switch audio communication simulator

This will be simulated using 5 PCs as shown in Figure 2.

![](media/image123.png){width="6.343055555555556in"
height="2.9159722222222224in"}

Figure 2: Simulation Platform

PC 1 and PC 5: PCs under Windows OS with VOIP Terminal Simulator
Software of France Telecom R&D.

PC 3: PCs under WinNT OS with Network Simulator Software (NetDisturb).

[Basic Principles:]{.underline}

The platform simulates a packet switch interactive communication between
two users using PC1 and PC5 as their relatives VOIP terminals. PC1 sends
encoded packets that are encapsulated using IP/UDP/RTP headers to PC5.
PC1 receives these IP/UDP/RTP audio packets from PC5.

3.2.2 France Telecom Network simulator

The core network simulator, as implemented, works under IPv4.

Figure 3 shows the possible parameters that can be modified, but, in
this test, only \"loss Law\" will have two values, all the others
settings being fixed.

![](media/image5.png){width="6.573611111111111in"
height="3.9131944444444446in"}

Figure 3: IP simulator interface

On both links, one can choose delay and loss laws. Both links can be
treated separately or on the same way. For example, delay can be set to
a fixed value but can also be set to another law such as exponential
law.

3.2.3 Headsets and Sound Card

To avoid echo problems, it has been decided to use headsets, instead of
handsets. The monaural headsets are connected to the sound cards of the
PCs supporting the AMR simulators.

The sound level in the earphones can be adjusted, if needed, by the
users. But, in practice, the original settings, defined during the
preliminary tests, and producing a comfortable listening level, will not
be modified. The microphones are protected by a foam ball in order to
reduce the \"pop\" effect. It is also suggested to the user to avoid to
place the acoustic opening of the microphone in front of the mouth.

3.2.4 Test environment

Each of the two subjects participating to the conversations is installed
in a test room. They sit on an armchair, in front of a table. The test
rooms are acoustically insulated. All the test equipments are installed
in a third room, connected to the test rooms. The background noise level
is checked by a sound level meter. The measurement microphone, connected
to the Sound level meter is located at the equivalent of the center of
the subject\'s head. The noise level is A weighted.

3.2.5 Calibration and test conditions monitoring

Speech level

Before the beginning of a set of experiment, the end to end transmission
level is checked subjectively, to ensure that there is no problem. If it
is necessary to check the speech level following procedure will apply.
An artificial mouth placed in front of the microphone of the Headset A,
in the LRGP position -See ITU-T Rec. P.64-, generates in the artificial
ear (according to ITU-T Rec. P57) coupled to the earphone of the Head
set B the nominal level defined in section 4.3. If necessary, the level
is adjusted with the receiving volume control of the headset. The
similar calibration is done by inverting headsets A and B.

Delay

The overall delay (from the input of sound card A to the output of sound
card B) will be adjusted for each test condition taking into account the
delay of the related codec in order to have a fixed delay around 250ms.
This value of 250ms is close to the hypothetical delay computed for AMR
and AMRWB through the UMTS network.

3.3 Test Conditions

+---------------+----------------+----------------+----------------+
| **Condition** | **Experimental |                |                |
|               | actors**       |                |                |
+---------------+----------------+----------------+----------------+
|               |                | IP conditions  | Mode           |
|               |                | (Packet loss   |                |
|               |                | ratio)         |                |
+---------------+----------------+----------------+----------------+
| 1             |                | 0%             | AMR NB         |
|               |                |                | 6,7kbit/s      |
+---------------+----------------+----------------+----------------+
| 2             |                | 0%             | AMR-NB 12,2    |
|               |                |                | kbit/s         |
+---------------+----------------+----------------+----------------+
| 3             |                | 0%             | AMR-WB         |
|               |                |                |                |
|               |                |                | 12,65 kbit/s   |
+---------------+----------------+----------------+----------------+
| 4             |                | 0%             | AMR-WB         |
|               |                |                |                |
|               |                |                | 15,85 kbit/s   |
+---------------+----------------+----------------+----------------+
| 5             |                | 0%             | G. 723.1       |
|               |                |                |                |
|               |                |                | 6,4 kbit/s     |
+---------------+----------------+----------------+----------------+
| 6             |                | 0%             | G.729          |
|               |                |                |                |
|               |                |                | 8 kbit/s       |
+---------------+----------------+----------------+----------------+
| 7             |                | 0%             | G.722          |
|               |                |                |                |
|               |                |                | 64 kbit/s +    |
|               |                |                | plc            |
+---------------+----------------+----------------+----------------+
| 8             |                | 0%             | G.711 + plc    |
+---------------+----------------+----------------+----------------+
| 9             |                | 3%             | AMR NB         |
|               |                |                | 6,7kbit/s      |
+---------------+----------------+----------------+----------------+
| 10            |                | 3%             | AMR-NB 12,2    |
|               |                |                | kbit/s (delay  |
|               |                |                | 300 ms)        |
+---------------+----------------+----------------+----------------+
| 11            |                | 3%             | AMR-WB         |
|               |                |                |                |
|               |                |                | 12,65 kbit/s   |
+---------------+----------------+----------------+----------------+
| 12            |                | 3%             | AMR-WB         |
|               |                |                |                |
|               |                |                | 15,85 kbit/s   |
+---------------+----------------+----------------+----------------+
| 13            |                | 3%             | G. 723.1       |
|               |                |                |                |
|               |                |                | 6,4 kbit/s     |
+---------------+----------------+----------------+----------------+
| 14            |                | 3%             | G.729          |
|               |                |                |                |
|               |                |                | 8 kbit/s       |
+---------------+----------------+----------------+----------------+
| 15            |                | 3%             | G.722          |
|               |                |                |                |
|               |                |                | 64 kbit/s +    |
|               |                |                | plc            |
+---------------+----------------+----------------+----------------+
| 16            |                | 3%             | G.711 + plc    |
+---------------+----------------+----------------+----------------+

  ----------------------- ---- ---------------------------------------------------------------------------------------------------------------------------------------------------------
  Listening Level         1    79 dBSPL
  Listeners               32   Naïve Listeners per langage
  Groups                  16   2 subjects/group
  Rating Scales           5    
  Languages               1    See table
  Listening System        1    Monaural headset (flat response in the audio bandwidth of interest: 50Hz-7kHz). The other ear is open.
  Listening Environment        Room Noise: Hoth Spectrum at 30dBA (as defined by ITU-T, Recommendation P.800, Annex A, section A.1.1.2.2.1 Room Noise, with table A.1 and Figure A.1),
  ----------------------- ---- ---------------------------------------------------------------------------------------------------------------------------------------------------------

**References**

*Tdoc S4-030564-* Test Plan for the AMR Narrow-Band Packet switched
Conversation test

*Tdoc S4-030565-* Test Plan for the AMR Wide-Band Packet switched
Conversation test

**END**

Annex A Example Instructions for the conversation test

**Table :** Instructions to subjects.

+----------------------------------------------------------------------+
| **INSTRUCTIONS TO SUBJECTS**                                         |
|                                                                      |
| In this experiment we are evaluating systems that might be used for  |
| telecommunication services.                                          |
|                                                                      |
| You are going to have a conversation with another user. The test     |
| situation is simulating communications between two mobile phones.    |
| All the situations will correspond to silent environment condition   |
|                                                                      |
| After the completion of each call conversation, you will have to     |
| give your opinions on the quality, by answering to the following     |
| questions that will be displayed on the screen of the black box in   |
| front of you. Your judgment will be stored. You have 8 seconds to    |
| answer to each question. After \"pressing\" the button on the        |
| screen, another question will be displayed. You continue the         |
| procedure for the 5 following questions.                             |
|                                                                      |
| Question 1: How do you judge the quality of the voice of your        |
| partner?                                                             |
|                                                                      |
|   ----------- ------ ------ ------ -----                             |
|   Excellent   Good   Fair   Poor   Bad                               |
|   ----------- ------ ------ ------ -----                             |
|                                                                      |
| Question 2: Do you have difficulties to understand some words?       |
|                                                                      |
|   -------------- ------- ------------------- -------- -------        |
|   All the time   Often   Some time to time   Rarely   Never          |
|   -------------- ------- ------------------- -------- -------        |
|                                                                      |
| Question 3: How did you judge the conversation when you interacted   |
| with your partner?                                                   |
|                                                                      |
| +------------+------------+------------+------------+------------+   |
| | Excellent  | Good       | Fair       | Poor       | Bad        |   |
| | int        | int        | int        | int        | int        |   |
| | eractivity | eractivity | eractivity | eractivity | eractivity |   |
| |            |            |            |            |            |   |
| | (similar   | (in few    | (          | (often,    | (it was    |   |
| | to         | moments,   | sometimes, | you were   | impossible |   |
| | fa         | you were   | you were   | talking    | to have an |   |
| | ce-to-face | talking    | talking    | simul      | i          |   |
| | situation) | simul      | simul      | taneously, | nteractive |   |
| |            | taneously, | taneously, | and you    | con        |   |
| |            | and you    | and you    | had to     | versation) |   |
| |            | had to     | had to     | interrupt  |            |   |
| |            | interrupt  | interrupt  | yourself)  |            |   |
| |            | yourself)  | yourself)  |            |            |   |
| +------------+------------+------------+------------+------------+   |
|                                                                      |
| Question 4: Did you perceive any impairment (noises, cuts,...)? In   |
| that case, was it:                                                   |
|                                                                      |
|   -----                                                              |
| ---------- --------------------------------------- ----------------- |
| --------------- ----------------------- ---------------------------- |
|   No                                                                 |
| impairment   Slight impairment, but not disturbing   Impairment slig |
| htly disturbing   Impairment disturbing   Very disturbing Impairment |
|   -----                                                              |
| ---------- --------------------------------------- ----------------- |
| --------------- ----------------------- ---------------------------- |
|                                                                      |
| Question 5: How do you judge the global quality of the               |
| communication?                                                       |
|                                                                      |
|   ----------- ------ ------ ------ -----                             |
|   Excellent   Good   Fair   Poor   Bad                               |
|   ----------- ------ ------ ------ -----                             |
|                                                                      |
| From then on you will have a break approximately every 30 minutes.   |
| The test will last a total of approximately 60 minutes.              |
|                                                                      |
| Please do not discuss your opinions with other listeners             |
| participating in the experiment.                                     |
+----------------------------------------------------------------------+

Annex B: Example Scenarios for the conversation test

The pretexts used for conversation test are those developed by the Rurh
University (Bochum, Germany) within the context of ITU-T SG12 . These
scenarios have been elaborated to allow a conversation well balanced
within both participants and lasting approximately 2\'30 or 3\', and to
stimulate the discussion between persons that know each other to
facilitate the naturalness of the conversation. They are derived from
typical situations of every day life: railways inquiries, rent a car or
an apartment, etc. Each condition should be given a different scenario.

Examples coming from ITU-T SG 12 COM12-35 \"Development of scenarios for
short conversation test\", 1997

\- Scenario 1 : Pizza service

Subject 1:

+----------------------------------+----------------------------------+
| Your Name :                      | Clemence                         |
+----------------------------------+----------------------------------+
| Reason for the call              | 1 large Pizza                    |
+----------------------------------+----------------------------------+
| Condition which should be        | For 2 people,                    |
| applied to the exchange of       |                                  |
| information                      | Vegetarian pizza prefered        |
+----------------------------------+----------------------------------+
| Information you want to receive  | Topping                          |
| from your partner                |                                  |
|                                  | Price                            |
+----------------------------------+----------------------------------+
| Information that your partner    | Delivery address : 41 industry   |
| requires                         | street,Oxford                    |
|                                  |                                  |
|                                  | Phone : 7 34 20                  |
+----------------------------------+----------------------------------+
| Question to which neither you    | How long will it take?           |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

Subject 2:

+----------------------------------+----------------------------------+
| Your Name :                      | Pizzeria Roma                    |
+----------------------------------+----------------------------------+
| Information from which you       | <table>                          |
| should select the details which  | <tbody>                          |
| your partner requires            | <tr class="odd">                 |
|                                  | <td>Pizzas</td>                  |
|                                  | <td>1 person</td>                |
|                                  | <td>2 persons</td>               |
|                                  | <td>4 persons</td>               |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td><p>Toscana</p>               |
|                                  | <p>(ham, mush                    |
|                                  | rooms, tomatoes,cheese)</p></td> |
|                                  | <td>3.2£</td>                    |
|                                  | <td>5.95£</td>                   |
|                                  | <td>10.5£</td>                   |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <td><p>Tonno</p>                 |
|                                  | <p>(Tuna, on                     |
|                                  | ions, tomatoes, cheese)</p></td> |
|                                  | <td>3.95£</td>                   |
|                                  | <td>7.5£</td>                    |
|                                  | <td>13.95£</td>                  |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td><p>Fabrizio</p>              |
|                                  | <p>(salami                       |
|                                  | , ham, tomatoes, heese)</p></td> |
|                                  | <td>4.2£</td>                    |
|                                  | <td>7.95£</td>                   |
|                                  | <td>14.95£</td>                  |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <td><p>Vegetaria</p>             |
|                                  | <p>(spinach, mush                |
|                                  | rooms, tomatoes,cheese)</p></td> |
|                                  | <td>4.5£</td>                    |
|                                  | <td>8.5£</td>                    |
|                                  | <td>15.95£</td>                  |
|                                  | </tr>                            |
|                                  | </tbody>                         |
|                                  | </table>                         |
+----------------------------------+----------------------------------+
| Information you want to receive  | Name                             |
| from your partner                |                                  |
|                                  | address                          |
|                                  |                                  |
|                                  | telephone number                 |
+----------------------------------+----------------------------------+
| Question to which neither you    |                                  |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

\- Scenario 2 : Information on flights

Subject 1:

+----------------------------------+----------------------------------+
| Your Name :                      | Parker                           |
+----------------------------------+----------------------------------+
| Reason for the call              | Intended journey: London         |
|                                  | Heathrow  Düsseldorf            |
+----------------------------------+----------------------------------+
| Condition which should be        | On June 23th,                    |
| applied to the exchange of       |                                  |
| information                      | Morning flight,                  |
|                                  |                                  |
|                                  | Direct flight preferred          |
+----------------------------------+----------------------------------+
| Information you want to receive  | Departure :                      |
| from your partner                |                                  |
|                                  | Arrival                          |
|                                  |                                  |
|                                  | Flight number                    |
+----------------------------------+----------------------------------+
| Information that your partner    | Reservation : 1 seat, Economy    |
| requires                         | class                            |
|                                  |                                  |
|                                  | Address: 66 middle street,       |
|                                  | Sheffield                        |
|                                  |                                  |
|                                  | Phone: 21 08 33                  |
+----------------------------------+----------------------------------+
| Question to which neither you    | From which airport is it easier  |
| nor your partner will have       | to get into Cologne center :     |
| information.                     | Düsseldorf or Cologne/Bonn       |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

Subject 2:

+----------------------------------+----------------------------------+
| Your Name :                      | Heathrow flight information      |
+----------------------------------+----------------------------------+
| Information from which you       | <table>                          |
| should select the details which  | <tbody>                          |
| your partner requires            | <tr class="odd">                 |
|                                  | <td>Flight schedule</td>         |
|                                  | <td>Lufthansa</td>               |
|                                  | <td>British Airways</td>         |
|                                  | <td>Lufthansa</td>               |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td>Flight number</td>           |
|                                  | <td>LH 2615</td>                 |
|                                  | <td>BA 381</td>                  |
|                                  | <td>LH 413</td>                  |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <t                               |
|                                  | d>London Heathrow departure</td> |
|                                  | <td>6:30</td>                    |
|                                  | <td>6:35</td>                    |
|                                  | <td>8:20</td>                    |
|                                  | </tr>                            |
|                                  | <tr class="even">                |
|                                  | <td><p>Brussels arrival</p>      |
|                                  | <p>Brussels departure</p></td>   |
|                                  | <td></td>                        |
|                                  | <td><p>7:35</p>                  |
|                                  | <p>8:00</p></td>                 |
|                                  | <td></td>                        |
|                                  | </tr>                            |
|                                  | <tr class="odd">                 |
|                                  | <td>Düsseldorf arrival</td>      |
|                                  | <td>7:35</td>                    |
|                                  | <td>9:05</td>                    |
|                                  | <td>9:25</td>                    |
|                                  | </tr>                            |
|                                  | </tbody>                         |
|                                  | </table>                         |
+----------------------------------+----------------------------------+
| Information you want to receive  | Name                             |
| from your partner                |                                  |
|                                  | address                          |
|                                  |                                  |
|                                  | telephone number                 |
|                                  |                                  |
|                                  | number of seats                  |
|                                  |                                  |
|                                  | Class : Business or Economy      |
+----------------------------------+----------------------------------+
| Question to which neither you    |                                  |
| nor your partner will have       |                                  |
| information.                     |                                  |
|                                  |                                  |
| You should discuss and find a    |                                  |
| solution that is acceptable to   |                                  |
| both of you.                     |                                  |
+----------------------------------+----------------------------------+

ITU-T SG 12 COM12-35 \"Development of scenarios for short conversation
test\", 1997

Annex C: Results to be provided

For contractual purposes, the information which needs to be provided is
defined here.

The information required from each test Laboratory is a table containing
the following information for each of the conditions in the experiment:

The \"Mean Opinion Score (MOS)\" obtained for all the subjects.

When the conditions are symmetrical, the mean value is calculated from
all the result for the two test rooms..

For the dissymmetric conditions, the mean is calculated on the two test
conditions, each result cumulating the results obtained in each
condition of background noise.

The Standard Deviation of the \"MOS\" obtained for all the subjects, for
each test condition.

The specific statistical comparisons are specified in Annex C.

Annex D: Data analysis and presentation of results

D.1 Calculation of MOS and Standard Deviation

The (overall) MOS/DMOS for confounded subjects for condition C (Yc) can
then be obtained from:

![](media/image115.wmf){width="0.9118055555555555in"
height="0.4909722222222222in"}

The standard deviation (S) for condition C, denoted as Sc, can be
calculated as:

![](media/image116.wmf){width="0.20833333333333334in"
height="0.20833333333333334in"}=
![](media/image117.wmf){width="2.0277777777777777in"
height="0.5277777777777778in"}

Finally, the confidence interval (CI) at the (1-α) level can be
calculated for![](media/image118.wmf){width="0.5965277777777778in"
height="0.16666666666666666in"} as:

![](media/image119.wmf){width="1.1805555555555556in"
height="0.4166666666666667in"}

D.2 Presentation of Basic Statistical Results

The test results should be reported by the test Laboratory and the
Global Analysis Laboratory as follows:

Calculate and tabulate \"Mean Opinion Scores\" for the (opinion scales,
Standard Deviations and Confidence Intervals as shown in Table E.1.

**Table C.1 - Layout for presentation of test results.**

D.3 Thorough analysis

Two statistical analyses should be conducted on the data obtained with
these subjective scales. The first analysis consists in a Multiple
ANalysis OF VAriance (MANOVA), which globally indicates the possible
effect of the experimental factors (*i.e.*, different conditions). Then,
a specific ANOVA should be run on each dependent variable (the five
scales) to test if there is an effect of a specific experimental factor
for a given subjective variable. In other words, these statistical
analyses indicate if the differences observed between the MOS obtained
for the different conditions are significant, for one given dependant
variable (ANOVA) or for the whole of dependant variables (MANOVA).
Finally, Pearson\'s linear correlations should be computed between the
results of all subjective variables, to see which are those preponderant
or dependent on others.

######### Annex G: Test Plan for Global Analysis of PSS Conversation Tests

Source: Dynastat^1^

Title: Proposed Test Plan for Global Analysis of PSS Conversation Tests
(R1)

Document for: Discussion and Approval

Agenda Item: 7, 13.1

1\. Introduction

This contribution presents a proposal for conducting a Global Analysis
of the results derived from the 3GPP Conversation Tests for Packet
Switched (PS) networks. Phase I of these tests are described in two test
plans \-- S4-030564 for conversation tests using the Adaptive Multi-Rate
Narrow-Band (AMR-NB) codec, S4-030565 for conversation tests using the
Adaptive Multi-Rate Wide-Band (AMR-WB) codec. The test plan for the
Phase II tests are described in S4-030747 for conversation tests
comparing various ITU-T standardized speech codecs. The Phase I test
plans specify similar experimental designs involving 24 test conditions
and 16 pairs of subjects. They also specify that three Listening
Laboratories (LL) will conduct the tests in different languages: Arcon
for North American English (NAE), NTT-AT for Japanese, and France
Telecom for French. The Phase II test plan involves 16 conditions and a
single Listening Lab (France Telecom) conducting the test in two
languages (French and Arabic).

2\. Phase I - AMR-NB Tests

Table 1 shows the 24 test conditions involved in the AMR-NB conversation
tests.

Table 1. Test Conditions in the PS Conversation Tests for AMR-NB

![](media/image124.wmf){width="3.6256944444444446in"
height="4.309027777777778in"}

Test conditions 1-18 are symmetrical in that both subjects in a
conversation-pair are listening in quiet (i.e., no noise) rooms.
Conditions 19-24, on the other hand, are asymmetrical, one subject is
listening in a quiet room, the other in a noisy room. Conditions 1-18
are categorized by four experimental factors:

\- Delay -- 300 msec and 500 msec

\- AMR-NB mode (rate) -- 6.7 kbps and 12.2 kbps

\- Packet Loss -- 0% and 3%

\- Radio conditions -- 10^-2^, 10^-3^, and 5x10^-4^

These conditions can be assigned to two factorial designs for analysing
the effects of three of these factors. Table 2 shows the conditions
involved in the two three-factor analyses for the AMR-NB experiments.
Using the 12 conditions shown in Table 2a, the effects of Rate, Radio
Conditions, and Packet Loss can be evaluated (Delay held constant at 300
msec). Using the 12 conditions shown in Table 2b, the effects of Delay,
Radio Conditions, and Packet Loss can be evaluated (Rate held constant
at 12.2 kbps).

![](media/image125.png){width="6.665972222222222in"
height="2.8430555555555554in"}

The three sets of paired conditions involving noise (i.e., conditions
19/20, 21/22, and 23/24) can be used to compare the effects of *sender
in noise/receiver in quiet* with those for *sender in quiet/receiver in
noise* for the three noise environments.

3\. Phase I - AMR-WB Tests

Table 3 shows the test conditions involved in the AMR-WB conversation
tests. As in the AMR-NB tests, conditions 1-18 are symmetrical and
conditions 19-24 are asymmetrical. Conditions 1-18 are categorized by
four experimental factors:

\- RoHC -- present and absent

\- AMR-NB mode (rate) -- 6.7 kbps and 12.2 kbps

\- Packet Loss -- 0% and 3%

\- Radio conditions -- 10^-2^, 10^-3^, and 5x10^-4^

Table 3. Test Conditions in the PS Conversation Tests for AMR-WB

![](media/image126.wmf){width="4.75625in" height="5.206944444444445in"}

Consistent with the AMR-NB tests, conditions 1-18 can be assigned to two
factorial designs for analysing the effects of three of these factors.
Table 4 shows the conditions involved in the two three-factor analyses
for the AMR-WB experiments. Using the 12 conditions shown in Table 4a,
the effects of Rate, Radio Conditions, and Packet Loss can be evaluated
(RoHC present in all conditions). Using the 12 conditions shown in Table
4b, the effects of RoHC, Radio Conditions, and Packet Loss can be
evaluated (Rate held constant at 12.65 kbps).

![](media/image127.png){width="6.665972222222222in" height="2.6875in"}

Again, consistent with the tests for AMR-NB, the three sets of paired
conditions involving noise (i.e., conditions 19/20, 21/22, and 23/24)
can be used to compare the effects of *sender in noise/receiver in
quiet* with those for *sender in quiet/receiver in noise* for the three
noise environments.

4\. Phase II - ITU-T Codec Tests

Table 5 shows the test conditions involved in the conversation tests
designed to compare the performance of standardized ITU-T codecs in
packet switched networks. The test involves eight codecs and two levels
of packet loss, 0% and 3%.

![](media/image128.wmf){width="3.7402777777777776in"
height="3.115972222222222in"}

Table 5. Test Conditions in the PS Conversation Tests for ITU-T Codecs

5\. Global Analyses

The purpose of the Global Analysis task is to bring together the results
from the different Listening Labs/languages (Phase I - NAE, French,
Japanese; Phase II -- French, Arabic) and combine them, where
appropriate, such that conclusions may be drawn about the performance of
the AMR-NB and AMR-WB codecs in packet switched networks. This task is
complicated by the fact that in the conversation tests multiple
criterion measures are collected for each condition. In the tests
involved here, listeners are required to rate each condition on five
aspects of the communication situation:

\- Quality of the voice of their partner

\- Difficulty of understanding words

\- Quality of interaction with their partner

\- Degree of impairments

\- Global communication quality

Each of these criteria is measured using ratings on five-category rating
scales. Each criterion also represents a separate independent variable
which must be evaluated in a Global Analysis. The appropriate analysis
for this situation is a Multivariate Analysis of Variance (MANOVA). The
first step in MANOVA involves an omnibus test for the combination of all
independent variables. A number of statistical techniques may be
employed in MANOVA to determine whether the independent variables are
measuring different or the same underlying variable. Other techniques,
discriminant analysis in particular, determine the contribution provided
by each independent variable to a composite variable that maximally
separates the data on the dependent variables. The omnibus MANOVA test
is then followed by separate Analyses of Variance (ANOVA) for each
independent variable. The F-ratios for the individual ANOVA\'s are
adjusted (Bonferroni) to account for the fact that multiple tests are
being performed. It is proposed here to perform MANOVA\'s and the
associated univariate ANOVA\'s separately for each of the six
experiments (AMR-NB and AMR-WB from each of the three listening labs).
Examination of the results of these analyses will determine if there is
a single composite independent variable for each experiment and whether
these composites are similar across experiments and across listening
labs. The results of these analyses will determine whether it is
appropriate to combine the results across listening labs.

Pearson\'s correlation coefficients will be computed to identify and
illustrate the inter-relationships among the dependent variables.

If the results can be legitimately combined across listening labs, a
nested ANOVA for *Conditions* and *Listening Labs* will be conducted
separately for each codec, AMR-NB and AMR-WB. Table 5 shows a
generalized Source Table for the appropriate ANOVA with the effects of
*Listening Labs* nested within the effects of *Subjects*.

One task of the Global Analysis exercise will be to provide an Excel
spreadsheet to the individual Listening Labs for delivery of the raw
ratings. The Global Analysis task will also include a comprehensive
report containing the results of the various statistical analyses
described above. Dynastat will present the final report at the February
2004 meeting of 3GPP-SA4.

![](media/image129.wmf){width="3.9694444444444446in"
height="2.2805555555555554in"}

Table 6. Generalized ANOVA Source Table for Combining Results across
Listening Labs.

6\. References

S4-030564 Test Plan for the AMR Narrow-Band Packet Switched Conversation
Test

S4-030565 Test Plan for the AMR Wide-Band Packet Switched Conversation
Test

S4-030747 Test plan for Packet Switched Conversation Test. Comparison of
quality offered by different speech coders.

######### Annex H: Test Plan for Performance characterisation of VoIMS over HSDPA/EUL channels; listening only tests 

H.1 Introduction
================

This annex describes subjective evaluation methods for characterising
the overall performance of VoIMS over HSDPA/EUL radio channels. The main
purpose is to evaluate and verify adequate subjective performance of the
AMR and AMR-WB speech codecs defined in TS 26.114.

The VoIMS performance characterisation for HSDPA/EUL channels consists
of subjective evaluation with listening-only and conversation test
methodology. The former evaluates the basic subjective quality of the
selected speech codecs when conducting buffer adaptation to the network
delay variations. Listening-only tests are further completed with
overall delay analysis. The latter is verifying the effect of overall
delay variations in conversational situations.

Listening only tests will concentrate on the effect of channel error and
channel jitter to speech quality instead of the impact of overall
end-to-end delay in speech conversation. The end-to-end delay impact is
considered in delay analysis conducted on the whole processed test
material.

H.2 Listening only test conditions
==================================

Table H.1: Noise types for listening only test

  ------------ ---------------
  Noise type   Level (dBSNR)
  Clean        \-
  Car          15 dB
  Cafeteria    20 dB
  ------------ ---------------

Table H.2: Test details for listening only

  ----------------------------------- ---- --------------------------------------------------------------------------------------------------------------
  Listening Level                     1    79 dBSPL
  Reference Conditions (narrowband)   8    MNRU 5, 13, 21, 29, 37 dB, direct, clean 5.9 kbit/s, clean 12.2 kbit/s
  Reference Conditions (wideband)     8    MNRU 5, 13, 21, 29, 37, 45 dB, direct, clean 12.65 kbit/s
  Test Conditions                     2    Fixed buffer (buffer size set to the average of adaptive JBM in the same network condition), adaptive JBM
  Listeners                           32   Naïve Listeners
  Groups                              4    8 subjects/group
  Rating Scales                       1    P.800.2 ACR (clean condition), DCR (background noise)
  Languages                           2    Finnish and Swedish
  Listening System                    1    Monaural headset audio bandwidth 3.4kHz (narrowband) 7.0 kHz (wideband). The other ear is open.
  Listening Environment                    Room Noise: Hoth Spectrum at 30dBA (as defined by ITU-T Recommendation P.800: Annex A, section A.1.1.2.2.1 )
  Number of Talkers                   8    4 males, 4 females
  Number of Samples/Talker            5    4 for the test, 1 for the preliminary items
  ----------------------------------- ---- --------------------------------------------------------------------------------------------------------------

Table H.3: Definition of Radio Network Conditions

+----------------------------+-------------------+-----------------+
| Condition Name             | Network Load:     | Network Load:   |
|                            |                   |                 |
|                            | 40/45/60 per cell | 80/100 per cell |
+----------------------------+-------------------+-----------------+
| DL:                        | DL-LT             | DL-HT           |
|                            |                   |                 |
| PedB3\_km+PedA3\_km        |                   |                 |
+----------------------------+-------------------+-----------------+
| DL:                        | DH-LT             | DH-HT           |
|                            |                   |                 |
| VehA30km+Veh120km+PedB30km |                   |                 |
+----------------------------+-------------------+-----------------+
| UL:                        | UL                |                 |
|                            |                   |                 |
| PedB3\_km+PedA3\_km        |                   |                 |
+----------------------------+-------------------+-----------------+
| UL:                        | UH                |                 |
|                            |                   |                 |
| VehA30km+Veh120km+PedB30km |                   |                 |
+----------------------------+-------------------+-----------------+

Table H.4: Definition of Radio Network Channels conditions

  --------- -------------------------
  Channel   Radio Network Condition
  Ch1       DL-LT-UL
  Ch2       DL-LT-UH
  Ch3       DL-HT-UL
  Ch4       DL-HT-UH
  Ch5       DH-LT-UL
  Ch6       DH-LT-UH
  Ch7       DH-HT-UL
  Ch8       DH-HT-UH
  --------- -------------------------

H.3 End-to-end delay analysis
=============================

An end-to-end delay analysis shall be evaluated in terms of
characterizing the additional delay introduced by the tested jitter
buffer. The analysis shall include a statistical representation of the
buffering time for all channels as well as an analysis of the introduced
error concealment operations from the jitter buffer, i.e so called late
losses.

H.4 Listening only experiments
==============================

The goal of this test is to evaluate the impact of the HSDPA/EUL radio
channel conditions on the speech quality especially when the channel is
subject to packet losses and jitter. Subjective quality score and delay
will be used as metrics to evaluate the results. The test will be
designed based on P.800.Sec.6.2.

Table H.5: Test conditions for listening-only tests with AMR-NB

  ------- ------------ ----------------- --------- -----------------------------
  Cond.   Noise Type   Frame Loss Rate   Channel   AMR-Modes (fixed RTP delay)
  1-1     Clean        0.01              Ch1       5.9kbit/s ( 150 ms)
  1-2     Clean        0.01              Ch2       5.9kbit/s ( 150 ms)
  1-3     Clean        0.01              Ch3       12.2kbit/s ( 150 ms)
  1-4     Clean        0.01              Ch4       12.2kbit/s ( 150 ms)
  ------- ------------ ----------------- --------- -----------------------------

Table H.6: Test conditions for listening-only tests with AMR-NB in
background noise

  ------- ------------ ----------------- --------- -----------------------------
  Cond.   Noise Type   Frame Loss Rate   Channel   AMR-Modes (fixed RTP delay)
  2-1     Car          0.01              Ch5       5.9kbit/s ( 150 ms)
  2-2     Cafeteria    0.01              Ch6       5.9kbit/s ( 150 ms)
  2-3     Car          0.01              Ch7       12.2kbit/s ( 150 ms)
  2-4     Cafeteria    0.01              Ch8       12.2kbit/s ( 150 ms)
  ------- ------------ ----------------- --------- -----------------------------

Table H.7: Test conditions for listening-only tests with AMR-WB

  ------- ------------ ----------------- --------- --------------------------
  Cond.   Noise Type   Frame Loss Rate   Channel   AMR-WB (fixed RTP delay)
  3-1     Clean        0.01              Ch1       12.65 kbit/s (150 ms)
  3-2     Clean        0.01              Ch2       12.65 kbit/s (150 ms)
  3-3     Clean        0.01              Ch3       12.65 kbit/s (150 ms)
  3-4     Clean        0.01              Ch4       12.65 kbit/s (150 ms)
  ------- ------------ ----------------- --------- --------------------------

Table H.8: Test conditions for listening-only tests with AMR-WB in
background noise

  ------- ------------ ----------------- --------- --------------------------
  Cond.   Noise Type   Frame Loss Rate   Channel   AMR-WB (fixed RTP delay)
  4-1     Car          0.01              Ch5       12.65 kbit/s (150 ms)
  4-2     Car          0.01              Ch6       12.65 kbit/s (150 ms)
  4-3     Cafeteria    0.01              Ch7       12.65 kbit/s (150 ms)
  4-4     Cafeteria    0.01              Ch8       12.65 kbit/s (150 ms)
  ------- ------------ ----------------- --------- --------------------------

H.5 Test material processing
============================

The term VoIP client is used to include speech encoder and RTP
packetization on the sender side; a jitter buffer management (JBM)
scheme and speech decoder on the receiver side. Figure 1 shows a test
scenario.

Figure H.1: Test setup for VoIP codecs for listening only test

The implementation of the system shown in Figure 1 has the following
functional components:

I VoIP Client/transmitter containing

> a Pre-processing, including e.g. suitable pre-filtering and signal
> level control
>
> b AMR/AMR-WB encoder
>
> c RTP payload packetisation

II Error insertion device (EID) applying error-delay patterns to the
\"transmitted\" RTP stream

III VoIP Client/receiver (and Network interface) containing

> a RTP payload depacketisation
>
> b Jitter buffer management (JBM)
>
> c AMR/AMR-WB decoder
>
> d Post-processing

For the listening-only test, the simulator can be implemented as an
off-line tool. It includes Voice Encoding, RTP packetisation and error
Insertion. Here, the error insertion device reads input RTP stream
stored into a file, applies given error-delay pattern, and writes
modified output RTP stream into a file. For this purpose the following
storage protocol is introduced:

The raw-data speech (linear PCM masked to 14 bits at 8 kHz sampling rate
for AMR-NB and at 16 kHz sampling rate for AMR-WB) is carried within
VoIP client and receiver. The encoder output is then stored with the
AMR-NB/AMR-WB file storage format according to media types audio/amr and
audio/amr-wb, as specified in sections 5.1 and 5.3 of RFC 3267. The data
exchanged between RTP packetization/depacketisation and error insertion
device is a stream of encapsulated RTP packets in the RTPdump format
shown in Table 9 and Table 10.

Table H.9: RTPdump file header elements.

  ------------- ------------------------------ ------------------------------------------
  **Element**   **Size**                       **Description**
  Start         32 bits (\"struct timeval\")   Start time (GMT) of the file
  Source        32 bits (\"long\")             Source (IP) address
  Port          16 bits (\"short\")            UDP port number
  Padding       16 bits (\"short\")            Padding data to provide 32-bit alignment
  ------------- ------------------------------ ------------------------------------------

Table H.10: RTPdump packet header elements.

  ------------- --------------------- --------------------------------------------------------
  **Element**   **Size**              **Description**
  Length        16 bits (\"short\")   Length of the packet (in bytes), including this header
  Plen          16 bits (\"short\")   Length of the RTP packet (RTP header + RTP payload)
  Offset        32 bits (\"long\")    Milliseconds since the start of the file
  ------------- --------------------- --------------------------------------------------------

Preparation of the evaluation speech material can be based on the
following pseudo code:

> Read in first speech packet
>
> receivedPktTime = time of first received speech packet,
>
> playoutTime = time of the first received speech packet.
>
> lastReceivedPkt = 0
>
> do {
>
> While (receivedPktTime \<= playoutTime) {
>
> Deliver the received speech packet to the VoIP client
>
> Read in next speech packet
>
> Set receivedPktTime = time of next received speech packet
>
> If (no more packets) {
>
> lastReceivedPkt=1
>
> break;
>
> }
>
> }
>
> While (playoutTime \< receivedPktTime) {
>
> Request speech samples from VoIP client
>
> VoIP client returns Tp sec of speech samples
>
> Write out Tp sec to file output
>
> Set playoutTime = playoutTime + Tp
>
> }
>
> } While (VoIP client has PCM samples & lastReceivedPkt==1)

The VoIP client should, when requested speech samples, return short
duration of PCM samples, e.g., 1ms. To ensure fair testing and verify
the de-jitter and time warping aspects in a VoIP system, the
network-decoder interface controls (i) the delivery of encoded speech
packets to the speech decoder and (ii) controls the output of speech
data from the speech decoder. However, to enable more realistic
operation, the VoIP client is given the freedom of deciding how many
speech samples it wants to output for each NCIM speech output request.

######### Annex I: Illustrative scheme for jitter buffer management

This annex describes an illustrative example on jitter buffer management
(JBM) solution. This illustrative example is described as pseudo code in
Section I.1, and Section I.2 provides a performance analysis of one
particular implementation according to the pseudo code.

I.1 Pseudo code
===============

The pseudo code consists of two main parts:

1\) Reception functionality, including the decapsulation of received RTP
payload and storing the received speech frames into a buffer.

2\) Decoding functionality, taking care of reading the frames from the
buffer and providing a frame of decoded speech (or error concealment
data) upon request.

To illustrate the relationship between these two functional parts in a
simple way, the pseudo code is structured in a form of a simulation
model in which a main loop handles the reception and decoding
functionalities:

\- The *main loop* models the time line -- at each execution of this
loop the simulated \"wall clock time\" is increased by one clock tick.
Furthermore, the other two loops -- reception loop and the decoding loop
-- are implemented inside the main loop.

\- The *reception loop* is executed as many times as needed to process
the new packets available at the packet input at/before current time.

\- The *decoding loop* is executed as many times as needed to process
all frames in the buffer scheduled for decoding at/before current time.

It is straightforward to implement the contents of the *reception loop*
in function that is called each time a new RTP payload is received to
provide the reception functionality. Similarly, the operations in the
*decoding loop* can be implemented in a function that is called each
time the audio device requests a new frame of speech to provide the
decoding functionality.

Table I.1 describes the variables used in the pseudo code. Note that in
addition to variables introduced in the table, the pseudo code also uses
the constant FRAME\_DURATION to indicate a frame duration as number of
RTP clock ticks (FRAME\_DURATION = 160 for AMR, FRAME\_DURATION = 320
for AMR-WB). Furthermore, constants THR1 and THR2 are used to control
the fine tuning of the onset frame buffering time.

Table I.1: Variables used in the pseudo code.

  ------------------------ -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
  **Variable**             **Purpose**                                                                                                                                                                                                                                                                            **Description / usage**
  current\_time            Current simulation time as clock ticks at RTP time stamp clock rate                                                                                                                                                                                                                    The current time is initialised to random value -- indicated by \"NOW\" in the pseudo code. The value is increased by one at the each execution of the main loop to simulate the passing of time.
  rx\_time                 Reception time of the current/next RTP packet (as clock ticks at RTP time stamp clock rate)                                                                                                                                                                                            The reception time is initialised to the same value as current\_time. The value is updated each time a new packet is available in the packet input.
  dec\_time                Decoding time of the next frame (as clock ticks at RTP time stamp clock rate)                                                                                                                                                                                                          The value is initialised by adding the value of desired buffering delay JBM\_BUFFER\_DELAY for the initial value of the current\_time. This variable is updated after each decoded frame by increasing the value by number of RTP clock ticks corresponding to one frame (160 ticks for 8 kHz clock rate used for AMR, 320 ticks for 16 kHz clock rate used for AMR-WB).
  rtp\_ts                  RTP timestamp of the current/next RTP packet (as clock ticks at RTP time stamp clock rate)                                                                                                                                                                                             The value is updated each time a new input packet is captured
  frame\_ts                RTP timestamp of the current (received) frame (as clock ticks at RTP time stamp clock rate)                                                                                                                                                                                            The frame timestamp value is set/updated when parsing a packet (containing several frames)
  Next\_ts                 RTP timestamp of the frame to be decoded next (as clock ticks at RTP time stamp clock rate)                                                                                                                                                                                            The variable is used both to request the next frame in decoding order from the buffer and to detect the frames that arrive late
  end\_of\_input           Indication of input speech data status                                                                                                                                                                                                                                                 A status variable that is initialised to value FALSE -- the value is set to TRUE when the end of the input packet file is encountered.
  buffer\_occupancy        Buffer fill level in number of frames                                                                                                                                                                                                                                                  A variable that is used to indicate buffering status -- needed for detecting the end of the simulation and to detect buffer overflows.
  loss\_burst\_len         Number of consecutive frames replaced by error concealment                                                                                                                                                                                                                             The value of this variable is increased each time the decoder needs to invoke the error concealment operation. In case the value exceeds a predetermined threshold JBF\_LOSS\_PERIOD\_THR, the re-synchronisation operation is initiated by setting resync\_flag to value 1. In case of normal decoding the value of loss\_burst\_len is set to zero.
  resync\_flag             Flag to indicate that a re-synchronisation is needed.                                                                                                                                                                                                                                  See the description for the variable loss\_burst\_len above.
  onset\_flag              Indication that we are currently on the buffering time period before decoding the onset speech frame                                                                                                                                                                                   The value of this variable is set to one in the reception loop when an onset frame (i.e. the first speech frame after a non-speech period) is received. The decoding loop sets this value to zero when a requested frame from a buffer has been found and decoded.
  keep\_frame\_alignment   Indication whether the decoding time of a speech onset frame must be aligned with the current frame structure or not -- i.e. whether the decoding must take place at time T + n \* 20 ms, where T is the decoding time of the first frame of the session and n is an integer number.   Set to non-zero value to force keeping the original frame alignment at speech onsets, i.e. to force rounding the decoding time of the first frame of a talk spurt to occur at an integer multiple of 20 ms since the beginning of the session
  ------------------------ -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

/\* INITIALISATION \*/

*Read the first input frame, initialise variables based in received
packet*

/\* NOTE that time is measured in speech samples at RTP clock rate -- 8
kHz for AMR, 16 kHz for AMR-WB \*/

rx\_time = current\_time = NOW

next\_ts = rtp\_ts

/\* Set the desired initial buffering delay \*/

dec\_time = current\_time + JBF\_INITIAL\_DELAY

end\_of\_input = FALSE

buffer\_occupancy = 0

loss\_burst\_len = 0

resync\_flag = 0

onset\_flag = 0;

keep\_frame\_alingment = 1

/\* MAIN LOOP \*/

WHILE end\_of\_input == FALSE OR buffer\_occupancy \> 0

{

> /\* RECEPTION LOOP \*/
>
> WHILE end\_of\_input == FALSE AND rx\_time \<= current\_time
>
> {
>
> /\* Set RTP timestamp for the frame \*/
>
> frame\_ts = rtp\_ts
>
> /\* Loop over all frames in the packet \*/
>
> WHILE more frames in this packet
>
> {
>
> /\* Possible NO\_DATA frames are discarded \*/
>
> IF frame\_type != NO\_DATA
>
> {
>
> IF *speech onset detected*
>
> {
>
> *Find* bt\_min *and* bt\_max*, i.e. the minimum and maximum predicted
> buffering times over the period of* JBF\_HISTORY\_LEN *most recent
> frames*
>
> /\* Set new buffering time \*/
>
> buffer\_delay = bt\_max -- bt\_min
>
> /\* Set this as the next frame to be decoded \*/
>
> next\_ts = frame\_ts
>
> /\* Set decoding time \*/
>
> dec\_time = current\_time + buffer\_delay
>
> /\* Apply frame alignment if selected \*/
>
> IF keep\_frame\_alignment == 1
>
> {
>
> *Move* dec\_time *forward to the next frame boundary*
>
> }
>
> /\* Indicate for the decoder that we are buffering for speech onset
> \*/
>
> onset\_flag = 1;
>
> }
>
> /\* Check if the decoder has set the re-synchronisation flag \*/
>
> ELSE IF resync\_flag == 1
>
> {
>
> /\* Continue decoding from the first frame arriving after a loss
> period \*/
>
> next\_ts = frame\_ts
>
> /\* Clear the re-synchronisation flag \*/
>
> resync\_flag = 0
>
> }
>
> /\* Check if received frame is late by less than one frame slot \*/
>
> ELSE IF frame\_ts + FRAME\_DURATION == next\_ts AND *TS* \>= next\_ts
> NOT *in the buffer*
>
> {
>
> /\* Re-schedule this frame to be the next frame to be decoded \*/
>
> next\_ts = frame\_ts
>
> }
>
> *Compute predicted buffering time for the received frame and update
> buffering time history*
>
> /\* Check frame arrival time \*/
>
> IF frame\_ts \< next\_ts
>
> {
>
> *Discard the frame because it arrived late*
>
> Update RX log: TIME = rx\_time; RTP\_TS = frame\_ts; RX\_STATUS =
> late\_loss
>
> }
>
> ELSE
>
> {
>
> /\* Check buffer occupancy \*/
>
> IF buffer\_occupancy == MAX\_BUFFER\_OCCUPANCY
>
> {
>
> *Discard the frame because the buffer is full*
>
> Update RX log: TIME = rx\_time; RTP\_TS = frame\_ts; RX\_STATUS =
> overflow
>
> }
>
> ELSE
>
> {
>
> *Store the frame into the buffer*
>
> Update RX log: TIME = rx\_time; RTP\_TS = frame\_ts; RX\_STATUS = ok
>
> buffer\_occupancy++
>
> }
>
> }
>
> }
>
> /\* Update RTP timestamp for the next frame \*/
>
> frame\_ts += FRAME\_DURATION
>
> }
>
> *Read the next input packet*
>
> IF *new packet available*
>
> {
>
> *Update variables*
>
> rx\_time
>
> rtp\_ts
>
> }
>
> ELSE
>
> {
>
> end\_of\_input = TRUE
>
> }
>
> } /\* end of RECEPTION LOOP \*/
>
> /\* DECODING LOOP \*/
>
> WHILE dec\_time \<= current\_time
>
> {
>
> /\* Fine tune onset buffering time \*/
>
> IF onset\_flag == 1
>
> {
>
> first\_ts = *TS of the first frame in the buffer*
>
> /\* Early decoding of onset frame if buffer is filling too fast \*/
>
> IF buffer\_occupancy \* FRAME\_DURATION -- THR1 \>= buffer\_delay
>
> {
>
> next\_ts = first\_ts
>
> }
>
> /\* Postpone decoding of onset frame if buffer is filling too slowly
> \*/
>
> ELSE IF buffer\_occupancy \* FRAME\_DURATION + THR2 \< buffer\_delay
> AND next\_ts == first\_ts
>
> {
>
> next\_ts -= FRAME\_DURATION;
>
> }
>
> }
>
> *Request frame having the RTP timestamp value* next\_ts *from the
> buffer*
>
> IF *requested frame found*
>
> {
>
> *Decode speech or generate comfort noise (SID or SID\_FIRST frame)
> normally*
>
> Update DEC log: TIME = dec\_time; RX\_TIME = rcv\_time; RTP\_TS =
> next\_ts; DEC\_STATUS = ok
>
> buffer\_occupancy\--
>
> /\* Clear lost burst counter \*/
>
> loss\_burst\_len = 0
>
> /\* Clear speech onset flag \*/
>
> onset\_flag = 0
>
> }
>
> ELSE
>
> {
>
> IF *in speech state*
>
> {
>
> /\* Increase lost burst counter \*/
>
> loss\_burst\_len++
>
> /\* Check the loss period length \*/
>
> IF loss\_burst\_len \> JBF\_LOSS\_PERIOD\_THR
>
> {
>
> *Find the oldest frame in the buffer*
>
> IF *a frame having a time stamp value* new\_ts *found*
>
> {
>
> *Decode the frame found in the buffer (i.e. reset the decoding to
> continue from the oldest frame found in the buffer)*
>
> Update DEC log: TIME = dec\_time; RX\_TIME = rcv\_time; RTP\_TS =
> new\_ts; DEC\_STATUS = ok
>
> buffer\_occupancy\--
>
> /\* Set the time stamp \*/
>
> next\_ts = new\_ts
>
> /\* Clear lost burst counter \*/
>
> loss\_burst\_len = 0
>
> }
>
> ELSE
>
> {
>
> *Invoke error concealment*
>
> Update DEC log: TIME = dec\_time; RX\_TIME = N/A; RTP\_TS = next\_ts;
> DEC\_STATUS = error\_concealment
>
> /\* Set the re-synchronisation flag to trigger the decoding to
> continue from the next arriving frame \*/
>
> resync\_flag = 1
>
> }
>
> }
>
> ELSE
>
> {
>
> *Invoke error concealment*
>
> Update DEC log: TIME = dec\_time; RX\_TIME = N/A; RTP\_TS = next\_ts;
> DEC\_STATUS = error\_concealment
>
> }
>
> }
>
> ELSE
>
> {
>
> /\* DTX \*/
>
> *Continue comfort noise generation*
>
> Update DEC log: TIME = dec\_time; RX\_TIME = N/A; RTP\_TS = next\_ts;
> DEC\_STATUS = comfort\_noise
>
> }
>
> }
>
> /\* Update variables for decoding the next frame \*/
>
> dec\_time += FRAME\_DURATION
>
> next\_ts += FRAME\_DURATION
>
> } /\* end of DECODING LOOP \*/
>
> /\* CLOCK/TIMER UPDATE \*/
>
> current\_time++

}

I.2 Verification against the minimum performance requirements
=============================================================

This section provides a verification of an implementation of JBM
according to the pseudo code in Section I.1 against the minimum
performance requirements specified in Section 8.2.3 of TS 26.114 \[19\].
The verification was performed by using the implemented JBM algorithm
with the AMR codec. On each channel the simulation was repeated 20
times, each time with different random starting point on the channel.
The results provided in the following subsections indicate the observed
worst-case results (i.e. measured delay CDF closest to the delay
requirement CDF and the highest jitter loss rate).

The constants used in the pseudo code are set to the values given in
Table I.2 for the verification.

Table I.2: Constant values in pseudo code used in performance analysis.

  ------------------------ -----------------------------------
  Constant                 Value
  JBF\_INITIAL\_DELAY      160 \[ticks at 8 kHz clock rate\]
  JBF\_HISTORY\_LEN        100 \[frames\]
  JBF\_LOSS\_PERIOD\_THR   5 \[frames\]
  ------------------------ -----------------------------------

I.2.1 Delay performance
-----------------------

Figures from I.1 to I.6 below show the delay performance of the
implemented JBM and comparison against the minimum performance
requirement specified in Section 8.2.2.2.2 of TS 26.114 \[19\]. The
solid blue curve denotes the delay CDF for the implemented JBM, and the
black dash-dotted curve indicates the delay requirement CDF.

![](media/image131.wmf){width="5.833333333333333in" height="4.375in"}

Figure I.1: Delay performance of the implemented JBM on channel 1.

![](media/image132.wmf){width="5.833333333333333in" height="4.375in"}

Figure I.2: Delay performance of the implemented JBM on channel 2.

![](media/image133.wmf){width="5.833333333333333in" height="4.375in"}

Figure I.3: Delay performance of the implemented JBM on channel 3.

![](media/image134.wmf){width="5.833333333333333in" height="4.375in"}

Figure I.4: Delay performance of the implemented JBM on channel 4.

![](media/image135.wmf){width="5.833333333333333in" height="4.375in"}

Figure I.5: Delay performance of the implemented JBM on channel 5.

![](media/image136.wmf){width="5.833333333333333in" height="4.375in"}

Figure I.6: Delay performance of the implemented JBM on channel 6.

I.2.2 JBM induced error concealment operations
----------------------------------------------

Table I.3 summarizes the jitter loss rates of the implemented JBM for
all test channels, computed as specified in TS 26.114 Section 8.2.3.2.3.

Table I.3: The jitter loss for the tested JBM on test channels.

  ------------------- -------- -------- -------- -------- -------- -------
  **Channel**         **1**    **2**    **3**    **4**    **5**    **6**
  **JBM loss rate**   0.07 %   0.40 %   0.15 %   0.72 %   0.95 %   0.57%
  ------------------- -------- -------- -------- -------- -------- -------

######### Annex J: Test processing for listening only tests

This section specifies the method for the processing of the speech
material for the VoIMS over HSDPA/EUL listening only tests. The
processing steps are illustrated by block diagrams for a clear
understanding of the processing step. The processing of the speech
material will be performed using the ITU-T\'s Software Tool Library
Release 2000 (STL2000).

J.1 Speech preparation 
======================

The processing steps required for generation of the speech samples are
described below.

J.2 Pre-processing
==================

The first step is concatenation where all available speech samples are
merged into one long speech file. This file is then pre-processed
according to the figure below.

![](media/image137.wmf){width="5.375in" height="1.007638888888889in"}

Figure J.1. Pre-processing of MIRS filtered speech file

**STL2000 syntax**

concat infile1 ... infileN outfile\
filter --mod IRS16 infile outfile\
sv56demo --lev -26 --sf 16000 infile outfile

J.3 Processing of speech/background noise signal
================================================

Noise files are filtered by the MIRS filter. The noise files are then
converted to a near-field perception using the ∆SM filter.

Figure J.2. Noise processing

**STL2000 syntax**

filter --mod IRS16 infile outfile\
filter DSM infile outfile

Figure J.3. Background noise mixing

**STL2000 syntax**

sv56demo --rms --lev -26 --sf 16000 infile noisefile\
oper --gain dB 0 speechfile + AL noisefile 0 mixedfile

AL should be -15 for the car noise and -20 for the café noise.

J.4 Up and Down-Sampling, Rounding and Scaling
==============================================

Up- and down-sampling is needed because the sample rate of the original
speech files is 48 kHz, the processing is made with 8/16 kHz sampling
and the listening was made with 16 kHz. The figure below describes the
up- and down-sampling between 16 kHz and 8 kHz.

Figure J.4. Sample-rate conversion, rounding and scaling for narrow-band
filtered conditions

Figure J.5. Sample-rate conversion, rounding and scaling for
wideband-band filtered conditions

**STL2000 syntax (narrow-band)**

filter -down HQ2 infile outfile\
scaldemo -dB -gain 0 -bits 13 -round -nopremask -blk 160 infile outfile

(Processing ...)

scaldemo -dB -gain 0 -bits 13 -round -nopremask -blk 160 infile outfile\
filter -up HQ2 infile outfile 160

**STL2000 syntax (wide-band)**

scaldemo -dB -gain 0 -bits 14 -round -nopremask -blk 320 infile outfile

(Processing ...)

scaldemo -dB -gain 0 -bits 14 -round -nopremask -blk 320 infile outfile

J.5 Processing for Direct Conditions
====================================

The processing for \'direct\' conditions is very simple.

Figure J.6. Processing of speech for \'direct\' conditions

13 bits 8 kHz for AMR-NB, 14 bits 16 kHz for AMR-WB

J.6 Processing for MNRU conditions
==================================

MNRU conditions are generated as shown in the figure below.

Figure J.7. Processing of narrow-/wideband MNRU conditions.

For AMR-NB the format of the infile is 13 bits 8 kHz and the MNRU levels
are 5, 13, 21, 29, 37 dBq. For AMR-WB the format of the infile is 14
bits 16 kHz and the MNRU levels are 5, 13, 21, 29, 37, 45 dBq.

**STL2000 syntax (narrow-band)**

mnrudemo -Q x infile outfile 160 /\* x = dBq level \*/

**STL2000 syntax (wide-band)**

mnrudemo -Q x infile outfile 320 /\* x = dBq level \*/

J.7 Processing of voice over IMS over HSPA 
==========================================

The reference conditions with fixed JBM and the test conditions with
adaptive JBM are processed as described below.

Figure J.8. Processing of voice over IMS over HSPA.

The output from the encoder/RTP packetization and the input to the
JBM/decoder is in RTP-dump format.

The fixed JBM initial buffering delay is set in such a way that the
resulting end-to-end delay (including channel delay and buffering delay)
is similar to the average end-to-end delay of the adaptive JBM in the
same test condition.

**Command syntax for AMR/AMR-WB encoding & RTP packetization**

amr\_enc --dtx -fpp 1 --mode x --if infile --of outfile /\* x = 2 for
5.9 kbit/s mode, x = 7 for 12.2 kbit/s mode \*/

amrwb\_enc --dtx -fpp 1 --mode 2 --if infile --of outfile /\* x = 2 for
12.65 kbit/s mode \*/

**Command syntax for EID processing**

EID\_rtpdump --bs 24 --ps 128 --bl 20 --st x --df channelfile --if
infile --of outfile /\* x = offset to the channel file \*/

**Command syntax for adaptive JBM & AMR/AMR-WB decoding**

amr\_dec --bt 20 --bs 20 --if infile --of outfile\
amrwb\_dec --bt 20 --bs 20 --if infile --of outfile

**Command syntax for fixed JBM & AMR/AMR-WB decoding**

amr\_dec\_fixed --bt x --bs 20 --if infile --of outfile /\* x =
buffering time for the 1st received frame \*/

amrwb\_dec\_fixed --bt x --bs 20 --if infile --of outfile /\* x =
buffering time for the 1st received frame \*/

J.8 Post-processing
===================

Figure J.8. Post processing.

A window of length 1600 samples was used in the file separation.

**STL2000 syntax**

sv56demo --lev -26 --sf 16000 infile outfile\
astrip -wlen 1600 -blk 128000 -start no -n 1 infile outfile\_no /\* no =
file number i.e. 1 to 40 \*/

J.9 Test conditions
===================

The test conditions are described below:

Table J.1. Test conditions

  ------- ----------- ---------- ------------- ----------------- ------------ -----------------------------
  Cond.   Codec       JBM        Noise Type    Frame Loss Rate   Channel      AMR-Modes (fixed RTP delay)
  1       Direct NB              Clean                                        
  2       Direct WB              Clean                                        
  3       NB                     MNRU 5 dBq                                   
  4       NB                     MNRU 13 dBq                                  
  5       NB                     MNRU 21 dBq                                  
  6       NB                     MNRU 29 dBq                                  
  7       NB                     MNRU 37 dBq                                  
  8       WB                     MNRU 5 dBq                                   
  9       WB                     MNRU 13 dBq                                  
  10      WB                     MNRU 21 dBq                                  
  11      WB                     MNRU 29 dBq                                  
  12      WB                     MNRU 37 dBq                                  
  13      WB                     MNRU 45 dBq                                  
  14      AMR-NB      Fixed      Clean                           Error free   5.9 kbit/s (150 ms)
  15      AMR-NB      Fixed      Clean                           Error free   12.2 kbit/s (150 ms)
  16      AMR-NB      Fixed      Car                             Error free   5.9 kbit/s (150 ms)
  17      AMR-NB      Fixed      Car                             Error free   12.2 kbit/s (150 ms)
  18      AMR-NB      Fixed      Cafeteria                       Error free   5.9 kbit/s (150 ms)
  19      AMR-NB      Fixed      Cafeteria                       Error free   12.2 kbit/s (150 ms)
  20      AMR-WB      Fixed      Clean                           Error free   12.65 kbit/s (150 ms)
  21      AMR-WB      Fixed      Car                             Error free   12.65 kbit/s (150 ms)
  22      AMR-WB      Fixed      Cafeteria                       Error free   12.65 kbit/s (150 ms)
  23      AMR-NB      Fixed      Clean         0.01              Ch1          5.9kbit/s ( 150 ms)
  24      AMR-NB      Fixed      Clean         0.01              Ch2          5.9kbit/s ( 150 ms)
  25      AMR-NB      Fixed      Clean         0.01              Ch3          12.2kbit/s ( 150 ms)
  26      AMR-NB      Fixed      Clean         0.01              Ch4          12.2kbit/s ( 150 ms)
  27      AMR-NB      Fixed      Car           0.01              Ch5          5.9kbit/s ( 150 ms)
  28      AMR-NB      Fixed      Cafeteria     0.01              Ch6          5.9kbit/s ( 150 ms)
  29      AMR-NB      Fixed      Car           0.01              Ch7          12.2kbit/s ( 150 ms)
  30      AMR-NB      Fixed      Cafeteria     0.01              Ch8          12.2kbit/s ( 150 ms)
  31      AMR-WB      Fixed      Clean         0.01              Ch1          12.65 kbit/s (150 ms)
  32      AMR-WB      Fixed      Clean         0.01              Ch2          12.65 kbit/s (150 ms)
  33      AMR-WB      Fixed      Clean         0.01              Ch3          12.65 kbit/s (150 ms)
  34      AMR-WB      Fixed      Clean         0.01              Ch4          12.65 kbit/s (150 ms)
  35      AMR-WB      Fixed      Car           0.01              Ch5          12.65 kbit/s (150 ms)
  36      AMR-WB      Fixed      Car           0.01              Ch6          12.65 kbit/s (150 ms)
  37      AMR-WB      Fixed      Cafeteria     0.01              Ch7          12.65 kbit/s (150 ms)
  38      AMR-WB      Fixed      Cafeteria     0.01              Ch8          12.65 kbit/s (150 ms)
  39      AMR-NB      Adaptive   Clean         0.01              Ch1          5.9kbit/s ( 150 ms)
  40      AMR-NB      Adaptive   Clean         0.01              Ch2          5.9kbit/s ( 150 ms)
  41      AMR-NB      Adaptive   Clean         0.01              Ch3          12.2kbit/s ( 150 ms)
  42      AMR-NB      Adaptive   Clean         0.01              Ch4          12.2kbit/s ( 150 ms)
  43      AMR-NB      Adaptive   Car           0.01              Ch5          5.9kbit/s ( 150 ms)
  44      AMR-NB      Adaptive   Cafeteria     0.01              Ch6          5.9kbit/s ( 150 ms)
  45      AMR-NB      Adaptive   Car           0.01              Ch7          12.2kbit/s ( 150 ms)
  46      AMR-NB      Adaptive   Cafeteria     0.01              Ch8          12.2kbit/s ( 150 ms)
  47      AMR-WB      Adaptive   Clean         0.01              Ch1          12.65 kbit/s (150 ms)
  48      AMR-WB      Adaptive   Clean         0.01              Ch2          12.65 kbit/s (150 ms)
  49      AMR-WB      Adaptive   Clean         0.01              Ch3          12.65 kbit/s (150 ms)
  50      AMR-WB      Adaptive   Clean         0.01              Ch4          12.65 kbit/s (150 ms)
  51      AMR-WB      Adaptive   Car           0.01              Ch5          12.65 kbit/s (150 ms)
  52      AMR-WB      Adaptive   Car           0.01              Ch6          12.65 kbit/s (150 ms)
  53      AMR-WB      Adaptive   Cafeteria     0.01              Ch7          12.65 kbit/s (150 ms)
  54      AMR-WB      Adaptive   Cafeteria     0.01              Ch8          12.65 kbit/s (150 ms)
  55      Direct NB              Car                                          
  56      Direct NB              Cafeteria                                    
  57      Direct WB              Car                                          
  58      Direct WB              Cafeteria                                    
  ------- ----------- ---------- ------------- ----------------- ------------ -----------------------------

######### Annex K: Radio network simulation for HSDPA/EUL performance characterization

Two different radio network simulators were used to produce the radio
network conditions used in the HSDPA/EUL performance characterization
tests. Although both tests used the same RAB configurations, there were
some subtle differences beyond the downlink schedulers and the lengths
of the resulting channel profiles. The channel profiles used in the
testing were constructed based on results from both simulations.

The system simulation was dynamic and included explicit modelling of
fast fading, power control, CQI generation, scheduling of users, etc.
Channels that connected different transmit/receive antenna pairs were
generated at the UMTS slot rate (1500Hz). The instantaneous SINR seen at
each receiver was computed at the slot rate. Virtual decoders mapped a
sequence of slot rate SINRs to block error events at the TTI rate for
each physical channel. The virtual decoders must generate the same
statistical block error events as the true decoders operating on a bit
by bit basis in a link level simulation for the same TTI rate for each
physical channel under consideration.

Inner and outer loop power control loops were explicitly modelled for
the associated DPCH. The OVSF code and transmit power resources consumed
by the associated DPCH and HS-SCCH channels were modelled dynamically.
Errors made in HS-SCCH decoding were taken into account in determining
whether the corresponding HS-DSCH transmission is decoded correctly.

The system simulation attempted to model sufficiently the MAC-d PDU flow
and performance from the NodeB to the UE. Thus, the system simulation
was considered an \"over-the-air\" model and did not capture impairments
beyond the NodeB to UE subsystem

The RAB configuration can be found in 3GPP TS 25.993, sections 7.5.3 and
7.5.4. The respective simulator parameters are shown in the tables later
in this section.

The results from each respective simulation were then assembled into
channel profiles in the following way.

\- The results from simulation 1 entailed 16 samples for down link and
16 samples for up link with paired channel conditions PedB\_3km,
PedB30km, VehA\_30km and VehA\_120km. The location of the reference user
was fixed for all simulations.

**- The results from simulation 2 entailed 22 samples, where 20 are for
the down link and two for the up link, representing a paired channel
PedB\_3km. The difference between the 20 samples lied in the network
load (number of users) and the location of the reference user
(geometry).**

Table K.1: File attributes of the available data

  -------------------- ----------------------------------------------------------- ------------
  **Attribute Name**   **Details**                                                 **Number**
  **Link Direction**   **Up-Link, Down-link**                                      **2**
  **Network Load**     **40,45,60,80,100**                                         **5**
  **Channel Model**    **PedA-3km, PedB-3km, PedB30km, VehA-30km, VehA-120 km.**   **5**
  -------------------- ----------------------------------------------------------- ------------

The definition of the conditions follows the conventions given below.

Table K.2: Definition of the radio network conditions

+-----------------------------+-----------------+------------------+------------+
| **Radio Network Condition** | **Low Traffic** | **High Traffic** | **Uplink** |
|                             |                 |                  |            |
|                             | **Down Link**   | **Down Link**    |            |
+-----------------------------+-----------------+------------------+------------+
| **Low Mobility Mobile**     | **LM.LT**       | **LM.HT**        | **Lm**     |
+-----------------------------+-----------------+------------------+------------+
| **High Mobility Mobile**    | **HM.LT**       | **HM.HT**        | **Hm**     |
+-----------------------------+-----------------+------------------+------------+

\- Low Traffic (LT): 40, or 45, or 60 mobile users per cell

\- High Traffic (HT): 80, or 100 mobile users per cell

\- Low Mobility (LM, Lm): ITU --Channel-Model: PedB3\_km or PedA3\_km

\- High Mobility (HM, Hm): ITU-Channel-Model: VehA30km or Veh120km or
PedB30km

Table K.3: Simulation 1, radio network simulation parameters

+----------------------------------+----------------------------------+
| **Parameter**                    |                                  |
+----------------------------------+----------------------------------+
| UMTS BS Nominal TX Power \[dBm\] | **43**                           |
+----------------------------------+----------------------------------+
| P-CPICH Tx Power \[dBm\]         | **33**                           |
+----------------------------------+----------------------------------+
| UMTS BS Overhead TX Power        | **34**                           |
| \[dBm\] including paging, sync   |                                  |
| and P/S-CCPCH                    |                                  |
+----------------------------------+----------------------------------+
| UMTS UE TX Power Class \[dBm\]   | **21**                           |
+----------------------------------+----------------------------------+
| UMTS UE Noise Figure \[dB\]      | **10**                           |
+----------------------------------+----------------------------------+
| BS Antenna Gain \[dBi\]          | **17.1**                         |
+----------------------------------+----------------------------------+
| MS Antenna Gain \[dBi\]          | **0**                            |
+----------------------------------+----------------------------------+
| Shadowing Standard Deviation     | **8**                            |
| \[dB\]                           |                                  |
+----------------------------------+----------------------------------+
| Path Loss Model: COST 231        | **-136+35.22\*log10(d), d in     |
|                                  | km**                             |
+----------------------------------+----------------------------------+
| Shadow Site to site Correlation  | **50%**                          |
+----------------------------------+----------------------------------+
| Other Losses \[dB\]              | **8**                            |
+----------------------------------+----------------------------------+
| UMTS BS Antenna                  | **per TR 25.896 v6.0.0 A.3.1.1** |
|                                  |                                  |
| pattern                          | **65**                           |
|                                  |                                  |
| beamwidth \[degrees\]            |                                  |
+----------------------------------+----------------------------------+
| Number of MS Antennas            | **2**                            |
+----------------------------------+----------------------------------+
| Propagation Channel Mixture for  | **25% AWGN**                     |
| loading users                    |                                  |
|                                  | **37% PedB 3 kph**               |
|                                  |                                  |
|                                  | **13% PedB 30 kph**              |
|                                  |                                  |
|                                  | **13% VehA 30 kph**              |
|                                  |                                  |
|                                  | **12% VehA 120 kph**             |
+----------------------------------+----------------------------------+
| Number of loading users          | **E-DCH: 40 UEs per cell**       |
| simulated                        |                                  |
|                                  | **HSDPA: 40/60/80/100 UEs per    |
|                                  | cell**                           |
+----------------------------------+----------------------------------+
| Propagation Channel for the      | **Case 1: PedB 3 kph**           |
| Reference UE                     |                                  |
|                                  | **Case 2: PedB 30 kph**          |
|                                  |                                  |
|                                  | **Case 3: VehA 30 kph**          |
|                                  |                                  |
|                                  | **Case 4: VehA 120 kph**         |
+----------------------------------+----------------------------------+
| Location for Reference UE        | **Case 1: One cell in active     |
|                                  | set, UE geometry = 3.3 dB**      |
|                                  |                                  |
|                                  | **Case 2: Soft handoff with 2    |
|                                  | cells in active set, UE geometry |
|                                  | = 3.0 dB, UE serving cell        |
|                                  | geometry = -0.7 dB**             |
+----------------------------------+----------------------------------+
| Ec/Io Admission Threshold        | **-18 dB**                       |
+----------------------------------+----------------------------------+
| RSCP Admission Threshold         | **-115 dBm**                     |
+----------------------------------+----------------------------------+
| Number of Node Bs                | **19 Node Bs/57 cells**          |
+----------------------------------+----------------------------------+
| Cell layout                      | **3-Cell Clover-Leaf**           |
+----------------------------------+----------------------------------+
| Inter-site Distance \[m\]        | **2500**                         |
+----------------------------------+----------------------------------+
| Frequency                        | **1990 MHz**                     |
+----------------------------------+----------------------------------+

Table K.4 Simulation 1, traffic assumptions

+----------------------------------+----------------------------------+
| **Parameter**                    |                                  |
+----------------------------------+----------------------------------+
| User-Plane Traffic Model         | **100% VoIP**                    |
|                                  |                                  |
| Vocoder Type                     | **AMR 12.2**                     |
|                                  |                                  |
| Vocoder Voice Model Loading      | **Markov Process with 50%        |
| Users                            | activity (transition probability |
|                                  | = 0.01)**                        |
| Vocoder Voice Model Reference UE |                                  |
|                                  | **100% activity**                |
+----------------------------------+----------------------------------+
| VoIP Packet Overheads            | **1 byte RLC UM header**         |
|                                  |                                  |
|                                  | **4 bytes ROHC header**          |
+----------------------------------+----------------------------------+
| ROHC dynamics                    | **Resynchronization ignored**    |
+----------------------------------+----------------------------------+
| RTCP                             | **Not modeled**                  |
+----------------------------------+----------------------------------+
| SIP                              | **Not modeled**                  |
+----------------------------------+----------------------------------+
| SID Frames                       | **Not transmitted**              |
+----------------------------------+----------------------------------+
| RTP layer aggregation            | **None**                         |
+----------------------------------+----------------------------------+
| MAC-d PDU Size                   | **296 bits**                     |
+----------------------------------+----------------------------------+

**Table K.5 Simulation 1, other simulation assumptions**

+----------------------------------+----------------------------------+
| **Parameter**                    |                                  |
+----------------------------------+----------------------------------+
| UMTS Time Modelled \[s\]         | **60**                           |
+----------------------------------+----------------------------------+
| Training Time \[s\]              | **5**                            |
+----------------------------------+----------------------------------+
| UE Category                      | **5**                            |
+----------------------------------+----------------------------------+
| Receiver Type                    | **Rake with Mobile Receive       |
|                                  | Diversity from 2 Antennas**      |
|                                  |                                  |
|                                  | **(2 Rx correlation = 0.5,       |
|                                  | mismatch 2 dB)**                 |
+----------------------------------+----------------------------------+
| Downlink DCCH Traffic and        | **DCCH mapped to HS-DSCH, F-DPCH |
| Transport                        | used instead of assoc. DPCH.     |
|                                  | DCCH traffic modeled as 3.4kbps  |
|                                  | source with 5% activity          |
|                                  | factor.**                        |
+----------------------------------+----------------------------------+
| Max. HSDPA Transmit Power        | **18 watt -- power allocated for |
| (HS-SCCH + HS-PDSCH)             | all common and dedicated         |
|                                  | channels**                       |
+----------------------------------+----------------------------------+
| HS-SCCH Channel Model            | **Depends on loading**           |
|                                  |                                  |
| Number                           | **Yes**                          |
|                                  |                                  |
| Errors Impact HS-DSCH Decoding   | **Fixed Offset from F-DPCH**     |
|                                  |                                  |
| Power Allocation                 |                                  |
+----------------------------------+----------------------------------+
| Downlink Over-the air Delay      | **90**                           |
| Budget \[ms\] (MAC-d to MAC-d)   |                                  |
+----------------------------------+----------------------------------+
| Iub delay modelled               | **No**                           |
+----------------------------------+----------------------------------+
| HSDPA Scheduler Implementation   | **Proprietary**                  |
+----------------------------------+----------------------------------+
| Mobility Model                   | **Static UE locations**          |
+----------------------------------+----------------------------------+
| E-DCH Scheduling                 | **Non-scheduled transmission**   |
+----------------------------------+----------------------------------+
| E-DCH TTI length                 | **Both 10ms TTI and 2ms TTI**    |
+----------------------------------+----------------------------------+
| E-DCH max number of HARQ         | **2 Tx for 10ms TTI**            |
| transmissions                    |                                  |
|                                  | **4 Tx for 2ms TTI**             |
+----------------------------------+----------------------------------+
| E-DCH QoS                        | **Target 1% BLER post-HARQ**     |
+----------------------------------+----------------------------------+
| HS-DPCCH modeled for E-DCH       | **Yes**                          |
| simulation                       |                                  |
+----------------------------------+----------------------------------+

Table K.6 Simulation 2, simulation assumptions

  ---------------- --
  **Parameters**   
  ---------------- --

+----------------------------------+----------------------------------+
| Multipath channel models         | **PA3 and PB3**                  |
|                                  |                                  |
|                                  | **Fader type: JTC.**             |
+----------------------------------+----------------------------------+
| User path loss and setup         | **PA3:**                         |
|                                  |                                  |
|                                  | **Geometry from serving cell:    |
|                                  | 1.65 dB**                        |
|                                  |                                  |
|                                  | **Soft-handover geometry: 5.8    |
|                                  | dB**                             |
|                                  |                                  |
|                                  | **Soft-handover legs: 2**        |
|                                  |                                  |
|                                  | **PB3:**                         |
|                                  |                                  |
|                                  | **Geometry from serving cell:    |
|                                  | 0.09 dB**                        |
|                                  |                                  |
|                                  | **Soft-handover geometry: 5.22   |
|                                  | dB**                             |
|                                  |                                  |
|                                  | **Soft-handover legs: 2**        |
|                                  |                                  |
|                                  | **Number of UE antennas: 1.**    |
+----------------------------------+----------------------------------+
| Node B resources                 | **DL power reserved for common   |
|                                  | channels and DPCH for all users: |
|                                  | 7.5 Watt (30%)**                 |
|                                  |                                  |
|                                  | **3 Watt for common channels + 1 |
|                                  | Watt / \~100 users for DPCH**    |
|                                  |                                  |
|                                  | **Remaining power for all        |
|                                  | HS-SCCH and HS-PDSCH: 17.6       |
|                                  | Watt**                           |
|                                  |                                  |
|                                  | OVSF codes reserved for common   |
|                                  | channels:                        |
|                                  |                                  |
|                                  |                                  |
|                                  | ------------- --------- -------- |
|                                  |   **Channel**   **SF**    **Nb** |
|                                  |   **CPICH**     **256**   **1**  |
|                                  |   **P-CCPCH**   **256**   **1**  |
|                                  |   **S-CCPCH**   **256**   **1**  |
|                                  |   **E-AGCH**    **256**   **1**  |
|                                  |   **AICH**      **256**   **1**  |
|                                  |   **PICH**      **256**   **1**  |
|                                  |                                  |
|                                  | ------------- --------- -------- |
|                                  |                                  |
|                                  | **OVSF code usage modeled for    |
|                                  | dedicated channels:**            |
|                                  |                                  |
|                                  | **F-DPCH + AICH**                |
|                                  |                                  |
|                                  | **Soft-handover overhead: 1.8**  |
|                                  |                                  |
|                                  | **Up to 8 simultaneous HS-DSCH   |
|                                  | transmissions allowed.**         |
+----------------------------------+----------------------------------+
| IMS VoIP packet format and       | **AMR 12.2 kbps.**               |
| overheads                        |                                  |
|                                  | **VoIP packet with payload       |
|                                  | according to RFC3267.**          |
|                                  |                                  |
|                                  | **24-bit ROHC overhead.**        |
|                                  |                                  |
|                                  | **8-bit RLC overhead.**          |
|                                  |                                  |
|                                  | **No voice packet bundling.**    |
+----------------------------------+----------------------------------+
| VoIP traffic modelling           | **Voice users\' frame boundaries |
|                                  | are randomly time-staggered.**   |
|                                  |                                  |
|                                  | **SID transmitted every 160 ms   |
|                                  | of silence.**                    |
|                                  |                                  |
|                                  | **Voice activity model for       |
|                                  | background users:**              |
|                                  |                                  |
|                                  | **ON and OFF periods of duration |
|                                  | exponentially distributed, of    |
|                                  | average 3 seconds.**             |
|                                  |                                  |
|                                  | **50% voice activity.**          |
|                                  |                                  |
|                                  | **Voice activity model for       |
|                                  | selected user : 100% voice       |
|                                  | activity**                       |
+----------------------------------+----------------------------------+
| Signaling traffic                | **SRB, RTCP, and SIP not         |
|                                  | modeled.**                       |
+----------------------------------+----------------------------------+
| HSDPA scheduling                 | **VoIP traffic scheduler:**      |
|                                  |                                  |
|                                  | **Exponential scheduling rule    |
|                                  | with**                           |
|                                  | ![](media/image146.w             |
|                                  | mf){width="0.4166666666666667in" |
|                                  | height="0.25in"}**.**            |
|                                  |                                  |
|                                  | **SDU discarding in the MAC-HS   |
|                                  | modeled.**                       |
+----------------------------------+----------------------------------+
| HSDPA feedback delays            | **CQI delay: 8 slots from time   |
|                                  | of measure to start of HS-PDSCH  |
|                                  | transmission.**                  |
|                                  |                                  |
|                                  | **HARQ delay: minimum 15 slots   |
|                                  | from end of a transmission to    |
|                                  | start of a re-transmission.**    |
+----------------------------------+----------------------------------+
| HSDPA error modelling            | **HS-PDSCH: threshold-based      |
|                                  | decoder.**                       |
|                                  |                                  |
|                                  | **HS-SCCH: threshold-based       |
|                                  | decoder.**                       |
|                                  |                                  |
|                                  | **CQI: perfect estimation and    |
|                                  | with quantization errors.**      |
|                                  |                                  |
|                                  | **HS-DPCCH: HARQ feedback errors |
|                                  | modelled with ACK false alarm    |
|                                  | probability of 10^-3^ and ACK    |
|                                  | mis-detection probability of     |
|                                  | 10^-2^.**                        |
+----------------------------------+----------------------------------+
| RAB for HSDPA                    | **According to reference RAB     |
|                                  | configuration for VoIP over      |
|                                  | HSDPA in \[5\].**                |
+----------------------------------+----------------------------------+
| EUL format                       | **2 ms TTI, 3 transmissions**    |
+----------------------------------+----------------------------------+
| EUL scheduling                   | **Non-scheduled, autonomous      |
|                                  | transmissions.**                 |
|                                  |                                  |
|                                  | **Delay from received packet     |
|                                  | re-ordering not modelled**       |
+----------------------------------+----------------------------------+
| EUL error modelling              | **No errors on E-HICH**          |
|                                  |                                  |
|                                  | **4% independent errors on       |
|                                  | F-DPCH**                         |
|                                  |                                  |
|                                  | **E-DPCCH power modelled, but    |
|                                  | assumed error-free**             |
|                                  |                                  |
|                                  | **HS-DPCCH not modelled**        |
+----------------------------------+----------------------------------+
| Simulation duration              | **3,000 warm-up slots**          |
|                                  |                                  |
|                                  | **90,000 execution slots**       |
+----------------------------------+----------------------------------+
| RAB for EUL                      | **According to reference RAB     |
|                                  | configuration for VoIP over EUL  |
|                                  | in \[5\].**                      |
+----------------------------------+----------------------------------+

######### Annex L: Test Plan for the AMR NB/WB Conversation Test in UMTS over HSDPA/EUL

L.1 Introduction
================

This document contains the test plan of a conversation test for the
selected speech codecs of Adaptive Multi-Rate Narrow-Band (AMR-NB) and
Adaptive Multi-Rate Wide-Band (AMR-WB) in Packet Switched networks with
HSDPA/HSUPA radio interface, where HSUPA is also referred to as EUL, or
EDCH within the terminology of 3GPP-TSG-RAN. All the laboratories
participating in the conversation test will use the same test plan,
while each laboratory uses a different test language. Even if the test
rooms or the test equipments are not exactly the same in all the
laboratories, the calibration procedures and the tests equipment
characteristics will guarantee the similarity of the test conditions.
The details of the test plan is given in the following in 3 sections:

\- Section 2 gives the general information regarding the test.

\- Section 3 details the test design and test methodology

\- Section 4 provides procedure for the test arrangement and logistics

L.2 General Information
=======================

L.2.1 Permanent Documents
-------------------------

ITU-T Rec. P.800 Methods for Subjective Determination of Transmission
Quality

ITU-T Rec. P.805 Conversational Tests

L.2.2 Key Acronyms
------------------

  -------- ---------------------------------------------
  AMR-NB   Adaptive Multi-Rate Narrowband Speech Codec
  AMR-WB   Adaptive Multi-Rate Wide-band Speech Codec
  MOS      Mean Opinion Score
  HSPA     High Speed Packet Access
  HSDPA    High Speed Downlink Packet Access
  HSUPA    High Speed Uplink Packet Access
  -------- ---------------------------------------------

L.2.3 Contacts
--------------

The following persons should be contacted for questions related to the
test and test plan.

+-------------+-------------+-------------+-------------+-------------+
| Res         | Contacts    | Affiliation | Mail        | Phon        |
| ponsibility |             |             | Address     | e/Fax/Email |
+-------------+-------------+-------------+-------------+-------------+
| C           | Jim McGowan | Alc         | 67 Whippany | Tel: +1 908 |
| oordination |             | atel-Lucent | Rd. Rm      | 582 5667    |
|             |             |             | 2A-384,     |             |
| Test Bed    |             |             |             | Fax:        |
|             |             |             | Whippany,   | +1-9        |
|             |             |             | NJ 07891,   | 73-386-4555 |
|             |             |             | USA         |             |
|             |             |             |             | mcgowan\    |
|             |             |             |             | @lucent.com |
+-------------+-------------+-------------+-------------+-------------+
| 3GPP-TSG-S  | Paolo Usai  | ETSI MCC    | 650 Route   | Tel:+33 -4  |
| A4-SQ-Chair |             |             | des         | 92 94 42    |
|             |             |             | Lucioles\   | 36\         |
|             |             |             | 06921       | Fax: + 33 4 |
|             |             |             | Sophia      | 93 38 52 06 |
|             |             |             | Antipolis   |             |
|             |             |             | Cedex\      | paolo.usa   |
|             |             |             | France      | i\@etsi.org |
+-------------+-------------+-------------+-------------+-------------+
| Background  | Alan        | Dynastat    | 6850 Austin | Tel.:+1-5   |
| Noise       | Sharpley    |             | Center      | 12-476-4797 |
| Material    |             |             | Blvd.,      |             |
|             |             |             | Ste.150     | Fax:+1-5    |
|             |             |             |             | 12-472-2883 |
|             |             |             | Austin, TX  |             |
|             |             |             | 78731       | a           |
|             |             |             |             | sharpley\@d |
|             |             |             |             | ynastat.com |
+-------------+-------------+-------------+-------------+-------------+

L.2.4 Participants
------------------

Each test laboratory has the responsibility to organize its conversation
tests. The list of the participating test laboratories is the following:

+---------+------------------+------------------+------------------+
| **Lab** | **Company**      | **Test           | **Contact**      |
|         |                  | Language**       |                  |
+---------+------------------+------------------+------------------+
| 1       | France Telecom   | French           | Catherine        |
|         |                  |                  | Quinquis,        |
|         |                  |                  |                  |
|         |                  |                  | France Telecom\  |
|         |                  |                  | RD/TECH/SSTP\    |
|         |                  |                  | Technopole       |
|         |                  |                  | Anticipa\        |
|         |                  |                  | 2, Av P Marzin\  |
|         |                  |                  | 22307 Lannion,   |
|         |                  |                  | Cédex, France    |
|         |                  |                  |                  |
|         |                  |                  | Tel : +33-29605  |
|         |                  |                  | 1493             |
|         |                  |                  |                  |
|         |                  |                  | Fax : +33-29605  |
|         |                  |                  | 3530             |
|         |                  |                  |                  |
|         |                  |                  | cather           |
|         |                  |                  | ine.quinquis\@or |
|         |                  |                  | ange-ftgroup.com |
+---------+------------------+------------------+------------------+
| 2       | Dynastat         | English          | Alan Sharpley,   |
|         |                  |                  |                  |
|         |                  |                  | 6850 Austin      |
|         |                  |                  | Center Blvd.,    |
|         |                  |                  | Ste.150, Austin, |
|         |                  |                  | TX 78731, US     |
|         |                  |                  |                  |
|         |                  |                  | Tel.             |
|         |                  |                  | :+1-512-476-4797 |
|         |                  |                  |                  |
|         |                  |                  | Fax              |
|         |                  |                  | :+1-512-472-2883 |
|         |                  |                  |                  |
|         |                  |                  | <asharpl         |
|         |                  |                  | ey@dynastat.com> |
+---------+------------------+------------------+------------------+
| 3       | Beijing          | Chinese          | Prof. Xie Xiang, |
|         | Institute of     |                  |                  |
|         | Technology       |                  | No.5 South       |
|         |                  |                  | Zhongguancun     |
|         |                  |                  | Street, Haidian  |
|         |                  |                  | District,        |
|         |                  |                  | Beijing 100081,  |
|         |                  |                  | China            |
|         |                  |                  |                  |
|         |                  |                  | Phone: +86 10    |
|         |                  |                  | 68915838         |
|         |                  |                  |                  |
|         |                  |                  | xiex             |
|         |                  |                  | iang\@bit.edu.cn |
+---------+------------------+------------------+------------------+

L.3 Test Methodology
====================

L.3.1 Introduction
------------------

The method evaluates the effect of degradation on the quality of the
communications through the conversation-opinion tests recommended by the
ITU-T P.800. The conversation--opinion tests allow subjects in the test
to be in a more realistic situation in terms of the actual service
conditions experienced by telephone customers. In addition, the
conversation-opinion tests are suited to assess the effects of
impairments that can cause difficulty while conversing. Subjects
participate to the test in couple; they are seated in separate
sound-proof rooms and are asked to hold a conversation through the
transmission chain simulated by a computer that generates the impairment
of the communication link considered typical for the packet switched
network with HSDPA/HSUPA air-interface. The simulated network
configurations (including the terminal equipments) will be symmetrical
(in the two transmission paths as shown in Figure L.1, but the link
conditions in each direction can be asymmetrical (to be elucidated
later).

![](media/image147.wmf){width="5.760416666666667in"
height="1.386111111111111in"}

Figure L.1: Test Arrangement

L.3.2 Test Design
-----------------

### L.3.2.1 Description of the Test Bed

The test bed intends to provide an emulated transmission system that
resembles the UMTS with HSDPA/HSUPA, as shown by Figure L.2. The real
situation to be tested is a process in which a bit-stream is encoded by
AMR packet-wise and transmitted through a HSUPA and HSDPA
air-interfaces, so that it reaches the receiver, where it is decoded by
AMR decoder packet-wise. The bit-stream encounters impairments while
traversing through the system. The impairment is simulated by the
simulator off-line and played into the test bed during the test.

![](media/image148.wmf){width="5.9944444444444445in" height="1.25625in"}

Figure L.2: UMTS system under test

Simulated transmission links are implemented in hardware through two
computers, each being responsible for one direction, as shown in Figure
L.3. The Internet Protocol is implemented in both computers. Each AMR
frame generated by the AMR encoder is wrapped in a unique RTP packet
every 20 ms. At the receiver the RTP packets are buffered and delayed
according to the lower layer simulated receive time.

![](media/image149.wmf){width="6.002777777777778in"
height="2.352777777777778in"}

Figure L.3: Implementation of the Test Bed

The radio access bearer (RAB) represents the performance of the
HSDPA/HSUPA of the physical layer. During the test, the test bed uses
the delay-error profiles generated by the off-line simulation of the
RAB. A software unit that inserts the off-line generated delays and
errors into the RTP flows is implemented in each computer and allows
selections of different network and channel conditions.

### L.3.2.2 Transmission System

The transmission system is configured as a mobile-to-mobile connection
within an IMS with HSDPA downlink and an HSUPA uplink. The protocol
stack of the radio interface is shown in Figure L.4. The simulation of
the performance of the radio interface simulator is based on a network
layout of 19 cells and 57 sectors, while the output of the simulation is
a sequence of RLC packet reception status. A RLC packet is transmitted
from the mobile to the origination RNC, and from the destination RNC to
the destination RNC via the core network, before reaching the receive
mobile. The recorded traces include the delay and the error event of the
received RLC packets.

![](media/image150.wmf){width="5.499305555555556in"
height="1.9993055555555554in"}

Figure L.4: Transmission path through a UMTS

The transmission of IP/UDP/RTP/AMR packets over the core network is not
further simulated in details besides a static end-to-end delay.

### L.3.2.3 Radio Access Bearers

The AMR-NB/AMR-WB will encode speech at a 5.9 kbps, 12.2 kbps, and 12.65
kbps, respectively. The bit-stream will be encapsulated using IP/UDP/RTP
protocols and sent to the air-interface emulator located in the
origination computer. The output of the air-interface is the payload of
the IP packets, which are then sent through an RJ-45 port of the
origination computer and received by the destination computer, where the
RTP packets will be extracted and the AMR-NB/AMR-WB frames are buffered
and decoded.

The RABs underlying the test are specified in TS 25.993 in the following
sections:

\"

3.  \- RB for Conversational / unknown UL: \[max bitrate depending on UE
    category and TTI\] on E-DCH DL: \[max bitrate depending on UE
    category\] on HS-DSCH / PS RAB\
    + RB for interactive or background / UL : \[max bitrate depending on
    UE category and TTI\] on E-DCH DL : \[max bitrate depending on UE
    category\] on HS-DSCH / PS RAB\
    + RB for interactive or background / UL : \[max bitrate depending on
    UE category and TTI\] on E-DCH DL : \[max bitrate depending on UE
    category\] on HS-DSCH / PS RAB\
    + UL : \[max bitrate depending on UE category and TTI\] on E-DCH DL
    : \[max bit rate depending on UE category\] on HS-DSCH SRBs for
    DCCH\"

4.  RB for Conversational / Unknown UL: \[max bitrate depending on UE
    category and TTI\] on E-DCH DL: \[max bitrate depending on UE
    category\] on HS-DSCH / PS RAB\
    + RB for interactive or background / UL : \[max bitrate depending on
    UE category and TTI\] on E-DCH DL : \[max bitrate depending on UE
    category\] on HS-DSCH / PS RAB\
    + UL : \[max bitrate depending on UE category and TTI\] on E-DCH DL
    : \[max bit rate depending on UE category\] on HS-DSCH SRBs for
    DCCH\"

\"

### L.3.2.4 Test environment

An external sound card will be used for each computer of the test bed.
To avoid echo problems, headsets, instead of handsets will be used. The
monaural supra-aural headsets, the other ear uncovered, are connected to
the sound cards. But, in practice, the original settings, defined during
the preliminary tests, and producing a comfortable listening level, will
not be modified. A foam ball protects the microphones in order to reduce
the \"pop\" effect. The user should avoid to place the acoustic opening
of the microphone in front of the mouth

Each of the two subjects participating in the conversations is installed
in a test room. They sit in an armchair in front of a table. The test
rooms are acoustically insulated. All the test equipments are installed
in a third room, connected to the test rooms. When needed, the
background noise is generated in the appropriate test room through a set
of 4 loudspeakers. The background noise level is adjusted and controlled
by a sound level meter. The measurement microphone, connected to the
sound level meter is located at the equivalent of the center of the
subject\'s head. The noise level is A weighted.

Before the beginning of a set of experiments, the end-to-end
transmission level is checked subjectively, to ensure that there is no
problem. The speech level is checked by the following procedure: An
artificial mouth placed in front of the microphone of the Headset A, in
the LRGP position -See ITU-T Rec. P.64-, generates in the artificial ear
(according to ITU-T Rec. P57) coupled to the earphone of the Head set B
the nominal level defined in section 4.3. The level is adjusted
according to the bandwidth to -15 dB Pa for NB and to -18 dB Pa for WB ,
when necessary, with the receiving volume control of the headset.
Inverting headsets A and B does a similar calibration.

At each test laboratory the test bed must be calibrated, so that the
given value of fixed delay for the speech transmission is the same for
all labs.

L.3.3 Test Conditions
---------------------

Three codec rates will be tested: AMR-NB 5.9 kbps and 12.2 kbps, as well
as AMR-WB 12.65 kbps. Two different categories of test conditions are
defined and their combination makes the actual test conditions.

*Network Condition*

**Table L.1: Definition of the radio network conditions**

+-------------------------+-------------+--------------+--------+
| Radio Network Condition | Low Traffic | High Traffic | Uplink |
|                         |             |              |        |
|                         | Down Link   | Down Link    |        |
+-------------------------+-------------+--------------+--------+
| Low Mobility Mobile     | LM.LT       | LM.HT        | Lm     |
+-------------------------+-------------+--------------+--------+
| High Mobility Mobile    | HM.LT       | HM.HT        | Hm     |
+-------------------------+-------------+--------------+--------+

In specifics:

[- Low]{.underline} Traffic (LT): 40, or 45, or 60 mobile users per cell

[- High]{.underline} Traffic (HT): 80, or 100 mobile users per cell

[- Low]{.underline} Mobility (LM, Lm): ITU --Channel-Model: PedB3\_km or
PedA3\_km

[- High]{.underline} Mobility (HM, Hm): ITU-Channel-Model: VehA30km or
Veh120km or PedB30km

The uplinks are simulated as dedicated channel, hence the traffic
conditions apply only to the downlinks. From a mobile-to-mobile
connection, the order of the uplink and downlink plays no role.
Therefore, we have the following 8 possible construction of channel
conditions:

Table L.2 Notation for the mobile-to-mobile radio network conditions

  -------------- ---------------- ---------------
  ***Number***   ***Notation***   ***Meaning***
  \[1\]          Lm.LT.LM         Lm + LT.LM
  \[2\]          Lm.LT.HM         Lm+LT.HM
  \[3\]          Lm.HT.LM         Lm+HT.LM
  \[4\]          Lm.HT.HM         Lm+HT.HM
  \[5\]          Hm.LT.LM         Hm+LT.LM
  \[6\]          Hm.LT.HM         Hm+LT.HM
  \[7\]          Hm.HT.LM         Hm+HT.LM
  \[8\]          Hm.HT.HM         Hm+HT.HM
  -------------- ---------------- ---------------

*Acoustic Noise Condition*

The condition refers the characteristic background noise of the
subjects; four classes of noise will be deployed:

  ------------ ----------------------------------------------------------------------------------------------------------------------------------
  Noise type   Level (dB Pa )
  Car          -30
  Street       -35
  Cafeteria    -35
  Hoth         Spectrum at 30 dBA as defined by ITU-T, Recommendation P.800, Annex A, section A.1.1.2.2.1 Room Noise, with table A.1 and Figure
  ------------ ----------------------------------------------------------------------------------------------------------------------------------

The production of background noise follows the guide lines of ETSI EG
202 396-1 (clause 6).

*Combined Test Conditions*

Each test condition is assigned a unique number defined as following:

  ------------- ---------- -------------- ------------ ---------------
  x-y.z.c       x          y              Z            C
  e.g. 1-1.3a   AMR-Mode   Network Load   Experiment   Swap subjects
  ------------- ---------- -------------- ------------ ---------------

*Following conditions will be used for the tests:*

AMR-Mode 5.9 kbps (x=1): 8 conditions (y=1), 8 conditions (y=2)

+---------+----------+----------+----------+----------+----------+
| *Cond.* | *Noise   | *Radio   | *Noise   | *Desc    | *Cond.   |
|         | in Room  | Network* | in Room  | ription* | Number*  |
| *Label* | A*       |          | B*       |          |          |
|         |          | *Co      |          |          |          |
|         |          | ndition* |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-1.1   | Hoth     | A-\>B:   | Hoth     | Lm.LT.LM | 1        |
|         |          | \[1\]    |          |          |          |
|         |          |          |          | LM.LT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[1\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-1.2   | Car      | A-\>B:   | Car      | Hm.LT.HM | 2        |
|         |          | \[6\]    |          |          |          |
|         |          |          |          | HM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[6\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-1.3a  | Car      | A-\>B:   | Hoth     | Hm.LT.LM | 3        |
|         |          | \[5\]    |          |          |          |
|         |          |          |          | HM.LT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[2\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-1.3b  | Hoth     | A-\>B:   | Car      | Lm.LT.HM | 4        |
|         |          | \[2\]    |          |          |          |
|         |          |          |          | LM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[5\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-1.4   | C        | A-\>B:   | C        | Lm.LT.LM | 5        |
|         | afeteria | \[1\]    | afeteria |          |          |
|         |          |          |          | LM.LT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[1\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-1.5a  | C        | A-\>B:   | Street   | Lm.LT.HM | 6        |
|         | afeteria | \[2\]    |          |          |          |
|         |          |          |          | LM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[5\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-1.5b  | Street   | A-\>B:   | C        | Hm.LT.LM | 7        |
|         |          | \[5\]    | afeteria |          |          |
|         |          |          |          | HM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[2\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-1.6   | Street   | A-\>B:   | Street   | Hm.LT.HM | 8        |
|         |          | \[6\]    |          |          |          |
|         |          |          |          | HM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[6\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-2.1   | Hoth     | A-\>B:   | Hoth     | Lm.HT.LM | 9        |
|         |          | \[3\]    |          |          |          |
|         |          |          |          | LM.HT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[3\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-2.2   | Car      | A-\>B:   | Car      | Hm.HT.HM | 10       |
|         |          | \[8\]    |          |          |          |
|         |          |          |          | HM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[8\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-2.3a  | Car      | A-\>B:   | Hoth     | Hm.HT.LM | 11       |
|         |          | \[7\]    |          |          |          |
|         |          |          |          | HM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[4\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-2.3b  | Hoth     | A-\>B:   | Car      | Lm.HT.HM | 12       |
|         |          | \[4\]    |          |          |          |
|         |          |          |          | LM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[7\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-2.4   | C        | A-\>B:   | C        | Lm.HT.LM | 13       |
|         | afeteria | \[3\]    | afeteria |          |          |
|         |          |          |          | LM.HT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[3\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-2.5a  | C        | A-\>B:   | Street   | Lm.HT.HM | 14       |
|         | afeteria | \[4\]    |          |          |          |
|         |          |          |          | LM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[7\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-2.5b  | Street   | A-\>B:   | C        | Hm.HT.LM | 15       |
|         |          | \[7\]    | afeteria |          |          |
|         |          |          |          | HM.HT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[4\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 1-2.6   | Street   | A-\>B:   | Street   | Hm.HT.HM | 16       |
|         |          | \[8\]    |          |          |          |
|         |          |          |          | HM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[8\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+

AMR-Mode 12.2 kbps (x=2): 8 conditions (y=1), 8 conditions (y=2)

+---------+----------+----------+----------+----------+----------+
| *Cond.* | *Noise   | *Radio   | *Noise   | *Desc    | *Cond.   |
|         | in Room  | Network* | in Room  | ription* | Number*  |
| *Label* | A*       |          | B*       |          |          |
|         |          | *Co      |          |          |          |
|         |          | ndition* |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-1.1   | Hoth     | A-\>B:   | Hoth     | Lm.LT.LM | 1        |
|         |          | \[1\]    |          |          |          |
|         |          |          |          | LM.LT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[1\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-1.2   | Car      | A-\>B:   | Car      | Hm.LT.HM | 2        |
|         |          | \[6\]    |          |          |          |
|         |          |          |          | HM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[6\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-1.3a  | Car      | A-\>B:   | Hoth     | Hm.LT.LM | 3        |
|         |          | \[5\]    |          |          |          |
|         |          |          |          | HM.LT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[2\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-1.3b  | Hoth     | A-\>B:   | Car      | Lm.LT.HM | 4        |
|         |          | \[2\]    |          |          |          |
|         |          |          |          | LM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[5\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-1.4   | C        | A-\>B:   | C        | Lm.LT.LM | 5        |
|         | afeteria | \[1\]    | afeteria |          |          |
|         |          |          |          | LM.LT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[1\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-1.5a  | C        | A-\>B:   | Street   | Lm.LT.HM | 6        |
|         | afeteria | \[2\]    |          |          |          |
|         |          |          |          | LM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[5\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-1.5b  | Street   | A-\>B:   | C        | Hm.LT.LM | 7        |
|         |          | \[5\]    | afeteria |          |          |
|         |          |          |          | HM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[2\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-1.6   | Street   | A-\>B:   | Street   | Hm.LT.HM | 8        |
|         |          | \[6\]    |          |          |          |
|         |          |          |          | HM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[6\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-2.1   | Hoth     | A-\>B:   | Hoth     | Lm.HT.LM | 9        |
|         |          | \[3\]    |          |          |          |
|         |          |          |          | LM.HT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[3\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-2.2   | Car      | A-\>B:   | Car      | Hm.HT.HM | 10       |
|         |          | \[8\]    |          |          |          |
|         |          |          |          | HM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[8\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-2.3a  | Car      | A-\>B:   | Hoth     | Hm.HT.LM | 11       |
|         |          | \[7\]    |          |          |          |
|         |          |          |          | HM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[4\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-2.3b  | Hoth     | A-\>B:   | Car      | Lm.HT.HM | 12       |
|         |          | \[4\]    |          |          |          |
|         |          |          |          | LM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[7\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-2.4   | C        | A-\>B:   | C        | Lm.HT.LM | 13       |
|         | afeteria | \[3\]    | afeteria |          |          |
|         |          |          |          | LM.HT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[3\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-2.5a  | C        | A-\>B:   | Street   | Lm.HT.HM | 14       |
|         | afeteria | \[4\]    |          |          |          |
|         |          |          |          | LM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[7\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-2.5b  | Street   | A-\>B:   | C        | Hm.HT.LM | 15       |
|         |          | \[7\]    | afeteria |          |          |
|         |          |          |          | HM.HT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[4\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 2-2.6   | Street   | A-\>B:   | Street   | Hm.HT.HM | 16       |
|         |          | \[8\]    |          |          |          |
|         |          |          |          | HM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[8\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+

AMR-WB-Mode 12.65 kbps (x=3): 8 conditions (y=1), 8 conditions (y=2)

+---------+----------+----------+----------+----------+----------+
| *Cond.* | *Noise   | *Radio   | *Noise   | *Desc    | *Cond.   |
|         | in Room  | Network* | in Room  | ription* | Number*  |
| *Label* | A*       |          | B*       |          |          |
|         |          | *Co      |          |          |          |
|         |          | ndition* |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-1.1   | Hoth     | A-\>B:   | Hoth     | Lm.LT.LM | 1        |
|         |          | \[1\]    |          |          |          |
|         |          |          |          | LM.LT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[1\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-1.2   | Car      | A-\>B:   | Car      | Hm.LT.HM | 2        |
|         |          | \[6\]    |          |          |          |
|         |          |          |          | HM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[6\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-1.3a  | Car      | A-\>B:   | Hoth     | Hm.LT.LM | 3        |
|         |          | \[5\]    |          |          |          |
|         |          |          |          | HM.LT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[2\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-1.3b  | Hoth     | A-\>B:   | Car      | Lm.LT.HM | 4        |
|         |          | \[2\]    |          |          |          |
|         |          |          |          | LM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[5\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-1.4   | C        | A-\>B:   | C        | Lm.LT.LM | 5        |
|         | afeteria | \[1\]    | afeteria |          |          |
|         |          |          |          | LM.LT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[1\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-1.5a  | C        | A-\>B:   | Street   | Lm.LT.HM | 6        |
|         | afeteria | \[2\]    |          |          |          |
|         |          |          |          | LM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[5\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-1.5b  | Street   | A-\>B:   | C        | Hm.LT.LM | 7        |
|         |          | \[5\]    | afeteria |          |          |
|         |          |          |          | HM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[2\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-1.6   | Street   | A-\>B:   | Street   | Hm.LT.HM | 8        |
|         |          | \[6\]    |          |          |          |
|         |          |          |          | HM.LT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[6\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-2.1   | Hoth     | A-\>B:   | Hoth     | Lm.HT.LM | 9        |
|         |          | \[3\]    |          |          |          |
|         |          |          |          | LM.HT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[3\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-2.2   | Car      | A-\>B:   | Car      | Hm.HT.HM | 10       |
|         |          | \[8\]    |          |          |          |
|         |          |          |          | HM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[8\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-2.3a  | Car      | A-\>B:   | Hoth     | Hm.HT.LM | 11       |
|         |          | \[7\]    |          |          |          |
|         |          |          |          | HM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[4\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-2.3b  | Hoth     | A-\>B:   | Car      | Lm.HT.HM | 12       |
|         |          | \[4\]    |          |          |          |
|         |          |          |          | LM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[7\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-2.4   | C        | A-\>B:   | C        | Lm.HT.LM | 13       |
|         | afeteria | \[3\]    | afeteria |          |          |
|         |          |          |          | LM.HT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[3\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-2.5a  | C        | A-\>B:   | Street   | Lm.HT.HM | 14       |
|         | afeteria | \[4\]    |          |          |          |
|         |          |          |          | LM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[7\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-2.5b  | Street   | A-\>B:   | C        | Hm.HT.LM | 15       |
|         |          | \[7\]    | afeteria |          |          |
|         |          |          |          | HM.HT.Lm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[4\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+
| 3-2.6   | Street   | A-\>B:   | Street   | Hm.HT.HM | 16       |
|         |          | \[8\]    |          |          |          |
|         |          |          |          | HM.HT.Hm |          |
|         |          | B-\>A:   |          |          |          |
|         |          | \[8\]    |          |          |          |
+---------+----------+----------+----------+----------+----------+

Preliminary training conditions are 1-1.1 and 1-1.2 (colored within red
and blue, respectively, in the table)

*[Miscellaneous Conditions]{.underline}*

[]{.underline}

  -------------------- ---- --------------------------------------------------------------------------------------------------------
  Listening Level      1    79 dBSPL or 76 dBSPL (-15 dB Pa or -18 dB Pa)
  Listeners/Speakers   32   Naïve Listeners/Native Speakers
  Groups               16   2 subjects/group
  Rating Scales        5    see section 4.2
  Languages            3    French, English, Chinese
  Listening System     2    Monaural headset (flat response in the audio bandwidth of interest: 50Hz-7kHz). The other ear is open.
  Microphone           2    Frequency range: 100Hz-10kHz
  -------------------- ---- --------------------------------------------------------------------------------------------------------

L.4 Test Procedure
==================

The procedure and logistic of the test across test laboratories are
given in the following:

L.4.1 Time Projection 
---------------------

The following numbers characterizes the entire test:

  -------------------------------- ---- ------------------------------
  \#acoustic/radio conditions      8    2 subjects swapping
  \#network load conditions        2    Light, heavy
  \#codecs=\#experiments per lab   3    5.9kbps, 12.2kbps, 12.65kbps
  \#languages                      3    English, French, Chinese
  \#subjects per experiment        32   16 pairs
  -------------------------------- ---- ------------------------------

Each lab tests only one language. Each experiment covers 16 test
conditions. Each group has to perform 16 conversations, each of ca. 3
minutes. A session consists of 4 consecutive conversations,
corresponding to ca. 20 minutes test time. The subject panels for the
three experiments shall be independent, i.e. no subject will participate
in more than one experiment. The order of the presentation of test
conditions are provided in Appendix 2.

The test time projection is the following:

\- Practice and Training per group: 30 minutes

\- Conversation plus setup and data collection: 5 minutes

\- Break between sessions: 10 minutes

\- Number of breaks per experiment: 3

\- Work hours per day: 8 hours

\- Work days per week: 5 days

This results in 3 groups per day, i.e. 6 working days per experiment,
and 18 working days per laboratory, plus 1 day for system setup. In
total, one month per laboratory is estimated as the minimum

The project plan can be envisioned as the following:

  ------------ ---------------- ---------- -----------------
  Test Month   Laboratories     Duration   Starting Date
  Month 1      France Telecom   4 weeks    May 15, 2007
  Month 2      BIT              4 weeks    June 19, 2007
  Month 3      Dynastat         4 weeks    July 28, 2007
  Month 4      Dynastat (GAL)   \>1 week   August 28, 2007
  ------------ ---------------- ---------- -----------------

The actual time will be adapted to the specific situation of the
individual labs. The entire test is expected to take 3+ months.

L.4.2 Instructions to the Subjects
----------------------------------

The following instruction shall be given to the subjects in each lab in
the respective native language during the training phase prior to the
tests.

\"You are going to have a conversation with another user. The test
situation is simulating communications between two mobile phones. The
most of the situations will correspond to silent environment conditions,
but some other will simulate more specific situations, as in a car, or
in a railway station or in an office environment, when other people are
discussing in the background.

After the completion of each call conversation, you will have to give
your opinions on the quality, by answering to the following questions
that will be displayed on the screen of the black box in front of you.
Your judgment will be stored. You have 8 seconds to answer to each
question. After \"pressing\" the button on the screen, another question
will be displayed. You continue the procedure for the 5 following
questions.

![](media/image151.wmf){width="6.709722222222222in"
height="6.631944444444445in"}

From then on you will have a break approximately every 30 minutes. The
test will last a total of approximately 60 minutes.

Please do not discuss your opinions with other listeners participating
in the experiment.\"

L.4.3 Test Materials
--------------------

The pretexts used for conversation test are those developed by ITU-T
SG12. These scenarios have been elaborated to allow a conversation well
balanced within both participants and lasting approximately 2\'30 or
3\', and to stimulate the discussion between persons that know each
other to facilitate the naturalness of the conversation. They are
derived from typical situations of every day life: railways inquiries,
rent a car or an apartment, etc. Each condition should be given a
different scenario. Each lab is responsible for developing the actual
conversation materials to be used.

The examples are extracted from ITU-T rec. P.805 (2007) Appendices 4, 5
and 6.

Following the examples and the spirit given by this reference, the
actual materials should be developed and adapted to the language being
tested, the cultural specifics of the country of the lab and the local
situations, depending on where the test lab is located.

L.4.4 Deliverables 
------------------

The information required from each test laboratory is a table containing
the \"Opinion Score (OS)\", in ASCII file or in spreadsheet, obtained
from every subject for each conversation. No post processing is required
from the labs. The original data are provided by each lab using a
template that includes the following information:

Table L.3: Template for the raw data

  ------------ ---------------- --------------- ---------- ------------------------- ----------- ----------
  Subject ID   Test Condition   Test Material   *Rating*   Conversation Partner ID   Time/Date   Comments
                                                                                                 
                                                                                                 
                                                                                                 
  ------------ ---------------- --------------- ---------- ------------------------- ----------- ----------

Raw data deliverable spreadsheet will be provided to the test labs by
the Global Analysis Lab prior to the beginning of the tests.

L.4.5 Data Analysis
-------------------

Two statistical analyses should be conducted on the data obtained with
these subjective scales. The first analysis consists in a MANOVA, which
globally indicates the possible effect of the experimental factors
(*i.e.*, different conditions). Then, a specific ANOVA should be run on
each dependent variable to test if there is an effect of a specific
experimental factor for a given subjective variable. In other words,
these statistical analyses indicate if the differences observed between
the MOS obtained for the different conditions are significant, for any
given dependant variable (ANOVA) or for the entirety of all the
dependant variables (MANOVA). Finally, Pearson\'s linear correlations
should be computed between the results of all subjective variables, to
find out the specific dependent relations.

L.5 Working Document for the Performance Characterization of VoIMS over HSDPA/EDCH
==================================================================================

L.5.1 Introduction
------------------

TR 26.935 provides information on the performance of default speech
codec in packet switched conversational multimedia applications. The
transmission of IP/UDP/RTP/AMR packets over the UMTS air interface
(DCHs) wass simulated using the Conversational / Speech / UL:46 kbit/s /
PS RAB coming from TS 34.108 v. 4.7.0.

During TSG SA\#27 Tokyo \[SP-050089\], the new work item of
\"Performance Characterization of VoIMS over HSDPA/EUL\" was approved.
The goal of the work item is to test the codec performance when VoIP is
supported by HS-DSCH in the DL and EDCH in the UL.

L.5.2 System Overview
---------------------

The goal of the test system is to enable MOS tests of mobile-to-mobile
conversational voice services in a representative UMTS system supporting
VoIP over HSDPA/EDCH. The test system includes two independent links in
opposite directions, used by the two parties of an active conversation,
respectively. The two parties of the conversation are referred to as A
and B, respectively. Thus, the entities of the test system occur always
in pair, and the configuration of the link A-to-B and B-to-A are
identical, reflecting the symmetry of the conversational connection.

The principle of the design of the test system is the balance of the
fidelity to the reality and the feasibility of the implementation. The
UMTS system and the IP network with the designated channel types and
protocols will be simulated by means of digital computers. It is
therefore important that a design of the test system allows for the
verifications and repetitions, so that the correct implementation in
software can be achieved with the highest probability. To this end, a
modular design is taken.

Considering the fact that HARQ and ROHC introduce sources of delay
jitters for the packets in both directions, it is necessary to implement
them in two modules. Besides, the speech lab and the IP/Core network are
both independent of RAN in nature, it is reasonable to divide the entire
test system into 4 separate entities:

\- RN simulator,

\- IP/Core network simulator,

\- VoIP simulator and

\- Test Environment

This division results in 6 interfaces in each direction, as shown in
Fig.1. On the high level, each entity has the following respective
function:

\- Radio Network (RN) Simulator: This simulates the performance of the
protocol layers RLC/MAC/PHY for the downlink and the uplink, to produce
statistics for the air interfaces on the RLC packet stream. It is noted
that the RN simulator defined here is a sub-set of the RAN defined in
the UMTS and it aims at capturing the RAN impacts that are essential to
the VoIP performance characterisation.

\- IP/Core Simulator: This simulates the routing through a loaded IPv6
network, to capture the impairments of packet loss and delay. For the
purpose of testing the conversational services, only two entry/exit
pairs for the IP core network are needed---one entry/exit for RN(A) and
the other entry/exit for RN(B).

\- VoIP Simulator: This simulates the VoIP specific functions between
the sound cards and the RAN simulators, which comprises the speech
encoder/decoder, AMR/RTP/UDP/IP/PDCP packetizing/depacketizing, robust
header compression/decompression for both party A and party B of a
conversation, etc. Physically, the two ends of the VoIP are located in
the SRNC and belong to MAC-d entities of the two conversation parties,
respectively.

\- Speech Lab: This performs the MOS tests on the AMR/AMR-WB under the
network conditions simulated by VoIP, RN and IP/Core. Each side of the
conversation uses **appropriate playback hardware.** The requirement for
the test material and the test subject can be taken from TR26.935.

![](media/image152.wmf){width="5.9875in" height="3.936111111111111in"}

Figure L.5.1 Architecture of the Test System

The division of the test system into relatively independent entities
serves to clarify the concepts involved. The modular structure allows
for off-line simulation of each identified entity independently.
However, the designated conversational test requires the availability of
the simulated radio carrier in a real-time manner. The real-time
simulation of the entire system is hardware limited due to the
complexity of the RN simulator. Therefore a combination of the off-line
simulation of the RN and the on-line simulation of the VoIP is
considered. This is justified by the fact that a continuous stream of
RLC PDUs can be produced by the RN simulator regardless of the payload.

L.5.3 Radio Access Bearers
--------------------------

The radio bearers used for the simulation of the lower layer delay and
error performance are extracted from 25.993 in the following:

\"

7.5.3 RB for Conversational / unknown UL: \[max bitrate depending on UE
category and TTI\] on E-DCH DL: \[max bitrate depending on UE category\]
on HS-DSCH / PS RAB\
+ RB for interactive or background / UL : \[max bitrate depending on UE
category and TTI\] on E-DCH DL : \[max bitrate depending on UE
category\] on HS-DSCH / PS RAB\
+ RB for interactive or background / UL : \[max bitrate depending on UE
category and TTI\] on E-DCH DL : \[max bitrate depending on UE
category\] on HS-DSCH / PS RAB\
+ UL : \[max bitrate depending on UE category and TTI\] on E-DCH DL :
\[max bit rate depending on UE category\] on HS-DSCH SRBs for DCCH

\"

The minimum UE classes supporting this combination are : support of
HS-PDSCH, DL on HS-PDSCH: category 11 and support of E-DPDCH, UL on
E-DPDCH category 1.

This is supported in Release 6.

**7.5.3.1 Uplink**

+-------------+-------------+-------------+-------------+-------------+
|             | Radio       | *Radio      | Signalling  | *Signalling |
|             | Bearer\     | Bearer\     | Radio       | Radio       |
|             | on DPCH     | on E-DPCH*  | Bearer\     | Bearer\     |
|             |             |             | on DPCH     | on E-DPCH*  |
+-------------+-------------+-------------+-------------+-------------+
| Transport   |             | 7.          |             | 7.          |
| Channel     |             | 5.3.1.1.1.1 |             | 5.1.1.1.1.1 |
|             |             | for         |             |             |
|             |             | con         |             |             |
|             |             | versational |             |             |
|             |             | RB,         |             |             |
|             |             |             |             |             |
|             |             | 6.10.2.4.   |             |             |
|             |             | 6.1.1.1.1.1 |             |             |
|             |             | of \[1\]    |             |             |
|             |             | for         |             |             |
|             |             | Interactive |             |             |
|             |             | /Background |             |             |
|             |             | RBs (MAC-e  |             |             |
|             |             | muxed)      |             |             |
+-------------+-------------+-------------+-------------+-------------+
| TFCS        |             |             |             |             |
+-------------+-------------+-------------+-------------+-------------+
| Physical    | 6.10.2.     |             |             |             |
| Channel     | 4.6.1.1.2.1 |             |             |             |
|             | of \[1\]\   |             |             |             |
|             | E-TFCI      |             |             |             |
|             | table index |             |             |             |
|             | = 0; E-DCH  |             |             |             |
|             | minimum set |             |             |             |
|             | E-TFCI = =  |             |             |             |
|             | 29 (10 ms   |             |             |             |
|             | TTI, TB     |             |             |             |
|             | size 374    |             |             |             |
|             | bits) or 32 |             |             |             |
|             | (2 ms TTI,  |             |             |             |
|             | TB size 368 |             |             |             |
|             | bits)       |             |             |             |
+-------------+-------------+-------------+-------------+-------------+

Note: MAC-e multiplexing of scheduled and non-scheduled MAC-d flows is
allowed.

**7.5.3.1.1** Transport channel parameters

**7.5.3.1.1.1** Transport channel parameters for E-DCH

**7.5.3.1.1.1.1** MAC-d flow\#1 parameters for conversational / Unknown
UL: \[max bit rate depending on UE category and TTI\] on E-DCH / PS RAB

+----------------------+----------------------+----------------------+
| Higher layer         | RAB/Signalling RB    | RAB                  |
+----------------------+----------------------+----------------------+
| PDCP                 | PDCP header size,    | 0                    |
|                      | bit                  |                      |
+----------------------+----------------------+----------------------+
| RLC                  | Logical channel type | DTCH                 |
+----------------------+----------------------+----------------------+
|                      | RLC mode             | UM                   |
+----------------------+----------------------+----------------------+
|                      | Payload sizes, bit   | 88, 104, 136, 152,   |
|                      |                      | 168, 184, 200, 216,  |
|                      |                      | 280, 288, 304, 336   |
|                      |                      | (alt 328)            |
+----------------------+----------------------+----------------------+
|                      | Max data rate, bps   | Depends on UE        |
|                      |                      | category and TTI     |
+----------------------+----------------------+----------------------+
|                      | UMD PDU header, bit  | 8                    |
+----------------------+----------------------+----------------------+
| MAC                  | MAC-e multiplexing   | N/A                  |
+----------------------+----------------------+----------------------+
|                      | MAC-d PDU size, bit  | 96, 112, 144, 160,   |
|                      |                      | 176, 192, 208, 224,  |
|                      |                      | 288, 296, 312, 344   |
|                      |                      | (alt 336)            |
+----------------------+----------------------+----------------------+
|                      | Max MAC-e PDU        | (non-scheduled)      |
|                      | content size, bit    | (NOTE1)              |
+----------------------+----------------------+----------------------+
|                      | MAC-e/es header      | 18                   |
|                      | fixed part, bit      |                      |
+----------------------+----------------------+----------------------+
| Layer 1              | TrCH type            | E-DCH                |
+----------------------+----------------------+----------------------+
|                      | TTI                  | 10ms (alt. 2ms)      |
|                      |                      | (NOTE2)              |
+----------------------+----------------------+----------------------+
|                      | Coding type          | TC                   |
+----------------------+----------------------+----------------------+
|                      | CRC, bit             | 24                   |
+----------------------+----------------------+----------------------+
| NOTE1: Max MAC-e PDU |                      |                      |
| content sizes        |                      |                      |
| dependson            |                      |                      |
| non-scheduled grant  |                      |                      |
| given by SRNC        |                      |                      |
|                      |                      |                      |
| NOTE2: The support   |                      |                      |
| of 2ms TTI depends   |                      |                      |
| on the UE category.  |                      |                      |
+----------------------+----------------------+----------------------+

**7.5.3.2 Downlink**

+-------------+-------------+-------------+-------------+-------------+
|             | Radio       | Radio       | Signalling  | Signalling  |
|             | Bearer\     | Bearer\     | Radio       | Radio       |
|             | on DPCH     | on HS-PDSCH | Bearer\     | Bearer\     |
|             |             |             | on DPCH     | on HS-PDSCH |
+-------------+-------------+-------------+-------------+-------------+
| Transport   |             | 7.4         |             | 6.10.2.4.   |
| Channel     |             | .22.2.1.1.1 |             | 6.3.2.1.1.2 |
|             |             | for         |             | of \[1\]    |
|             |             | Con         |             |             |
|             |             | versational |             |             |
|             |             | RB          |             |             |
|             |             |             |             |             |
|             |             | 6.10.2.4.   |             |             |
|             |             | 5.1.2.1.1.1 |             |             |
|             |             | of \[1\]    |             |             |
|             |             | for         |             |             |
|             |             | Interactive |             |             |
|             |             | /Background |             |             |
|             |             | RBs         |             |             |
+-------------+-------------+-------------+-------------+-------------+
| TFCS        |             |             |             |             |
+-------------+-------------+-------------+-------------+-------------+
| Physical    | 6.10.2.     |             |             |             |
| Channel     | 4.5.1.2.2.2 |             |             |             |
|             | of \[1\]\   |             |             |             |
|             | The         |             |             |             |
|             | physical    |             |             |             |
|             | channel     |             |             |             |
|             | co          |             |             |             |
|             | nfiguration |             |             |             |
|             | shall use   |             |             |             |
|             | F-DPCH.     |             |             |             |
+-------------+-------------+-------------+-------------+-------------+

**7.5.4**

\"

RB for Conversational / Unknown UL: \[max bitrate depending on UE
category and TTI\] on E-DCH DL: \[max bitrate depending on UE category\]
on HS-DSCH / PS RAB\
+ RB for interactive or background / UL : \[max bitrate depending on UE
category and TTI\] on E-DCH DL : \[max bitrate depending on UE
category\] on HS-DSCH / PS RAB\
+ UL : \[max bitrate depending on UE category and TTI\] on E-DCH DL :
\[max bit rate depending on UE category\] on HS-DSCH SRBs for DCCH

\"

The minimum UE classes supporting this combination are: support of
HS-PDSCH, DL on HS-PDSCH: category 11 and support of E-DPDCH, UL on
E-DPDCH category 1.

This is supported in Release 6.

**7.5.4.1 Uplink**

+-------------+-------------+-------------+-------------+-------------+
|             | Radio       | *Radio      | Signalling  | *Signalling |
|             | Bearer\     | Bearer\     | Radio       | Radio       |
|             | on DPCH     | on E-DPCH*  | Bearer\     | Bearer\     |
|             |             |             | on DPCH     | on E-DPCH*  |
+-------------+-------------+-------------+-------------+-------------+
| Transport   |             | 7.          |             | 7.          |
| Channel     |             | 5.3.1.1.1.1 |             | 5.1.1.1.1.1 |
|             |             | for         |             |             |
|             |             | Con         |             |             |
|             |             | versational |             |             |
|             |             | RB          |             |             |
|             |             |             |             |             |
|             |             | 6.10.2.4.   |             |             |
|             |             | 6.1.1.1.1.1 |             |             |
|             |             | of \[1\]    |             |             |
|             |             | for         |             |             |
|             |             | Interactive |             |             |
|             |             | /Background |             |             |
+-------------+-------------+-------------+-------------+-------------+
| TFCS        |             |             |             |             |
+-------------+-------------+-------------+-------------+-------------+
| Physical    | 6.10.2.     |             |             |             |
| Channel     | 4.6.1.1.2.1 |             |             |             |
|             | of \[1\]\   |             |             |             |
|             | E-TFCI      |             |             |             |
|             | table index |             |             |             |
|             | = 0; E-DCH  |             |             |             |
|             | minimum set |             |             |             |
|             | E-TFCI = =  |             |             |             |
|             | 29 (10 ms   |             |             |             |
|             | TTI, TB     |             |             |             |
|             | size 374    |             |             |             |
|             | bits) or 32 |             |             |             |
|             | (2 ms TTI,  |             |             |             |
|             | TB size 368 |             |             |             |
|             | bits)       |             |             |             |
+-------------+-------------+-------------+-------------+-------------+

Note: MAC-e multiplexing of scheduled and non-scheduled MAC-d flows is
allowed

**7.5.4.2 Downlink**

  ------------------- ------------------------------------------------------ -------------------------------------------------------------------------------------------------- -------------------------- -------------------------------
                      Radio Bearer\                                          Radio Bearer\                                                                                      Signalling Radio Bearer\   Signalling Radio Bearer\
                      on DPCH                                                on HS-PDSCH                                                                                        on DPCH                    on HS-PDSCH

  Transport Channel                                                          7.4.22.2.1.1.1 for Conversational RB 6.10.2.4.5.1.2.1.1.1 of \[1\] for Interactive/Background RB                              6.10.2.4.6.3.2.1.1.2 of \[1\]

  TFCS                                                                                                                                                                                                     

  Physical Channel    6.10.2.4.5.1.2.2.2 of \[1\]\                                                                                                                                                         
                      The physical channel configuration shall use F-DPCH.                                                                                                                                 
  ------------------- ------------------------------------------------------ -------------------------------------------------------------------------------------------------- -------------------------- -------------------------------

L.5.4 Delay
-----------

The overall delay consists of the delay of the air interface as well as
the networks. The predominant issue that distinguishes VoIP from voice
service on circuit switched network is the variation of the delay with
respect to a fixed delay value, which is referred to as jitter. In order
to capture the impact of jitter on the performance of VoIP, a proper
assumption about the overall delay budget is necessary.

The fixed delay component is estimated using the following example of
delay budget for end-to-end VoIP calls in HSPA when the uplink uses 10
ms TTIs \[19\].

Table L.5.1. Example delay budget for VoIP in HSPA

  ---------------------------- ------------ ---------------------- -------------
  **Uplink (EUL 10 ms TTI)**   **Delay**    **Downlink (HSDPA)**   **Delay**
  AMR encoder                  35 ms        AMR decoder            5 ms
  UE L1/L2 processing          5 ms         UE L1/L2 processing    10 ms
  TTI alignment                0 -- 10 ms   \-                     \-
  Uu interleaving              10 ms        Uu interleaving        2 ms
  UL re-TX                     0 -- 80 ms   DL Scheduling          5 -- 100 ms
  RNC/Iub/Node B               10 ms        RNC/Iub/Noted B        10 ms
  Iu + Gi                      5 ms         Gi + Iu                5 ms
  **Sum min UL**               **65 ms**    **Sum min DL**         **37 ms**
  **Sum max UL**               **155 ms**   **Sum max DL**         **132 ms**
  ---------------------------- ------------ ---------------------- -------------

The different delay components are described below:

\- The AMR encoder and decoder delay components includes: buffering
time, due to the frame length (20 ms); look-ahead (5 ms); and processing
time (10 ms and 5 ms for uplink and downlink respectively).

\- The layer 1 and 2 processing time includes the following protocol
layers: Packet Data Convergence Protocol (PDCP); Radio Link Control
(RLC); Medium Access Control (MAC); and the Physical (PHY) layer.

\- The TTI alignment delay component is needed in uplink since the
packet may need to be buffered to align the transmission to the frame
structure of the radio interface. Note that it is possible to adjust the
speech encoder framing period to the air interface framing period to get
0 ms TTI alignment delay. Note also that EUL may use 2 ms TTIs, which
would reduce this value to 0 -- 2 ms. For downlink, the TTI alignment
delay is included in the DL Scheduling delay and is therefore not
specified as a separate delay component in this delay budget.

\- The Uu interleaving consists of the actual transmission over the air
interface, 10 ms and 2 ms for uplink and downlink respectively. The
delay for the uplink can be reduced by using 2 ms TTIs.

\- HARQ re-transmissions add only to the jitter but not to the fixed
delay component. For uplink, since 10 ms TTIs are used in this example
delay budget, the re-transmission time is estimated to 40 ms and that at
most 2 re-transmissions are performed before the packet is dropped. Note
that the allowed number of re-transmissions, and thus the delay jitter,
will be different for different implementations.

\- For downlink, the re-transmission time is included in the variable
part of the DL Scheduling delay. In this case, it is assumed that the
packet is dropped if it is delayed more than 100 ms in the scheduler.
Note that this delay is the sum of scheduling delay and re-transmission
delays. Note also that the scheduler is vendor specific and thus the
delay, and especially the variable part, depends entirely on how
different vendors choose to implement it.

\- The RNC/Iub/Node B delay number describes the RAN delays, i.e. Node B
and RNC processing times and transmission delays in-between these nodes.

\- The Core Network delay is included in the Iu+Gi delay component.

\- Delay for the backbone network is not included in this example.

In summary, the end-to-end packet delay, divided into two parts, is
estimated as the following:

\- A fixed part, which is identical to the minimum delay, i.e. 102 ms
+30 ms, where the 30 ms accounts for the backbone core network delay.

\- A variable part, which corresponds to the jitter, and is in the 0 --
185 ms range.

L.5.5 RN Simulator
------------------

High Speed Downlink Packet Access (HSDPA) is based on techniques such as
adaptive modulation/coding and hybrid ARQ to achieve high throughput.
The new channel HS-DSCH is terminated in the Node B and is applicable
only to PS domain RABs. MAC-d is retained in the S-RNC, while a new
entity, MAC-hs located in Node B, is introduced to host the
functionalities of hybrid ARQ, rate selection, and HS-DSCH scheduling.

EDCH for the uplink has the same features of fast rate scheduling,
hybrid ARQ, and adaptive coding in addition to DCH. It is managed by a
new entity MAC-e and terminated in Node B, while another new entity
MAC-es is introduced in S-RNC to manage the re-ordering of data from
different MAC-d\'s. The relation is shown in Figure L.5.2.

![](media/image153.wmf){width="4.7625in" height="2.827777777777778in"}

Figure L.5.2: MAC structure applicable to VoIMS via HSDPA/EDCH

The simulator will primarily simulate the functionalities of MAC-hs and
MAC-e for the downlink and uplink, respectively Scheduling for VoIP is
crucial in the downlink over the shared HS-DSCH, however, VoIP can
simply operate as a non-scheduled transmission (NST) in the uplink.

A simple implementation of RN simulator consists of the following
components:

1\) Radio Access Bearer: Mechanism of the protocols involved should be
implemented as assumed by the given RAB. For the physical layer radio
bearer the BLER of the physical channel corresponding to the given RB
deployed at the given UE location with the given mobile speed will be
measured for instantaneous Ec/Nt, and recorded for use by the system
level simulation. The RAB\'s are chosen from section L.5.3 Radio Access
Bearers.

2\) Cellular Network: This consists of assumptions of the cell
structure, channel models deployed, traffic load, antenna, locations of
users, etc. Interactions between a reference user and the Node B is to
be simulated here, for which the buffer configuration, the scheduler
algorithm, the delay budget, number of users, etc. are needed. This
simulator comprises the functions of Node\_B and Iu interface, a part of
the radio access network that is extensively simulated in 3GPP-RAN
working groups. However, the simulation work done for the pure capacity
has a different scope than here. The focus of the present work item is
to test a single connection that is representative for the service
provided by the network and the final test method is the listening test
instead of statistical description. For this reason, the radio network
simulator shall produce a sequence of coherent samples of error and
delay events, which different objective of the simulator designed to
evaluate the capacity or the channel quality based on statistic
evaluation. The setup, the parameters and the working assumptions need
to be designed specifically for this purpose. The expected main result
of the simulation is a sequence of error and delay events with
associated attributes necessary for the further processing. Details of
the simulation assumptions can be found in Appendix A.

3\) Packets stream: Payload traffic of the reference user will be mapped
to the bearer by adding. RLC/MAC headers and extracted from the radio
bearer by stripping the RLC/MAC header

4\) The PDCP/IP/UDP/RTP/AMR packets at interfaces A11 and B11 are given
to the transmission buffer of the RLC protocol working in UM. The RLC
may segment the given bits to make RLC SDUs, and add RLC headers
(sequence number and length indicators). By assumption, one IP packet is
placed into an RLC PDU that is filled with padding bits.

5\) To simplify the implementation and facilitate the typical continuous
speech tests, the design of the simulation should target on steady state
of the connection. This implies that we can disregard network
re-synchronization (although the terminal may engage in packet
resynchronization) and set-up during the simulation. Depending on the
assumptions, issues of the packaging, the segmentation and re-assembly
can also be ignored in case the AMR/AMR-WB frame fits into the RLC-SDU.
The given time limit for the determination of the packet loss during the
simulation comes from the delay budget planning, which simulates the
implementation of the queuing buffers.

Payload exchanged at the interfaces are:

\- A21, B21: PDCP packet with ROHC received in sequence

\- A31, B31: IP packets delivered in sequence

\- A32, B32: IP packets received in sequence

\- A22, B22: PDCP packets with ROHC delivered in sequence

L.5.6 Core Network
------------------

The network introduces time delay for the transmission. Payload
exchanged at the interfaces are:

\- A31, B31: IP packets received in sequence

\- A32, B32: IP packets delivered out of sequence

The IP packets are uniquely identified with a RLC PDU, when each
AMR/AMR-WB speech frame is conveyed by a single RLC PDU. This assumption
will simplify the implementation.

L.5.7 VoIP Client
-----------------

The current section discusses the actions of PDCP/AMR or PDCP/AMR-WB.
The PDCP entity is assumed to map to two RLC --UM entities, each used
for one of the two directions of the conversation, as shown in Figure
L.5.3. The payload exchanged at the interfaces are:

\- A11, B11: speech frames received in order

\- A21, B21: PDCP packets (RLC SDU) delivered in order

\- A22, B22: PDCP packets (RLC SDU) received in order

\- A12, B12: speech frames delivered in order within the given time
limit

\- For the conversational tests, AMR will encode the speech at the
designated rate in accordance with 26.101, to make the RTP/UDP/IP/PDCH
payload. Following TS 26.236, the RTP payload format should follow the
bandwidth efficient mode defined in RFC-3267, and one speech frame shall
be encapsulated in each RTP packet. Header compression according to RFC
3095 and TS 25.323 will be simulated as part of the PDCP protocol. For
the VoIP test we are only interested in the normal operation of the
PDCP, not the session set-up signalling .

Lossless RLC PDU size change. This is equal to assume that the RAB
remains the same during the call. The assumption reduces the simulation
complexity for the RN simulator.

![](media/image154.wmf){width="5.88125in" height="4.2659722222222225in"}

Figure L.5.3: Protocol stacks in VoIP entity

Consistently, only two PDU Formats will be considered:

\- PDCP-No-Header PDU

\- PDCP Data PDU

A decision is to be made in conjunction with other parameters in this
context. The simulation of ROHC operation aims at the implementation of
the state machine,Figure L.5.4.

![](media/image155.wmf){width="5.756944444444445in"
height="1.8805555555555555in"}

Figure L.5.4: State machine of the compressor operation.

Clearly, the transition depends on the lower layer quality. By QoS
assured delivery, the compressor can be maintained in SO state during
the call duration with the given probability. The simulation should
assume steady state in SO. We also assume the operation mode of ROHC to
be R (Reliable). That means it involves feedback. Assuming
PDCP-No-Header PDU, the simulator delivers/receives to/from the RN
simulator the RLC PDU, which consists of header and payload as
following:

RLC SDU = ROHC feedback header + ROHC base header + ROHC extension
header + UDP checksum + AMR payload

By assuming steady state of R mode operation, the header will only
contain 1 byte R-0, 2 bytes ACK and a 2 byte UDP checksum. For the
simulation of reference mobiles, there are two possibilities:

\- Allow state transition between FO and SO. This would require
simulation of coupled up-link and down-link.

\- Disallow state transition between FO and SO. This is equivalent to
assuming that the state transition is a rare event such that it does not
occur during a typical call. Then, the feedback from the de-compressor
would contain ACK only. Hence, the up link and the down link can be
simulated independently.

To facilitate the simulation, the second option will be taken.

L.5.8 Interfaces
----------------

The physical composition of the test system is depicted in Fig.1. It
shows that an end-to-end connection between A and B consists of the
following chain of entities:

\- Sound card (A)

\- VoIP (A)

\- RN(A) simulator

\- IP/Core simulator

\- RN(B) simulator

\- VoIP (B)

\- Sound card (B)

The figure, however, is not informative about the logical relation
between the protocols that are spread in all entities. Figure L,5,5
visualizes the logical relations among the components. It helps to
clarify the scope of each component simulators.

![](media/image156.wmf){width="5.2625in" height="1.6097222222222223in"}

Figure L.5.5: Logical Relations between simulator entities and
protocols. Color code:

![](media/image157.wmf){width="4.886805555555555in"
height="0.6354166666666666in"}

For the convenience of verification, it is of great advantage to
implement the system component-wise. Thus, the interfaces between the
component simulators have to be specified. The physical interfaces are
instances of 3 logical interfaces, respectively:

**- Interface 1** ={A11,A12,B11,B12}: the interface between sound card
and VoIP

**- Interface 2** = {A21, A22, B21, B22}: the interface between VoIP and
RN

**- Interface 3** ={A31, A32, B31, B32} : the interface between IP/Core
and RN

The interfaces determine the information to be exchanged between the
adjacent entities in the simulator and are specified in the following.

### L.5.8.1 Interface 1

This interface exchanges information regarding operation of the protocol
stacks AMR/RTP/UDP/IP/PDCP/RLC and the operation of rate selection. One
of the issues is the coherence of the actions when off-line simulation
method is used. Since each entity is simulated independent of others and
the output files of the simulation are used in a later time, the
consistency of the channel conditions and the selection made by AMR at a
given moment cannot be warranted unless careful measure is taken.

One of the measures to maintain the coherence is to restrict the
AMR/AMR-WB to a pre-selected single data rate for each test. This
approach is justified by the fact that the enhanced uplink and downlink
have already provided sufficient control and adaptation mechanism at the
lower layers, so that the channel condition experienced by the interface
1 is sufficiently stable and would hardly require rate switching. The
original concept of AMR is targeted at the balance between the
individual voice quality and overall capacity. But when we fix the
number of the supported users in our simulation in order to test the
probe user\'s voice quality, the capacity-quality trade-off would not
occur for the simulated cases. Hence, the testing of individual coder
from the AMR/AMR-WB would be sufficiently informative about the VoIP
performance for the give simulation set-up.

### L.5.8.2 Interface 2

The output file of the RN simulator at this interface consists of 3
columns of the following entries for a stream of RLC PDUs:

Table L.5.2: Data format of interface 2

  ----------------------- ------------------------- ----------------------------------- ------------------
  Sequence Number (int)   Loss Indicator (binary)   Accumulated Es/Nt after HARQ (dB)   Time Stamp (int)
  0                       1                         ..                                  0TTI
  1                       1                         ..                                  1TTI
  2                       0                         ..                                  2TTI
  ...                     ...                       ..                                  ...
  ----------------------- ------------------------- ----------------------------------- ------------------

### L.5.8.3 Interface 3

The transportation of the IP packet depends on the nodes traversed by
the datagram within the IP/Core network. What really maters here is the
delay and loss of a packet due to routing. This requires the IP/Core,
based on a given topology \[tbd\] and traffic load \[tbd\], to generate
a sequence of random events at A31 and B31, respectively, reflecting the
relative delay and the loss of the packet fed into the network at A32
and B32, respectively. Alternatively, the delay and loss can be
generated by an appropriate analytical model \[tbd\]. The file generated
by the IP/Core at the interfaces A32 and B32 shall have the following
format:

Table L.5.3: Data format of interface 3.

  ----------------------- ------------------------- ------------------
  Sequence Number (int)   Loss Indicator (binary)   Time Stamp (int)
  0                       1                         0TTI
  1                       1                         1TTI
  2                       0                         2TTI
  ...                     ...                       ...
  ----------------------- ------------------------- ------------------

L.5.9 Simulated HSPA Air-Interface 
----------------------------------

### L.5.9.1 General Description

For the down link, the over-the-air delay of a speech frame is defined
as the latency between the time a MAC-d PDU carrying a speech frame
enters the MAC-hs priority queue in the Node-B and the time the MAC-d
PDU is delivered (after reordering by the MAC-hs) to the UE. Similarly,
for the up link, the over-the-air delay of a speech frame is defined as
the latency between the time a MAC-d PDU carrying a speech frame enters
the MAC-d of the Node-B.

The delay of the network is the time consumed by a packet, while staying
within the network. Therefore, it is counted as the time difference
between the entry and exit of the network.

The delay value for each connection is measured as the sum of the
over-the-air delay for the up link and down link plus the network delay
and the processing delay at both ends, when the value is within the
delay budget.

A speech frame is declared to be lost if one of the following is true:

\- The MAC-d PDU is discarded at the Node-B transmitter due to
expiration of the MAC-hs discard timer

\- The MAC-d PDU is transmitted but not successfully received post-HARQ

\- The MAC-d PDU is successfully received after a specified delay bound

The MAC-hs discard timer and the MAC-hs T1 timer should be set
appropriately for the given the over-the-air delay budget.

### L.5.9.2 Error-Delay Profiles

**In \[2\], we received samples coming from different simulation
platforms**

\- Platform 1: Data contained in R1-061028.zip

\- Platform 2: Data contained in R1-061070.zip

Although both are generated following the network layout and
configuration of \[3\], there are subtle differences beyond the
schedulers and the trace lengths.

The samples from the platform 1 entail 16 samples for down link and 16
samples for up link with paired channel conditions PedB\_3km, PedB30km,
VehA\_30km and VehA\_120km. The location of the reference user is fixed
for all simulations.

The samples from the platform 2 entail 22 samples, where 20 are for the
down link and two for the up link, representing a paired channel
PedB\_3km. The difference between the 20 samples lies in the network
load (number of users) and the location of the reference user
(geometry).

To capture the essential in regard of our subjective tests, the samples
in the two groups have the following 4 attributes in common:

Table L.5.4: File attributes of the available data

  ---------------- ------------------------------------------------------- --------
  Attribute Name   Details                                                 Number
  Link Direction   Up-Link, Down-link                                      2
  Network Load     40,45,60,80,100                                         5
  Channel Model    PedA-3km, PedB-3km, PedB30km, VehA-30km, VehA-120 km.   5
  ---------------- ------------------------------------------------------- --------

Table L.5.5: Number of files and length of traces, grouped according to
the network load

  -------------- ------------------- -------------------------------
  Network Load   Number of Samples   Length without Repetition
  40             4                   4x60s
  45             10                  2x(215+155+95+55) ms
  60             4                   4x60s
  80             4                   4x60s
  100            14                  4x60s+2x(100+155+95+215+55)ms
  -------------- ------------------- -------------------------------

The definition of the conditions follow the conventions given below:

*Network Condition*

**Table L.5.6: Definition of the radio network conditions**

+-------------------------+-------------+--------------+--------+
| Radio Network Condition | Low Traffic | High Traffic | Uplink |
|                         |             |              |        |
|                         | Down Link   | Down Link    |        |
+-------------------------+-------------+--------------+--------+
| Low Mobility Mobile     | LM.LT       | LM.HT        | Lm     |
+-------------------------+-------------+--------------+--------+
| High Mobility Mobile    | HM.LT       | HM.HT        | Hm     |
+-------------------------+-------------+--------------+--------+

In specifics:

[- Low]{.underline} Traffic (LT): 40, or 45, or 60 mobile users per cell

[- High]{.underline} Traffic (HT): 80, or 100 mobile users per cell

[- Low]{.underline} Mobility (LM, Lm): ITU --Channel-Model: PedB3\_km or
PedA3\_km

[- High]{.underline} Mobility (HM, Hm): ITU-Channel-Model: VehA30km or
Veh120km or PedB30km

The uplinks are simulated as dedicated channel, hence the traffic
conditions apply only to the downlinks. From a mobile-to-mobile
connection, the order of the uplink and downlink plays no role.
Therefore, we have the following 8 possible construction of channel
conditions:

Table L.5.7: Notation for the mobile-to-mobile radio network conditions

  -------- ---------- ------------
  Number   Notation   Meaning
  \[1\]    Lm.LT.LM   Lm + LT.LM
  \[2\]    Lm.LT.HM   Lm+LT.HM
  \[3\]    Lm.HT.LM   Lm+HT.LM
  \[4\]    Lm.HT.HM   Lm+HT.HM
  \[5\]    Hm.LT.LM   Hm+LT.LM
  \[6\]    Hm.LT.HM   Hm+LT.HM
  \[7\]    Hm.HT.LM   Hm+HT.LM
  \[8\]    Hm.HT.HM   Hm+HT.HM
  -------- ---------- ------------

*Combined Test Conditions*

Each test condition is assigned a unique number defined as following:

  ------------- ---------- -------------- ------------ ---------------
  x-y.z.c       X          Y              z            c
  e.g. 1-1.3a   AMR-Mode   Network Load   Experiment   Swap subjects
  ------------- ---------- -------------- ------------ ---------------

The radio network conditions are identical for all the test cases with
all three codecs under test. Hence only the table for codec AMR5.9 is
shown as example in the following.

AMR-Mode 5.9 kbps (x=1): 8 conditions (y=1), 8 conditions (y=2)

+----------+----------+----------+----------+----------+----------+
| *        | *Noise   | *Radio   | *Noise   | *Desc    | *C       |
| Cond.No* | in Room  | Network* | in Room  | ription* | omments* |
|          | A*       |          | B*       |          |          |
|          |          | *Co      |          |          |          |
|          |          | ndition* |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-1.1    | Hoth     | A-\>B:   | Hoth     | Lm.LT.LM | sym      |
|          |          | \[1\]    |          |          |          |
|          |          |          |          | LM.LT.Lm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[1\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-1.2    | Car      | A-\>B:   | Car      | Hm.LT.HM | sym      |
|          |          | \[6\]    |          |          |          |
|          |          |          |          | HM.LT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[6\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-1.3a   | Car      | A-\>B:   | Hoth     | Hm.LT.LM | asym     |
|          |          | \[5\]    |          |          |          |
|          |          |          |          | HM.LT.Lm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[2\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-1.3b   | Hoth     | A-\>B:   | Car      | Lm.LT.HM | asym     |
|          |          | \[2\]    |          |          |          |
|          |          |          |          | LM.LT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[5\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-1.4    | C        | A-\>B:   | C        | Lm.LT.LM | sym      |
|          | afeteria | \[1\]    | afeteria |          |          |
|          |          |          |          | LM.LT.Lm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[1\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-1.5a   | C        | A-\>B:   | Street   | Lm.LT.HM | asym     |
|          | afeteria | \[2\]    |          |          |          |
|          |          |          |          | LM.LT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[5\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-1.5b   | Street   | A-\>B:   | C        | Hm.LT.LM | asym     |
|          |          | \[5\]    | afeteria |          |          |
|          |          |          |          | HM.LT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[2\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-1.6    | Street   | A-\>B:   | Street   | Hm.LT.HM | sym      |
|          |          | \[6\]    |          |          |          |
|          |          |          |          | HM.LT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[6\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-2.1    | Hoth     | A-\>B:   | Hoth     | Lm.HT.LM | sym      |
|          |          | \[3\]    |          |          |          |
|          |          |          |          | LM.HT.Lm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[3\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-2.2    | Car      | A-\>B:   | Car      | Hm.HT.HM | sym      |
|          |          | \[8\]    |          |          |          |
|          |          |          |          | HM.HT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[8\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-2.3a   | Car      | A-\>B:   | Hoth     | Hm.HT.LM | asym     |
|          |          | \[7\]    |          |          |          |
|          |          |          |          | HM.HT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[4\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-2.3b   | Hoth     | A-\>B:   | Car      | Lm.HT.HM | asym     |
|          |          | \[4\]    |          |          |          |
|          |          |          |          | LM.HT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[7\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-2.4    | C        | A-\>B:   | C        | Lm.HT.LM | sym      |
|          | afeteria | \[3\]    | afeteria |          |          |
|          |          |          |          | LM.HT.Lm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[3\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-2.5a   | C        | A-\>B:   | Street   | Lm.HT.HM | asym     |
|          | afeteria | \[4\]    |          |          |          |
|          |          |          |          | LM.HT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[7\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-2.5b   | Street   | A-\>B:   | C        | Hm.HT.LM | asym     |
|          |          | \[7\]    | afeteria |          |          |
|          |          |          |          | HM.HT.Lm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[4\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+
| 1-2.6    | Street   | A-\>B:   | Street   | Hm.HT.HM | sym      |
|          |          | \[8\]    |          |          |          |
|          |          |          |          | HM.HT.Hm |          |
|          |          | B-\>A:   |          |          |          |
|          |          | \[8\]    |          |          |          |
+----------+----------+----------+----------+----------+----------+

For the designated tests comprise the following components:

\- a VoIMS sender comprising of input capture (e.g. microphone), AMR
encoder, RTP packetization and IP stack, operating in real time; and

\- a VoIMS receiver comprising of IP stack, RTP de-packetization, AMR
decoder with appropriate jitter handling and an output devise (e.g.
headphone), operating in real tim

\- error-delay profiles (including error mask and time of delivery in
milliseconds) are generated using offline system simulations by RAN1.
The data files, sorted according to the radio network conditions, are
grouped into sets that represent the final test conditions. The data
files belong to the same set are concatenated so that a longer trace is
made. Up link and down link traces are combined, with addition of a
fixed delay value, to simulate delay and error trace of the
mobile-to-mobile connection, and

\- use the above error-delay profiles to inject delays and packet losses
in the VoIMS traffic in an error insertion devise running in real time.

Design and arrangement of the tests are detailed in the test plan.

#### L.5.A.1 Network Parameters

+----------------------------------+----------------------------------+
| **Parameter**                    |                                  |
+----------------------------------+----------------------------------+
| UMTS BS Nominal TX Power \[dBm\] | 43                               |
+----------------------------------+----------------------------------+
| P-CPICH Tx Power \[dBm\]         | 33                               |
+----------------------------------+----------------------------------+
| UMTS BS Overhead TX Power        | 34                               |
| \[dBm\] including paging, sync   |                                  |
| and P/S-CCPCH                    |                                  |
+----------------------------------+----------------------------------+
| UMTS UE TX Power Class \[dBm\]   | 21                               |
+----------------------------------+----------------------------------+
| UMTS UE Noise Figure \[dB\]      | 10                               |
+----------------------------------+----------------------------------+
| BS Antenna Gain \[dBi\]          | 17.1                             |
+----------------------------------+----------------------------------+
| MS Antenna Gain \[dBi\]          | 0                                |
+----------------------------------+----------------------------------+
| Shadowing Standard Deviation     | 8                                |
| \[dB\]                           |                                  |
+----------------------------------+----------------------------------+
| Path Loss Model: COST 231        | -136+35.22\*log10(d), d in km    |
+----------------------------------+----------------------------------+
| Shadow Site to site Correlation  | 50%                              |
+----------------------------------+----------------------------------+
| Other Losses \[dB\]              | 8                                |
+----------------------------------+----------------------------------+
| UMTS BS Antenna                  | per TR 25.896 v6.0.0 A.3.1.1     |
|                                  |                                  |
| pattern                          | 65                               |
|                                  |                                  |
| beamwidth \[degrees\]            |                                  |
+----------------------------------+----------------------------------+
| Propagation Channel Mixture for  | 25% AWGN                         |
| loading users                    |                                  |
|                                  | 37% PedA 3 kph                   |
|                                  |                                  |
|                                  | 13% PedA 30 kph                  |
|                                  |                                  |
|                                  | 13% VehA 30 kph                  |
|                                  |                                  |
|                                  | 12% VehA 120 kph                 |
+----------------------------------+----------------------------------+
| Propagation Channel for the      | Case 1: PedA 3 kph               |
| Reference UE                     |                                  |
|                                  | Case 2: VehA 30 kph              |
|                                  |                                  |
|                                  | Case 3: VehA 120 kph             |
+----------------------------------+----------------------------------+
| Ec/Io Admission Threshold        | -18 dB                           |
+----------------------------------+----------------------------------+
| RSCP Admission Threshold         | -115 dBm                         |
+----------------------------------+----------------------------------+
| Number of Node Bs                | 19 Node Bs/57 cells              |
+----------------------------------+----------------------------------+
| Locations of the Reference UE    | Geometrical centre of each       |
|                                  | sectored cell                    |
+----------------------------------+----------------------------------+
| Cell layout                      | 3-Cell Clover-Leaf               |
+----------------------------------+----------------------------------+
| Inter-site Distance \[m\]        | 2500                             |
+----------------------------------+----------------------------------+
| Frequency                        | 1990 MHz                         |
+----------------------------------+----------------------------------+
|                                  |                                  |
+----------------------------------+----------------------------------+
|                                  |                                  |
+----------------------------------+----------------------------------+

#### L.5.A.2 Traffic Assumptions (example: AMR 7.95)

+----------------------------------+----------------------------------+
| **Parameter**                    |                                  |
+----------------------------------+----------------------------------+
| User-Plane Traffic Model         | 100% VoIP                        |
|                                  |                                  |
| Vocoder Type                     | AMR 7.95                         |
|                                  |                                  |
| Vocoder Voice Model              | Markov Process with 50% activity |
|                                  | (transition probability = 0.01)  |
+----------------------------------+----------------------------------+
| Overhead : RTP payload (AMR      | 4 bits CMR                       |
| bandwidth efficient mode)        |                                  |
|                                  | 6 bits TOC per aggregated speech |
|                                  | frame                            |
|                                  |                                  |
|                                  | 7 bits padding for octet         |
|                                  | alignment                        |
|                                  |                                  |
|                                  | (assuming no aggregation)        |
+----------------------------------+----------------------------------+
| Overhead: RTP/UDP/IPv6           | 60 bytes                         |
| uncompressed header              |                                  |
+----------------------------------+----------------------------------+
| Overhead: RLC-UM                 | 2 bytes                          |
+----------------------------------+----------------------------------+
| ROHC                             | 1 byte R-0,                      |
|                                  |                                  |
|                                  | 2 bytes UDP checksum (will be    |
|                                  | zero bytes with UDP-Lite)        |
+----------------------------------+----------------------------------+
| ROHC                             | Resynchronization ignored        |
+----------------------------------+----------------------------------+
| RTCP                             | Not modeled                      |
+----------------------------------+----------------------------------+
| SIP                              | Not modeled                      |
+----------------------------------+----------------------------------+
| SID Frames                       | Not transmitted                  |
+----------------------------------+----------------------------------+
| Effective Data Rate with no RTP  | 10.8 kbps                        |
| layer aggregation                |                                  |
+----------------------------------+----------------------------------+
| MAC-d PDU Size[^9]               | 216 bits (one speech frame per   |
|                                  | MAC-d PDU)                       |
+----------------------------------+----------------------------------+

#### L.5.A.3 Other Assumptions 

+----------------------------------+----------------------------------+
| **Parameter**                    |                                  |
+----------------------------------+----------------------------------+
| UMTS Time Modelled \[s\]         | 180                              |
+----------------------------------+----------------------------------+
| Number of Simulation Runs        | 9                                |
+----------------------------------+----------------------------------+
| UE Category                      | 5                                |
+----------------------------------+----------------------------------+
| Receiver Type                    | Rake[^11] with Mobile Receive    |
|                                  | Diversity from 2 Antennas        |
|                                  |                                  |
|                                  | (2 Rx correlation = 0.5,         |
|                                  | mismatch 2 dB)                   |
+----------------------------------+----------------------------------+
| Associated DPCH Data Rate        | 3.4 kbps, SF 256                 |
+----------------------------------+----------------------------------+
| Associated DPCH Activity Factor  | 5%                               |
+----------------------------------+----------------------------------+
| HS-SCCH Channel Model            | Depends on loading               |
|                                  |                                  |
| Number                           | Yes                              |
|                                  |                                  |
| Errors Impact HS-DSCH Decoding   | Fixed Offset                     |
|                                  |                                  |
| Power Allocation                 |                                  |
+----------------------------------+----------------------------------+
| HSDPA Scheduler Implementation   |                                  |
+----------------------------------+----------------------------------+
| Mobility Model                   | Static location for UE           |
+----------------------------------+----------------------------------+
| Downlink Over-the air Delay      | 90                               |
| Budget \[ms\]                    |                                  |
+----------------------------------+----------------------------------+
| E-DCH Scheduling                 | Non-scheduled transmission       |
+----------------------------------+----------------------------------+
| E-DCH TTI length                 | Both 10ms and 2ms TTI            |
+----------------------------------+----------------------------------+
| E-DCH max number of HARQ         | 2 Tx for 10ms TTI                |
| transmissions                    |                                  |
|                                  | 6 Tx for 2ms TTI                 |
+----------------------------------+----------------------------------+

#### L.5.A.4 Simulation Methodology

The system simulation is dynamic and includes explicit modelling of fast
fading, power control, CQI generation, scheduling of users, etc.
Channels that connect different transmit/receive antenna pairs are
generated at the UMTS slot rate (1500Hz). The instantaneous SINR seen at
each receiver is computed at the slot rate. Virtual decoders map a
sequence of slot rate SINRs to block error events at the TTI rate for
each physical channel. The virtual decoders must generate the same
statistical block error events as the true decoders operating on a bit
by bit basis in a link level simulation for the same TTI rate for each
physical channel under consideration.

Inner and outer loop power control loops are explicitly modelled for the
associated DPCH. The OVSF code and transmit power resources consumed by
the associated DPCH and HS-SCCH channels are modelled dynamically.
Errors made in HS-SCCH decoding are taken into account in determining
whether the corresponding HS-DSCH transmission is decoded correctly.

The system simulation attempts to model sufficiently the MAC-d PDU flow
and performance from the NodeB to the UE. Thus, the system simulation is
considered an \"over-the-air\" model and does not capture impairments
beyond the NodeB to UE subsystem

Bibliography
============

\[1\] 3GPP TS 25.322 \"RLC Protocol\"

\[2\] 3GPP TS 34.108 \"Common test environments for User Equipment (UE)
conformance testing\"

\[3\] 3GPP TR 25.931 \"UTRAN functions, examples on signaling
procedures\"

\[4\] 3GPP TS 26.236 \"Performance characterization of the Enhanced
aacPlus and Extended Adaptive Multi-Rate - Wideband (AMR-WB+) audio
codecs\"

\[5\] 3GPP TS 25.323 \"Packet Data Convergence Protocol\"

\[6\] 3GPP TS 25.331 \"Radio Resource Control Protocol\"

\[7\] 3GPP TR 25.933 \"IP transport in UTRAN\"

\[8\] 3GPP TR 25.896 \"Feasibility Study for the Enhanced Uplink for
UTRA FDD\"

\[9\] IETF RFC 3095

\[10\] IETF RFC 3267

\[11\] 3GPP TR 25.932 \"Delay budget within the access stratum\"

\[12\] 3GPP TS 22.105 v3.6.0 \"Service and Capability\"

######### Annex M: Change history

  -------------------- ------------ -------------- -------- --------- ---------------------------------------------------------------- --------- ---------
  **Change history**                                                                                                                             
  **Date**             **TSG \#**   **TSG Doc.**   **CR**   **Rev**   **Subject/Comment**                                              **Old**   **New**
  2004-06              SP-24        SP-040342                         Version 6.0.0 approved at 3GPP TSG SA\#24                        2.0.0     6.0.0
  2007-06              SP-36                                          Version for Release 7                                            6.0.0     7.0.0
  2007-09              SP-37        SP-070633      0001     2         Characterisation of VoIMS over HSDPA/EUL                         7.0.0     7.1.0
  2007-12              SP-38        SP-070765      0002     2         Corrections to Characterization of VoIMS over HSDPA/EUL          7.1.0     7.2.0
  2007-12              SP-38        SP-070765      0003               Characterization of VoIMS over HSDPA/EUL -- Conversation Tests   7.1.0     7.2.0
  2008-12              SP-42                                          Version for Release 8                                            7.2.0     8.0.0
  2009-12              SP-46                                          Version for Release 9                                            8.0.0     9.0.0
  2011-03              SP-51                                          Version for Release 10                                           9.0.0     10.0.0
  2012-09              SP-57                                          Version for Release 11                                           10.0.0    11.0.0
  2014-09              SP-65                                          Version for Release 12                                           11.0.0    12.0.0
  2015-12              SP-70                                          Version for Release 13                                           12.0.0    13.0.0
  -------------------- ------------ -------------- -------- --------- ---------------------------------------------------------------- --------- ---------

  -------------------- ------------- ---------- -------- --------- --------- -------------------------------- -----------------
  **Change history**                                                                                          
  **Date**             **Meeting**   **TDoc**   **CR**   **Rev**   **Cat**   **Subject/Comment**              **New version**
  2017-03              75                                                    Version for Release 14           14.0.0
  2018-06              80                                                    Version for Release 15           15.0.0
  2020-07              \-            \-         \-       \-        \-        Update to Rel-16 version (MCC)   **16.0.0**
  -------------------- ------------- ---------- -------- --------- --------- -------------------------------- -----------------

[^1]: Question 4 contained two-parts. In the first part the subject
    answers whether he detects any disturbances - "yes" or "no." If he
    answers "yes," he then rates how annoying the disturbances were on a
    five-point scale. For practical purposes, a rating of 6 has been
    assigned to the responses of "no" disturbances detected. The ITU-T
    Recommendation for Conversational Testing, P.805, discusses Question
    4 but does not address the procedure to be applied to "no" votes.

[^2]: For MANOVA, there is no single universally accepted procedure for
    hypothesis testing but rather a number of different methods. For the
    analyses that follow, we have chosen Pillai Trace and the associated
    F-statistic as the criterion for significance, primarily because of
    its robustness to violations of MANOVA assumptions.

[^3]: The term "Conversational Quality" was introduced in previous AMR
    and AMR-WB Conversation Tests \[6\] but it has not been validated in
    the ITU-T Recommendation for Conversational Testing, P.805. The
    Conversational Quality values reported in this document are specific
    to the particular lab and the experiment from which they are
    derived. Scores are not absolute and comparisons across experiments
    are not valid.

[^4]: contact: ImreVarga

    [Imre.Varga \@siemens.com](mailto:bernhard.wimmer@siemens.com)

    Tel: +49 89 722 47537

    Siemens AG, ICM MP

    Grillparzerstrasse 10a, 81675 Munich, Germany

[^5]: contacts:

    Catherine Quinquis

    <catherine.quinquis@francetelecom.com>

    Tel: +33 2 96 05 14 93

    France Telecom T&I/R&D

    2 avenue Pierre Marzin, 22397 Lannion, France Jean-Yves Monfort

    <Jeanyves.monfort@francetelecom.com>

    Tel : +33296053171

    France Telecom T&I/R&D

    2 avenue Pierre Marzin, 22397 Lannion, France

[^6]: contact: ImreVarga

    [Imre.Varga \@siemens.com](mailto:bernhard.wimmer@siemens.com)

    Tel: +49 89 722 47537

    Siemens AG, ICM MP

    Grillparzerstrasse 10a, 81675 Munich, Germany

[^7]: contacts:

    Catherine Quinquis

    <Catherine.quinquis@francetelecom.com>

    Tel: +33 2 96 05 14 93

    France Telecom T&I/R&D

    2 avenue Pierre Marzin, 22397 Lannion, France Jean-Yves Monfort

    <Jeanyves.monfort@francetelecom.com>

    Tel : +33296053171

    France Telecom T&I/R&D

    2 avenue Pierre Marzin, 22397 Lannion, France

[^8]: 

[^9]: 

[^10]: 

[^11]: 
