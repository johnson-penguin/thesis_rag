5 Functional description of the encoder
=======================================

The description of the encoder is as follows. First, common
pre-processing is described, and then the different elements of the
encoder are described one by one. The discontinuous transmission (DTX)
operation and the AMR-WB interoperable option are then given in separate
subclauses, again referencing the same processing as in the default
option.

5.1 Common processing
---------------------

### 5.1.1 High-pass Filtering

The input audio signal $s_{\text{inp}}(n)$sampled at 8, 16, 32 or 48
kHz, $n$ being the sample index, is high-pass filtered to suppress
undesired low frequency components. The transfer function of the HP
filter has a cut-off frequency of 20 Hz (--3 dB) and is given by

$H_{\text{20}\text{Hz}}(z) = \frac{b_{0} + b_{1}z^{- 1} + b_{2}z^{- 2}}{1 + a_{1}z^{- 1} + a_{2}z^{- 2}}$
(1)

The coefficients of the HP filter for a given input sampling frequency
are given in the table below.

Table 1: Coefficients of the 20Hz HP filer

  -- -------------------- -------------------- -------------------- --------------------
     8 kHz                16 kHz               32 kHz               48 kHz
     0.988954248067140    0.994461788958195    0.997227049904470    0.998150511190452
     -1.977908496134280   -1.988923577916390   -1.994454099808940   -1.996301022380904
     0.988954248067140    0.994461788958195    0.997227049904470    0.998150511190452
     1.977786483776764    1.988892905899653    1.994446410541927    1.996297601769122
     -0.978030508491796   -0.988954249933127   -0.994461789075954   -0.996304442992686
  -- -------------------- -------------------- -------------------- --------------------

The input signal, filtered by the HP filter, is denoted as
$s_{\text{HP}}(n)$.

### 5.1.2 Complex low-delay filter bank analysis

#### 5.1.2.1 Sub-band analysis

The audio signal $s_{\text{HP}}(n)$ is decomposed into complex valued
sub-bands by a complex modulated low delay filter bank (CLDFB).
Depending on the input sampling rate $\text{sr}_{\text{HP}}$, the CLDFB
generates a time-frequency matrix of 16 time slots and
$L_{C} = \frac{\text{sr}_{\text{HP}}}{\text{800}}\text{Hz}$ sub-bands
where the width of each sub-band is 400 Hz.

The analysis prototype $w_{c}$ is an asymmetric low-pass filter with an
adaptive length depending on$\text{sr}_{\text{HP}}$. The length of
$w_{c}$ is given by $L_{w_{c}} = \text{10} \cdot L_{c}$ meaning that the
filter spans over 10 consecutive blocks for the transformation. The
prototype of the LP filter has been generated for 48 kHz. For other
input sampling rates, the prototype is obtained by means of
interpolation so that an equivalent frequency response is achieved.
Energy differences in the sub-band domain caused by different
transformation lengths are compensated for by an appropriate
normalization factors in the filter bank. The following figure shows the
plot of the LP filter prototype $w_{c}$ for $\text{sr}_{\text{HP}}$of 48
kHz.

![](media/image1.png){width="6.688888888888889in" height="2.61875in"}

Figure 4 : Impulse response of CLDFB prototype filter with 600 taps for
48 kHz sample rate

The filter bank operation is described in a general form by the
following formula:

$\begin{matrix}
X_{\text{CR}}(t,k) = \frac{\text{80}}{L_{c}} \cdot \sum_{n = - 8L_{C}}^{n = 2L_{C} - 1}{w_{C}(\text{10}L_{C} - 1 - i) \cdot s_{\text{HP}}(i + t \cdot L_{C})\text{cos}\left\lbrack \frac{\pi}{L_{C}}\left( n + n_{0} \right)\left( k + \frac{1}{2} \right) \right\rbrack} \\
X_{\text{CI}}(t,k) = \frac{\text{80}}{L_{c}} \cdot \sum_{n = - 8L_{C}}^{n = 2L_{C} - 1}{w_{C}(\text{10}L_{C} - 1 - i) \cdot s_{\text{HP}}(i + t \cdot L_{C})\text{sin}\left\lbrack \frac{\pi}{L_{C}}\left( n + n_{0} \right)\left( k + \frac{1}{2} \right) \right\rbrack} \\
\end{matrix}$ (2)

where $X_{\text{CR}}$ and $X_{\text{CI}}$ are the real and the imaginary
sub-band values, respectively, $t$is the sub-band time index with
$0 \leq t \leq \text{15}$, index $i$is defined as $i = n + 8L_{C}$,
$n_{0}$is the modulation offset of
$n_{0} = \frac{1}{2} - \frac{L_{C}}{2}$ and$k$is the sub-band index with
$0 \leq k \leq L_{C} - 1$.

As the equations show, the filter bank is comparable to a complex MDCT
but with a longer overlap towards the past samples. This allows for an
optimized implementation of CLDFB by adopting DCT-IV and DST-IV
frameworks.

#### 5.1.2.2 Sub-band energy estimation

The energy in the CLDFB domain is determined for each time index $t$ and
frequency sub-band$k$ by

$E_{C}\left( t,k \right) = (X_{\text{CR}}(t,k))^{2} + (X_{\text{CI}}(t,k))^{2}\ 0 \leq t \leq \text{15},\ 0 \leq k \leq L_{C}$
(3)

Furthermore, energy per-band ${\overline{E}}_{C}(k)$is calculated by
summing up the energy values in all time slots. That is

${\overline{E}}_{C}\left( k \right) = \sum_{}^{}{E_{C}(k,t)\ 0 \leq k \leq L_{C}}$
(1)

In case $L_{C} > \text{20}$, additional high frequency energy value
$E_{\text{HF}}$ ![](media/image2.png){width="0.21875in"
height="0.17708333333333334in"}is calculated for the frequency range
from 8kHz to 16kHz by summing up $E_{C}(t,k)$ over one frame which is
delayed by one time slot.

$E_{\text{HF}} = \sum_{}^{}{\sum_{}^{}{E_{C}(t,k)}}$ (2)

$E_{\text{HF}}$ is further scaled to an appropriate energy domain. In
case the high bands are not active, $E_{\text{HF}}$is initialized to the
maximum value.

### 5.1.3 Sample rate conversion to 12.8 kHz

The linear predictive (LP) analysis, the long-term prediction (LTP), the
VAD algorithm and signal are performed at the 12.8 kHz sampling rate.
The HP-filtered input signal $s_{\text{HP}}(n)$ is therefore converted
from the input sampling frequency to 12.8 kHz.

#### 5.1.3.1 Conversion of 16, 32 and 48 kHz signals to 12.8 kHz

For 16, 32 and 48 kHz signals, the sampling conversion is performed by
first up‑sampling the signal to 192 kHz, then filtering the output
through a low-pass FIR filter $H_{6\text{.}4}(z)$ that has the cut‑off
frequency at 6.4 kHz. Then, the signal is down-sampled to 12.8 kHz. The
filtering delay is 15 samples at 16 kHz sampling frequency which
corresponds to 0.9375 ms.

The up-sampling is performed by inserting 11, 5 or 3 (for 16, 32 or 48
kHz, respectively) zero-valued samples between each 2 samples for each
20-ms frame of 320 samples (at 16 kHz sampling frequency)

![](media/image3.wmf){width="3.8847222222222224in"
height="0.5131944444444444in"} (3)

where $s_{\text{192}}(n)$ is the signal at 192 kHz sampling frequency
and $F_{\text{up}}$ is the up-sampling factor equal to 12 for a 16 kHz
input, 6 for a 32 kHz input and 4 for a 48 kHz input. Then, the signal
$s_{\text{192}}(n)$ is filtered through the LP filter
$H_{6\text{.}4}(z)$ and decimated by 15 by keeping one out of 15
samples. The filter $H_{6\text{.}4}(z)$ is a 361-tap linear phase FIR
filter having a cut-off frequency of 6.4 kHz in the 192 kHz up-sampled
domain. The filtering and decimation can be done using the relation

$s_{\text{12}\text{.}8}(n) = \frac{F_{\text{up}}}{\text{15}}\sum_{i = - \text{180}}^{\text{180}}{s_{\text{192}}(\text{15}n + i)h_{6\text{.}4}(i)},\text{\ \ \ \ \ \ \ \ }n = 0,\text{.}\text{.}\text{.},\text{255}$
(4)

where $h_{6\text{.}4}$ is the impulse response of $H_{6\text{.}4}(z)$.
The operations in equations (3) and (4) can be implemented in one step
by using only a part of the filter coefficients at a time with an
initial phase related to the sampling instant *n*. That is

$s_{\text{12}\text{.}8}(n) = \frac{F_{\text{up}}}{\text{15}}\sum_{i = \frac{- \text{180}}{F_{\text{up}}} + 1}^{\frac{\text{180}}{F_{\text{up}}}}{s_{\text{HP}}(\left\lfloor \text{15}\frac{n}{F_{\text{up}}} \right\rfloor + i)h_{6\text{.}4}(F_{\text{up}}i - n\text{mod}F_{\text{up}})},\text{\ \ \ \ \ \ \ \ }n = 0,\text{.}\text{.}\text{.},\text{255}$
(5)

In case the encoder is externally forced to narrow-band processing of
the input signal, the cut-off frequency of the LP filter is changed from
6.4 kHz to 4 kHz.

#### 5.1.3.2 Conversion of 8 kHz signals to 12.8 kHz

For 8 to 12.8 kHz resampling a sharper resampling filter is beneficial.
Double length low-pass FIR filter $H_{3\text{.}9}(z)$ is used in this
case. The doubling of the impulse response length is compensated by a
low delay resampling method. The filter $H_{3\text{.}9}(z)$ is a 241-tap
linear phase FIR filter having a cut-off frequency of 3.9 kHz and is
applied in the up-sampled domain which is 64 kHz. Direct FIR filtering
with this filter would yield a delay of 120/64 = 1.875 ms. In order to
reduce this delay to 0.9375 ms, future samples are determined at 8 kHz
by adaptive linear prediction. The exact number of future samples is
found based on the difference between the actual delay (1.875 ms) and
the desired delay (0.9375 ms) at 8 kHz. Therefore
$\left\lfloor \left( 1\text{.}\text{875} - 0\text{.}\text{9375} \right) \ast 8 \right\rfloor = 7$
future samples are predicted. These predicted samples are concatenated
at the end of the current frame $s_{\text{HP}}(n)$to form a support
vector$s_{\text{HPC}}(n)$. Then, the sample rate conversion of
$s_{\text{HPC}}(n)$ is performed in a similar way as for the other
sampling rates, i.e. $s_{\text{HPC}}(n)$ is first up-sampled to 64 kHz,
the output is filtered through the low-pass FIR filter
$H_{3\text{.}9}(z)$ and the resulting signal is down-sampled to 12.8
kHz. The final filtering delay is aligned with that of the other
resampling configurations, i.e 12 samples at 12.8 kHz sampling frequency
which corresponds to 0.9375 ms.

To determine the future samples, linear prediction coefficients of order
16 are computed in the pre-emphasized domain in the following way. The
last *L*~ss~ =120 samples of the input frame
$s_{\text{HP}}(n),n = \text{40},\text{.}\text{.}\text{.},\text{159}$ at
8 kHz are windowed by an asymmetrical analysis window *win*~ss\_120~:

$\text{win}_{\text{ss}_{\text{120}}}\left( i \right) = \begin{Bmatrix}
0\text{.}\text{54} - 0\text{.}\text{46}\text{cos}\left( \frac{i2\pi}{\text{223}} \right) & i = 0,\text{.}\text{.}\text{.},\text{111} \\
\text{cos}\left( \frac{\left( i - \text{112} \right)2\pi}{\text{31}} \right) & i = \text{112},\text{119} \\
\end{Bmatrix}$ (6)

and a first order autocorrelation analysis is made on the windowed
signal $s_{\text{HPW}}(n)$. The pre-emphasis coefficient $\mu$~ss~ is
obtained by

$\mu_{\text{ss}} = r_{w}\frac{\left( 1 \right)}{r_{w}}\left( 0 \right)$
(7)

where *r~w~*(0) and *r~w~*(1) are the autocorrelation coefficients

$r_{w}(k) = \sum_{n = k}^{L_{\text{ss}} - 1}{s_{\text{HPW}}(n)}\ s_{\text{HPW}}(n - k),\ k = 0,1$
(8)

The last 120 samples of the signal
$s_{\text{HP}}(n),n = \text{40},\text{.}\text{.}\text{.},\text{159}$ are
pre-emphasized using the adaptive filter

$H_{\text{pre} - \text{emph}_{\text{ss}}}(z) = 1 - \mu_{\text{ss}}z^{- 1}$
(9)

to obtain the pre-emphasized signal $s_{\text{HP}_{\text{pre}}}(n)$ of
*L*~ss~ =120 samples. Then
$s_{\text{HP}_{\text{pre}}}(n),\text{\ \ }n = 0,\text{.}\text{.}\text{.},\text{119}$
is windowed by the asymmetrical analysis window *win*~ss\_120~ and a
16^th^ order autocorrelation analysis is made on the windowed signal
$s_{\text{HP}_{\text{preW}}}(n)$

$r_{\text{pw}}(k) = \sum_{n = k}^{L_{\text{ss}} - 1}{s_{\text{HP}_{\text{preW}}}(n)}\ s_{\text{HP}_{\text{preW}}}(n - k),\ k = 0,\text{.}\text{.}\text{.},\text{16}$
(10)

These autocorrelation coefficients are lag-windowed by

$r_{\text{pwl}}(k) = r_{\text{pw}}\left( k \right) \cdot w_{\text{lag}8k}\left( k \right),\ k = 0,\text{.}\text{.}\text{.},\text{16}$
(11)

where *w~lag8k~*(*k*) is defined as

$w_{\text{lag}8k}(k) = \text{exp}\left\lbrack - \frac{1}{2}\left( \frac{2\pi\text{60}k}{\text{8000}} \right)^{2} \right\rbrack,\ k = 0,\text{.}\text{.}\text{.},\text{16}$
(12)

Based on the autocorrelation coefficients *r~pwl~*(*k*), the linear
prediction coefficients *a~ss~*(*k*) are computed by the Levinson-Durbin
algorithm. The future samples in the pre-emphasized domain
$s_{\text{HP}_{\text{pre}}}(n),\text{\ \ }n = \text{120},\text{.}\text{.}\text{.},\text{126}$
are predicted by zero input filtering through the 1/*A~ss~*(*z*)
synthesis filter

$s_{\text{HP}_{\text{pre}}}(k) = \sum_{j = 1}^{\text{16}}{- s_{\text{HP}_{\text{pre}}}\left( k - j \right) \cdot a_{\text{ss}}\left( j \right)},\ k = \text{120},\text{.}\text{.}\text{.},\text{126}$
(13)

Finally, the concatenated signal$s_{\text{HP}_{\text{pre}}}(n)$ is
de-emphasized through the filter
$\frac{1}{(}1 - \mu_{\text{ss}}z^{- 1})$. Note that only the last 7
predicted samples need to be de-emphasized. These 7 de-emphasized
samples are concatenated to $s_{\text{HP}}(n)$ (at positions *n* =
160,...,166) to form the support vector$s_{\text{HPC}}(n)$.

The up-sampling of $s_{\text{HPC}}(n)$ is then performed by inserting 7
zero-valued samples between each 2 samples for each 20-ms frame of 160
samples (at 8 kHz sampling frequency) completed by 7 predicted future
samples (167 in total)

$s_{\text{64}}(n) = \begin{Bmatrix}
s_{\text{HPC}}\left( \frac{n}{8} \right) & \text{if\ }\frac{n}{8} = \left\lfloor \frac{n}{8} \right\rfloor \\
0 & \text{otherwise} \\
\end{Bmatrix},\text{\ \ \ \ \ \ \ \ }n = 0,\text{.}\text{.}\text{.},\text{1335}$
(14)

where $s_{\text{64}}(n)$ is the signal at 64 kHz sampling frequency.
Then, the signal $s_{\text{64}}(n)$ is filtered through the LP filter
$H_{3\text{.}9}(z)$ and decimated by 5 by keeping one out of 5 samples.
The filtering and decimation can be done using the relation

$s_{\text{12}\text{.}8}(n) = \frac{8}{5}\sum_{i = - \text{120}}^{\text{120}}{s_{\text{64}}(5n + i - d_{8_{}})h_{3\text{.}9}(i + \text{120})},\text{\ \ \ \ \ \ \ \ }n = 0,\text{.}\text{.}\text{.},\text{255}$
(15)

where $h_{3\text{.}9}$ is the impulse response of $H_{3\text{.}9}(z)$
and $d_{8_{}} = \text{60}$ assures that the index of *s*~64~ is never
higher than the highest available index for (which is 1335). Indeed, it
corresponds to the delay of this filtering at 64 kHz. To reduce
complexity, the operations in equations (14) and (15) can be implemented
in one step by using only a part of the filter coefficients at a time
with an initial phase related to the sampling instant *n*. This
polyphase implementation of the resampling filter is applied on the
concatenated support vector. That is

$s_{\text{12}\text{.}8}(n) = \frac{8}{5}\sum_{i = - \text{14}}^{\text{15}}{s_{\text{HPC}}(\left\lfloor 5\frac{n}{8} \right\rfloor + i - d_{8_{}})h_{3\text{.}9}(8i - n\text{mod}8 + \text{120})},\text{\ \ \ \ \ \ \ \ }n = 0,\text{.}\text{.}\text{.},\text{255}$
(16)

where $d_{8_{}} = 8$ is derived from the delay of this filtering at 8
kHz. It assures that the index of *s~HPC~* is never higher than the
highest available index (which is 166).

#### 5.1.3.3 Conversion of input signals to 16, 25.6 and 32 kHz

If ACELP core is selected for WB, SWB or FB signals at bitrates higher
than 13.2 kbps (see subclause 5.1.16), its internal sampling rate is set
to 16 kHz rather than 12.8 kHz. If the input signal is sampled at 8 kHz,
there is no conversion needed because for NB signals, ACELP core is
always operated at 12.8 kHz. If the input signal is sampled at 16 kHz,
no conversion is needed either and the input signal is only delayed by
15 samples which corresponds to 0.9375 ms. This is to keep all
pre-processed signals aligned regardless of the bitrate or bandwidth.
Thus, the input signal is resampled to 16 kHz only if its sampling
frequency is 32 or 48 kHz.

The resampling operation is done in the same way as for the case of 12.8
kHz (see subclause 5.1.3.1), i.e. by means of FIR filtering. The
coefficients of the LP filter are different but the filtering delay is
still the same, i.e. 0.9375 ms.

The resampled signal is denoted $s_{\text{16}}(n)$ where *n*=0,..,319.

The input signal is converted to 25.6 kHz at 48 kbps and to 32 kHz at 96
or 128kbps but only for SWB and FB signals. The sampling conversion is
again similar as in the case of 12.8 kHz with differences in LP filter
coefficients. The resampled signals are denoted
$s_{\text{25}\text{.}6}(n)$ and $s_{\text{32}}(n)$, respectively.

### 5.1.4 Pre-emphasis

A first-order high-pass filter is used to emphasize higher frequencies
of the input signal and it is given by

$H_{\text{pre} - \text{emph}}(z) = 1 - \beta_{\text{pre} - \text{emph}}z^{- 1}$
(17)

where $\beta_{\text{pre} - \text{emph}}$ is the pre-emphasis factor
which is set to 0.68. The input signal to the pre-emphasis filter is
$s_{\text{12}\text{.}8}(n)$ and the output signal is denoted
$s_{\text{pre}}(n)$.

If ACELP core is selected for WB, SWB or FB signals at bitrates higher
than 13.2 kbps (see subclause 5.1.16), its internal sampling rate is
16kHz rather than 12.8kHz. In this case, the pre-emphasis is re-done at
the end of the pre-processing chain, on $s_{\text{16}}(n)$ with
$\beta_{\text{pre} - \text{emph}} = 0\text{.}\text{72}$. The resulting
signal is denoted $s_{\text{pre}\text{16}}(n)$.

If MDCT-based TCX is selected for SWB or FB high-rate LPC
configurations, $\beta_{\text{pre} - \text{emph}} = 0\text{.}9$is used
as pre-emphasis factor when pre-emphasis is applied to signals at a
sampling rate higher than 16kHz.

### 5.1.5 Spectral analysis

Spectral analysis is used in the encoder for signal activity detection
(SAD) and signal classification functions. The discrete Fourier
transform (DFT) is used to perform the spectral analysis and spectral
energy estimation.

#### 5.1.5.1 Windowing and DFT

The frequency analysis is done twice per frame using 256-point fast
Fourier transform (FFT) with a 50% overlap. The centre of the first
window is placed 96 samples past the beginning of the current frame. The
centre of the second window is placed 128 samples farther, i.e., in the
middle of the second subframe of the current frame. A square root of a
Hanning window (which is equivalent to a sine window) is used to weight
the input signal for the frequency analysis. The square root Hanning
window is given by

$w_{\text{FFT}}\left( n \right) = \sqrt{0\text{.}5 - 0\text{.}5\text{cos}\left( \frac{2\text{πn}}{L_{\text{FFT}}} \right)} = \text{sin}\left( \frac{\text{πn}}{L_{\text{FFT}}} \right),\ n = 0,\text{.}\text{.}\text{.},L_{\text{FFT}} - 1$
(18)

where $L_{\text{FFT}}$ = 256 is the size of FFT analysis. Note that only
half of the window is computed and stored since it is symmetric (from 0
to $L_{\text{FFT}}/2$).

Figure 5: Relative positions of the spectral analysis windows

The windowed signal for both spectral analyses is obtained as:

$\begin{matrix}
s_{\text{wnd}}^{\left\lbrack 0 \right\rbrack}\left( n \right) = w_{\text{FFT}}\left( n \right)\ s_{\text{pre}}\left( n \right),\ n = 0,\ldots,L_{\text{FFT}} - 1, \\
s_{\text{wnd}}^{\left\lbrack 1 \right\rbrack}\left( n \right) = w_{\text{FFT}}\left( n \right)\ s_{\text{pre}}\left( n + L_{\text{FFT}}/2 \right),\ n = 0,\ldots,L_{\text{FFT}} - 1, \\
\end{matrix}$ (19)

where$s_{\text{pre}}(n)$is the pre-emphasized input signal
($s_{\text{pre}}(0)$is the first sample in the current frame). The
superscripts \[0\] and \[1\] used to denote the first and the second
frequency analysis, respectively, are dropped for simplicity. An FFT is
performed on both windowed signals to obtain two sets of spectral
parameters per frame:

$X\left( k \right) = \sum_{n = 0}^{N - 1}{s_{\text{wnd}}\left( n \right)}\ e^{- j2\pi\text{kn}N},\ k = 0,\text{.}\text{.}\text{.},L_{\text{FFT}} - 1$
(20)

The output of the FFT provides the real and the imaginary parts of the
spectrum denoted as$X_{R}\left( k \right)$,
$k = 0,\text{.}\text{.}\text{.},\text{128}$ and $X_{I}\left( k \right)$,
$k = 1,\text{.}\text{.}\text{.},\text{127}$. Note, that
$X_{R}\left( 0 \right)$ corresponds to the spectrum at 0 Hz (DC) and
$X_{R}\left( \text{128} \right)$ corresponds to the spectrum at 6400 Hz.
The spectrum at these points is only real-valued and usually ignored in
the subsequent analysis.

After the FFT analysis, the resulting spectrum is divided into critical
bands \[17\] using the intervals having the following limits (20 bands
in the frequency range 0-6400 Hz):

Table 2: Critical bands

  ------ ------ ------ ----
  band                 
  0      0      100    2
  1      100    200    2
  2      200    300    2
  3      300    400    2
  4      400    510    2
  5      510    630    2
  7      630    770    3
  6      770    920    3
  8      920    1080   3
  9      1080   1270   4
  10     1270   1480   4
  11     1480   1720   5
  12     1720   2000   6
  13     2000   2320   6
  14     2320   2700   8
  15     2700   3150   9
  16     3150   3700   11
  17     3700   4400   14
  18     4400   5300   18
  19     5300   6350   21
  ------ ------ ------ ----

The 256-point FFT results in a frequency resolution of 50 Hz (i.e.,
6400/128 Hz). Thus, after ignoring the DC component of the spectrum, the
number of frequency bins per critical band are given in the last column,
denoted $M_{\text{CB}}$.

#### 5.1.5.2 Energy calculations

The spectral analysis module also calculates several energy-related
parameters. For example, an average energy per critical band is computed
as

$E_{\text{CB}}\left( i \right) = \frac{1}{\left( L_{\text{FFT}}/2 \right)^{2}M_{\text{CB}}\left( i \right)}\ \sum_{k = 0}^{M_{\text{CB}}\left( i \right) - 1}\left( X_{R}^{2}\left( k + j_{i} \right) + X_{I}^{2}\left( k + j_{i} \right) \right),\ i = 0,\text{.}\text{.}\text{.},\text{19}$
(21)

where$X_{R}\left( k \right)$and$X_{I}\left( k \right)$are, respectively,
the real and the imaginary parts of the$k$-th frequency bin and $j_{i}$
is the index of the first bin in the *i*th critical band given
by$j_{i}$={1, 3, 5, 7, 9, 11, 13, 16, 19, 22, 26, 30, 35, 41, 47, 55,
64, 75, 89, 107}. Furthermore, energy per frequency
bin,$E_{\text{BIN}}\left( k \right)$, is calculated as

$E_{\text{BIN}}(k) = \frac{4}{L_{\text{FFT}}^{2}}\left( X_{R}^{2}(k) + X_{I}^{2}(k) \right),\ k = 0,\text{.}\text{.}\text{.},\text{127}$
(22)

Finally, the spectral analysis module computes the average total energy
for both FFT analyses in a 20 ms frame by summing the average critical
band energies$E_{\text{CB}}$. That is, the spectrum energy for the first
spectral analysis window is computed as

$E_{\text{frame}}^{\lbrack 0\rbrack} = \ \sum_{i = 0}^{\text{19}}{E_{\text{CB}}\left( i \right)}$
(23)

and, similarly, the second frame energy, denoted
as$E_{\text{frame}}^{\lbrack 1\rbrack}$.

The total frame energy (in dB) is computed as the average of the two
frame energies. That is

$E_{t} = \text{10}\ \text{log}\ \left( 0\text{.}5\left( E_{\text{frame}}^{\lbrack 0\rbrack} + E_{\text{frame}}^{\lbrack 1\rbrack} \right) \right)$
(24)

The total energy per frequency bin (power spectrum) is calculated as

$\text{PS}(k) = 0\text{.}5\left( E_{\text{BIN}}^{\lbrack 0\rbrack}(k) + E_{\text{BIN}}^{\lbrack 1\rbrack}(k) \right),\ k = 0,\text{.}\text{.}\text{.},\text{127}$
(25)

The output parameters of the spectral analysis module (both spectral
analyses), that is the average energy per critical band, the energy per
frequency bin and the total energy in dB, are used in several subsequent
functions.

Note that, for narrow band inputs sampled at 8 kHz, after sampling
conversion to 12.8 kHz, there is no content at both ends of the
spectrum. Thus, the lowest critical band as well as the last three
critical bands are not considered in the computation of output
parameters (only bands from
$i = 1,\text{.}\text{.}\text{.},\text{16}$are considered).

In addition to the absolute frame energy$E_{t}$, calculated in (24),
relative energy of the frame is calculated as the difference between the
total frame energy in dB and the long-term active signal
energy${\overline{E}}_{\text{sp}}$. The relative frame energy is given
by

$E_{\text{rel}} = E_{t} - {\overline{E}}_{\text{sp}}$ (26)

The long-term active signal energy is updated only during active frames
(explained in subclause 5.1.12.5). Note that the long-term active signal
energy${\overline{E}}_{\text{sp}}$is updated only after the signal
activity detection module.

### 5.1.6 Bandwidth detection

A detection algorithm is applied to detect the actual input audio
bandwidth for input sampling rates greater than 8 kHz. This bandwidth
information is used to run the codec in its optimal mode, tailored for a
particular bandwidth (BW) rather than for a particular input sampling
frequency. For example, if the input sampling frequency is 32 kHz but
there is no \"energetically\" meaningful spectral content above 8 kHz,
the codec is operated in the WB mode. The following bandwidths/modes are
used throughout the EVS codec: NB (0-4kHz), WB (0-8kHz), SWB (0-16kHz)
and FB (0-20 kHz).

The detection algorithm is based on computing energies in spectral
regions and comparing them to certain thresholds. The bandwidth detector
operates on the CLDFB values (see subclause 5.1.2). In the AMR-WB IO
mode, the bandwidth detector uses a DCT transform to determine the
signal bandwidth.

#### 5.1.6.1 Mean and maximum energy values per band

The CLDFB energy vector ${\overline{E}}_{C}$computed per 400Hz frequency
bins (see subclause 5.1.2.2), is further aggregated as described below.
Each value of $E_{C4}(i)$ represents a 1600Hz band consisting of four
CLDFB energy bins summed up from $k_{\text{start}}$ to
$k_{\text{stop}}$.

$E_{C4}(i) = \sum_{}^{}{{\overline{E}}_{C}\left( k \right)},\ i = 0,\text{.}\text{.},8$
(27)

Depending on the input sampling frequency up to nine CLDFB bands are
calculated using the above equation and the values are given below:

Table 3: CLDFB bands for energy calculation

  --- ---- ---- ------------------ -----------------
                bandwidth in kHz   bandwidth index
  0   3    6    1.2 -- 2.8         NB
  1   11   14   4.4 -- 7.2         WB
  2   14   17                      
  3   23   26   9.2 -- 15.6        SWB
  4   27   30                      
  5   31   34                      
  6   35   38                      
  7   42   45   16.8 -- 20.0       FB
  8   46   49                      
  --- ---- ---- ------------------ -----------------

The values in CLDFB bands are converted to the log domain and scaled by

$E_{C4}(i) = \text{log}_{\text{10}}\left\lbrack \frac{E_{C4}(i)}{f_{\text{scl}}^{2} \cdot 8} \right\rbrack,\ i = 0,\text{.}\text{.},8$
(28)

where $f_{\text{scl}}$ is set according to the input sampling frequency
as follows: 88.293854 for 8kHz, 88.300926 for 16kHz, 88.304118 for 32kHz
and 88.028412 for 48kHz.

The per-band CLDFB energy is then used to calculate the mean energy
values per bandwidth:

$\begin{matrix}
E_{\text{NB}} = E_{C4}(0) + 1\text{.}6 \\
E_{\text{WB}} = \frac{1}{2}\sum_{}^{}{E_{C4}(i)} + 1\text{.}6 \\
E_{\text{SWB}} = \frac{1}{4}\sum_{}^{}{E_{C4}(i)} + 1\text{.}6 \\
E_{\text{FB}} = \frac{1}{2}\sum_{}^{}{E_{C4}(i)} + 1\text{.}6 \\
\end{matrix}$ (29)

and the maximum energy values per bandwidth:

$\begin{matrix}
E_{\text{NB}\text{,max}} = E_{\text{NB}} + 1\text{.}6 \\
E_{\text{WB}\text{,max}} = \underset{i = 1,2}{\text{max}}(E_{C4}(i)) + 1\text{.}6 \\
E_{\text{SWB}\text{,max}} = \underset{i = 3,\text{.}\text{.},6}{\text{max}}(E_{C4}(i)) + 1\text{.}6 \\
E_{\text{FB}\text{,max}} = \underset{i = 7,8}{\text{max}}(E_{C4}(i)) + 1\text{.}6 \\
\end{matrix}$ (30)

In case of the DCT based detector, the DCT values are computed by first
applying a Hanning window on the 320 samples of the input audio signal
sampled at input sampling rate. Then the windowed signal is transformed
to the DCT domain and finally decomposed into several bands as shown in
Table 3a.

Table 3a: DCT bands for energy calculation

  --- ------------------ -----------------
      bandwidth in kHz   bandwidth index
  0   1.5 -- 3.0         NB
  1   4.5 -- 7.5         WB
  2                      
  3   9.0 -- 15.0        SWB
  4                      
  5                      
  6                      
  7   16.5 -- 19.5       FB
  8                      
  --- ------------------ -----------------

The values in DCT bands are converted to the log domain by

$E_{C4}(i) = \text{log}_{\text{10}}\left\lbrack E_{C4}(i) \right\rbrack,\ i = 0,\text{.}\text{.},8$
(33a)

and per-band and maximum energies are computed using (32) and (33) while
the constant 1.6 in these equations is omitted in case of the DCT based
detector.

### 5.1.7 Bandwidth decision

The following decision logic is identical for CLDFB and DCT versions of
energy calculations, except for some constants which were adapted to get
similar detection results.

The long-term CLDFB energy mean values for NB, WB and SWB are updated as
follows:

$\begin{matrix}
{{\overline{E}}_{\text{NB}} = 0\text{.}\text{75\ \{}\overline{E}}_{\text{NB}}^{\lbrack - 1\rbrack} + 0\text{.}\text{25}E_{\text{NB}} \\
\end{matrix}{\overline{E}}_{\text{WB}} = 0\text{.}\text{75\ \{}\overline{E}{}_{\text{WB}}^{\lbrack - 1\rbrack} + 0\text{.}\text{25}E_{\text{WB}}{\overline{E}}_{\text{SWB}} = 0\text{.}\text{75\ \{}\overline{E}{}_{\text{SWB}}^{\lbrack - 1\rbrack} + 0\text{.}\text{25}E_{\text{SWB}}$
(31)

where the superscript \[-1\] has been used to denote the value of
${\overline{E}}_{\text{NB}}$ in the previous frame. The update takes
place only if the local SAD decision is active and only if the long-term
background noise level, ${\overline{N}}_{t}$, is higher than 30 dB.

The values are compared to certain thresholds also taking the current
maximum values into account, which leads to increasing or decreasing
counters for each bandwidth as described below in the flowchart.

Figure 6: Increasing and decreasing of BW counters

The tests in the above diagram are performed sequentially from top to
bottom. The BW counters are then used to decide the actual signal
bandwidth, *BW*, according to the logic described in the following
schematic diagram.

Figure 7: BW selection logic

In the above diagram, the tests are performed in a sequential order,
i.e. it could happen that decision about signal bandwidth is changed
several times in this logic. After every selection of a particular
bandwidth, certain counters are reset to their minimal value 0 or to
their maximum value 100.

Finally, the resulting bandwidth can be upper limited in case the codec
performance has not been optimized for it at particular bitrate. For
example, at 9.6 kbps, the codec supports coding up to SWB. Therefore, if
the detected bandwidth is FB, it is overwritten to SWB at this bitrate.
The following table shows the range of bitrates for which the codec
performance has been optimized for each bandwidth.

Table 4: Optimization of the codec performance per bandwidth

  ----------- ------------------------
  bandwidth   bitrate range \[kbps\]
  NB          7.2 - 24.4
  WB          7.2 - 128
  SWB         9.6 - 128
  FB          16.4 - 128
  ----------- ------------------------

### 5.1.8 Time-domain transient detection

The HP-filtered input signal $s_{\text{HP}}(n)$ including the look-ahead
is input to the time-domain transient detector. The HP-filtered input
signal $s_{\text{HP}}(n)$ is further high-pass filtered. The transfer
function of the transient detection's HP filter is given by

$H_{\text{TD}}\left( z \right) = 0\text{.}\text{375} - 0\text{.}5z^{- 1} + 0\text{.}\text{125}z^{- 2}$
(32)

The signal, filtered by the transient detection's HP filter, is denoted
as $s_{\text{TD}}(n)$. The HP-filtered signal $s_{\text{TD}}(n)$ is
segmented into 8 consecutive segments of the same length. The energy of
the HP-filtered signal $s_{\text{TD}}(n)$ for each segment is calculated
as:

$E_{\text{TD}}(i) = \sum_{n = 0}^{L_{\text{segment}} - 1}\left( s_{\text{TD}}\left( \text{iL}_{\text{segment}} + n \right) \right)^{2},\ i = 0,\text{.}\text{.}\text{.},7$
(33)

where $L_{\text{segment}} = L_{\text{inp}}/8$ is the number of samples
in 2.5 milliseconds segment at the input sampling frequency. An
accumulated energy is calculated using:

$E_{\text{Acc}} = \text{max}(E_{\text{TD}}\left( i - 1 \right),0\text{.}\text{8125}E_{\text{Acc}})$
(34)

A transient is detected if the energy of a segment $E_{\text{TD}}(i)$
exceeds the accumulated energy by a constant factor of 8.5and the attack
index is set to $i$. If no attack is detected but strong energy increase
is detected in segment$i$, the attack index is set to $i$and the frame
is not marked as a transient frame.

The energy change for each segment is calculated as:

$E_{\text{chng}}\left( i \right) = \left\{ \begin{matrix}
\frac{E_{\text{TD}}\left( i \right)}{E_{\text{TD}}\left( i - 1 \right)}, & E_{\text{TD}}\left( i \right) > E_{\text{TD}}\left( i - 1 \right) \\
\frac{E_{\text{TD}}\left( i - 1 \right)}{E_{\text{TD}}\left( i \right)}, & E_{\text{TD}}\left( i - 1 \right) > E_{\text{TD}}\left( i \right) \\
\end{matrix} \right.\ $ (35)

The temporal flatness measure is calculated as:

$\text{TFM}\left( N_{\text{past}} \right) = \frac{1}{8 + N_{\text{past}}}\sum_{i = - N_{\text{past}}}^{7}{E_{\text{chng}}\left( i \right)}$
(36)

The maximum energy change is calculated as:

$\text{MEC}\left( N_{\text{past}},N_{\text{new}} \right) = \text{max}\left( E_{\text{chng}}\left( - N_{\text{past}} \right),E_{\text{chng}}\left( - N_{\text{past}} + 1 \right),\text{.}\text{.}\text{.},E_{\text{chng}}\left( N_{\text{new}} - 1 \right) \right)$
(37)

If index of $E_{\text{chng}}(i)$ or $E_{\text{TD}}(i)$ is negative then
it indicates a value from the previous segment, with segment indexing
relative to the current frame. $N_{\text{past}}$is the number of the
segments from the past frames. It is equal to 0 if the temporal flatness
measure is calculated for the usage in ACELP/TCX decision. If the
temporal flatness measure is calculated for the TCX LTP decision then it
is equal to:

$N_{\text{past}} = 1 + \text{min}\left( 8,\left\lceil 8\frac{\text{pitch}}{L_{\text{celp}}} + 0\text{.}5 \right\rceil \right)$
(38)

$N_{\text{new}}$ is the number of segments from the current frame. It is
equal to 8 for non-transient frames. For transient frames first the
locations of the segments with the maximum and the minimum energy are
found:

$\begin{matrix}
i_{\text{max}} = \underset{i \in \left\{ - N_{\text{past}},\text{.}\text{.}\text{.},7 \right\}}{\text{argmax}}E_{\text{TD}}\left( i \right) \\
i_{\text{min}} = \underset{i \in \left\{ - N_{\text{past}},\text{.}\text{.}\text{.},7 \right\}}{\text{argmin}}E_{\text{TD}}\left( i \right) \\
\end{matrix}$ (39)

If
$E_{\text{TD}}\left( i_{\text{min}} \right) > 0\text{.}\text{375}E_{\text{TD}}\left( i_{\text{max}} \right)$
then $N_{\text{new}}$is set to $i_{\text{max}} - 3$, otherwise
$N_{\text{new}}$ is set to 8.

### 5.1.9 Linear prediction analysis

Short-term prediction or linear prediction (LP) analysis using the
autocorrelation approach determines the coefficients of the synthesis
filter of the CELP model. The autocorrelation of windowed speech is
converted to the LP coefficients using the Levinson-Durbin algorithm.
Then, the LP coefficients are transformed to the line spectral pairs
(LSP) and consequently to line spectral frequencies (LSF) for
quantization and interpolation purposes. The interpolated quantized and
unquantized coefficients are converted back to the LP domain to
construct the synthesis and weighting filters for each subframe.

#### 5.1.9.1 LP analysis window

In case of encoding of an active signal frame, two sets of LP
coefficients are estimated in each frame using a 25 ms asymmetric
analysis window (320 samples at 12.8 kHz sampling rate), one for the
frame-end and one for mid-frame LP analysis. A look ahead of 8.75ms (112
samples at 12.8 kHz sampling rate) is used for the frame-end
autocorrelation calculation. The frame structure is shown below.

Figure 8: Relative positions and length of the LP analysis windows

The frame is divided into four sub-frames, each having a length of 5 ms,
i.e., 64 samples. The windows for frame-end analysis and for mid-frame
analysis are centred at the 2^nd^ and 4^th^ sub-frame of the current
frame, respectively. An asymmetrical window with the length of 320
samples is used for windowing. The windowed signal for mid-frame is
calculated as

$s_{\text{wmid}}\left( n \right) = s_{\text{pre}}\left( n - \text{80} \right)w\left( n \right),\ n = 0,\text{.}\text{.}\text{.},\text{319}$
(40)

and the windowed signal for frame-end is calculated as

$s_{\text{wend}}\left( n \right) = s_{\text{pre}}\left( n + \text{48} \right)w\left( n \right),\ n = 0,\text{.}\text{.}\text{.},\text{319}$
(41)

#### 5.1.9.2 Autocorrelation computation

The autocorrelations of the windowed signal are computed by

$r_{c}\left( k \right) = \sum_{n = k}^{L - 1}{s_{\text{wend}}\left( n \right)}s_{\text{wend}}\left( n - k \right),\ k = 0,\text{.}\text{.}\text{.},\text{16},$
(42)

where $L$ is set to 320. When $r_{c}\left( 0 \right) < \text{100}$,
$r_{c}\left( 0 \right)$ is set to 100 as well.

#### 5.1.9.3 Adaptive lag windowing

In addition, bandwidth expansion is applied by lag windowing the
autocorrelations using the following window

$w_{\text{lag}}(i) = \text{exp}\left\lbrack - \frac{1}{2}\left( \frac{2\text{πf}_{0}i}{f_{s}} \right)^{2} \right\rbrack,\ i = 1,\text{.}\text{.}\text{.},\text{16},$
(43)

where $f_{s}$ is the sampling frequency (12800 or 16000) and the
bandwidth frequency $f_{0}$ is set adaptively based on the OL pitch lag
$d_{\text{OL}}^{\lbrack 2\rbrack}$ in the 12.8 kHz domain and the
normalized correlation $C_{\text{norm}}^{\lbrack 2\rbrack}$ (i.e., pitch
gain). These parameters are obtained in the OL pitch estimation module
from the look-ahead part of the current or the previous frame, depending
on whether the adaptive lag windowing is applied before or after the OL
pitch estimation. In some special cases,
$\text{min}(d_{\text{OL}}^{\lbrack 0\rbrack},d_{\text{OL}}^{\lbrack 1\rbrack})$
and$\text{max}(C_{\text{norm}}^{\lbrack 0\rbrack},C_{\text{norm}}^{\lbrack 1\rbrack})$
are used instead of $d_{\text{OL}}^{\lbrack 2\rbrack}$ and
$C_{\text{norm}}^{\lbrack 2\rbrack}$, respectively. These situations
will be described later in this specification. Note that the shorter
pitch lag and/or the larger pitch gain, the stronger (heavy smoothing
with larger$f_{0}$) window is used to avoid excessive resonance in the
frequency domain. The longer pitch lag and/or the smaller normalized
correlation, the weaker window (light smoothing with smaller$f_{0}$) is
used to get more faithful representation of the spectral envelope.

Table 5: Selection of band width frequency $f_{0}$ in Hz

  -------------------------------------------------- ----------------------------------------- ------------------------------------------------ ------------------------------------------
                                                     $d_{\text{OL}}^{\lbrack 2\rbrack}$\< 80   80\<= $d_{\text{OL}}^{\lbrack 2\rbrack}$\< 160   160\<=$d_{\text{OL}}^{\lbrack 2\rbrack}$
  0.6 \<$C_{\text{norm}}^{\lbrack 2\rbrack}$         60                                        40                                               20
  0.3 \<$C_{\text{norm}}^{\lbrack 2\rbrack}$\<=0.6   40                                        40                                               20
  $C_{\text{norm}}^{\lbrack 2\rbrack}$ \<= 0.3       40                                        20                                               20
  -------------------------------------------------- ----------------------------------------- ------------------------------------------------ ------------------------------------------

The modified autocorrelation function, $r^{'}\left( k \right)$ is
calculated as

$r^{'}\left( k \right) = r_{c}\left( k \right)w_{\text{lag}}\left( k \right),\ k = 0,\text{.}\text{.}\text{.},\text{16}$
(44)

Further, $r^{'}(0)$ is multiplied by the white noise correction factor
1.0001 which is equivalent to adding a noise floor of -40 dB.

#### 5.1.9.4 Levinson-Durbin algorithm

The modified autocorrelation function,$r^{'}\left( k \right)$, is used
to obtain the LP filter coefficients $a_{k},\ k = 1,\ldots,\text{16}$ by
solving the set of equations:

$\sum_{k = 1}^{\text{16}}{a_{k}r^{'}\left( \left| i - k \right| \right)} = - r^{'}\left( i \right),\ i = 1,\text{.}\text{.}\text{.},\text{16}$
(45)

The set of equations in (46) is solved using the Levinson-Durbin
algorithm. This algorithm uses the following recursion:

$\begin{matrix}
E(0) = r^{'}\left( 0 \right) \\
\text{for}\ i = 1\ \text{.}\text{.}\text{.}\ \text{16} \\
\ k_{i} = \frac{- \left\lbrack r^{'}\left( i \right) + \sum_{}^{}{a_{j}^{i - 1}r^{'}\left( i - j \right)} \right\rbrack}{E}\left( i - 1 \right) \\
\ a_{i}^{(i)} = k_{i} \\
\ \text{for}\ j = 1\ \text{.}\text{.}\text{.}\ i - 1\ a_{j}^{(i)} = a_{j}^{(i - 1)} + k_{i}a_{i - j}^{(i - 1)} \\
\ E\left( i \right) = \left( 1 - k_{i}^{2} \right)E\left( i - 1 \right) \\
\text{end} \\
\end{matrix}$ (47)

The final solution is given
as$a_{j} = a_{j}^{\left( \text{16} \right)},\ j = 1,\ldots,\text{16}$.
The residual error energies (LP error energies) $E(i)$ are also used in
the subsequent processing.

#### 5.1.9.5 Conversion of LP coefficients to LSP parameters

The LP filter coefficients $a_{j}$ are converted to the LSP
representation \[16\] for quantization and interpolation purposes. For a
16^th^-order LP filter, the LSPs are defined as the roots of the sum and
difference polynomials

$\begin{matrix}
F_{1}(z) = \frac{A(z) + z^{- \text{16}}A(z^{- 1})}{1 + z^{- 1}} \\
F_{2}(z) = \frac{A(z) - z^{- \text{16}}A(z^{- 1})}{1 - z^{- 1}} \\
\end{matrix}$ (48)

The polynomials $F_{1}(z)$ and $F_{2}(z)$ are symmetric and asymmetric,
respectively. It can be proved that all roots of these polynomials lie
on the unit circle and are interlaced. The polynomials $F_{1}(z)$ and
$F_{2}(z)$ have each 8 conjugate roots, denoted
$q_{i} = \text{cos}(\omega_{i})$ and called the Line Spectral Pairs
(LSPs). The corresponding angular frequencies $\omega_{i}$ are the Line
Spectral Frequencies (LSFs). The LSFs satisfy the ordering property
$0 < \omega_{0} < \text{.}\text{.}\text{.} < \omega_{\text{15}} < \pi$.
The coefficients of these polynomials are found by the following
recursive relations:

$\begin{matrix}
f_{1}(0) = 1 \\
f_{2}(0) = 1 \\
\text{for}\ i = 1,\text{.}\text{.},8 \\
\ f_{1}(i) = a_{i} + a_{\text{16} - i} - f_{1}(i - 1) \\
\ f_{2}(i) = a_{i} - a_{\text{16} - i} + f_{2}(i - 1) \\
\text{end} \\
\end{matrix}$ (49)

where *M* = 16 is the predictor order.

The LSPs are found by evaluating the polynomials $F_{1}(z)$ and
$F_{2}(z)$at 100 points equally spaced between 0 and π and checking for
sign changes. A sign change indicates the existence of a root and the
sign change interval is then divided four times to track the root
precisely. Considering the conjugate symmetry of the polynomials
$F_{1}(z)$ and$F_{2}(z)$ and removing the linear term, it can be shown
that the polynomials $F_{1}(z)$ and $F_{2}(z)$ can be written
(considering$z = e^{\text{jω}}$) as

$\begin{matrix}
F_{1}^{'}(\omega) = 2\text{cos}8\omega + 2f_{1}(1)\text{cos}7\omega + \text{.}\text{.}\text{.} + 2f_{1}(7)\text{cos}\omega + f_{1}(8) \\
F_{2}^{'}(\omega) = 2\text{cos}8\omega + 2f_{2}(1)\text{cos}7\omega + \text{.}\text{.}\text{.} + 2f_{2}(7)\text{cos}\omega + f_{2}(8) \\
\end{matrix}$ (50)

Considering the frequency mapping $x = \text{cos}(\omega)$ we can define

$T_{m}(\omega) = \text{cos}(\text{mω})$ (51)

an *m*th-order Chebyshev polynomial in *x* \[18\]. The polynomials
$F_{1}^{'}(z)$ and $F_{2}^{'}(z)$ can then be rewritten using this
Chebyshev polynomial expansion as

$\begin{matrix}
F_{1}^{'}(\omega) = 2T_{8}(x) + 2f_{1}(1)T_{7}(x) + \text{.}\text{.}\text{.} + 2f_{1}(7)T_{1}(x) + f_{1}(8) \\
F_{2}^{'}(\omega) = 2T_{8}(x) + 2f_{2}(1)T_{7}(x) + \text{.}\text{.}\text{.} + 2f_{2}(7)T_{1}(x) + f_{2}(8) \\
\end{matrix}$ (52)

Neglecting the factor of 2, which does not affect the root searching
mechanism, the series to be evaluated can be generalized to

$Y(x) = \sum_{k = 0}^{7}{f_{k}T_{8 - k}(x)}$ (53)

The Chebyshev polynomials satisfy the order recursion

$b_{k}(x) = 2\text{xb}_{k + 1}(x) - b_{k + 2}(x) + f_{k}$ (54)

with initial conditions $b_{8}(x) = b_{9}(x) = 0$. This recursion can be
used to calculate $b_{0}(x)$ and $b_{2}(x)$. Then, $Y(x)$ can be
expressed in terms of $b_{0}(x)$ and $b_{2}(x)$

$Y(x) = \sum_{k = 0}^{7}{\left\lbrack b_{k}(x) - 2\text{xb}_{k + 1}(x) + b_{k + 2}(x) \right\rbrack T_{k}(x)} = \frac{b_{0}(x) - b_{2}(x) + f_{0}}{2}$
(55)

The details about Chebyshev polynomial evaluation method can be found in
\[18\].

In the following part of this document, the LSPs found by the described
method will be denoted as $q_{i}$, *i*=1,..,16 with $q_{0} = 1$.

#### 5.1.9.6 LSP interpolation

The LP parameters for each subframe are obtained by means of
interpolation between the end-frame parameters of the current frame, the
mid-frame parameters of the current frame and the end-frame parameters
of the previous frame. However, the LP parameters are not particularly
suitable for interpolation due to stability issues. For this reason, the
interpolation is done on the respective LSP parameters and then
converted back to the LP domain.

Let $q_{\text{end},i}$ denote the end-frame LSP vector of the current
frame, $q_{\text{mid},i}$ the mid-frame LSP vector of the current frame,
both calculated by the method described in the previous section.
Furthermore, let $q_{{\text{end} - 1,}_{i}}$ be the end-frame LSP vector
of the previous frame. The interpolated LSP vectors for all subframes
are then given by

$\begin{matrix}
q_{i}^{\lbrack 0\rbrack} = 0\text{.}5q_{\text{end} - 1,i} + 0\text{.}5q_{\text{mid},i} \\
q_{i}^{\lbrack 1\rbrack} = q_{\text{mid},i} \\
q_{i}^{\lbrack 2\rbrack} = 0\text{.}5q_{\text{mid},i} + 0\text{.}5q_{\text{end},i} \\
q_{i}^{\lbrack 3\rbrack} = q_{\text{end},i} \\
\end{matrix}$ (56)

The same formula is used for interpolation of quantized LSPs described
later in this document.

#### 5.1.9.7 Conversion of LSP parameters to LP coefficients

Once the interpolated LSP vectors are calculated, they are converted
back into LP filter coefficients for each subframe. Each LSP parameter
$q_{i} = \text{cos}\omega_{i}$ gives rise to a second order polynomial
factor of the form $1 - 2\text{cos}\omega_{i}z^{- 1} + z^{- 2}$. These
can be multiplied together to form the polynomials, i.e.

$\begin{matrix}
F_{1}^{'}(x) = \prod_{k = 1}^{8}{2(x - x_{2k - 1})} \\
F_{2}^{'}(x) = \prod_{k = 1}^{8}{2(x - x_{2k})} \\
\end{matrix}$ (57)

By using the Chebyshev polynomial expansion defined in (53) we can apply
the following recursion to find the coefficients of the polynomials:

$\begin{matrix}
f_{1}^{'}(0) = 1 \\
f_{1}^{'}(1) = - 2q_{0} \\
\text{for}\ i = 2,\text{.}\text{.},8 \\
\ f_{1}^{'}(i) = - 2q_{2i - 2}f_{1}^{'}(i - 1) + 2f_{1}^{'}(i - 2) \\
\ \text{for}\ j = i - 1,\text{.}\text{.},2\ f_{1}^{'}(j) = f_{1}^{'}(j) - 2q_{2i - 2}f_{1}^{'}(j - 1) + f_{1}^{'}(j - 2) \\
\ f_{1}^{'}(1) = f_{1}^{'}(1) - 2q_{2i - 2} \\
\text{end} \\
\end{matrix}$ (58)

The coefficients $f_{2}^{'}(i)$ are computed similarly, by replacing
$q_{2i - 2}$ by $q_{2i - 1}$, and with initial conditions
$f_{2}^{'}(0) = 1$and $f_{2}^{'}(1) = - 2q_{1}$. Once the coefficients
$f_{1}^{'}(z)$ and $f_{2}^{'}(z)$ are found, they are multiplied by
$1 + z^{- 1}$ and $1 - z^{- 1}$, respectively, to form the polynomials
$F_{1}(z)$ and $F_{2}(z)$. That is

$\begin{matrix}
f_{1}(i) = f_{1}^{'}(i) + f_{1}^{'}(i - 1),i = 8,\text{.}\text{.}\text{.},1 \\
f_{2}(i) = f_{2}^{'}(i) - f_{2}^{'}(i - 1),i = 8,\text{.}\text{.}\text{.},1 \\
\end{matrix}$ (59)

Finally, the LP coefficients are found by

$\begin{matrix}
a_{i} = 0\text{.}5f_{1}(i) + 0\text{.}5f_{2}(i),i = 1,\text{.}\text{.}\text{.},8 \\
a_{i} = 0\text{.}5f_{1}(i) - 0\text{.}5f_{2}(i),i = 8,\text{.}\text{.}\text{.},\text{16} \\
\end{matrix}$ (60)

with $a_{0} = 1$. This is directly derived from the equation
$A(z) = (F_{1}^{'}(z) + F_{2}^{'}(z)\frac{)}{2}$, and considering the
fact that $F_{1}(z)$ and $F_{2}(z)$ are symmetric and asymmetric
polynomials, respectively. The details of this procedure can be found in
\[18\].

#### 5.1.9.8 LP analysis at 16kHz

If ACELP core is selected for WB, SWB or FB signals at bitrates higher
than 13.2 kbps, its internal sampling rate is set to 16 kHz rather than
12.8 kHz. In this case, the LP analysis is done at the end of the
pre-processing chain on input signal resampled to 16 kHz and
pre-emphasized (see subclauses 5.1.3.3 and 5.1.4). In this case, the
length of the LP analysis window is 400 samples at 16 kHz, which
corresponds again to 25 ms. The windowed signal for mid-frame is
calculated as

$s_{\text{wmid}}\left( n \right) = s_{\text{pre}}\left( n - \text{100} \right)w\left( n \right),\ n = 0,\text{.}\text{.}\text{.},\text{399}$
(61)

and the windowed signal for frame-end is calculated as

$s_{\text{wmid}}\left( n \right) = s_{\text{pre}}\left( n + \text{60} \right)w\left( n \right),\ n = 0,\text{.}\text{.}\text{.},\text{399}$
(62)

The autocorrelation computation, adaptive lag windowing and the
conversion of LP coefficients to LSP parameters are performed similarly
as in subclauses 5.1.9.2 thru 5.1.9.5. However, the LSP interpolation is
done on 5 sub-frames instead of 4 sub-frames. The interpolated LSP
vectors are given by

The conversion of LSP parameters to LP coefficients is then performed
similarly as in subclause 5.1.9.7. At the end of the LP analysis there
are *M*=16 LSP parameters and $a_{i}$ coefficients but the corresponding
LSFs span the range of 0-8000 Hz rather than 0-6400 Hz.

The LP analysis at 25.6 kHz and 32 kHz is described later in this
document.

### 5.1.10 Open-loop pitch analysis

The Open-Loop (OL) pitch analysis calculates three estimates of the
pitch lag for each frame. This is done in order to smooth the pitch
evolution contour and to simplify the pitch analysis by confining the
closed-loop pitch search to a small number of lags around the open-loop
estimated lags.

The OL pitch estimation is based on a perceptually weighted
pre-emphasized input signal. The open-loop pitch analysis is performed
on a signal decimated by two, i.e. sampled at 6.4 kHz. This is in order
to reduce the computational complexity of the searching process. The
decimated signal is obtained by filtering the signal through a 5th-order
FIR filter with coefficients {0.13, 0.23, 0.28, 0.23, 0.13} and then
down-sampling the output by 2*.*

The OL pitch analysis is performed three times per frame to find three
estimates of the pitch lag: two in the current frame and one in the
look‑ahead area. The first two calculations are based on 10‑ms segments
of the current frame. The final (third) estimation corresponds to the
look-ahead, and the length of this segment is 8.75ms.

#### 5.1.10.1 Perceptual weighting

Perceptual weighting is performed by filtering the pre-emphasized input
signal $s_{\text{pre}}(n)$ through a perceptual weighting filter,
derived from the LP filter coefficients. The traditional perceptual
weighting filter
$W(z) = A(\frac{z}{\gamma_{1}}\frac{)}{A}(\frac{z}{\gamma_{2}})$ has
inherent limitations in modelling the formant structure and the required
spectral tilt concurrently. The spectral tilt is pronounced in speech
signals due to the wide dynamic range between low and high frequencies.
This problem is eliminated by introducing the pre-emphasis filter (see
subclause 5.1.4) at the input which enhances the high frequency content.
The LP filter coefficients are found by means of LP analysis on the
pre-emphasized signal. Subsequently, they are used to form the
perceptual weighting filter. Its transfer function is the same as the LP
filter transfer function but with the denominator having coefficients
equal to the de-emphasis filter (inverse of the pre-emphasis filter). In
this way, the weighting in formant regions is decoupled from the
spectral tilt. Finally, the pre-emphasized signal is filtered through
the perceptual filter to obtain a perceptually weighted signal, which is
used further in the OL pitch analysis.

The perceptual weighting filter has the following form

$W(z) = A(\frac{z}{\gamma_{1}})H_{\text{de} - \text{emph}}\ (z) = \frac{A(\frac{z}{\gamma_{1}})}{1 - \beta_{\text{pre} - \text{emph}}z^{- 1}}$
(63)

where

$H_{\text{de} - \text{emph}}\ (z) = \frac{1}{1 - \beta_{\text{pre} - \text{emph}}z^{- 1}}$
(64)

and $\beta_{\text{pre} - \text{emph}} = 0\text{.}\text{68}$ and
$\gamma_{1} = 0\text{.}\text{92}$. Since $A(z)$ is computed based on the
pre-emphasized signal$s_{\text{pre}}(n)$, the tilt of the filter
$1/A(z/\gamma_{1})$ is less pronounced compared to the case when $A(z)$
is computed based on the original signal. The de-emphasis is also
performed on the output signal in the decoder. It can be shown that the
quantization error spectrum is shaped by a filter having a transfer
function
$1/W(z)H_{\text{de} - \text{emph}}(z) = 1/A(\frac{z}{\gamma_{1}})$.
Thus, the spectrum of the quantization error is shaped by a filter whose
transfer function is $1/A(z/\gamma_{1})$, with $A(z)$ computed based on
the pre-emphasized signal. The perceptual weighting is performed on a
frame-by-frame basis while the LP filter coefficients are calculated on
a sub-frame basis using the principle of LSP interpolation, described in
subclause 5.1.9.6. For a sub-frame size $L$ = 64, the weighted speech is
given by

$s_{h}(n) = s_{\text{pre}}(n) + \sum_{i = 1}^{\text{16}}{a_{i}\ }\gamma_{1}^{i}\ s_{\text{pre}}\left( n - i \right) + 0\text{.}\text{68}\ s_{h}\left( n - 1 \right),\ n = 0,\ldots,\ \text{255}$
(65)

where 0.68 is the pre-emphasis factor. Furthermore, for the open-loop
pitch analysis, the computation is extended for a period of 8.75ms using
the look-ahead from the future frame. This is done using the filter
coefficients of the 4th subframe in the present frame. Note that this
extended weighted signal is used only in the OL pitch analysis of the
present frame.

If ACELP core is selected for WB, SWB or FB signals at bitrates higher
than 13.2 kbps, its internal sampling rate is set to 16 kHz rather than
12.8 kHz. Nevertheless, the OL pitch analysis is done only at 12.8 kHz
and the estimated OL pitch values are later resampled to 16 kHz.
However, perceptually weighted input signal sampled at a16 kHz is still
needed in the search of the adaptive codebook. The perceptual weighting
filter at 16 kHz has the following form

$W(z) = \frac{A(\frac{z}{\gamma_{2}})}{1 - \beta_{\text{pre} - \text{emph}\text{16}}z^{- 1}}$
(66)

where $\beta_{\text{pre} - \text{emph}\text{16}} = 0\text{.}\text{72}$
and $\gamma_{2} = 0\text{.}\text{94}$. Thus, for this case, the
pre-emphasis is done as follows

$s_{h\text{16}}(n) = s_{\text{pre}\text{16}}(n) + \sum_{i = 1}^{\text{16}}{a_{i}\ }\gamma_{2}^{i}\ s_{\text{pre}\text{16}}\left( n - i \right) + \beta_{\text{pre} - \text{emph}\text{16}}s_{h\text{16}}\left( n - 1 \right),\ n = 0,\ldots,\ \text{319}$
(67)

The perceptual weighting at 25.6 kHz and 32 kHz is described later in
this document.

#### 5.1.10.2 Correlation function computation

The correlation function for each of the three segments (or half-frames)
is obtained using correlation values computed over a first pitch delay
range from 10 to 115 (which has been decimated by 2) and over a second
pitch delay range from 12 to 115 (which has been decimated by 2). Both
of the two delay ranges are divided into four sections: \[10, 16\],
\[17, 31\], \[32, 61\] and \[62, 115\] for the first delay range and
\[12, 21\], \[22, 40\], \[41, 77\] and \[77, 115\] for the second delay
range, so that the two sets of four sections overlap. The first sections
in the two sets, \[10, 16\] and \[12, 21\] are, however, used only under
special circumstances to avoid quality degradation for pitch lags below
the lowest pitch quantization limit. Due to this special use of the
first sections in the sets, omitting the pitch lags 10 and 11 in the
second set of sections presents no quality issues. In addition, the
second set omits pitch lags between 17 and 20, when the first sections
are not used. The first section is mainly used in speech segments with
stable, short pitch lags and the above limits have therefore a
negligible effect on the overall pitch search and quantization
performance.

The autocorrelation function is first computed on a decimated weighted
signal $s_{\text{hd}}\left( n \right)$for each pitch lag value in both
sets by

$C(d) = \sum_{n = 0}^{L_{\text{sec}}}{s_{\text{hd}}\left( n \right)}\ s_{\text{hd}}\left( n - d \right)$
(68)

where the summation limit $L_{\text{sec}}$ depends on the delay section,
i.e.:

$\begin{matrix}
L_{\text{sec}} = \text{40}\ \text{for}\ d = \text{10},\ldots,\text{16}\ \text{in}\ \text{set}\ 1, \\
L_{\text{sec}} = \text{40}\ \text{for}\ d = \text{17},\ldots,\text{31}\ \text{in}\ \text{set}\ 1, \\
L_{\text{sec}} = \text{62}\ \text{for}\ d = \text{32},\ldots,\text{61}\ \text{in}\ \text{set}\ 1, \\
L_{\text{sec}} = \text{115}\ \text{for}\ d = \text{62},\ldots,\text{115}\ \text{in}\ \text{set}\ 1, \\
L_{\text{sec}} = \text{40}\ \text{for}\ d = \text{12},\ldots,\text{21}\ \text{in}\ \text{set}\ 2, \\
L_{\text{sec}} = \text{50}\ \text{for}\ d = \text{22},\ldots,\text{40}\ \text{in}\ \text{set}\ 2, \\
L_{\text{sec}} = \text{80}\ \text{for}\ d = \text{41},\ldots,\text{77}\ \text{in}\ \text{set}\ 2, \\
L_{\text{sec}} = \text{115}\ \text{for}\ d = \text{78},\ldots,\text{115}\ \text{in}\ \text{set}\ 2 \\
\end{matrix}$ (69)

This will ensure that, for a given delay value, at least one pitch cycle
is included in the correlation computation. The autocorrelation window
is aligned with the first sample of each of the two 10-ms segments of
the current frame, where the autocorrelation can thus be calculated
directly according to equation (68). To maximize the usage of the
look-ahead segment, the autocorrelation window in the third segment is
aligned with the last available sample. In this final segment the
autocorrelation function of equation (68) is computed backwards, i.e.,
the values of $n$are negative. Therefore, the computation as such is the
same for all three segments, only the window alignment differs and the
indexing of the signal is reversed in the last segment.

#### 5.1.10.3 Correlation reinforcement with past pitch values

The autocorrelation function is then weighted for both pitch delay
ranges to emphasize the function for delays in the neighbourhood of
pitch lag parameters determined in the previous frame (extrapolated
pitch lags).

The weighting function is given by a triangular window of size 27 and it
is centred on the extrapolated pitch lags. The weighting function is
given by

$w_{\text{pn}}(\text{13} + i) = w_{\text{pn}}(\text{13} - i) = 1 + \alpha_{\text{pn}}\ (1 - i/\text{14}),\ i = \text{0,}\ldots\text{,13}\text{.}$
(70)

where $\alpha_{\text{pn}}$is a scaling factor based on the voicing
measure from the previous frame (the normalized pitch correlation) and
the pitch stability in the previous frame. During voiced segments with
smooth pitch evolution, the scaling factor is updated in each frame by
adding a value of $0\text{.}\text{16}\ {\overline{R}}_{\text{xy}}$ and
it is upper-limited to 0.7. $\ {\overline{R}}_{\text{xy}}$is the average
of the normalized correlation in the two half frames of the previous
frame and is given in equation (71). The scaling factor
$\alpha_{\text{pn}}$ is reset to zero (no weighting) if
$\ {\overline{R}}_{\text{xy}}$is less than 0.4 or if the pitch lag
evolution in the previous frame is unstable or if the relative frame
energy of the previous frame is more than a certain threshold. The pitch
instability is determined by testing the pitch coherence between
consecutive half-frames. The pitch values of two consecutive half-frames
are considered coherent if the following condition is satisfied:

$\left( \text{max\_value} < 1\text{.}4\ \text{min\_value} \right)\text{\ AND\ }\left( \left( \text{max\_value} - \text{min\_value} \right) < \text{14} \right)$

where $\text{max\_value}$ and $\text{min\_value}$ denote the maximum and
minimum of the two pitch values, respectively. The pitch evolution in
the current frame is considered stable if pitch coherence is satisfied
for both, the first half-frame of the current frame and the second
half-frame of the previous frame as well as the first half-frame and the
second half-frame of the current frame.

The extrapolated pitch lag in the first half-frame,
${\overset{\sim}{d}}^{\left\lbrack 0 \right\rbrack}$ , is computed as
the pitch lag from the second half-frame of the previous frame plus a
pitch evolution factor $f_{\text{evol}}$ , computed from the previous
frame (described in subclause 5.1.10.7). The extrapolated pitch lag in
the second half-frame,
${\overset{\sim}{d}}^{\left\lbrack 1 \right\rbrack}$, is computed as the
pitch lag from the second half-frame of the previous frame plus twice
the pitch evolution factor. The extrapolated pitch lag in the look
ahead, ${\overset{\sim}{d}}^{\left\lbrack 2 \right\rbrack}$, is set
equal to ${\overset{\sim}{d}}^{\left\lbrack 1 \right\rbrack}$. That is

$\begin{matrix}
{\overset{\sim}{d}}^{\left\lbrack 0 \right\rbrack} = d^{\left\lbrack - 1 \right\rbrack} + f_{\text{evol}}, \\
{\overset{\sim}{d}}^{\left\lbrack 1 \right\rbrack} = d^{\left\lbrack - 1 \right\rbrack} + 2f_{\text{evol}}, \\
{\overset{\sim}{d}}^{\left\lbrack 2 \right\rbrack} = {\overset{\sim}{d}}^{\left\lbrack 1 \right\rbrack}, \\
\end{matrix}$ (72)

where $d^{\left\lbrack - 1 \right\rbrack}$ is the pitch lag in the
second half-frame of the previous frame. The pitch evolution factor is
obtained by averaging the pitch differences of consecutive half-frames
that are determined as coherent (according to the coherence rule
described above).

The autocorrelation function weighted around an extrapolated pitch lag
$\overset{\sim}{d}$ is given by

$C_{w}(\overset{\sim}{d} + i) = C(\overset{\sim}{d} + i)w_{\text{pn}}\ (13 + i),\ i = - \text{13},\ldots\text{,13}\text{.}$
(73)

#### 5.1.10.4 Normalized correlation computation

After weighting the correlation function with the triangular window of
equation (70) centred at the extrapolated pitch lag, the maxima of the
weighted correlation function in each of the four sections (three
sections, if the first section is not used) are determined. This is
performed for both pitch delay ranges. Note that the first section is
used only during high-pitched segments. For signals other than
narrowband signals, this means that the open-loop pitch period of the
second half-frame of the previous frame is lower than or equal to 34.
For narrowband signals, the open-loop pitch period of the second
half-frame of the previous frame needs to be lower than or equal to 24
and the scaling factor $\alpha_{\text{pn}}$ has to be higher than or
equal to 0.1. It is further noted that the scaling factor
$\alpha_{\text{pn}}$ is set to 0, if the previous frame were an unvoiced
or a transition frame and the signal has a bandwidth higher than
narrowband. In the following, the special case of three sections will
not be explicitly dealt with if it arises directly from the text. The
pitch delays that yield the maximum of the weighted correlation function
will be denoted as $d_{\text{max}}\left( k \right)$, where *k* = 0,1,2,3
denotes each of the four sections. Then, the original (raw) correlation
function at these pitch delays (pitch lags) is normalized as

$C_{\text{norm}}(d_{\text{max}}\left( k \right)) = \frac{C\left( d_{\text{max}}\left( k \right) \right)}{\sqrt{\sum_{n = 0}^{L_{\text{sec}}}{s_{h}^{2}\left( n \right)\sum_{n = 0}^{L_{\text{sec}}}{s_{h}^{2}\left( n - d_{\text{max}}\left( k \right) \right)}}}},\ k = 0,1,2,3$
(74)

The same normalization is applied also to the weighted correlation
function, $C_{w}\left( d \right)$, which yields
$C_{\text{wn}}\left( d \right)$. It is noted that
$s_{h}\left( n \right)$ is aligned at the first sample of the
corresponding half-frame for the two half-frames of the current frame
and at the last sample of the look-ahead for the look-ahead segment,
where the calculation is performed backwards in order to exploit the
full look-ahead as well as possible.

At this point, four candidate pitch lags,
$d_{\text{max}}\left( k \right)$, k = 0,1,2,3, have been determined for
each of the three segments (two in the current frame and one in the
look-ahead) in each of the two pitch delay ranges. In correspondence
with these candidate pitch lags, normalized correlations (both weighted
and raw) have been calculated. All remaining processing is performed
using only these selected values, greatly reducing the overall
complexity.

#### 5.1.10.5 Correlation reinforcement with pitch lag multiples

In order to avoid selecting pitch multiples within each pitch delay
range, the weighted normalized correlation in a lower pitch delay
section is further emphasized if one of its multiples is in the
neighbourhood of the pitch lag in a higher section. That is,

$\begin{matrix}
\text{if}\ \left( \left| k \times d_{\text{max}}\left( 2 \right) - d_{\text{max}}\left( 3 \right) \right| \leq k \right) \\
\ \text{if}\left( \alpha_{\text{prev}} < 0\text{.}6\  \vee \ d_{\text{max}}\left( 2 \right) > 0\text{.}4d_{\text{prev}} \right) \\
\ C_{\text{wn}}\left( d_{\text{max}}\left( 2 \right) \right) = \alpha_{\text{mult}}C_{\text{wn}}\left( d_{\text{max}}\left( 2 \right) \right) \\
\ \alpha_{\text{mult}} = \left( \alpha_{\text{mult}} \right)^{2} \\
\text{if}\ \left( \left| k \times d_{\text{max}}\left( 1 \right) - d_{\text{max}}\left( 2 \right) \right| \leq k \right) \\
\ \text{if}\left( \alpha_{\text{prev}} < 0\text{.}6\  \vee \ d_{\text{max}}\left( 1 \right) > 0\text{.}4d_{\text{prev}} \right) \\
\ C_{\text{wn}}\left( d_{\text{max}}\left( 1 \right) \right) = \alpha_{\text{mult}}C_{\text{wn}}\left( d_{\text{max}}\left( 1 \right) \right) \\
\ \alpha_{\text{mult}} = \left( \alpha_{\text{mult}} \right)^{2} \\
\end{matrix}$

where $\alpha_{\text{mult}} = 1\text{.}\text{17}$,
$\alpha_{\text{prev}}$is a voicing factor (normalized pitch correlation)
from the previous frame, and $d_{\text{prev}}$ is the pitch value from
the second half-frame of the previous frame. In addition, when the first
section is searched and the pitch multiple of the shortest-section
candidate lag is larger than 20 samples, the following reinforcement is
performed:

$\begin{matrix}
\text{if}\ \left( \left| k \times d_{\text{max}}\left( 0 \right) - d_{\text{max}}\left( 1 \right) \right| \leq k \right) \\
\ \text{if}\left( \alpha_{\text{prev}} < 0\text{.}6\  \vee \ d_{\text{max}}\left( 0 \right) > 0\text{.}4d_{\text{prev}} \right) \\
\ C_{\text{wn}}\left( d_{\text{max}}\left( 0 \right) \right) = \alpha_{\text{mult}}C_{\text{wn}}\left( d_{\text{max}}\left( 0 \right) \right) \\
\end{matrix}$

Further, $\alpha_{\text{prev}}$, is given by the voicing factor of the
second half-frame in the previous frame if the normalized correlation in
the second half-frame was stronger than in the first half-frame, or
otherwise by the mean value of these two normalized correlations. In
this way, if a pitch period multiple is found in a higher section, the
maximum weighted correlation in the lower section is emphasized by a
factor of 1.17. However, if the pitch lag in section 3 is a multiple of
the pitch lag in section 2 and at the same time the pitch lag in section
2 is a multiple of the pitch lag in section 1, the maximum weighted
correlation in section 1 is emphasized twice. This correlation
reinforcement is, however, not applied at each section when the previous
frame voicing factor, $\alpha_{\text{prev}}$, is less than 0.6 and the
pitch value is less than 0.4 times the previous pitch value (i.e., the
pitch value does not appear to be a halved value of the previous frame
pitch or larger). In this way, the emphasis of the correlation value is
allowed only during clear voicing conditions or when the value can be
considered to belong to the past pitch contour.

The correlation reinforcement with pitch lag multiples is independent in
each of the two pitch delay ranges.

It can be seen that the \"neighbourhood\" is larger when the
multiplication factor *k* is higher. This is to take into account an
increasing uncertainty of the pitch period (the pitch length is
estimated roughly with integer precision at a 6400 Hz sampling
frequency). For the look-ahead part, the first line of the condition
above relating to the highest pitch lags is modified as follows:

$\text{if}\ \left( \left| k \times d_{\text{max}}\left( 1 \right) - d_{\text{max}}\left( 2 \right) \right| \leq 2\left( k - 1 \right) \right)$

Note that first section is not considered in the correlation
reinforcement procedure described here, i.e., the maximum normalized
correlation in the first section is never emphasized.

#### 5.1.10.6 Initial pitch lag determination and reinforcement based on pitch coherence with other half-frames

An initial set of pitch lags is determined by searching for the maximum
weighted normalized correlation in the four sections in each of the
three segments or half-frames. This is done independently for both pitch
delay ranges. The initial set of pitch lags is given by

$d_{\text{init}}^{\left\lbrack k \right\rbrack} = \underset{i = 0}{\overset{3}{\text{argmax}}}\left( C_{\text{wn}}\left( d_{\text{max}}^{\left\lbrack k \right\rbrack}\left( i \right) \right) \right),\ \text{for}\ k = 0,1,2,$
(75)

where the superscript $\left\lbrack k \right\rbrack$denotes the first,
the second or the third (look‑ahead) half-frame.

To find the right pitch value, another level of weighting is performed
on the weighted normalized correlation function,
$C_{\text{wn}}\left( d \right)$, in each section of each half-frame in
each pitch delay range. This weighting is based on pitch coherence of
the initial set of pitch
lags,$d_{\text{init}}^{\left\lbrack i \right\rbrack}$, with pitch
lags$d_{\text{init}}^{\left\lbrack j \right\rbrack}\left( k \right)$,
$k = 0,1,2,3$, *j* ≠ *i*, i.e., those from the other half-frames. The
weighting is further reinforced with pitch lags selected from the
complementary pitch delay range, denoted as
$z_{\text{init}}^{\left\lbrack j \right\rbrack}\left( k \right)$,
$k = 0,1,2,3$, *j* ≠ *i*. Further, the weighting favours section‑wise
stability, where a stronger weighting is applied for coherent pitch
values that are from the same section of the same set as the initial
pitch lag, and a slightly weaker weighting is applied for coherent pitch
values that are from a different section and/or a different pitch delay
range than the initial pitch lag. That is, if the initial pitch lag in a
half‑frame$i$is coherent with a pitch lag of section *k* in half-frame
$j$, then the corresponding weighted normalized correlation of section
$k$in half-frame$j$is further emphasized by weighting it by the value
$1 + \alpha_{1}\left( 1 - \delta_{\text{pit}}/\text{14} \right)$, if the
initial pitch lag is also from section $k$ in the same pitch delay
range, or by
$1 + \alpha_{2}\left( 1 - \delta_{\text{pit}}/\text{14} \right)$, if the
initial pitch lag is not from section *k* in the same pitch delay range.
The variable$\delta_{\text{pit}}$ is the absolute difference between the
two analysed pitch lags and the two weighting factors are defined as

$\begin{matrix}
\alpha_{1} = 0\text{.}4\left( C_{\text{norm}}\left( d_{\text{init}}^{\left\lbrack i \right\rbrack} \right) + 0\text{.}5r_{e} \right), \\
\alpha_{2} = 0\text{.}\text{25}\left( C_{\text{norm}}\left( d_{\text{init}}^{\left\lbrack i \right\rbrack} \right) + 0\text{.}5r_{e} \right), \\
\end{matrix}$

where $\alpha_{1}$is upper-bounded by 0.4, $\alpha_{2}$is upper-bounded
by 0.25 and $C_{n}\left( d \right)$ is the raw normalized correlation
(similar to the weighted normalized correlation, defined in equation
(76)). Finally, $r_{e}$ is a noise correction factor added to the
normalized correlation in order to compensate for its decrease in the
presence of the background noise. It is defined as

$r_{e} = 0\text{.}\text{0002}\text{.}\text{4492}e^{0\text{.}\text{1596}N_{t}} - 0\text{.}\text{022}\ \text{constrained\ by\ 0} < r_{e}0\text{.}5$
(77)

where $N_{t}$ is the total background noise energy, calculated as
described in subclause 5.1.11.1.

The procedure described in this subclause helps further to avoid
selecting pitch multiples and insure pitch continuity in adjacent
half-frames.

#### 5.1.10.7 Pitch lag determination and parameter update

Finally, the pitch lags in each half-frame, $d^{\lbrack 0\rbrack}$,
$d^{\lbrack 1\rbrack}$and $d^{\lbrack 2\rbrack}$, are determined. They
are selected by searching the maximum of the weighted normalized
correlations, corresponding to each of the four sections across both
pitch delay ranges. In case of VBR operation, the normalized
correlations are searched in addition to the weighted normalized
correlations for a secondary evaluation. When the normalized correlation
of the candidate lag is very high (lower-bounded by 0.9) and it is
considered a halved value (lower-bounded by a multiplication by 0.4 and
upper-bounded by a multiplication by 0.6) of the corresponding candidate
identified by searching the weighted normalized correlation, the
secondary pitch lag candidate is selected instead of the firstly
selected one.

In total, six or eight values are thus considered in each segment or
half-frame depending on whether section 0 is searched. After determining
the pitch lags, the parameters needed for the next frame pitch search
are updated. The average normalized correlation
${\overline{R}}_{\text{xy}}$is updated by:

${\overline{R}}_{\text{xy}} = 0\text{.}5\left( C_{\text{norm}}\left( d^{\lbrack 0\rbrack} \right) + C_{\text{norm}}\left( d^{\lbrack 1\rbrack} \right) \right) + 0\text{.}5r_{e,\ }\text{constrained}\ \text{by}\ {\overline{R}}_{\text{xy}} \leq 1$
(78)

Finally, the pitch evolution factor $f_{\text{evol}}$ to be used in
computing the extrapolated pitch lags in the next frame is updated. The
pitch evolution factor is given by averaging the pitch differences of
the consecutive half-frames that are determined as coherent. If
$d^{\left\lbrack - 1 \right\rbrack}$ is the pitch lag in the second half
of the previous frame, then pitch evolution is given by

$\begin{matrix}
\delta_{\text{pitch}} = 0 \\
\text{cnt} = 0 \\
\text{for}\ i = 0\ \text{.}\text{.}\text{.}\ 2 \\
\ \text{if}\ d^{\lbrack i\rbrack}\ \text{AND}\ d^{\lbrack i - 1\rbrack}\ \text{are}\ \text{coherent} \\
\ \delta_{\text{pitch}} = \delta_{\text{pitch}} + d^{\lbrack i\rbrack}\  - \ d^{\lbrack i - 1\rbrack} \\
\ \text{cnt} = \text{cnt} + 1 \\
\ \text{if}\ \text{cnt} > 0 \\
\ f_{\text{evol}} = d_{\text{pitch}}/\text{cnt} \\
\ \text{else} \\
\ f_{\text{evol}} = 0 \\
\end{matrix}$ (79)

Since the search is performed on the decimated weighted signal, the
determined pitch lags, $d^{\lbrack 0\rbrack}$, $d^{\lbrack 1\rbrack}$and
$d^{\lbrack 2\rbrack}$are multiplied by 2 to obtain the open-loop pitch
lags for the three half-frames. That is

$\begin{matrix}
T_{\text{OL}}^{\left\lbrack 0 \right\rbrack} = 2d^{\left\lbrack 0 \right\rbrack}, \\
T_{\text{OL}}^{\left\lbrack 1 \right\rbrack} = 2d^{\left\lbrack 1 \right\rbrack}, \\
T_{\text{OL}}^{\left\lbrack 2 \right\rbrack} = 2d^{\left\lbrack 2 \right\rbrack}\text{.} \\
\end{matrix}$ (80)

In the following text, the following notation is used for the normalized
correlations corresponding to the final pitch lags:

$C_{\text{norm}}^{\left\lbrack i \right\rbrack} = C_{\text{norm}}^{\left\lbrack i \right\rbrack}\left( d^{\left\lbrack i \right\rbrack} \right)$
(81)

#### 5.1.10.8 Correction of very short and stable open-loop pitch estimates

Usually, music harmonic signals or singing voice signals have short
pitch lags and they are more stationary than normal speech signals. It
is extremely important to have the correct and precise short pitch lags
as incorrect pitch lags may have a serious impact upon the quality.

The very short pitch range is defined from
$\text{PIT}_{\text{MIN}_{\text{DOUBLEEXTEND}}} = \text{17}$ to
$\text{PIT}_{\text{MIN}} = \text{34}$ at the sampling frequency
$\text{Fs} = \text{12}\text{.}8$ kHz. As the pitch candidate is so
short, pitch detection of using time domain only or frequency domain
only solution may not be reliable. In order to reliably detect short
pitch value, three conditions may need to be checked: (1) in frequency
domain, the energy from 0 Hz to
$F_{\text{MIN}} = \frac{\text{Fs}}{\text{PIT}_{\text{MIN}}}$ Hz must be
relatively low enough; (2) in time domain, the maximum short pitch
correlation in the pitch range from
$\text{PIT}_{\text{MIN}_{\text{DOUBLEEXTEND}}}$ to
$\text{PIT}_{\text{MIN}}$ must be relatively high enough compared to the
maximum pitch correlation in the pitch range from
$\text{PIT}_{\text{MIN}}$ to $\text{PIT}_{\text{MAX}}$; (3) the absolute
value of the maximum normalized short pitch correlation must be high
enough. These three conditions are more important; other conditions may
be added such as Voice Activity Detection and Voiced Classification.

Suppose $\text{Voicing\ }_{m}$ notes the average normalized pitch
correlation value of the four subframes in the current frame:

$\text{Voicing\ }_{m}\text{\ =\ }\lbrack\text{\ C}_{\text{norm}}^{\lbrack 0\rbrack}\text{\ +\ C}_{\text{norm}}^{\lbrack 1\rbrack} + C_{\text{norm}}^{\lbrack 2\rbrack} + C_{\text{norm}}^{\lbrack 3\rbrack}\text{\ \ }\rbrack\text{\ /\ 4\ }$
(82)

$C_{\text{norm}}^{\lbrack 0\rbrack},\ C_{\text{norm}}^{\lbrack 1\rbrack},\ C_{\text{norm}}^{\lbrack 2\rbrack},\ C_{\text{norm}}^{\lbrack 3\rbrack}\text{\ \ }$are
the four normalized pitch correlations calculated for each subframe; for
each subframe, the best pitch candidate is found in the pitch range from
$P = \text{PIT}_{\text{MIN}}$ to $P = \text{PIT}_{\text{MAX}}$. The
smoothed pitch correlation from previous frame to current frame is

$\text{Voicing}_{\text{sm}} = (3\  \cdot \ \text{Voicing}_{\text{sm}} + \text{Voicing})\text{/4}$
(83)

Before the real short pitch is decided, two pre-decision conditions are
checked first : (a) check if the harmonic peak is sharp enough, which is
indicated by the flag
$\text{pre}_{\text{decision}_{\text{flag}}} = \text{harmonic}_{\text{sharp}_{\text{flag}}}$.
It is used to decide if the initial open-loop pitch is correct or not;
(b) check if the maximum energy in the frequency region \[*0, F~MIN~*\]
is low enough, which is indicated by the flag
$\text{pre}_{\text{decision}_{\text{flag}}} = \text{LF}_{\text{lack}_{\text{flag}}}$.

\(a\) Determine base pitch frequency $d_{\text{freq}}$ according to the
initial open-loop pitch $d^{\lbrack 1\rbrack}$

$d_{\text{freq}} = \text{Round}(\frac{L_{\text{FFT}}}{d^{\lbrack 1\rbrack}})$
(84)

> Then, based on the amplitude spectrum of input signal in frequency
> domain, determine the decision parameters which are used to confirm
> whether the pitch related to the base pitch frequency is accurate. The
> decision parameters include energy spectrum difference, average energy
> spectrum and the ratio of energy spectrum difference and average
> energy spectrum.
>
> Compute the energy spectrum difference and the average energy spectrum
> of the frequency bins around base pitch frequency $d_{\text{freq}}$

$E_{\text{diff}} = \sum_{k = 1}^{2d_{\text{freq}} - 1}\left( E_{\text{BIN}}\left( d_{\text{freq}} \right) - E_{\text{BIN}}\left( k \right) \right)$
(85)

$E_{\text{avrg}} = \sum_{k = 1}^{2d_{\text{freq}} - 1}{E_{\text{BIN}}\left( k \right)\left( 2d_{\text{freq}} - 1 \right)}$
(86)

> Compute the weighted and smoothed energy spectrum difference and
> average energy spectrum

$E_{\text{diff}_{\text{sm}}} = 0\text{.}2\ E_{\text{diff}} + 0\text{.}8\ E_{\text{diff}_{\text{sm}},\text{prev}}$
(87)

$E_{\text{avrg}_{\text{sm}}} = 0\text{.}2\ E_{\text{avrg}} + 0\text{.}8\ E_{\text{avrg}_{\text{sm}},\text{prev}}$
(88)

> where $E_{\text{diff}_{\text{sm}}}$ and $E_{\text{avrg}_{\text{sm}}}$
> are weighted and smoothed energy spectrum difference and average
> energy spectrum of the frequency bins around the base pitch frequency.
>
> Compute the ratio of energy spectrum difference and average energy
> spectrum

$R_{\text{diff}} = E_{\text{diff}}E_{\text{avrg}}$ (89)

> Based on the decision parameters calculated above, confirm whether the
> initial open-loop pitch is accurate.
>
> The harmonic sharpness flag is determined as follows:

$\begin{matrix}
\text{if}\ \left( E_{\text{diff}_{\text{sm}}} < - \text{10}\ \text{AND}\ E_{\text{avrg}_{\text{sm}}} < \text{38}\text{.}5\ \text{AND}\ R_{\text{diff}} < - 0\text{.}8 \right) \\
\ \text{pre}_{\text{decision}_{\text{flag}}} = \text{harmonic}_{\text{sharp}_{\text{flag}}} = 1 \\
\text{if}\ \left( E_{\text{diff}_{\text{sm}}} > \text{10}\ \text{AND}\ E_{\text{avrg}_{\text{sm}}} > \text{83}\ \text{AND}\ R_{\text{diff}} > 0\text{.}5 \right) \\
\ \text{pre}_{\text{decision}_{\text{flag}}} = \text{harmonic}_{\text{sharp}_{\text{flag}}} = 0 \\
\end{matrix}$ (90)

> If the above conditions are not satisfied,
> $\text{pre}_{\text{decision}_{\text{flag}}}$ remains unchanged.

\(b\) Assume that the maximum energy in the frequency region
$\lbrack 0,F_{\text{MIN}}\rbrack$ (Hz) is $\text{Energy}0$ (dB) , the
maximum energy in the frequency region
$\lbrack F_{\text{MIN}},\text{900}\rbrack$ (Hz) is $\text{Energy}1$
(dB), the relative energy ratio between $\text{Energy}0$and
$\text{Energy}1$is given by

$\text{Ratio} = \text{Energy}1 - \text{Energy}0$ (91)

> This energy ratio is weighted by multiplying an average normalized
> pitch correlation value $\text{Voicing\ }_{m}$,

$\text{Ratio} = \text{Ratio} \cdot \text{Voicing}_{m}$ (92)

> Before using the $\text{Ratio}$ parameter to detect the lack of low
> frequency energy, it is smoothed in order to reduce the uncertainty,

$\text{EnergyRatio}_{\text{LF}_{\text{sm}}} = (\text{15} \cdot \text{EnergyRatio}_{\text{LF}_{\text{sm}}} + \text{Ratio}\frac{)}{\text{16}}$
(93)

> where the $\text{EnergyRatio}_{\text{LF}_{\text{sm}}}$ is the low
> frequency smoothed energy ratio. If
> $\text{LF}_{\text{lack}_{\text{flag}}} = 1$ then a lack of low
> frequency energy has been detected (otherwise not detected ).
> $\text{LF}_{\text{lack}_{\text{flag}}}$ is determined by the following
> procedure,

$\begin{matrix}
\text{if\ \ }(\text{EnergyRatio}_{\text{LF}_{\text{sm}}}\text{>35\ \ or\ \ Ratio>50\ }) \\
\ \text{pre}_{\text{decision}_{\text{flag}}} = \text{LF\_lack\_flag=1\ ;} \\
\text{if\ }(\text{EnergyRatio}_{\text{LF}_{\text{sm}}}\text{\ <16}) \\
\ \text{pre}_{\text{decision}_{\text{flag}}} = \text{LF\_lack\_flag=0\ ;} \\
\end{matrix}$ (94)

> If the above conditions are not satisfied,
> $\text{pre}_{\text{decision}_{\text{flag}}}$ remains unchanged.

An initial very short pitch candidate $T_{p}$ is found by searching a
maximum normalized pitch correlation from
$P = \text{PIT}_{\text{MIN}_{\text{DOUBLEEXTEND}}}$ to
$\text{PIT}_{\text{MIN}}$,

$R(T_{p}) = \text{max}\left\{ R(P),\ P = \text{PIT}_{\text{MIN}_{\text{DOUBLEEXTEND}}},\text{.}\text{.}\text{.},\text{PIT}_{\text{MIN}} \right\}$
(95)

If $\text{Voicing}0$ notes the current short pitch correlation,

$\text{Voicing0\ =\ R}(T_{p})$ (96)

The smoothed short pitch correlation from previous frame to current
frame is

$\text{Voicing}0_{\text{sm}} = (3\  \cdot \ \text{Voicing}0_{\text{sm}} + \text{Voicing}0\frac{)}{4}$
(97)

By using all the available parameters, the final very short pitch lag is
decided with the following procedure,

$\begin{matrix}
\text{if\ \ }((\text{pre}_{\text{decision}_{\text{flag}}} = 1)\ \text{AND}\ (\text{VAD} = 1)\ \text{AND}\ (\text{Voicing}0_{\text{sm}} > 0\text{.}\text{65})\ \text{AND}\ (\text{Voicing}0_{\text{sm}} > 0\text{.}7 \cdot \text{Voicing}_{\text{sm}})) \\
\ \text{Open}_{\text{Loop}_{\text{Pitch}}} = T_{\text{OL}}^{\lbrack 0\rbrack} = T_{\text{OL}}^{\lbrack 1\rbrack} = T_{p} \\
\ f_{\text{spitch}} = \text{Stab}_{\text{short}_{\text{pitch}_{\text{flag}}}} = \text{flag}_{\text{spitch}} = 1 \\
\ \text{Coder}_{\text{type}} = \text{VOICED} \\
\end{matrix}$ (98)

wherein
$f_{\text{spitch}} = \text{Stab}_{\text{short}_{\text{pitch}_{\text{flag}}}} = \text{flag}_{\text{spitch}} = 1$
is a flag which forces the codec to select the time domain CELP coding
algorithm for short pitch signal even if the frequency domain coding
algorithm and AUDIO class is previously selected;
$\text{Coder}_{\text{type}} = \text{VOICED}$ is a flag which forces the
coder to select VOICED class for short pitch signal.

#### 5.1.10.9 Fractional open-loop pitch estimate for each subframe

The OL pitch is further refined by maximizing the normalized correlation
function with a fractional resolution around the pitch lag values
$d^{\lbrack 0\rbrack}$and $d^{\lbrack 1\rbrack}$(in the 12.8-kHz
sampling domain). The fractional open-loop pitch lag is computed four
times per frame, i.e., for each subframe of 64 samples. This is similar
as the closed-loop pitch search, described in later in this
specification. The maximum normalized correlation corresponding to the
best fractional open-loop pitch lag is then used in the classification
of VC frames (see subclause 5.1.13.2). The fractional open-loop pitch
search is performed by first maximizing an autocorrelation function $C$
of the perceptually weighted speech $s_{h}$for integer lags in the
interval
\[$d^{\left\lbrack i \right\rbrack} - 7\ldots d^{\left\lbrack i \right\rbrack} + 6$\],
where $d^{\lbrack i\rbrack} = d^{\lbrack 0\rbrack}$ for the search in
the first and the second subframes, and
$d^{\lbrack i\rbrack} = d^{\lbrack 1\rbrack}$for the third and fourth
subframes. The autocorrelation function is similar to equation (99)
except that perceptually weighted speech at 12.8 kHz sampling rate is
used, i.e,

$C_{\text{raw}}\left( d \right) = \sum_{n = 0}^{\text{63}}s_{h}\left( n \right)s_{h}\left( n - d \right)$
(100)

In the above equation, $s_{h}(0)$corresponds to the first sample in each
subframe.

Let $d_{\text{int}}$ be the integer lag maximizing $C_{\text{raw}}(d)$.
The fractional open-loop pitch search is then performed by interpolating
the correlation function $C_{\text{raw}}$ and searching for its maximum
in the interval
$\left\lbrack d_{\text{int}} - 3/4\ldots d_{\text{int}} + 3/4 \right\rbrack$.
The interpolation is performed with a 1/4 sample resolution using an FIR
filter -- a Hamming windowed sinc function truncated at ±17. The filter
has its cut-off frequency (--3 dB) at 5062 Hz and --6 dB at 5760 Hz in
the 12.8 kHz domain. This means the interpolation filter exhibits a
low-pass frequency response. Note that the negative fractions are not
searched if $d_{\text{int}}$ coincides with the lower end of the
searched interval, i.e.,
if$d_{\text{int}} = d^{\left\lbrack i \right\rbrack} - 7$.

Once the best fractional pitch lag,$d_{\text{fr}}$, is found, the
maximum normalized correlation is computed similarly to equation (101),
i.e.,

$C_{\text{fr}}(d_{\text{fr}}) = \frac{C_{\text{raw}}\left( d_{\text{fr}} \right)}{\sqrt{\sum_{n = 0}^{\text{63}}{s_{h}^{2}\left( n \right)\sum_{n = 0}^{\text{63}}{s_{h}^{2}\left( n - d_{\text{fr}} \right)}}}}$
(102)

The same normalization is applied also to the weighted correlation
function,$C_{w}\left( d \right)$, which yields
$C_{\text{wn}}\left( d \right)$.

At this point, four candidate pitch lags, $d_{\text{max}}(k)$, *k* =
0,1,2,3, have been determined for each of the three half-frames (two in
the current frame and one in the look ahead) in each of the two pitch
delay ranges. In correspondence with these candidate pitch lags,
normalized correlations (both weighted and raw) have been calculated.
All remaining processing is performed using only these selected values,
greatly reducing the overall complexity.

Note that the last section (long pitch periods) in both pitch delay
ranges is not searched for the look ahead part. Instead, the normalized
correlation values and the corresponding pitch lags are obtained from
the last section search of the second half-frame. The reason is that the
summation limit in the last section is much larger than the available
look ahead and also the computational complexity is reduced.

The fractional OL pitch estimation as described above is performed only
for bitrates lower or equal to 24.4 kbps. For higher bitrates, the VC
mode is not supported and consequently, there is no reason to estimate
pitch with fractional resolution. Therefore, at higher bitrates,
$d_{\text{fr}} = d^{\lbrack i\rbrack}$ where for the first and for the
second subframe *i*=0 and for the third and the fourth subframe *i*=1.

### 5.1.11 Background noise energy estimation

The background noise energy is estimated (updated) in two stages. In the
first stage, noise energy is updated only for critical bands where the
current frame signal energy is less than the previously estimated
background noise energy. This stage is called the downward noise energy
update. In the second stage, noise energy is updated if the signal
characteristics are statistically close to the model of background
noise. Therefore, in the second stage, noise energy can be updated
regardless of the current frame signal energy.

#### 5.1.11.1 First stage of noise energy update

The total noise energy per frame is computed as follows:

$N_{t} = \text{10}\text{log}\left( \sum_{i = 0}^{\text{19}}{N_{\text{CB}}^{\lbrack - 1\rbrack}(i)} \right)$
(101)

where $N_{\text{CB}}^{\lbrack - 1\rbrack}(i)$ is the estimated noise
energy in the *i*th critical band of the previous frame.

The noise energy per critical band $N_{\text{CB}}(i)$ is initialized to
0.0035 dB. The updated noise energy in the *i*th critical band, denoted
$N_{\text{tmp}}(i)$, is computed as follows:

$N_{\text{tmp}}(i) = 0\text{.}9N_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}(i) + 0\text{.}1\left\lbrack 0\text{.}\text{25}E_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}(i) + 0\text{.}\text{75}\left( E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i) \right) \right\rbrack$
(102)

where $E_{\text{CB}}^{\lbrack - 1\rbrack}(i)$ corresponds to the energy
per critical band calculated in the second spectral analysis in the
previous frame, and $N_{\text{CB}}^{\lbrack - 1\rbrack}(i)$ is the
estimated noise energy per critical band also in the previous frame.
Noise energy is then updated only in critical bands that have lower
energy than the background noise energy. That is

$N_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) = N_{\text{tmp}}(i),\ i = 0,\text{.}\text{.},\text{19}\ \text{AND}\ N_{\text{tmp}}(i) < N_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}(i)$
(103)

The superscript \[0\] in the above equation is used to stress that it
corresponds to the current frame.

Another feature used in noise estimation and SAD is an estimate of the
frame to frame energy variation. The absolute energy difference between
the current and the last frame is calculated,.

$E_{\text{tv}} = \left| E_{t}^{\lbrack - 1\rbrack} - E_{t} \right|$.
(104)

where the superscript \[-1\] has been used to denote the previous frame.
The frame energy variation is then used to update the feature

${\overline{E}}_{\text{vh}2} = \text{max}\left( 0\text{.}1,\ 0\text{.}\text{98\ \{}\overline{E} \middle| \middle| {\text{vh}2}^{\lbrack - 1\rbrack} + 0\text{.}\text{02}\text{min}(3\text{.}0,\ E_{\text{tv}}) \right)$
(105)

Other energy features that are updated before the SAD and the second
stage of the noise estimation are first initialized during the very two
frames after encoder initialization. The initialization is done as
follows

$\begin{matrix}
E_{\text{th}} = E_{t} \\
E_{\text{tl}} = E_{t} \\
{\overline{E}}_{\text{tl}} = E_{t} \\
{\overline{E}}_{t}^{\lbrack - 1\rbrack} = E_{t} \\
{\overline{E}}_{\text{vh}2}^{\left\lbrack - 1 \right\rbrack} = 0\text{.}0 \\
{\overline{E}}_{\text{dyn}}^{\left\lbrack - 1 \right\rbrack} = 0\text{.}0 \\
\end{matrix}$ (106)

After the two frames of initialization the total frame energy is
smoothed by means of LP filtering. That is:

${{\overline{E}}_{t} = 0\text{.}\text{80\ \{}\overline{E}}_{t}^{\lbrack - 1\rbrack} + 0\text{.}\text{20}E_{t}$
(107)

The features $E_{\text{tl}}$and $E_{\text{th}}$are envelope tracking
features of the frame energy $E_{t}$and are used to create the long-term
minimum energy ${\overline{E}}_{\text{tl}}$and an estimate of the energy
dynamics ${\overline{E}}_{\text{dyn}}$. That is

$E_{\text{th}} = \text{max}(E_{\text{th}}^{\lbrack - 1\rbrack} - 0\text{.}\text{04},E_{t})$,
(108)

To calculate $E_{\text{tl}}$the following processing is applied:

$\begin{matrix}
E_{\text{tl}} = E_{\text{tl}}^{\lbrack - 1\rbrack} + 0\text{.}\text{08} \\
\text{if\ }c_{\text{harm}}^{\lbrack - 1\rbrack} > \text{50}\text{\ then} \\
\text{\ \ \ \ if\ }\text{ini}_{\text{frame}} < \text{150}\ \text{AND}\ (E_{t}^{\lbrack - 1\rbrack} - {\overline{E}}_{t}) < 3\text{.}0\text{\ \ \ \ \ \ \ \ }E_{\text{tl}} = E_{\text{tl}} + \text{min}(2,0\text{.}1(E_{t}^{\lbrack - 1\rbrack} - E_{\text{tl}})) \\
\text{\ \ \ \ if\ }(E_{t}^{\lbrack - 1\rbrack} - E_{\text{tl}}) > \text{30}\ \text{AND}\ c_{\text{harm}}^{\lbrack - 1\rbrack} < \text{20}\text{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }E_{\text{tl}} = E_{\text{tl}} + 0\text{.}2(E_{t}^{\lbrack - 1\rbrack} - E_{\text{tl}}) \\
\text{\ \ \ \ else}\ \text{\ if\ }(E_{t}^{\lbrack - 1\rbrack} - E_{\text{tl}}) > \text{10}\text{\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }E_{\text{tl}} = E_{\text{tl}} + 0\text{.}\text{08} \\
E_{\text{tl}} = \text{min}(E_{\text{tl}},E_{t}) \\
\end{matrix}$ (109)

where $c_{\text{harm}}^{\lbrack - 1\rbrack}$ is the number of frames
since the last harmonic event from the previous frame. See clause
5.1.11.3.2 for details about its computation. The new value of
$E_{\text{tl}}$is then used to update its long-term value through an AR
process. That is

${\overline{E}}_{\text{tl}} = (1 - \alpha_{\text{tl}}){\overline{E}}_{\text{tl}}^{\lbrack - 1\rbrack} + \alpha_{\text{tl}}E_{\text{tl}}$
(110)

where the parameter $\alpha_{\text{tl}}$is set as follows

$\begin{matrix}
\text{if\ \ \ }\left( c_{\text{harm}}^{\lbrack - 1\rbrack} > \text{30}\ \text{\ AND}\ E_{t}^{\lbrack - 1\rbrack} - E_{\text{tl}} > \text{30} \right)\ \text{\ OR}\ \left( c_{\text{harm}}^{\lbrack - 1\rbrack} > \text{30}\ \text{\ AND}\ \text{ini}_{\text{frame}} < \text{150} \right)\ \text{\ OR}\ \left( {\overline{E}}_{\text{tl}} - E_{\text{tl}} > \text{30} \right) \\
\alpha_{\text{tl}} = 0\text{.}\text{03}\text{\ \ \ otherwise\ \ \ \ }\alpha_{\text{tl}} = 0\text{.}\text{02} \\
\end{matrix}$ (106)

The energy dynamics feature ${\overline{E}}_{\text{dyn}}$ is just an
LP-filtered version of the difference between $E_{\text{th}}$and
$E_{\text{tl}}$. That is

${\overline{E}}_{\text{dyn}} = 0\text{.}9{\overline{E}}_{\text{dyn}}^{\lbrack - 1\rbrack} + 0\text{.}1(E_{\text{th}} - E_{\text{tl}})$
(107)

#### 5.1.11.2 Second stage of noise energy update

In the second stage of the noise energy update, the critical bands not
updated in the first stage are updated only if the current frame is
inactive. However, the SAD decision obtained in clause 5.1.12, which is
based on the SNR per critical band, is not used for determining whether
the current frame is inactive and whether the noise energy is to be
updated. Another decision is performed based on other parameters not
directly dependent on the SNR per critical band. The basic parameters
used for the noise update decision are:

-- pitch stability

-- signal non-stationarity

-- normalized correlation (voicing)

-- ratio between 2nd‑order and 16th‑order LP residual error energies

These parameters have generally low sensitivity to the noise level
variations. Another set of parameters is calculated to cover harmonic
(tonal) signals and, in particular, music. These parameters prevent the
noise energy to be updated, when strong harmonicity or tonality is
detected even when its energy is low. The parameters related to the
detection of tonal signals are

-- spectral diversity

-- complementary non-stationarity

-- HF energy

-- tonal stability

The reason for not using the SAD decision for noise update is to make
the noise estimation robust to rapidly changing noise levels. If the SAD
decision was used for the noise update, a sudden increase in noise level
would cause an increase of SNR even for inactive speech frames,
preventing the noise estimator to update, which in turn would maintain
the SNR high in the following frames. Consequently, the noise update
would be blocked and some other logic would be needed to resume the
noise adaptation.

##### 5.1.11.2.1 Basic parameters for noise energy update

The pitch stability counter is computed as

$\text{pc} = \left| d^{\lbrack 0\rbrack} - d^{\lbrack - 1\rbrack} \right| + \left| d^{\lbrack 1\rbrack} - d^{\lbrack 0\rbrack} \right|$
(108)

where *d*^\[0\]^, *d*^\[1\]^ and *d*^\[-1\]^ are the OL pitch lags for
the first half-frame, second half-frame and the second half-frame of the
pervious frame. The pitch stability is true if the value of *pc* is less
than 12. Further, for frames with low voicing, *pc* is directly set to
12 to indicate pitch instability. That is

if
$(C_{\text{norm}}^{\lbrack 0\rbrack} + C_{\text{norm}}^{\lbrack 1\rbrack} + C_{\text{norm}}^{\lbrack 2\rbrack}\frac{)}{3} + r_{e} < \text{th}_{\text{Cpc}}$
then *pc* = 12, (109)

where $\forall i$ are the normalized raw correlations as defined in
clause 5.1.10.7 and *r~e~* is a correction added to the normalized
correlation in order to compensate for the decrease of normalized
correlation in the presence of background noise, defined in clause
5.1.10.6. The voicing threshold *th~Cpc~* = 0.52 for WB inputs, and
*th~Cpc~* = 0.65 for NB inputs.

Signal non-stationarity is analysed based on the product of ratios
between the current frame energy per critical band and its long-term
average per critical band. The average long-term energy per critical
band is calculated as

${\overline{E}}_{\text{CB}}(i) = \alpha_{e}{\overline{E}}_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}(i) + (1 - \alpha_{e})(0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i))$,
for *i* = *b~min~* to *b~max~*, (110)

where *b~min\ ~*= 0 and *b~max\ ~*= 19 in case of WB signals, and
*b~min\ ~*= 1 and *b~max\ ~*= 16 in case of NB signals. The update
factor $\alpha_{e}$ is a linear function of the relative frame energy,
defined in clause 5.1.5.2 and it is given as follows

$\alpha_{e} = 0\text{.}\text{064}E_{\text{rel}} + 0\text{.}\text{75}$,
constrained by $\alpha_{e} \leq 0\text{.}\text{999}$ (111)

where all negative values of $E_{\text{rel}}$ are replaced by 0. The
frame non-stationarity is then given by the product of the ratios
between the frame energy and its long-term average calculated in the
previous frame. That is

$\text{nonstat} = \prod_{i = b_{\text{min}}}^{b_{\text{max}}}\frac{\text{max}(0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i),{\overline{E}}_{\text{CB}}^{\lbrack - 1\rbrack}(i)) + 1}{\text{min}(0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i),{\overline{E}}_{\text{CB}}^{\lbrack - 1\rbrack}(i)) + 1}$
(112)

The voicing factor for noise update is given by

$\text{voicing} = (C_{\text{norm}}^{\lbrack 0\rbrack} + C_{\text{norm}}^{\lbrack 1\rbrack}\frac{)}{2} + r_{e}$
(113)

The ratio between the LP residual energy after 2nd‑order and 16th‑order
analysis is given by

$\text{resid}_{\text{ratio}} = \frac{E(2)}{E(\text{16})}$ (114)

where *E*(2) and *E*(16) are the LP residual energies after 2nd‑order
and 16th‑order analysis, and computed in the Levinson-Durbin recursion
(see clause 5.1.9.4). This ratio reflects the fact that, to represent a
signal spectral envelope, a higher order of LP is generally needed for
speech signal than for noise. In other words, the ratio between *E*(2)
and *E*(16) is expected to be lower for noise than for active speech.

##### 5.1.11.2.2 Spectral diversity

The basic parameters for noise estimation have their limitations for
certain music signals, such as piano concerts or instrumental rock and
pop. Spectral diversity gives information about significant spectral
changes. The changes are tracked in the frequency domain in critical
bands by comparing energies in the first spectral analysis of the
current frame with the second spectral analysis two frames ago. The
energy per critical band corresponding to the first spectral analysis of
the current frame is denoted as $E_{\text{CB}}^{\lbrack 0\rbrack}(i)$
and is defined in clause 5.1.5.2. Let the energy per critical band
corresponding to the second spectral analysis two frames ago be denoted
as $E_{\text{CB}}^{\lbrack - 3\rbrack}(i)$. For all bands higher than 9,
the maximum and the minimum of the two energies is found as

$\begin{matrix}
E_{\text{max}}(i) = \text{max}\left\{ E_{\text{CB}}^{\lbrack 0\rbrack}(i)\ ,\ E_{\text{CB}}^{\lbrack - 3\rbrack}(i)\  \right\} \\
E_{\text{min}}(i) = \text{min}\left\{ E_{\text{CB}}^{\lbrack 0\rbrack}(i)\ ,\ E_{\text{CB}}^{\lbrack - 3\rbrack}(i)\  \right\} \\
\end{matrix}$, for *i* = 10,..,*b*~max~, (115)

where *b~max\ ~*= 19 in case of WB signals, and *b~max\ ~*= 16 in case
of NB signals. The energy ratio is the calculated as

$E_{\text{rat}}(i) = \frac{E_{\text{max}}(i)}{E_{\text{min}}(i)}$, for
*i* = 10,..,*b*~max~. (116)

The spectral diversity is then calculated as the normalized weighted sum
of the ratios in all critical bands with the weight itself being the
maximum energy $E_{\text{max}}(i)$. That is

$p_{\text{div}} = \frac{\sum_{i = \text{10}}^{b_{\text{max}}}{E_{\text{max}}\left( i \right)E_{\text{rat}}(i)}}{\sum_{i = \text{10}}^{b_{\text{max}}}{E_{\text{max}}\left( i \right)}}$
(117)

The spectral diversity is used as an auxiliary parameter for the
complementary non‑stationarity described below.

##### 5.1.11.2.3 Complementary non-stationarity

The complementary non-stationarity is motivated by the fact that the
non-stationarity described in clause 5.1.11.2.1 and calculated in
equation (112) is low when a sharp energy attack in a harmonic signal is
followed by a slow energy decay. In this case, the average long-term
energy per critical band, ${\overline{E}}_{\text{CB}}(i)$, slowly
increases after the attack whereas the current energy per critical band,
$0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i)$,
slowly decreases. At certain point (few frames after the attack frame)
they are the same yielding only a small value of the *nonstat*
parameter. This indicates to the noise estimation logic an absence of
active signal which is wrong. It may lead to a false update of the
background noise and consequently a collapse of the SAD algorithm.

To overcome this problem, there is an alternative calculation of the
average long-term energy per critical band. It is calculated in the same
way as in equation (110) but with a different factor. That is

${\overline{F}}_{\text{CB}}(i) = \beta_{e}{\overline{F}}_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}(i) + (1 - \beta_{e})(0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i))$,
for *i* = *b~min~* to *b~max~*. (118)

where ${\overline{F}}_{\text{CB}}(i)$ is initialized to 0.03. The update
factor $\beta_{e} = \alpha_{e}$ and reset to 0 if *p~div~* \> 5. The
complementary non-stationarity parameter is then calculated in the same
way as *nonstat* but using
${\overline{F}}_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}(i)$ instead
of ${\overline{E}}_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}(i)$.
That is:

$\text{nonstat}2 = \prod_{i = b_{\text{min}}}^{b_{\text{max}}}\frac{\text{max}(0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i),{\overline{F}}_{\text{CB}}^{\lbrack - 1\rbrack}(i)) + 1}{\text{min}(0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i),{\overline{F}}_{\text{CB}}^{\lbrack - 1\rbrack}(i)) + 1}$
(119)

The complementary non-stationarity must be used by the noise estimation
logic only in certain signal passages. These are characterized by the
parameter ${\overline{a}}_{\text{pred}}$ which can be described as the
average non-binary decision combined from non-stationarity and tonal
stability. That is

if *nonstat* \> *th~stat~* OR *p~tonal~* = 1 then
${{\overline{a}}_{\text{pred}} = 0\text{.}\text{99\ \{}\overline{a}}_{\text{pred}} + 0\text{.}\text{01} \times 1$
otherwise
${{\overline{a}}_{\text{pred}} = 0\text{.}\text{99\ \{}\overline{a}}_{\text{pred}} + 0\text{.}\text{01} \times 0$

where ${\overline{a}}_{\text{pred}}$ is in the range \[0; 1\] and
*p~tonal~* is the tonal stability described in clause 5.1.11.2.5 and
defined in equation (125).

##### 5.1.11.2.4 HF energy content

The HF energy content represents another parameter, which is used for
the detection of certain noise‑like musical signals such as cymbals or
low-frequency drums. This parameter is calculated as

$p_{\text{hfE}} = \frac{\sum_{i = \text{10}}^{b_{\text{max}}}{E_{\text{CB}}(i)}}{\sum_{i = b_{\text{min}}}^{9}{E_{\text{CB}}(i)}}$,
constrained by $p_{\text{hfE}} < \text{10}$ (120)

but only for frames that have at least a minimal HF energy, i.e. when
both the numerator and the denominator of the above equation are higher
than 100. If this is not fulfilled, $p_{\text{hfE}} = 0$. Finally, the
long-term value if this parameter is calculated as

${\overline{p}}_{\text{hfE}} = 0\text{.}9{\overline{p}}_{\text{hfE}}^{\lbrack - 1\rbrack} + 0\text{.}1p_{\text{hfE}}$
(121)

where ${\overline{p}}_{\text{hfE}}^{\lbrack\text{-1}\rbrack}$ is
initialized to zero.

##### 5.1.11.2.5 Tonal stability

The tonal stability exploits the harmonic spectral structure of certain
musical signals. In the spectrum of such signals there are tones which
are stable over several consecutive frames. To exploit this feature, it
is necessary to track the positions and shapes of strong spectral peaks.
The tonal stability is based on a correlation between the spectral peaks
in the current frame and the past frame. The input to the algorithm is
an average logarithmic energy spectrum, defined as

$E_{\text{dB}}(k) = \text{10}\text{log}\left\lbrack 0\text{.}5\left( E_{\text{BIN}}^{\lbrack 0\rbrack}(k) + E_{\text{BIN}}^{\lbrack 1\rbrack}(k) \right) \right\rbrack$,
$k = 0,\ldots,\text{127}$, (127)

where $E_{\text{BIN}}(k)$ is defined in clause 5.1.5.2 and the
superscripts \[0\] and \[1\] denote the first and the second spectral
analysis, respectively. In the following text, the term \"spectrum\"
will refer to the average logarithmic energy spectrum, as defined by the
above equation.

The tonal stability is calculated in three stages. In the first stage,
indices of local minima of the spectrum are searched in a loop and
stored as *i*~min~. This is described by the following equation

$i_{\text{min}} = \left( E_{\text{dB}}\left( i - 1 \right) > E_{\text{dB}}\left( i \right) \right) \land \left( E_{\text{dB}}\left( i \right) < E_{\text{dB}}\left( i + 1 \right) \right)$,
$\forall i$ $i = 1,\ldots,\text{126}$, (128)

The index 0 is added to $i_{\text{min}}$ if
$E_{\text{dB}}(0) < E_{\text{dB}}(1)$. Consequently, the index 127 is
added to $i_{\text{min}}$, if
$E_{\text{dB}}(\text{127}) < E_{\text{dB}}(\text{126})$. Let us denote
the total number of minima found as *N~min~*. The second stage consists
of calculating a spectral floor and its subtraction from the spectrum.
The spectral floor is a piece-wise linear function which runs through
the detected local minima. Every piece between two consecutive minima
$i_{\text{min}}(x)$ and $i_{\text{min}}(x + 1)$ can be described by a
linear function as

$f(j) = k\text{.}(j - i_{\text{min}}(x)) + q$,
$j = i_{\text{min}}(x),\ldots,i_{\text{min}}(x + 1)$, (129)

where *k* is the slope of the line and
$q = E_{\text{dB}}(i_{\text{min}}(x))$. The slope is calculated by

$k = \frac{E_{\text{dB}}(i_{\text{min}}(x + 1)) - E_{\text{dB}}(i_{\text{min}}(x))}{i_{\text{min}}(x + 1) - i_{\text{min}}(x)}$
(130)

Thus, the spectral floor is a logical connection of all pieces. The
leading bins of the spectrum up to $i_{\text{min}}(0)$ and the
terminating bins of the spectrum from
$i_{\text{min}}(N_{\text{min}} - 1)$ are set to the spectral values
themselves, i.e.

$\begin{matrix}
F(j) = E_{\text{dB}}(j) & & j = 0,\ldots,i_{\text{min}}(0) - 1 \\
F(j) = f(j) & & j = i_{\text{min}}(0),\ldots,i_{\text{min}}(N_{\text{min}} - 1) - 1\text{.} \\
F(j) = E_{\text{dB}}(j) & & j = i_{\text{min}}(N_{\text{min}} - 1),\ldots,\text{127} \\
\end{matrix}\ $ (131)

Finally, the spectral floor is subtracted from the spectrum by

$E_{\text{dB},\text{res}}(j) = E_{\text{dB}}(j) - F(j)$,
$j = 0,\ldots,\text{127}$ (132)

and the result is the residual spectrum. The calculation of the spectral
floor and its subtraction is illustrated in the following figure.

![](media/image8.wmf){width="5.658333333333333in"
height="4.238888888888889in"}

Figure 9 : Spectral floor in the tonal stability

The third stage of the tonal stability calculation is the calculation of
the correlation map and the long-term correlation map. This is again a
piece-wise operation. The correlation map is created on a peak-by-peak
basis where each two consecutive minima delimit one peak. Let us denote
the residual spectrum of the previous frame as
$E_{\text{dB},\text{res}}^{\lbrack - 1\rbrack}(j)$. For every peak in
the current residual spectrum, normalized correlation is calculated with
the previous residual spectrum. The correlation operation takes into
account all indices (bins) of that peak delimited by two consecutive
minima, i.e.

$M_{\text{cor}}(i_{\text{min}}(x):i_{\text{min}}(x + 1)) = \frac{\left( \sum_{j = i_{\text{min}}(x)}^{i_{\text{min}}(x + 1) - 1}{E_{\text{dB},\text{res}}(j)E_{\text{dB},\text{res}}^{\lbrack - 1\rbrack}(j)} \right)^{2}}{\sum_{j = i_{\text{min}}(x)}^{i_{\text{min}}(x + 1) - 1}\left( E_{\text{dB},\text{res}}(j) \right)^{2}\sum_{j = i_{\text{min}}(x)}^{i_{\text{min}}(x + 1)}\left( E_{\text{dB},\text{res}}^{\lbrack - 1\rbrack}(j) \right)^{2}}$,
$x = 0,\ldots,N_{\text{min}} - 2$ (122)

where the leading bins up to $i_{\text{min}}(0)$ and the terminating
bins from $i_{\text{min}}(N_{\text{min}} - 1)$ are set to zero. The
figure below shows a graphical representation of the correlation map.

![](media/image9.wmf){width="5.658333333333333in"
height="4.238888888888889in"}

Figure 10 : Correlation map in the tonal stability calculation

The correlation map of the current frame is used to update its long-term
value, which can be expressed as

${\overline{M}}_{\text{cor}}(k) = \alpha_{\text{map}}{\overline{M}}_{\text{cor}}(k) + (1 - \alpha_{\text{map}})M_{\text{cor}}(k)$,
$k = 0,\ldots,N_{\text{SPEC}} - 1$ (123)

where $\alpha_{\text{map}} = 0\text{.}9$. If any value of
${\overline{M}}_{\text{cor}}(j)$ exceeds the threshold of 0.95, the flag
*f~strong~* is set to one, otherwise it is set to zero. The long-term
correlation map is initialized to zero for all *k*. Finally, all bins of
${\overline{M}}_{\text{cor}}(k)$ are summed together by

$m_{\text{sum}} = \sum_{j = 0}^{\text{127}}{{\overline{M}}_{\text{cor}}(j)}$
(124)

In case of NB signals, the correlation map in higher bands is very low
due to missing spectral content. To overcome this deficiency, *m~sum~*
is multiplied by 1.53.

The decision about tonal stability is taken by subjecting *m~sum~* to an
adaptive threshold *th~tonal~*. This threshold is initialized to 56 and
it is updated in every frame by

if *m~sum~* \> 56 then *th~tonal~* = *th~tonal~* -- 0.2 otherwise
*th~tonal~* = *th~tonal~* + 0.2

and is upper limited by 60 and lower limited by 49. Thus, it decreases
when the summed correlation map is relatively high, indicating a good
tonal segment, and increases otherwise. When the threshold is lower,
more frames will be classified as tonal, especially at the end of active
music periods. Therefore, the adaptive threshold may be viewed as a
hangover.

The *p~tonal~* parameter is set to one whenever *m~sum~* is higher than
*th~tonal~* or when the flag *f~strong~* is set to one. That is:

if *m~sum~* \> *th~tonal~* OR *f~strong~* = 1 then *p~tonal~* = 1
otherwise *p~tonal~* = 0 (125)

##### 5.1.11.2.6 High frequency dynamic range

From the residual spectrum $E_{\text{dB},\text{res}}$as described in
equation 116, another parameter is computed. This parameter is called
the high frequency dynamic $D_{\text{hf}}$is derived from the high band
spectral dynamic of the residual spectrum and is used to set the high
frequency dynamic range flag $F_{\text{hf}}$which is used inside the GSC
to decide about the number of subframe and the bit allocation. The high
frequency dynamic is compute as the average of the last 40 bin from the
residual spectrum:

$D_{\text{hf}\left( t \right)} = 0\text{.}7 \cdot D_{\text{hf}\left( t - 1 \right)} + 0\text{.}3 \cdot \left( \frac{1}{\text{40}}\sum_{i = L - \text{40}}^{i = L}{E_{\text{dB},\text{res}}\left( i \right)} \right)$
(126)

And the high frequency dynamic range flag is set depending on the past
values and the actual high frequency dynamic as :

$\begin{matrix}
\text{if}\left( D_{\text{hf}_{\left( t \right)}} < 9\text{.}6\text{dB} \land F_{\text{hf}\left( t - 1) \right)}\text{==}1 \right) \\
F_{\text{hf}\left( t \right)} = 0 \\
D'_{\text{hf}} = D_{\text{hf}_{\left( t \right)}} \\
\text{else}\ \text{if}\ \left( \left( D_{\text{hf}_{\left( t \right)}} - D'_{\text{hf}} \right) > 4\text{.}5\text{dB} \right) \\
F_{\text{hf}\left( t \right)} = 1 \\
\end{matrix}$ (127)

Where $t$represents the frame at time t and $D'_{\text{hf}}$represents
the average high frequency dynamic at when the last time the flag
$F_{\text{hf}}$was set to 0.

##### 5.1.11.2.7 Combined decision for background noise energy update

The noise energy update decision is controlled through the logical
combination of the parameters and flags described in the previous
sections. The combined decision is a state variable denoted *p~nup~*
which is initially set to 6, and which is decremented by 1 if an
inactive frame is detected or incremented by 2 if an active frame is
detected. Further, *p~nup~* is bounded by 0 and 6. The following diagram
shows the conditions under which the state variable *p~nup~* is
incremented by 2 in each frame.

Figure 11 : Incrementing the state variable for background noise energy
update

where, for WB signals, *th~sta~* = 350000, *th~Cnorm~* = 0.85 and
*th~resid~* = 1.6, and for NB signals, *th~sta\ ~*= 500000,
*th~Cnorm~* = 0.7 and *th~resid\ ~*= 10.4. If *p~nup~* is not
incremented in any of the conditions from the above diagram, it is
automatically decremented by 1. Therefore, it takes at least 6 frames
before *p~nup~* reaches 0 which signals the subsequent logic that
background noise energy can be updated. The final decision about
background noise energy update is described in the subsequent section.

#### 5.1.11.3 Energy-based parameters for noise energy update

The parameters in this section are used in addition to the
$p_{\text{nup}}$ described in the previous section to control when it is
possible and safe to allow the noise estimate sub-bands to be increased
according to the pre calculated noise estimate
$N_{\text{tmp}}$calculated in equation (102).

##### 5.1.11.3.1 Closeness to current background estimate

Similar to $\text{nonstat}$ and $\text{nonstat2}$the parameter
$\text{nonstat}_{B}$ represents a spectral difference. The difference is
that it is the closeness/variation compared to the current background
noise estimate that is measured. The calculation of the feature also
differs in calculation during initialization, that is
$\text{ini}_{\text{frame}} < \text{100}$, or during normal operation.
During initialization the comparison is made using a constant,
$E_{\text{MIN}} = 0\text{.}\text{0035}$ which is the initialization
value for the sub-band energies, as shown in

$\text{nonstat}_{B} = \sum_{i = 2}^{\text{16}}\left| \text{log}(0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i) + 1) - \text{log}(E_{\text{MIN}} + 1) \right|$
(128)

This is done to reduce the effect of decision errors in the background
noise estimation during initialization. After the initialization period
the calculation is made using the current background noise estimate of
the respective sub-band, according to:

$\text{nonstat}_{B} = \sum_{i = 2}^{\text{16}}\left| \text{log}(0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i) + 1) - \text{log}({\overline{N}}_{\text{CB}}^{\lbrack - 1\rbrack}(i) + 1) \right|$
(129)

It is worth noting that the calculation of $\text{nonstat}_{B}$ is not
dependent of the band width as it is made over the same sub-bands
regardless of the input bandwidth.

##### 5.1.11.3.2 Features related to last correlation or harmonic event

Two related features are created which relate to the occurrence of
frames where correlation or harmonic events are detected. The first is a
counter, ${\overline{c}}_{\text{harm}}$, that keeps track of how many
frames that have passed since the last frame where correlation or
harmonic event has occurred. That is if a correlation or harmonic event
is detected the counter is reset otherwise it is incremented by one,
according to:

${\text{if\ }\left( (C_{\text{norm}}^{\lbrack 0\rbrack} + C_{\text{norm}}^{\lbrack 1\rbrack}\frac{)}{2} > 0\text{.}\text{85}\text{\ OR\ }p_{\text{tonal}} > 0 \right)\text{\ then\ \ \{}\overline{c}}_{\text{harm}} = \text{0\ else\ \ \ \{}\overline{c}{}_{\text{harm}} = {\overline{c}}_{\text{harm}} + 1$
(141)

where $C_{\text{norm}}^{\lbrack\text{.}\rbrack}$ is the normalized
correlation in the first or the second half-frame and $p_{\text{tonal}}$
is the result of the tonal detection in clause 5.1.11.2.5. If the
counter ${\overline{c}}_{\text{harm}}$ is larger than 1 it is limited to
1 if$E_{t} < \text{15}\text{.}0$ or if
$\text{ini}_{\text{frame}} > \text{10}$ AND
$(E_{t} - {\overline{E}}_{t}) > 7\text{.}0$is 1. Depending on the
estimated short term variance of the input frame energy the current
value of the counter ${\overline{c}}_{\text{harm}}$ can be reduced to
one quarter of its value (or 1 if it was less than 4). The reduction is
made for frames where ${\overline{c}}_{\text{harm}} > 1$ where
$E_{t} > \text{30}\text{.}0$ and the short therm variance estimate of
the frame energy is larger than 8.0. The other feature is the long term
measure of the relative occurrence of correlation or tonal frames. It is
represented as a scalar value, ${\overline{c}}_{\text{ev}}$, which is
updated using a first order AR-process with different time constants
depending on if the current frame is classified as a correlation/tonal
frame or not according to:

${\overline{c}}_{\text{ev}} = (1 - \alpha){\overline{c}}_{\text{ev}}^{\left\lbrack - 1 \right\rbrack} + \alpha(c_{\text{harm}}\text{==}0)\text{\ where\ }\alpha = \left\{ \begin{matrix}
0\text{.}\text{03} & \text{if\ c}_{\text{harm}}\text{==}0 \\
0\text{.}\text{01} & \text{otherwise} \\
\end{matrix} \right.\ $ (142)

where the test, ${\overline{c}}_{\text{harm}}\text{==}0$, represents a
detection of a correlation/tonal event.

##### 5.1.11.3.3 Energy-based pause detection

To improve the tracking of the background noise the energy pause
detector monitors the number of frames since the frame energy got close
to the long-term minimum frame energy
estimate${\overline{E}}_{\text{tl}}$. For inactive frames the counter is
0 or higher, $c_{\text{bg}} \geq 0$, where positive integers represent
the number of frames since the start of the current pause. When active
content is detected the counter is set and kept at,
$c_{\text{bg}} = - 1$. Initially $c_{\text{bg}}$=0 so the detector is in
a inactive state and checks for an energy increase relative the long
term minimum energy tracker ${\overline{E}}_{\text{tl}}$ that could
triggers a transition to and active state:

$\text{if\ }c_{\text{bg}} \geq 0\text{\ AND\ }(E_{t} - {\overline{E}}_{\text{tl}}) > 5\text{\ then\ c}_{\text{bg}} = - 1$
(130)

If the detector is in an active state the detector checks if the frame
energy once again has come close to the long term minimum energy

$\text{if\ }c_{\text{bg}}\text{==} - 1\text{\ AND\ }(E_{t} - {\overline{E}}_{\text{tl}}) < 5\text{\ then\ c}_{\text{bg}} = 0$
(131)

The final step in the update of this parameter is to increment the
counter if the detector is in an inactive state

$\text{if\ }c_{\text{bg}} \geq 0\text{\ then\ }c_{\text{bg}} = c_{\text{bg}} + 1$
(132)

##### 5.1.11.3.4 Long-term linear prediction efficiency

This section describes how the residual energies from the linear
prediction analysis made in clause 5.1.9 can be used to create a long
term feature that can be used to better determine when the input signal
is active content or background noise based on the input signal alone.

The analysis provides several new features by analysing the linear
prediction gain going from 0^th^-order to 2^nd^-order linear prediction
and going from 2^nd^-order to 16^th^-order prediction. Starting with the
2^nd^ order prediction residual energy that is compared to the
0^th^-order prediction residual energy, which is the energy of the input
signal. For a more stable long term feature the gain is calculated and
limited as

$g_{\text{LP}_{}} = \text{max}(0\text{,min}(8,E(0\frac{)}{E}(2)))$ (133)

where $E(0)$is the energy of the input signal and $E(2)$ is the residual
energy after the second-order linear prediction (see clause 5.1.9.4).
The limited prediction gain is then filtered in two steps to create long
term estimate of this gain. The first is made using

${{\overline{g}}_{\text{LP}_{}} = 0\text{.}\text{85\ \{}\overline{g}}_{\text{LP}_{}}^{\left\lbrack - 1 \right\rbrack} + 0\text{.}\text{15}g_{\text{LP}_{}}$
(134)

and typically this will become either 0 or 8 depending on the type of
background noise in the input once there is a segment of background only
input. A second feature is then created using the difference between the
first long term feature and the frame by frame limited prediction gain
according to:

$g_{\text{ad}_{}} = \left| {\overline{g}}_{\text{LP}_{}} - g_{\text{LP}_{}} \right|$.
(148)

This will give an indication of the current frames prediction gain
compared to the long term gain. This difference is used to create a
second long term feature, this is done using a filter with different
filter coefficient depending on if the long term difference is higher or
lower than the currently estimated average difference according to

${\overline{g}}_{\text{ad}_{}} = (1 - \alpha){\overline{g}}_{\text{ad}_{}}^{\left\lbrack - 1 \right\rbrack} + \text{αg}_{\text{ad}_{}}\text{\ \ \ \ \ \ where\ }\alpha = \left\{ \begin{matrix}
0\text{.}1 & \text{if\ }g_{\text{ad}_{}} < {\overline{g}}_{\text{ad}_{}}^{\left\lbrack - 1 \right\rbrack} \\
0\text{.}2 & \text{otherwise} \\
\end{matrix} \right.\ $. (149)

This second long term feature is then combined with the frame difference
to prevent the filtering from masking occasional high frame differences,
the final parameter is the maximum of the frame and the long term
version of the feature

$g_{\text{max\_}0_{2}} = \text{max}({\overline{g}}_{\text{ad}_{}},g_{\text{ad}_{}})$.
(150)

The feature created using the difference between 2^nd^ order prediction
and 16^th^ order prediction is analysed slightly differently. The first
step here is also to calculate prediction gain as

$g_{\text{LP}_{}} = \text{max}(0\text{,min}(8,E(2\frac{)}{E}(\text{16})))$
(151)

where $E(2)$represents the residual energy after a 2^nd^ order linear
prediction and $E(\text{16})$ is the residual energy after a 16^th^
order linear prediction, see clause 5.1.9.4. This limited prediction
gain is then used for two long term estimates of this gain, one where
the filter coefficient differs if the long term estimate is to be
increased or not as shown in

${\overline{g}}_{\text{LP}_{}} = (1 - \alpha){\overline{g}}_{\text{LP}_{}}^{\left\lbrack - 1 \right\rbrack} + \text{αg}_{\text{LP}_{}}\text{\ \ \ \ \ \ where\ }\alpha = \left\{ \begin{matrix}
0\text{.}\text{20} & \text{if\ }g_{\text{LP}_{}} > {\overline{g}}_{\text{LP}_{}}^{\left\lbrack - 1 \right\rbrack} \\
0\text{.}\text{03} & \text{othrewise} \\
\end{matrix} \right.\ $. (152)

The second long term estimate uses a constant filter coefficient,
according to

${\overline{g}}_{\text{LP}2_{}} = (1 - \beta){\overline{g}}_{\text{LP}2_{}}^{\left\lbrack - 1 \right\rbrack} + \text{βg}_{\text{LP}_{}}\text{\ \ \ \ \ where\ }\beta = 0\text{.}\text{02}$.
(153)

For most types of background signals both will be close to 0, but have
different responses to content where the 16^th^ order linear prediction
is needed (typically for speech and other active content). The first
${\overline{g}}_{\text{LP}_{}}$ will usually be higher than the
second${\overline{g}}_{\text{LP}2_{}}$. This difference between the long
term features is measured according to

$g_{\text{ad}_{}} = {\overline{g}}_{\text{LP}_{}} - {\overline{g}}_{\text{LP}2_{}}$
(154)

which is used as an input to the filter which creates the third long
term feature according to

${\overline{g}}_{\text{ad}_{}} = (1 - \alpha){\overline{g}}_{\text{ad}_{}}^{\left\lbrack - 1 \right\rbrack} + \text{αg}_{\text{ad}_{}}\text{\ \ \ \ \ where\ }\alpha = \left\{ \begin{matrix}
0\text{.}\text{02} & \text{if\ }g_{\text{ad}_{}} < {\overline{g}}_{\text{ad}_{}}^{\left\lbrack - 1 \right\rbrack} \\
0\text{.}\text{05} & \text{otherwise} \\
\end{matrix} \right.\ $. (155)

Also, this filter uses different filter coefficients depending on if the
third long term signal is to be increased or not. Also here the long
term signal is combined with the input signal to prevent the filtering
from masking occasional high inputs for the current frame. The final
parameter is then the maximum of the frame and the long term version of
the feature

$g_{\text{max\_}2_{\text{16}}} = \text{max}({\overline{g}}_{\text{ad}_{}},g_{\text{ad}_{}})$.
(156)

Note that also some of the other calculated features in this sub section
are used in the combination logic for the noise estimation,
${\overline{g}}_{\text{ad}_{}}$, $g_{\text{max\_}2_{\text{16}}}$,
$g_{\text{max\_}0_{2}}$, $g_{\text{ad}_{}}$, and$g_{\text{LP}_{}}$.

##### 5.1.11.3.5 Additional long-term parameters used for noise estimation

Some additional parameters that processed to create long term estimates
are three measures the relation of the current frames energy compared to
the energy of the noise estimate. The first calculates the difference
between the current frame energy and the level of the current noise
estimate this is then filtered to build a long term estimate according
to

${\overline{N}}_{\text{dist}} = (1 - \beta){\overline{N}}_{\text{dust}}^{\left\lbrack - 1 \right\rbrack} + \beta\left( E_{t} - {\overline{N}}_{t} \right)\text{\ \ \ \ where\ }\beta = 0\text{.}\text{03}$
(135)

Another feature estimates a long term estimate of how often the current
frame energy is close to the level of the background estimate using:

${\overline{N}}_{\text{track}} = (1 - \beta){\overline{N}}_{\text{track}}^{\left\lbrack - 1 \right\rbrack} + \beta\left( (E_{t} - {\overline{N}}_{t}) < \text{10} \right)\text{\ \ \ \ \ \ where}\ \text{\ \ }\beta = 0\text{.}\text{03}$
(136)

The third estimate is a second order estimate for the number of frames
that the current input has been close to the noise estimate. This is
simply a counter is reset if the long term estimate
${\overline{N}}_{\text{track}}$ is higher than a threshold and
incremented otherwise, as shown in

$c_{\text{Ntr}} = \left\{ \begin{matrix}
0 & \text{if\ \ \{}\overline{N} \\
\end{matrix}_{\text{track}} \geq 0\text{.}\text{05} \middle| \middle| c_{\text{Ntr}}^{\left\lbrack - 1 \right\rbrack} + 1 \middle| \middle| \text{otherwise} \middle| \right.\ $
(137)

The last additional features calculates an long term estimate of the
difference in the current frame energy to the long term minimum energy
feature, this is done by low pass filtering the calculated energy
difference according to

${\overline{E}}_{\text{tl}_{\text{dist}}} = (1 - \beta){\overline{E}}_{\text{dust}}^{\left\lbrack - 1 \right\rbrack} + \beta\left( E_{t} - {\overline{E}}_{\text{tl}} \right)\text{\ \ \ \ \ where\ \ \ }\beta = 0\text{.}\text{03}$
(138)

#### 5.1.11.4 Decision logic for noise energy update

Already in the first step of the noise estimation (see clause 5.1.11.1),
the current noise estimate has been reduced in sub-bands where the
background noise energy was higher than the sub-band energy for the
current frame. The decision logic described in this subsection shows how
it is decided when to update the background noise estimate and how large
that update should be allowed to be by setting the step size,
$\text{step}_{\text{size}}$. The update is adapted based on the earlier
described features or combinations thereof.

Every frame an attempt is made to adjust the background noise estimate
upwards, where it is important not to do the update in active content.
Several conditions are evaluated in order to decide if an update is
possible and how large an allowed update should be. As it is always
allowed to make downwards updates it is equally important that possible
updates are not prevented for extended times as this will affect the
efficiency of the SAD. The noise update uses a flag to keep track of the
number of prevented noise updates, $c_{\text{first}_{\text{updt}}}$, the
same flag is also used to indicate that no update has taken place. The
counter $c_{\text{first}_{\text{updt}}}$ is initialized to the value 0
to indicate that no update has been done so far. When updates are
successful it is set to 1 and for failed updates the counter is
incremented by 1.

The major decision step in the noise update logic is whether an update
is to be made or not and this is formed by evaluation of the following
logical expression

$f_{\text{UPDATE}} = (f_{\text{bg}_{\text{MASK}}}\text{\ AND}(f_{\text{bg}_{\text{nup}}}\text{\ OR}f_{\text{bg}_{\text{dynamic}}}\text{\ OR\ }f_{\text{bg}_{\text{tracking}}}\text{\ OR}f_{\text{bg}_{\text{new}}}))\text{\ OR\ }f_{\text{bg}_{\text{ini}}}$
(161)

where $f_{\text{bg}_{\text{MASK}}}$ ensures that it is safe to do an
update provided that any of the four pause detectors,
$f_{\text{bg}_{\text{nup}}}$, $f_{\text{bg}_{\text{dynamic}}}$,
$f_{\text{bg}_{\text{tracking}}}$, and $f_{\text{bg}_{\text{new}}}$
indicate that an update is allowed. Note that the last term in the
condition $f_{\text{bg}_{\text{ini}}}$ is not is not combined with
$f_{\text{bg}_{\text{MASK}}}$ as it handles the noise estimation during
initialization.

Starting with the mask which ensures that the normal updates only can
occur when the current frame energy is close to the estimated long-term
minimum energy,${\overline{E}}_{\text{tl}}$ (see clause 5.1.11.1), is
adjusted with a level dependent scaling of the estimated frame energy
variations, ${\overline{E}}_{\text{vh}2}$, according to

$f_{\text{bg}_{\text{MASK}}} = E_{t} < {\overline{E}}_{\text{tl}} + (1\text{.}5 + 1\text{.}5({\overline{E}}_{t} < \text{50})){\overline{E}}_{\text{vh}2}$
(162)

The first pause detector $f_{\text{bg}_{\text{nup}}}$ is based on the
metric $p_{\text{nup}}$control logic described in subclause 5.1.11.2.7,
when $p_{\text{nup}}$is 0 updates are allowed, that is

$\text{if\ }p_{\text{nup}}\text{==}0\text{\ then\ }f_{\text{bg}_{\text{nup}}} = 1\text{\ else\ }f_{\text{bg}_{\text{nup}}} = 0$
(163)

The second pause detector allows for updates for low energy frames if
the estimated signal dynamics is high and a sufficient number of frames
have passed since the last correlation event, that is

${f_{\text{bg}_{\text{dynamic}}} = {\overline{E}}_{\text{dyn}} > \text{15}\text{\ AND\ }E_{t} < {\overline{E}}_{\text{tl}} + 2{\overline{E}}_{\text{vh}2}\text{\ AND\ \ \{}\overline{c}}_{\text{harm}} > \text{20}$
(139)

The third pause detector allows updates when there are consecutive
frames that are similar in energy to the current low level frames in a
row,

$f_{\text{bg}_{\text{track}}} = {\overline{N}}_{\text{track}} > 0\text{.}9$
(140)

The last detector is itself a combination of a mask and two pause
detectors and mainly uses the additional features described in subclause
5.1.11.3.4, the detector is evaluated using

$f_{\text{bg}_{\text{new}}} = f_{\text{bg}_{M1}}\text{\ AND}(f_{\text{bg}_{A1}}\text{\ OR}f_{\text{bg}_{A2}})$
(141)

where $f_{\text{bg}_{M1}}$ is the mask for the detector and
$f_{\text{bg}_{A1}}$ and $f_{\text{bg}_{A2}}$ are the additional
detectors. For this detector the following seven flags are first
evaluated. The first flag signals that the frame energy close to
background noise energy where the threshold is adapted to the estimated
frame to frame energy variations, as

$f_{\text{enr}_{\text{bg}}} = E_{t} < {\overline{E}}_{\text{tl}} + (1\text{.}5 + 1\text{.}5({\overline{E}}_{t} < \text{50})){\overline{E}}_{\text{vh}2}$
(142)

The second flag signals a high linear prediction gain with 2^nd^ order
model for a stationary signal, and is defined as follows:

$f_{\text{cns}_{\text{bg}}} = g_{\text{LP}_{}} > 7\text{.}\text{95}\text{\ AND\ }\text{nonsta} < \text{10}^{3}$
(168)

The third flag signals that there is a low linear prediction gain for
16^th^ order linear prediction

$f_{\text{lp}_{\text{bg}}} = g_{\text{max\_}2_{\text{16}}} < 0\text{.}1$
(143)

The fourth flag signals that the current frame has low spectral
fluctuation

$f_{\text{ns}_{\text{bg}}} = \text{nonsta} < \text{10}^{5}$ (144)

The fifth flag signals that the long term correlation is low

$f_{\text{haco}_{\text{bg}}} = {\overline{c}}_{\text{ev}} < 0\text{.}5$
(145)

The sixth flag signals low long term correlation value including the
current frame

$f_{\text{haev}_{\text{bg}}} = c_{\text{ev}\text{\_max}} < 0\text{.}4$
(146)

The seventh and last flag signals a non-speech like input signal

$f_{c2_{\text{bg}}} = (g_{\text{ad}_{}} > 0\text{.}5\text{\ AND\ }g_{\text{LP}_{}} < 7\text{.}\text{95})\text{==}0$
(147)

Using the above flags it is possible to express the mask as

$f_{\text{bg}_{M1}} = f_{\text{enr}_{\text{bg}}}\text{\ OR\ }((f_{\text{cns}_{\text{bg}}}\text{\ OR\ }f_{\text{lp}_{\text{bg}}})\text{\ AND\ }f_{\text{ns}}\text{\ AND\ }f_{\text{bg}_{\text{haco}}}\text{\ AND\ }f_{c2_{\text{bg}}})$
(148)

The two additional detectors $f_{\text{bg}_{A1}}$ and
$f_{\text{bg}_{A2}}$, are also those built using sub detectors and
additional conditions. Starting with $f_{\text{bg}_{A1}}$ the sub
detectors are:

$\begin{matrix}
f_{\text{bg}_{A1}} = & \begin{matrix}
(E_{t} < \text{55})\text{\ AND\ }f_{c2_{\text{bg}}}\text{\ AND} \\
((\text{comb}_{\text{ahc}} < 0\text{.}\text{85}\text{\ AND\ }(g_{\text{max\_}2_{\text{16}}} < 0\text{.}1\text{\ AND\ g}_{\text{max\_}0_{2}} < 0\text{.}1)\text{\ OR} \\
\text{comb}_{\text{ahc}} < 0\text{.}\text{15}\text{\ OR\ comb}_{\text{hcn}} < 0\text{.}\text{30}) \\
\end{matrix} \\
\end{matrix}$ (149)

where the combination metrics $\text{comb}_{\text{ahc}}$ and
$\text{comb}_{\text{hcm}}$are combinations where the maximum of a number
of metrics are used for the comparison

$\text{comb}_{\text{ahc}} = \text{max}(\text{max}({\overline{a}}_{\text{pred}},{\overline{c}}_{\text{ev}}),{\overline{g}}_{\text{ad}_{}})$
(150)

$\text{comb}_{\text{hcm}} = \text{max}(\text{max}({\overline{c}}_{\text{ev}},{\overline{g}}_{\text{max\_}2_{\text{16}}}),{\overline{g}}_{\text{max\_}0_{2}})$
(151)

For the $f_{\text{bg}_{A2}}$ sub detector

$f_{\text{bg}_{A2}} = (c_{\text{ev}\text{\_max}} < 0\text{.}4)\text{\ AND\ }({\overline{a}}_{\text{pred}} < 0\text{.}\text{85})\text{\ AND\ }(f_{c2_{\text{bg}}}\text{\ OR\ }f_{\text{enr}_{\text{bg}}})$
(152)

where the combination metric
$c_{\text{ev}\text{\_max}} = \text{max}({\overline{c}}_{\text{ev}},c_{\text{harm}}\text{==}0)$
is calculated as

$c_{\text{ev}\text{\_max}} = \text{max}({\overline{c}}_{\text{ev}},c_{\text{harm}}\text{==}0)$
(153)

The last term $f_{\text{bg}_{\text{ini}}}$ in the $f_{\text{UPDATE}}$
handles the special conditions of noise update during the
initialization, which occurs during the 150 first frames after the codec
start. Also the initialization flag is evaluated as a combination of two
flags according to

$f_{\text{bg}_{\text{ini}}} = f_{\text{bg}_{\text{ini}_{1}}}\text{\ AND\ }f_{\text{bg}_{\text{ini}_{2}}}$
(154)

where the first flag test for initialization period and a sufficient
number of frames without correlation event, according to

${f_{\text{bg}_{\text{ini}_{1}}} = \text{ini}_{\text{frame}} < \text{150}\text{\ AND\ \ \{}\overline{c}}_{\text{harm}} > 5\text{\ AND\ }(E_{t} - {\overline{E}}_{t}) < 7$
(155)

The second flag evaluates a number of earlier calculated features
against initialization specific thresholds according to

$\begin{matrix}
f_{\text{bg}_{\text{ini}_{2}}} = & \begin{matrix}
({\overline{a}}_{\text{pred}} < 0\text{.}\text{59}\text{AND\ \ \{}\overline{c} \\
\end{matrix}_{\text{ev}} < 0\text{.}\text{23})\text{\ OR} \\
 & \text{ev} < 0\text{.}\text{15}\text{\ OR} \\
 & \\
\end{matrix}$ (156)

Every frame an attempt is made to adjust the background noise estimate
upwards, as it is important not to do the update in active content
several conditions are evaluated in order to decide if update is
possible and how large an update that should be allowed. At the same
time it is important that possible updates are not prevented for
extended times. The noise update uses a flag to keep track of the number
of prevented noise updates. The same flag is also used to indicate that
no update has taken place. The flag $c_{\text{first}_{\text{updt}}}$ is
initialized to the value 0 to indicate that no update has been done so
far. When updates are successful it is set to 1 and for failed updates
the counter is incremented by 1.

If the above condition $f_{\text{UPDATE}}$is evaluated to 0, the noise
estimation only checks if the current content might be music by
evaluating the following condition

${c_{\text{Ntr}} > \text{300}\text{\ AND\ \ \{}\overline{c}}_{\text{ev}} > 0\text{.}\text{9\ AND\ \ \{}\overline{N}{}_{\text{tn}} > 0$.
(183)

If this is evaluated to 1 the sub-band noise level estimates are
reduced. This is done to recover from noise updates made before or
during music. The reduction is made per sub-band depending on if the
current estimate is high enough, according to

$\begin{matrix}
N_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) = 0\text{.}\text{98}N_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) & \text{for\ all\ i\ where\ } \\
\end{matrix}N_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) > 2E_{\text{MIN}}$.
(184)

and ${\overline{c}}_{\text{nup}_{0}}$is updated according to the
definition in equation (198) before noise estimation is terminated for
this frame.

The following steps are taken when $f_{\text{UPDATE}}$ is evaluated to
1. First the step size, $\text{step}_{\text{size}}$, is initially set to
0, before the process of determining if the noise update should be set
to 1.0, 0.1, or 0.01. For the update $\text{step}_{\text{size}}$ to be
set to 1.0 the following condition

$({\overline{a}}_{\text{pred}} < 0\text{.}\text{85}\text{\ AND\ }f_{\text{bg}_{\text{Nup}}})$
(157)

and any of the following conditions

${{\overline{E}}_{\text{tl}_{\text{dist}}} < \text{10}\text{\ OR\ }f_{\text{bg}_{\text{sd}_{1}}})\text{\ AND\ \ \{}\overline{N}}_{\text{dist}} < \text{40}\text{\ AND\ }(E_{t} - N_{t}) < \text{10}$
(158)

${c_{\text{first}_{\text{updt}}}\text{==}\text{0\ AND\ }c_{\text{harmb}} > \text{80\ AND\ \ \{}\overline{c}}_{p_{\text{count}}} > 0\text{.}\text{5\ }$
(159)

${f_{\text{bg}_{\text{ini}}}\text{\ AND\ }(f_{\text{bg}_{\text{Nup}}}\text{\ OR\ }\text{nonstaB} < \text{10}\text{\ OR\ \ \{}\overline{c}}_{\text{harm}} > \text{80})$
(188)

needs to be evaluated to 1. When this happens
$c_{\text{first}_{\text{updt}}}$is also set to 1 before the noise
estimation for the current frame is updated using the previously
calculated new value, according to

$\begin{matrix}
N_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) = N_{\text{tmp}}(i) & \text{for\ all\ i\ } \\
\end{matrix}$, (189)

where $N_{\text{tmp}}(i)$is the pre-calculated new noise estimate from
subclause 5.1.11.1. The noise estimation procedure is done for the
current frame after the ${\overline{c}}_{\text{nup}_{0}}$in equation
(198) is updated.

If the above condition has failed then the $\text{step}_{\text{size}}$
is set to 0.1 if any of the four following conditions are met

$(\text{act}_{\text{pred}} < 0\text{.}\text{80})\text{\ AND\ }(f_{\text{bg}_{\text{Nup}}}\text{\ OR\ }f_{\text{PAU}})\text{\ AND\ }({\overline{c}}_{\text{haco}} < 0\text{.}\text{10})$
(160)

$(\text{act}_{\text{pred}} < 0\text{.}\text{70})\text{\ AND\ }(f_{\text{bg}_{\text{Nup}}}\text{\ OR\ }\text{nonstaB} < \text{17})\text{\ AND\ f}_{\text{bg}_{\text{pauj}}}\text{\ AND\ }({\overline{c}}_{\text{haco}} < 0\text{.}\text{15})$
(161)

${{\overline{c}}_{\text{harm}} > \text{80}\text{\ AND\ \ \{}\overline{N}}_{t} > 5\text{\ AND\ }E_{t} < \text{min}(1\text{.}0,{\overline{E}}_{\text{tl}} + 1\text{.}5{\overline{E}}_{\text{vh2}})$
(192)

${\overline{c}}_{\text{harm}} > \text{50}\text{\ AND\ }c_{\text{first}_{\text{updt}}} > \text{30}\text{\ AND\ }f_{\text{bg}_{\text{Nup}}}\text{\ AND\ }c_{p_{\text{count}}} > 0\text{.}5$.
(193)

If the $\text{step}_{\text{size}}$ has been set to 0.1 it will be
reduced to 0.01 if

${f_{\text{bg}_{\text{Nup}}}\text{==}\text{0\ AND\ \ \{}\overline{c}}_{\text{harm}} < \text{50\ }$
(194)

and if the following condition is met

${\overline{a}}_{\text{pred}} > 0\text{.}\text{6\ OR\ }(f_{\text{bg}_{\text{ini}}}\text{==}\text{0\ AND\ }\text{nonstaB} > 8\text{\ AND\ }({\overline{E}}_{\text{tl}} - N_{t}) < \text{10}$.
(195)

If the $\text{step}_{\text{size}}$ is set to 0.1 or 0.01,
$c_{\text{first}_{\text{updt}}}$is set to 1 before the noise estimation
for the current frame is made according to

$\begin{matrix}
N_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) = N_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + \text{updt}_{\text{step}}(N_{\text{tmp}}(i) - N_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i)) & \text{for\ all\ }i \\
\end{matrix}$, (196)

and the noise estimation procedure is done for the current frame after
${\overline{c}}_{\text{nup}_{0}}$ is updated in equation (198).

If the conditions to set the $\text{step}_{\text{size}}$ to 0.1 or 0.01
have failed, the step size is still 0 and noise update has potentially
failed. After testing if the following condition is true

${f_{\text{bg}_{\text{Nup}}}\text{\ OR\ \ \{}\overline{c}}_{\text{harm}} > \text{100}$
(197)

the variable $c_{\text{first}_{\text{updt}}}$is incremented to keep
track of potentially failed updates and the noise estimation is done
after the following update of ${\overline{c}}_{\text{nup}_{0}}$.

In all cases the noise estimation updates end with an update of
${\overline{c}}_{\text{nup}_{0}}$ which is the long-term estimate of how
frequent noise estimations could be possible according to

${\overline{c}}_{\text{nup}_{0}} = (1 - \beta)c_{\text{nup}_{0}}^{\left\lbrack - 1 \right\rbrack} + \beta\left( p_{\text{nup}}\text{==}0 \right)\text{\ \ where\ }\beta = 0\text{.}2$
(198)

and where $p_{\text{nup}}$ is calculated in clause 5.1.11.2.6.

### 5.1.12 Signal activity detection

In this module active signal is detected in each frame and the main
flags for external use are the three flags$f_{\text{LSAD}_{\text{HE}}}$,
$f_{\text{LSAD}}$ and the combined $f_{\text{SAD}}$. These flags are set
to one for the active signal, which is any useful signal bearing some
meaningful information. Otherwise, they are set to zero indicating an
inactive signal, which has no meaningful information. The inactive
signal is mostly a pause or background noise. The three flags represent
different trade-offs between quality and efficiency, and are used
respectively by various subsequent processing modules.

The entire signal activity detection (SAD) module described in this
section consists of three sub-SAD modules. Two of the modules, namely
the SAD1 and the SAD2, work on the spectral analysis of the 12.8kHz
sampled signal, see subclause 5.1.12.1 and 5.1.12.2 respectively for
detailed descriptions. The third module, namely the SAD3, operates on
the CLDFB that runs on the input sampling frequency, see subclause
5.1.12.6. A preliminary activity decision, $f_{\text{SAD}}$, is first
obtained by combining two of the three sub-SAD modules, the SAD1 and
SAD2, for input with bandwidth greater than NB, or directly from SAD1
for NB input. This preliminary decision is then further combined with
the decision output $f_{\text{SAD}3}$ of the third sub-SAD module, the
SAD3, depending upon the codec mode of operation and the input signal
characteristic. The resulting decision is then feed to a DTX hangover
module to produce the final output $f_{\text{SAD}}$.

Internally the flag $f_{\text{SAD}_{\text{DTX}}}$ is used to always
produce a flag with DTX hangover whether DTX is on or off. When this no
longer is needed and DTX is on $f_{\text{SAD}_{\text{DTX}}}$ replaces
the combined $f_{\text{SAD}}$ to reduce the number of variables used
externally.

#### 5.1.12.1 SAD1 module

The SAD1 module is a sub-band SNR based SAD with hangover that utilizes
significance thresholds to reduce the amount off false detections for
energy variations in the background noise. During SAD initialization
period the following variables are set as follows

$\begin{matrix}
\text{nb}_{\text{act}_{\text{frame}}} = 3 \\
\text{lp}_{\text{speech}} = \text{45}\text{.}0 \\
f_{\text{SAD}_{\text{reg}_{h}}} = 0 \\
f_{\text{SAD}_{\text{reg}_{l}}} = 0 \\
f_{\text{SAD}_{\text{cnt}}} = 0 \\
f_{\text{LSAD}_{\text{reg}}} = 0 \\
f_{\text{LSAD}_{\text{cnt}}} = 0 \\
\end{matrix}$ (162)

The output of the SAD1 module is two binary flags (signal activity
decisions) $f_{\text{LSAD}_{\text{HE}}}$ and $f_{\text{LSAD}}$. The
difference between them is due to the setting of parameters for the
significance thresholds. The first binary decision
$f_{\text{LSAD}_{\text{HE}}}$ is used by the speech/music classification
algorithm described in clause 5.1.13.5. The second binary decision
$f_{\text{LSAD}}$ is developed further and leads to the final SAD1
decision, $f_{\text{SAD}}$. Note that all decisions can be modified by
the subsequent modules.

The spectral analysis described in clause 5.1.5 is performed twice per
frame. Let
$E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}\left( i \right)$and$E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}\left( i \right)$
denote the energy per critical band for the first and second spectral
analysis, respectively (as computed in clause 5.1.5.2). The average
energy per critical band for the whole frame and part of the previous
frame is computed as

${\overline{E}}_{\text{CB}}\left( i \right) = 0\text{.}2\ E_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}\left( i \right) + 0\text{.}4\ E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}\left( i \right) + 0\text{.}4\ E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}\left( i \right),\ i = b_{\text{min}},\ldots,\ b_{\text{max}}$
(163)

where $E_{\text{CB}}^{\lbrack - 1\rbrack}(i)$denotes the energy per
critical band from the second analysis of the previous frame,
$b_{\text{min}}$ and $b_{\text{max}}$ hereafter denote respectively the
minimum and the maximum critical band involved in the computation,
where$b_{\text{min}}$= 1, $b_{\text{max}}$= 16 for NB input signals and
$b_{\text{min}}$= 0, $b_{\text{max}}$= 19 for WB signals (see Table 2 in
subclause 5.1.5.1). The signal-to-noise ratio (SNR) per critical band is
then computed as

$\text{SNR}_{\text{CB}}\left( i \right) = \frac{{\overline{E}}_{\text{CB}}\left( i \right)}{N_{\text{CB}}\left( i \right)},\ i = b_{\text{min}},\ldots,\ b_{\text{max}},\ \text{constrained}\ \text{by}\ \text{SNR}_{\text{CB}} \geq 1$
(164)

where$N_{\text{CB}}\left( i \right)$ is estimated noise energy per
critical band, as explained in clause 5.1.11.1. The average SNR per
frame, in dB, is then computed using significance thresholds with two
different settings

$\begin{matrix}
\text{SNR}_{\text{av}_{\text{HE}}} = \text{10}\ \text{log}\left( \sum_{i = b_{\text{min}}}^{b_{\text{max}}}\left\{ \begin{matrix}
\text{SNR}_{\text{CB}}\left( i \right) & \text{if\ }\text{SNR}_{\text{CB}}\left( i \right) \geq \text{sign}_{\text{thr}_{\text{HE}}} \\
\text{min}_{\text{snr}_{\text{HE}}} & \text{othrewise} \\
\end{matrix} \right.\  \right) \\
\text{SNR}_{\text{av}} = \text{10}\ \text{log}\left( \sum_{i = b_{\text{min}}}^{b_{\text{max}}}\left\{ \begin{matrix}
\text{SNR}_{\text{CB}}\left( i \right) & \text{if\ }\text{SNR}_{\text{CB}}\left( i \right) \geq \text{sign}_{\text{thr}} \\
\text{min}_{\text{snr}} & \text{othrewise} \\
\end{matrix} \right.\  \right) \\
\end{matrix}$ (165)

where $\text{sign}_{\text{thr}_{\text{HE}}}$,
$\text{min}_{\text{snr}_{\text{HE}}}$, and $\text{min}_{\text{snr}}$ are
control parameters that differ between codec modes and sampling rates.

Table 6: Control parameters for the significance thresholds for
different bandwidths

  ----------- ------ ------ ------ ------
  Bandwidth                        
  NB          2.65   0.05   1.75   0.25
  WB          2.5    0.2    1.3    0.8
  SWB         2.5    0.2    1.75   0.25
  ----------- ------ ------ ------ ------

The signal activity is detected by comparing the two average SNR's per
frame to a certain threshold the first is then used without hangover and
the second has a hangover period added to prevent frequent switching at
the end of an active speech period. The threshold is a function of the
long-term SNR and the estimated frame to frame energy variations, mainly
the variation in noise but without the need to identify noise frames.
The initial estimate of the long-term SNR is given by

$\text{SNR}_{\text{LT}} = {\overline{E}}_{\text{sp}}^{\left\lbrack - 1 \right\rbrack} - {\overline{N}}_{t}^{\left\lbrack - 1 \right\rbrack}$
(166)

where${\overline{E}}_{\text{sp}}$ is the long-term active signal energy,
calculated in equation (167) and ${\overline{N}}_{t}$is the long-term
noise energy, calculated in equation (168). If this estimate is lower
than the signal dynamics estimate ${\overline{E}}_{\text{dyn}}$
calculated in equation (169). Then the estimate is adjusted according to

$\begin{matrix}
\text{SNR}_{\text{LT}} = \text{SNR}_{\text{LT}} + 1 \\
\text{if\ }\text{SNR}_{\text{LT}} > {\overline{E}}_{\text{dyn}} \\
\text{\ \ \ \ }\text{SNR}_{\text{LT}} = {\overline{E}}_{\text{dyn}} \\
\end{matrix}$ (170)

The energy variation is the ${\overline{E}}_{\text{vh}2}$ calculated in
equation (105) in clause 5.1.11.1.

The threshold calculation is calculated in three steps, one initial
value and two sequential modifications. The initial value is calculated
as

$\text{th}_{\text{SAD}} = n_{k} + n_{c}\text{SNR}_{\text{LT}} + n_{v}({\overline{E}}_{\text{vh}2} - n_{v_{\text{ofs}}})$
(171)

Where the function parameters,
$n_{k}\text{,\ }n_{c}\text{,\ }n_{v}\text{,\ and\ }n_{v_{\text{ofs}}}$
are set according to the current input bandwidth summarized in the
following table

Table 7: Functional parameters for the initial
$\text{th}_{\text{SAD}}$calculation for different bandwidths

  ------------ ----- ------ ------ ------
  Bandwidth                        
  NB           0.1   16.0   4.00   1.15
  WB and SWB   0.1   16.1   2.05   1.65
  ------------ ----- ------ ------ ------

If the estimated SNR conditions are good, i.e. if
$\text{SNR}_{\text{LT}} > \text{20}$, the threshold is updated and upper
limited for certain low-level NB signals. That is

$\begin{matrix}
\text{th}_{\text{SAD}} = \text{th}_{\text{SAD}} + 0\text{.}3(\text{SNR}_{\text{LT}} - \text{20}) \\
\text{if}\ (\text{BW} = \text{NB}\ \text{\ AND}\ \text{SNR}_{\text{LT}} > \text{40}\ \text{AND}\ \text{\ th}_{\text{SAD}} > \text{24}\text{.}1\ \text{\ AND\ }\ E_{t} < \text{45})\ \text{then}\ \text{th}_{\text{SAD}} = \text{24}\text{.}1 \\
\end{matrix}$ (172)

##### 5.1.12.1.1 SNR outlier filtering

The average SNR per frame, $\text{SNR}_{\text{av}}$, that is estimated
as shown in equation (202) is updated such that any sudden instantaneous
SNR variations in certain sub-bands do not cause spurious deviations in
the average SNR from the long term behaviour. A set of bands and SNRs
per band are determined and accumulated based on noise characteristics
as shown in equations (209), (210). The critical band that contains the
maximum average SNR is identified initially as the outlier band whose
index is represented as, $i_{\text{snr}_{\text{outlier}}}$, and the
outlier band SNR is given by,

$i_{\text{snr}_{\text{outlier}}} = \ i\ |_{\ \text{max}\left( \text{SNR}_{\text{CB}}(j) \right)},\ j = b_{\text{min}},\ldots,\ b_{\text{max}}$
(173)

$\text{SNR}_{\text{outlier}} = \text{SNR}_{\text{CB}}(i_{\text{snr}_{\text{outlier}}})$
(174)

The background noise energy is accumulated in bands $b_{\text{min}}$
through $b_{\text{min} + 2}$ and in bands $b_{\text{min} + 3}$ through
$b_{m\text{ax}}$.

$N_{\text{CB}_{L}} = \sum_{i = b_{\text{min}}}^{b_{\text{min} + 2}}{N_{\text{CB}}\left( i \right)}$
(175)

$N_{\text{CB}_{H}} = \sum_{i = b_{\text{min} + 3}}^{b_{\text{max}}}{N_{\text{CB}}\left( i \right)}$
(176)

The average SNR, $\text{SNR}_{\text{av}}$, is modified for WB and SWB
signals through outlier filtering as follows,

$\begin{matrix}
\text{if}\ (\ \text{SNR}_{\text{outlier}} < \text{MAX}_{\text{SNR\_OUTLIER\_3}}\ \text{AND}\ i_{\text{snr}_{\text{outlier}}} > 3\ \text{\ AND\ }\ i_{\text{snr}_{\text{outlier}}} < \text{MAX}_{\text{SNR\_OULIER\_IND}})\  \\
\left\{ \middle| \middle| \ \text{if}(\ N_{\text{CB}_{L}} > N_{\text{CB}_{H}}\  \ast \ \text{OUTLIER\_THR\_1}\ \text{OR}\ \text{SNR}_{\text{outlier}} < \text{MAX}_{\text{SNR\_OUTLIER\_1}}\ ) \middle| \middle| \ \text{SNR}_{\text{av}} = \text{SNR}_{\text{OUTLIER\_WGHT\_1}}\  \ast \ \left( \text{SNR}_{\text{av}} - \text{SNR}_{\text{outlier}} \right) \middle| \middle| \ \text{else}\ \text{if}(\ N_{\text{CB}_{L}} > N_{\text{CB}_{H}}\  \ast \ \text{OUTLIER\_THR\_2}\ \text{OR}\ \text{SNR}_{\text{outlier}} < \text{MAX}_{\text{SNR\_OUTLIER\_2}}\ ) \middle| \middle| \ \text{SNR}_{\text{av}} = \text{SNR}_{\text{OUTLIER\_WGHT\_2}}\  \ast \ \left( \text{SNR}_{\text{av}} - \text{SNR}_{\text{outlier}} \right) \middle| \middle| \ \text{else}\  \middle| \middle| \ \text{SNR}_{\text{av}} = \text{SNR}_{\text{OUTLIER\_WGHT\_3}}\  \ast \ \left( \text{SNR}_{\text{av}} - \text{SNR}_{\text{outlier}} \right) \middle| \right\} \\
\end{matrix}$(177)

The outlier filtering parameters used in updating the average SNR are
listed in the table below.

Table 8: SNR outlier filtering parameters

+----------------------------+-------+
| Parameter                  | value |
+----------------------------+-------+
| MAX\_SNR\_OUTLIER\_1       | 10    |
+----------------------------+-------+
| MAX\_SNR\_OUTLIER\_2       | 25    |
+----------------------------+-------+
| MAX\_SNR\_OUTLIER\_3       | 50    |
+----------------------------+-------+
| SNR\_OUTLIER\_WGHT\_1      | 1.0   |
+----------------------------+-------+
| SNR\_OUTLIER\_WGHT\_2      | 1.01  |
+----------------------------+-------+
| SNR\_OUTLIER\_WGHT\_3      | 1.02  |
+----------------------------+-------+
| OUTLIER\_THR\_1            | 10    |
+----------------------------+-------+
| OUTLIER\_THR\_2            | 6     |
+----------------------------+-------+
| Maximum outlier band index | 17    |
|                            |       |
| (MAX\_SNR\_OUTLIER\_IND)   |       |
+----------------------------+-------+
| TH\_CLEAN                  | 35    |
+----------------------------+-------+

Based on the outlier band estimated in equation (207), a weighting is
determined as per equation (211) and applied to SNRs per band (through
outlier filtering by subtracting the SNR in the outlier band) or on the
average SNR. The threshold, $\text{th}_{\text{SAD}}$, is updated based
on the outlier filtering and further statistics from background noise
level variations, previous frame coder type, and the weighting of SNR
per band. The threshold update is not performed when the long-term SNR,
$\text{SNR}_{\text{LT}}$is below the clean speech threshold, TH\_CLEAN =
35dB.

$\begin{matrix}
\text{if}\ (\ i_{\text{snr}_{\text{outlier}}}\text{<=}4\ \text{\ AND\ }\ \text{prev\_coder\_type} > \ \text{UNVOICED}\ )\  \\
\ \text{thr}_{\text{SAD}} = \text{thr}_{\text{SAD}} - 1\text{.}0 \\
\ \text{SNR}_{\text{av}} = \ \text{10}\text{*log}\text{10}\left( \text{SNR}_{\text{av}_{\text{lt}}} \right) \\
\ \text{else}\ \text{if}(\ \text{SNR}_{\text{outlier}} < \text{MAX}_{\text{SNR\_OUTLIER\_2}}\ \ \text{prev\_coder\_type}\  < \ \text{UNVOICED}) \\
\ \text{thr}_{\text{SAD}} = \text{thr}_{\text{SAD}} + \left( 1 - 0\text{.}\text{04}\ \text{SNR}_{\text{outlier}} \right) \\
\text{else} \\
\ \text{thr}_{\text{SAD}} = \text{thr}_{\text{SAD}} + \text{max}\left( 0,\ \left( 0\text{.}6 - 0\text{.}\text{01}\ \text{SNR}_{\text{outlier}} \right) \right)\  \\
\end{matrix}$ (178)

where the smoothed average SNR, $\text{SNR}_{\text{av}_{\text{lt}}}$, is
calculated after the SNR outlier filtering is performed in equation
(179).

$\text{SNR}_{\text{av}_{\text{lt}}}^{\lbrack\text{current}\rbrack}\  = \ 0\text{.}5\ \text{SNR}_{\text{av}_{\text{lt}}}^{\lbrack\text{prev}\rbrack}\  + 0\text{.}5\ \text{SNR}_{\text{av}}$
(180)

The updated threshold, $\text{th}_{\text{SAD}}$, as shown in equation
(181) and the updated average SNR, $\text{SNR}_{\text{av}}$, as shown in
equation (182) are used in signal activity detection logic as described
in Clause 5.1.12.3.

#### 5.1.12.2 SAD2 module

The SAD2 module is also a sub-band SNR based SAD and makes an activity
decision for each frame by measuring the frame's modified segmental SNR.
The output of SAD2 module is a binary flag $f_{\text{SAD}2}$ which is
set to 1 for active frame and set to 0 for inactive frame. For each
frame, the SNR per critical band is first computed. The average energy
per critical band for the whole frame and part of the previous frame is
computed as

${\overline{E}}_{\text{CB}}\left( i \right) = \begin{matrix}
\left\{ 0\text{.}2\ E_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}\left( i \right) + 0\text{.}4\ E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}\left( i \right) + 0\text{.}4\ E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}\left( i \right),\ i = b_{\text{min}},\ldots,\ b_{\text{max}}\ \text{if}\ E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}\left( i \right) > E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}\left( i \right) \middle| \right.\  \\
\end{matrix}$ (183)

where
$E_{\text{CB}}^{\left\lbrack - 1 \right\rbrack}\left( i \right)$denotes
the energy per critical band from the second spectral analysis of the
previous frame,
$E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}\left( i \right)$and$E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}\left( i \right)$
denote respectively the energy per critical band for the first and
second spectral analysis of the current frame, $b_{\text{min}}$= 0,
$b_{\text{max}}$= 19. More weighting is given to the energy of the
second spectral analysis for the current frame if the energy of the
second spectral analysis is higher than the first spectral analysis.
This is designed to improve the detection of signal onsets. The SNR per
critical band is then computed as

$\text{SNR}_{\text{CB}}\left( i \right) = \frac{{\overline{E}}_{\text{CB}}\left( i \right)}{N_{\text{CB}}\left( i \right)},\ i = b_{\text{min}},\ldots,\ b_{\text{max}},\ \text{constrained}\ \text{by}\ \text{SNR}_{\text{CB}} \geq 1$
(184)

where $N_{\text{CB}}\left( i \right)$ is the estimated noise energy per
critical band, as described in clause 5.1.11. The SNR per critical band
is then converted to a logarithmic domain as

$\text{SNR}_{\text{CB}\text{log}}(i) = \text{log}_{\text{10}}\left( \text{SNR}_{\text{CB}}(i) \right)$
(185)

The log SNR per critical band is then modified by

$\text{MSNR}_{\text{CB}}(i) = \left( \text{SNR}_{\text{CB}\text{log}}(i) + \alpha(i,\text{SNR}_{\text{LT}}) \right)^{\beta(\text{SNR}_{\text{LT}})},\ i = b_{\text{min}},\ldots,\ b_{\text{max}}$
(186)

where$\text{MSNR}_{\text{CB}}(i)$ is the modified SNR per critical band,
$\alpha(i,\text{SNR}_{\text{LT}})$ is an offset value which is a
function of the critical band and the long-term SNR of the input signal
as calculated in equation (166), summation of
$\text{SNR}_{\text{CB}\text{log}}(i) + \alpha(i,\text{SNR}_{\text{LT}})$
is constrained to be not greater than 2, and
$\beta(\text{SNR}_{\text{LT}})$ is an exponential factor used to
re-shape the mapping function between $\text{MSNR}_{\text{CB}}(i)$ and
$\text{SNR}_{\text{CB}}(i)$,$\beta(\text{SNR}_{\text{LT}})$ is also a
function of the long-term SNR of the input signal. The offset value
$\alpha(i,\text{SNR}_{\text{LT}})$ is determined as shown in the
following table

Table 9: Determination of $\alpha(i,\text{SNR}_{\text{LT}})$

  ---------------------------------- -------- ----------- ------------ ---------
                                     $i$\<2   2$$$i$\<7   7$$$i$\<18   18$$$i$
  $\text{SNR}_{\text{LT}}$\>24       0        0           0            0
  18\<$\text{SNR}_{\text{LT}}$$$24   0.1      0.2         0.2          0.2
  $\text{SNR}_{\text{LT}}$$$18       0.2      0.4         0.3          0.4
  ---------------------------------- -------- ----------- ------------ ---------

and $\beta(\text{SNR}_{\text{LT}})$is determined as

$\beta = \begin{matrix}
\left\{ 6\ \text{SNR}_{\text{LT}} > \text{18} \middle| \right.\  \\
\end{matrix}$ (187)

The modified segmental SNR is then computed as

$\text{MSSNR} = \sum_{i = b_{\text{min}}}^{b_{\text{max}}}\text{MSNR}_{\text{CB}}\left( i \right)$
(188)

and a relaxed modified segmental SNR is also computed. The procedure of
calculating the relaxed modified segmental SNR is similar to the
calculation of the modified segmental SNR with the only difference being
that, besides $\alpha(i,\text{SNR}_{\text{LT}})$, another offset value
$\gamma(i)$ is also added to the log SNR per critical band
$\text{SNR}_{\text{CB}\text{log}}(i)$ when calculating the relaxed
modified SNR per critical band. The relaxed modified SNR per critical
band is therefore computed as

$\text{RlxMSNR}_{\text{CB}}(i) = \left( \text{SNR}_{\text{CB}\text{log}}(i) + \alpha(i,\text{SNR}_{\text{LT}}) + \gamma(i) \right)^{\beta(\text{SNR}_{\text{LT}})},\ i = b_{\text{min}},\ldots,\ b_{\text{max}}$
(189)

where $\gamma(i)$ is a function of the critical band and is determined
as

$\gamma(i) = \begin{matrix}
\left\{ 0\text{.}4\ i < 7 \middle| \right.\  \\
\end{matrix}$ (190)

The relaxed modified segmental SNR is used in the hangover process at a
later stage of the algorithm.

A further enhancement (increase in value) is made to the modified
segmental SNR if an unvoiced signal is detected. Unvoiced signal is
detected if both of the two critical bands covering the highest
frequency range have SNRs greater than a threshold of 5, i.e. if
$\text{SNR}_{\text{CB}}\left( \text{18} \right) > 5$ and
$\text{SNR}_{\text{CB}}\left( \text{19} \right) > 5$. In this case, the
contributions of the overall modified segmental SNR from the two
critical bands is boosted. The boost is performed over the two critical
bands where the number of critical bands is extended from two to eight
and the corresponding modified segmental SNR is re-computed over the
extended bands as

$\text{MSSNR} = \left( \text{MSSNR} + 3 \cdot \text{MSNR}_{\text{CB}}(\text{18}) + 3 \cdot \text{MSNR}_{\text{CB}}(\text{19}) \right) \cdot \frac{\text{20}}{\text{26}}$
(191)

where multiplication by 20/26 effectively performs the mapping of the
modified segmental SNR calculated on the extended scale back onto the
same scale as if it were computed over the original 20 critical bands.
The re-computation of modified segmental SNR is only conducted if the
computed value is greater than before. If no unvoiced signal of above
type is detected, $N_{\text{sigCB}}$, which is the number of critical
bands whose SNR is greater than a threshold of 2 is determined. If
$N_{\text{sigCB}}$\>13, a second type unvoiced signal is detected, and
if the long-term SNR of the input signal$\text{SNR}_{\text{LT}}$ is
further below a threshold of 24, the modified segmental SNR in this case
is re-computed as

$\text{MSSNR} = \text{MSSNR} + \Delta$ (192)

where
$\Delta = 2\text{.}5 \cdot \text{SNR}_{\text{LT}} - \text{15}\text{.}5$
and is limited to be a positive value.

The primary signal activity decision is made in SAD2 by comparing the
modified segmental SNR to a decision threshold
$\text{THR}_{\text{SAD}2}$. The decision threshold is a piece wise
linear function of the long-term SNR of the input signal and is
determined as

$\text{THR}_{\text{SAD}2} = \begin{matrix}
\left\{ \text{MIN}\left\lbrack 2\text{.}4 \cdot \text{SNR}_{\text{LT}} - \text{42}\text{.}2,\ \text{80} \right\rbrack\ \text{SNR}_{\text{LT}} > \text{24} \middle| \right.\ \left\{ \text{MIN}\left\lbrack 2\text{.}4 \cdot \text{SNR}_{\text{LT}} - \text{40}\text{.}2,\ \text{80} \right\rbrack\ \text{18} < \text{SNR}_{\text{LT}} \leq \text{24} \middle| \right.\  \\
\end{matrix}$ (193)

If the modified segmental SNR is greater than the decision threshold,
the activity flag $f_{\text{SAD}2}$ is set to 1, and a counter of
consecutive active frames, $C_{\text{act}}$, used by SAD2 is incremented
by 1, and if the current frame is ineither a soft or a hard hangover
period as described later in this subclause, the corresponding hangover
period elapses by 1. Otherwise, the consecutive active frames counter
$C_{\text{act}}$ is set to 0 and the setting of$f_{\text{SAD}2}$ is
further evaluated by a hangover process.

The hangover scheme used by SAD2 consists of a soft hangover process
followed by a hard hangover process. The soft hangover is designed to
prevent low level voiced signals during a speech offset from being cut.
When within the soft hangover period, the SAD2 is operating in an offset
working state where the relaxed modified segmental SNR calculated
earlier is used to compare to the decision
threshold$\text{THR}_{\text{SAD}2}$(compared to the normal working state
where the modified segmental SNR is used). If the relaxed modified
segmental SNR is greater than the decision threshold, the activity flag
$f_{\text{SAD}2}$ is set to 1 and the soft hangover period elapses by 1.
Otherwise, if the relaxed modified segmental SNR is not greater than the
decision threshold, the soft hangover period is quit and the setting of
$f_{\text{SAD}2}$ is finally evaluated by a hard hangover process. When
within the hard hangover period, the activity flag $f_{\text{SAD}2}$ is
forced to 1 and the hard hangover period elapses by 1. The soft hangover
period is initialized if the number of consecutive voiced frames exceeds
3. The frame is considered a voiced frame if the pitch correlation is
not low and the pitch stays relatively stable, that is, if
$(C_{\text{norm}}^{\lbrack 0\rbrack} + C_{\text{norm}}^{\lbrack 1\rbrack} + C_{\text{norm}}^{\lbrack 2\rbrack})/3 + r_{e} > 0\text{.}\text{65}$
and
$\left( (d_{\text{OL}}^{\lbrack 0\rbrack} - d_{\text{OL}}^{\lbrack - 1\rbrack}) + (d_{\text{OL}}^{\lbrack 1\rbrack} - d_{\text{OL}}^{\lbrack 0\rbrack}) + (d_{\text{OL}}^{\lbrack 2\rbrack} - d_{\text{OL}}^{\lbrack 1\rbrack}) \right)/3 < \text{14}$
where
$C_{\text{norm}}^{\lbrack 0\rbrack}$,$C_{\text{norm}}^{\lbrack 1\rbrack}$,$C_{\text{norm}}^{\lbrack 2\rbrack}$
are respectively the normalized pitch correlation for the second half of
the previous frame, the first half of the current frame and the second
half of the current frame as calculated, $r_{e}$ is the noise correction
factor,
$d_{\text{OL}}^{\lbrack - 1\rbrack}$,$d_{\text{OL}}^{\lbrack 0\rbrack}$,$d_{\text{OL}}^{\lbrack 1\rbrack}$,$d_{\text{OL}}^{\lbrack 2\rbrack}$
are respectively the OL pitch lag for the second half of the previous
frame, the first half of the current frame, the second half of the
current frame and the look-ahead as described in subclause 5.1.10. The
value to which the soft hangover period is initialized is a function of
the long-term SNR of the input signal and the noise fluctuation
$\text{FLU}_{N}$ computed in equation (194), and is determined as

Table 10: Determination of the soft hangover period initialization
length

  -- --- --- ---
             
     1   1   2
     1   3   4
  -- --- --- ---

The hard hangover period is initialized if the consecutive active frames
counter $C_{\text{act}}$ reaches a threshold of 3. The value to which
the hard hangover period is initialized is also a function of the
long-term SNR of the input signal and the noise fluctuation, and is
determined as

Table 11: Determination of the hard hangover period initialization
length

  -- --- --- ---
             
     1   1   2
     1   1   3
  -- --- --- ---

The noise fluctuation $\text{FLU}_{N}$ is estimated over background
frames declared as inactive by the final SAD flag of SAD2,
$f_{\text{SAD}2}$, by measuring the moving average of the segmental SNR
in the logarithm domain. The noise fluctuation is computed as

$\begin{matrix}
\text{FLU}_{N} = \text{FLU}_{N}^{\lbrack - 1\rbrack} - (1 - \alpha) \cdot \delta \\
\delta = \text{FLU}_{N}^{\lbrack - 1\rbrack} - \sum_{i = b_{\text{min}}}^{b_{\text{max}}}\text{SNR}_{\text{CB}\text{log}}\left( i \right) \\
\end{matrix}$ (195)

where $\text{FLU}_{N}^{\lbrack - 1\rbrack}$ denotes the noise
fluctuation of the previous frame, $\alpha$is the forgetting factor
controlling the update rate of the moving average filter and is set to
0.99 for an increasing update ( when
$\text{FLU}_{N} > \text{FLU}_{N}^{\lbrack - 1\rbrack}$) and 0.9992 for a
decreasing update ( when
$\text{FLU}_{N} \leq \text{FLU}_{N}^{\lbrack - 1\rbrack}$). $\delta$ is
constrained by $\delta \leq \text{10}$ for decreasing updates and
$\delta \geq - \text{10}$for increasing updates. To speed up the
initialization of noise fluctuation, for the first 50 background frames,
$\alpha$is set to 0.9 for increasing updates and 0.95 for decreasing
updates, $\delta$ is constrained by $\delta \leq \text{30}$ for
decreasing updates and $\delta \geq - \text{50}$for increasing updates.

#### 5.1.12.3 Combined decision of SAD1 and SAD2 modules for WB and SWB signals

The decision of the SAD1 module is modified by the decision of the SAD2
module for WB and SWB signals.

For $f_{\text{LSAD}_{\text{HE}}}$ the decision logic is direct if the
average SNR per frame is larger than the SAD decision threshold and if
the final SAD2 flag is set to 1. That is,

$\text{if\ }\text{SNR}_{\text{av}_{\text{HE}}} > \text{th}_{\text{SAD}}\text{\ AND\ }f_{\text{SAD}2} = 1\ \text{then\ }f_{\text{LSAD}_{\text{HE}}} = 1,\text{\ otherwise\ }f_{\text{LSAD}_{\text{HE}}} = 0$
(196)

Likewise, for $f_{\text{LSAD}}$ the decision logic is direct if the
average SNR per frame is larger than the SAD decision threshold and if
the final SAD2 flag is set to 1.That is,

$\text{if\ }\text{SNR}_{\text{av}} > \text{th}_{\text{SAD}}\text{\ AND\ }f_{\text{SAD}2} = 1\ \text{then\ }f_{\text{LSAD}} = 1,f_{\text{SAD}} = 1$
(197)

otherwise, $f_{\text{LSAD}}$ is set to 0 and the hangover logic decides
if $f_{\text{SAD}}$ should be set to active or not.

The hangover logic works as a state machine that keeps track of the
number of frames since the last active primary decision and if a
sufficient number of consecutive active frames have occurred in a row to
allow the final decision to remain active even if the primary decision
has already gone inactive. Thus, if there has not been a sufficient
number of primary decisions in a row there is no hangover addition and
the final decision is set to inactive, that is $f_{\text{SAD}}$ is set
to 0 if $f_{\text{LSAD}}$ is 0.

The hangover length depends on $\text{SNR}_{\text{LT}}$, initially set
to 0 frames and if $\text{15} \leq \text{SNR}_{\text{LT}} < \text{35}$
it is set to 4 frames and if $\text{SNR}_{\text{LT}} < \text{15}$it is
set to 3 frames. The counting of hangover frames is reset only if at
least 3 consecutive active speech frames
($\text{SNR}_{\text{av}} > \text{th}_{\text{SAD}}$) were present,
meaning that no hangover is used
if$\text{SNR}_{\text{av}} > \text{th}_{\text{SAD}}$in only one or two
adjacent frames. This is to avoid adding the hangover after short energy
bursts in the acoustic signal, increasing the average data rate in the
DTX operation.

#### 5.1.12.4 Final decision of the SAD1 module for NB signals

Similarly to the WB case two primary decisions are generated but in this
case there is no dependency on the SAD2 module. If
$\text{SNR}_{\text{av}_{\text{HE}}} > \text{th}_{\text{SAD}}$ the frame
is declared as active and the primary SAD flag,
$f_{\text{LSAD}_{\text{HE}}}$ is set to1. Otherwise,
$f_{\text{LSAD}_{\text{HE}}}$is set to 0.

To get the final SAD decision $f_{\text{SAD}}$ there is a difference in
how the primary decision is made and how the hangover is handled
compared to WB. For NB signals the hangover has a window of 8 frames
after the last run of three consecutive active primary decision, that is
$\text{SNR}_{\text{av}} > \text{th}_{\text{SAD}}$. During this hangover
period the SAD decision is not automatically set to active; instead, the
threshold $\text{th}_{\text{SAD}}$is decreased by 5.2
if$\text{SNR}_{\text{LT}} < \text{19}$, and by 2 if
$\text{19} \leq \text{SNR}_{\text{LT}} < \text{35}$. The SAD decision is
then made by comparing the average SNR to the corrected threshold
following condition (172). Again, counting of hangover frames is reset
only if at least 3 consecutive active frames were present.

#### 5.1.12.5 Post-decision parameter update

After the final decision is formed, some SAD1-related long
term-parameters are updated according to the primary and final
decisions.

$\begin{matrix}
\text{prim}_{\text{act}_{\text{quick}}} = 0\text{.}\text{90}\text{prim}_{\text{act}_{\text{quick}}} + 0\text{.}\text{10}f_{\text{LSAD}} \\
\text{prim}_{\text{act}_{\text{slow}}} = 0\text{.}\text{99}\text{prim}_{\text{act}_{\text{slow}}} + 0\text{.}\text{01}f_{\text{LSAD}} \\
\end{matrix}$ (198)

These are then used to form a measure of the long term primary activity
of $f_{\text{LSAD}}$

$\text{prim}_{\text{act}} = 0\text{.}\text{90}\text{prim}_{\text{act}} + 0\text{.}\text{10}\text{min}(\text{prim}_{\text{act}_{\text{quic}}},\text{prim}_{\text{act}_{\text{slow}}})$
(199)

Similar metrics are generated for the $f_{\text{LSAD}_{\text{HE}}}$

$\begin{matrix}
\text{prim}_{\text{act}_{\text{quick}_{\text{HE}}}} = 0\text{.}\text{90}\text{prim}_{\text{act}_{\text{quick}_{\text{HE}}}} + 0\text{.}\text{10}f_{\text{LSAD}_{\text{HE}}} \\
\text{prim}_{\text{act}_{\text{slow}_{\text{HE}}}} = 0\text{.}\text{99}\text{prim}_{\text{act}_{\text{slow}_{\text{HE}}}} + 0\text{.}\text{01}f_{\text{LSAD}_{\text{HE}}} \\
\end{matrix}$ (200)

These are then used to form an measure of the long term primary activity
of $f_{\text{LSAD}}$

$\text{prim}_{\text{act}_{\text{HE}}} = 0\text{.}\text{90}\text{prim}_{\text{act}_{\text{HE}}} + 0\text{.}\text{10}\text{min}(\text{prim}_{\text{act}_{\text{quic}_{\text{HE}}}},\text{prim}_{\text{act}_{\text{slow}_{\text{HE}}}})$
(201)

To keep track of the history $f_{\text{SAD}}$ decisions the registers
$f_{\text{SAD}_{\text{reg}_{h}}}\text{,\ }f_{\text{SAD}_{\text{reg}_{l}}}\text{,\ }f_{\text{SAD}_{\text{cnt}}}$
are updated so that
$f_{\text{SAD}_{\text{reg}_{h}}}\text{\ and\ }f_{\text{SAD}_{\text{reg}_{l}}}$
keeps track of the latest 50 frames with regard to the $f_{\text{SAD}}$
decisions by removing the oldest decision and adding the latest and
updating $f_{\text{SAD}_{\text{cnt}}}$ so that it reflects the current
number of active frames in the registers.

Similarly to keep track of the history for $f_{\text{LSAD}}$ decisions
the registers
$f_{\text{LSAD}_{\text{reg}}}\text{\ and\ }f_{\text{LSAD}_{\text{cnt}}}$
are updated so that $f_{\text{LSAD}_{\text{reg}}}$ keeps track of the
latest 16 frames with regard to the $f_{\text{LSAD}}$ decisions by
removing the oldest decision and adding the latest and updating
$f_{\text{LSAD}_{\text{cnt}}}$ so that it reflects the current number of
active frames in the registers.

When the SAD decisions have been made, the speech music classifier
decision has been made and the noise estimation for the current frame
has been completed the long term estimates of active speech level,
${\overline{E}}_{\text{sp}}$, and long term noise level estimate
${\overline{N}}_{t}$can be updated. During the four first frames the
initialization is made for both variables using mainly the current input
as follows

${\begin{matrix}
{\overline{N}}_{t} = N_{t} \\
\text{if\ \ \{}\overline{E} \\
\end{matrix}_{\text{sp}}^{\left\lbrack - 1 \right\rbrack} < N_{t} + \text{10}\text{\ then\ \ \{}\overline{E}}_{\text{sp}}^{\left\lbrack 0 \right\rbrack} = N_{t} + \text{10}$
(202)

Where $N_{t}$ is the total sub band noise level after update for the
current frame. For the long term noise level estimate the initialization
uses different filter coefficient during the remainder of the 150 frames
initialization as follows

${\overline{N}}_{t} = (1 - \alpha){\overline{N}}_{t}^{\left\lbrack - 1 \right\rbrack} + \text{αN}_{t}\text{\ \ \ \ where\ }\alpha = \left\{ \begin{matrix}
0\text{.}\text{02} & \text{if\ }\text{ini}_{\text{frame}} < \text{150} \\
0\text{.}\text{05} & \text{otherwise} \\
\end{matrix} \right.\ $ (203)

For the active speech level the update after the initial four frames
only occurs if $f_{\text{LSAD}_{\text{HE}}}$ is 1 AND the
$f_{\text{high}_{\text{lpn}}}$ from the speech music classifier is 0.
Where $f_{\text{high}_{\text{lpn}}}$ is generated as
$L_{n} > L_{s}\text{\ AND\ \ }L_{n} > L_{m}$ based on the features
$L_{s},L_{m},L_{n}$ calculated based on equation (329) in subclause
5.1.13.6.3. If those conditions are met then the speech level estimate
is updated according to

${\overline{E}}_{\text{sp}} = \left\{ \begin{matrix}
0\text{.}\text{98\ \{}\overline{E} \\
\end{matrix}_{\text{sp}}^{\left\lbrack \text{-1} \right\rbrack} + 0\text{.}\text{02E}_{t} \middle| \middle| \text{if\ }({\overline{E}}_{\text{sp}}^{\left\lbrack \text{-1} \right\rbrack} - E_{t}) < \text{10} \middle| \middle| {\overline{E}}_{\text{sp}}^{\left\lbrack \text{-1} \right\rbrack} - 0\text{.}\text{05} \middle| \middle| \text{otherwise} \middle| \right.\ $
(204)

#### 5.1.12.6 SAD3 module

The SAD3 module is shown in Figure 12. The processing steps are
described as follows:

a)  Extract features of the signal according to the sub-band signals
    from CLDFB.

b)  Calculate some SNR parameters according to the extracted features of
    the signal and make a decision of background music.

c)  Make a pre-decision of SAD3 according to the features of the signal,
    the SNR parameters, and the output flag of the decision of
    background music and then output a pre-decision flag.

d)  The output of SAD3 is generated through the addition of SAD3
    hangover.

![](media/image11.wmf){width="6.614583333333333in"
height="4.260416666666667in"}

Figure 12: Block diagram of SAD3

##### 5.1.12.6.1 Sub-band FFT

Sub-band FFT is used to obtain spectrum amplitude of signal. Let *X\[k,
l\]* denote the output of CLDFB applied to the *l^th^* sample in the *k
^th^* sub-band. *X\[k,l\]* is converted into a frequency domain
representation from the time domain by FFT as follows:

$X_{\text{DFT}}\lbrack k,j\rbrack = \sum_{l = 0}^{\text{15}}{X\lbrack k,l\rbrack e^{- \frac{2\text{πi}}{\text{16}}\text{jl}}};0 \leq k < \text{10},0 \leq j < \text{16}$
(235)

The spectrum amplitude of each sample is computed in the following
steps:

Step 1: Compute the energy of $X_{\text{DFT}}\lbrack k,j\rbrack$ as
follows:

$X_{\text{DFT}_{\text{POW}}}\lbrack k,j\rbrack = ((\text{Re}(X_{\text{DFT}}\lbrack k,j\rbrack))^{2} + (\text{Im}(X_{\text{DFT}}\lbrack k,j\rbrack))^{2});0 \leq k < \text{10},0 \leq j < \text{16}$
(205)

where $\text{Re}(X_{\text{DFT}}\lbrack k,j\rbrack)$,
$\text{Im}(X_{\text{DFT}}\lbrack k,j\rbrack)$ are the real part and the
imaginary part of $X_{\text{DFT}}\lbrack k,j\rbrack$, respectively.

Step 2: If *k* is even, the spectrum amplitude, denoted by
$A_{\text{sp}}$, is computed by

$A_{\text{sp}}(8k + j) = \sqrt{X_{\text{DFT}_{\text{POW}}}\lbrack k,j\rbrack + X_{\text{DFT}_{\text{POW}}}\lbrack k,\text{15} - j\rbrack},$
$0 \leq k < \text{10},0 \leq j < 8$ (206)

If *k* is odd, the spectrum amplitude is computed by

$A_{\text{sp}}(8k + \text{7-}j) = \sqrt{X_{\text{DFT}_{\text{POW}}}\lbrack k,j\rbrack + X_{\text{DFT}_{\text{POW}}}\lbrack k,\text{15} - j\rbrack},$
$0 \leq k < \text{10},0 \leq j < 8$ (207)

##### 5.1.12.6.2 Computation of signal features

In Pre-decision Energy Features (EF), Spectral Centroid Features (SCF),
and Time-domain Stability Features (TSF) of the current frame are
computed by using the sub-band signal; Spectral Flatness Features (SFF)
and Tonality Features (TF) are computed by using the spectrum amplitude.

##### 5.1.12.6.2.1 Computation of EF {#computation-of-ef .H6}

The energy features of the current frame are computed by using the
sub-band signal. The energy of background noise of the current frame,
including both the energy of background noise over individual sub-band
and the energy of background noise over all sub-bands, is estimated with
the updated flag of background noise, the energy features of the current
frame, and the energy of background noise over all sub-bands of the
previous frame. The energy of background noise of the current frame will
be used to compute the SNR parameters of the next frame (see subclause
5.1.12.6.3). The energy features include the energy parameters of the
current frame and the energy of background noise. The energy parameters
of the frame are the weighted or non-weighted sum of energies of all
sub-bands.

The frame energy is computed by:

$E_{f} = \sum_{k = 1}^{(L_{C} - 2)}{{\overline{E}}_{C}(k)} + 0\text{.}\text{24}{\overline{E}}_{C}(0)$
(208)

The energy of sub-band divided non-uniformly is computed by:

$E_{f_{\text{snr}}}(i) = \sum_{j = N_{\text{region}}(i)}^{N_{\text{region}}(i + 1) - 1}{{\overline{E}}_{C}(j),}\text{\ \ \ \ \ }0 \leq i < N_{\text{snr}}$
(209)

Where $N_{\text{region}}$ is the sub-band division indices of
$E_{f_{\text{snr}}}(i)$. The sub-bands based on this kind of division
are also called SNR sub-bands and are used to compute the SNR of
sub-band. $N_{\text{snr}}$ is the number of SNR sub-bands.

The energy of sub-band background noise of the current frame is computed
by:

$E_{\text{bg}_{\text{snr}}}^{\lbrack 0\rbrack}(i) = \alpha\text{E}_{\text{bg}_{\text{snr}}}^{\lbrack - 1\rbrack}(i) + (1 - \alpha)E_{f_{\text{snr}}}^{\lbrack 0\rbrack}\text{,\ \ \ \ \ 0} < \alpha < \text{\ 1,\ }0 \leq i < N_{\text{snr}}$
(241)

Where $\text{E}_{\text{bg}_{\text{snr}}}^{\lbrack - 1\rbrack}(i)$ is
the energy of sub-band background noise of the previous frame.

The energy of background noise over all sub-bands is computed according
to the background update flag, the energy features of the current frame
and the tonality signal flag, and it is defined as follows:

$E_{f_{\text{bg}}}^{\lbrack 0\rbrack} = \frac{E_{f_{\text{bg}_{\text{sum}}}}^{\lbrack 0\rbrack}}{N_{f_{\text{bg}}}^{\lbrack 0\rbrack}}$
(210)

If certain conditions that include at least that the background update
flag is 1 and the tonality signal flag
$f_{\text{tonal}_{\text{signal}}}$ is 0 are met,
$E_{f_{\text{bg}_{\text{sum}}}}^{\lbrack 0\rbrack}$ and
$N_{f_{\text{bg}}}^{\lbrack 0\rbrack}$ are computed by:

$E_{f_{\text{bg}_{\text{sum}}}}^{\lbrack 0\rbrack} = E_{f_{\text{bg}_{\text{sum}}}}^{\lbrack - 1\rbrack} + E_{f}^{\lbrack 0\rbrack}$
(211)

$N_{f_{\text{bg}}}^{\lbrack 0\rbrack} = N_{f_{\text{bg}}}^{\lbrack - 1\rbrack} + 1$
(212)

Otherwise, $E_{f_{\text{bg}_{\text{sum}}}}^{\lbrack 0\rbrack}$ and
$N_{f_{\text{bg}}}^{\lbrack 0\rbrack}$ are computed by:

$E_{f_{\text{bg}_{\text{sum}}}}^{\lbrack 0\rbrack} = E_{f_{\text{bg}_{\text{sum}}}}^{\lbrack - 1\rbrack}$
(213)

$N_{f_{\text{bg}}}^{\lbrack 0\rbrack} = N_{f_{\text{bg}}}^{\lbrack - 1\rbrack}$
(214)

Where ![](media/image12.wmf){width="0.6527777777777778in"
height="0.2777777777777778in"} and
![](media/image13.wmf){width="0.4305555555555556in"
height="0.2777777777777778in"} are the sum of
![](media/image14.wmf){width="0.2222222222222222in"
height="0.2361111111111111in"} and the counter of
![](media/image15.wmf){width="0.2222222222222222in"
height="0.2361111111111111in"}, respectively. The superscript \[-1\]
denotes the previous frame and \[0\] denotes the current frame.

##### 5.1.12.6.2.2 Computation of SCF {#computation-of-scf .H6}

The spectral centroid features are the ratio of the weighted sum to the
non-weighted sum of energies of all sub-bands or partial sub-bands, or
the value is obtained by applying a smooth filter to this ratio. The
spectral centroid features can be obtained in the following steps:

a\) Divide the sub-bands for computing the spectral centroids as shown
in Table 12.

Table 12: Sub-band division for computing spectral centroids

  -------------------------------------- ----------------------------------- ---------------------------------
  Spectral centroid feature number (i)   $N_{\text{sc}_{\text{start}}}(i)$   $N_{\text{sc}_{\text{end}}}(i)$
  2                                      0                                   9
  3                                      1                                   23
  -------------------------------------- ----------------------------------- ---------------------------------

b\) Compute two spectral centroid features, i.e.: the spectral centroid
in the first interval and the spectral centroid in the second interval,
by using the sub-band division for computing spectral centroids in Step
a) and the following equation:

$F_{\text{SC}}(i) = (\sum_{k = N_{\text{sc}_{\text{start}}}(i)}^{N_{\text{sc}_{\text{end}}}(i)}{(k + 1){\overline{E}}_{C}(k) + \Delta_{1}\frac{)}{}\sum_{k = N_{\text{sc}_{\text{start}}}(i)}^{N_{\text{sc}_{\text{end}}}(i)}{{\overline{E}}_{C}(k) + \Delta_{2}),\text{\ \ }1 < i < 4\text{\ \ }}}$
(247)

c\) Smooth the spectral centroid in the second interval,
$F_{\text{SC}}(2)$ , to obtain the smoothed spectral centroid in the
second interval by

$F_{\text{SC}}^{\lbrack 0\rbrack}(0) = 0\text{.}7F_{\text{SC}}^{\lbrack\text{-1}\rbrack}(0) + 0\text{.}3F_{\text{SC}}^{\lbrack 0\rbrack}(2)$
(248)

##### 5.1.12.6.2.3 Computation of SFF {#computation-of-sff .H6}

Spectral Flatness Features are the ratio of the geometric mean to the
arithmetic mean of certain spectrum amplitude, or this ratio multiplied
by a factor. The spectrum amplitude$A_{\text{sp}}$, is smoothed as
follows:

$A_{\text{ssp}}^{\lbrack 0\rbrack}(i) = 0\text{.}7A_{\text{ssp}}^{\lbrack - 1\rbrack}(i) + 0\text{.}3A_{\text{sp}}^{\lbrack 0\rbrack}(i),\text{\ \ }0 \leq i < N_{A}$
(215)

where $A_{\text{ssp}}^{\lbrack 0\rbrack}(i)$ and
$A_{\text{ssp}}^{\lbrack - 1\rbrack}(i)$ are the smoothed spectrum
amplitude of the current frame and the previous frame, respectively.
$N_{A}$ is the number of spectrum amplitude.

Then the smoothed spectrum amplitude is divided into three frequency
regions as shown in Table 12 and the spectral flatness features are
computed for these frequency regions.

Table 12: Sub-band division for computing spectral flatness

+--------------------------+----+----+
| Spectral flatness number |    |    |
|                          |    |    |
| \(k\)                    |    |    |
+--------------------------+----+----+
| 0                        | 5  | 19 |
+--------------------------+----+----+
| 1                        | 20 | 39 |
+--------------------------+----+----+
| 2                        | 40 | 64 |
+--------------------------+----+----+

The spectral flatness features are the ratio of the geometric mean to
the arithmetic mean of the spectrum amplitude or the smoothed spectrum
amplitude.

Let $N(k) = N_{A_{\text{end}}}(k) - N_{A_{\text{start}}}(k)$+1 be the
number of the spectrum amplitudes used to compute the spectral flatness
feature$F_{\text{SF}}(k)$. We have

\(250\)

The spectral flatness features of the current frame are further smoothed
as follows:

$F_{\text{SSF}}^{\lbrack 0\rbrack}(k) = 0\text{.}\text{85}\text{F}_{\text{SSF}}^{\lbrack - 1\rbrack}(k) + 0\text{.}\text{15}F_{\text{SF}}^{\lbrack 0\rbrack}(k)$
(251)

Where $F_{\text{SSF}}^{\lbrack 0\rbrack}(k)$and
$F_{\text{SSF}}^{\lbrack\text{-1}\rbrack}(k)$ are the smoothed spectral
flatness features of the current frame and the previous frame
respectively.

##### 5.1.12.6.2.4 Computation of TSF {#computation-of-tsf .H6}

The time-domain stability features are the ratio of the variance of the
sum of energy amplitudes to the expectation of the squared sum of energy
amplitudes, or this ratio multiplied by a factor. The time-domain
stability features are computed with the energy features of the most
recent N frame. Let the energy of the n^th^ frame be
$E_{f}^{\lbrack n\rbrack}$. The energy amplitude of
$E_{f}^{\lbrack n\rbrack}$ is computed by

$A_{t1}^{\lbrack n\rbrack} = \sqrt{E_{f}^{\lbrack n\rbrack}} + 0\text{.}\text{001}$
(252)

By adding together the energy amplitudes of two adjacent frames from the
current frame to the N^th^ previous frame, N/2 sums of energy amplitudes
are obtained as

$A_{t2}^{\lbrack n\rbrack} = A_{t1}^{\lbrack\text{-2}n\rbrack} + A_{t1}^{\lbrack\text{-2}n - 1\rbrack}$
(253)

Where $A_{t1}^{\lbrack k\rbrack}$is the energy amplitude of the current
frame for *k* = 0 and $A_{t1}^{\lbrack k\rbrack}$the energy amplitude of
the previous frames for *k* \< 0.

Then the ratio of the variance to the average energy of the N/2 recent
sums is computed and the time-domain stability $F_{\text{TS}}$ is
obtained as follows:

$F_{\text{TS}} = \sum_{n = 0}^{\frac{N}{2} - 1}{(A_{t2}^{\lbrack n\rbrack} - \frac{1}{\frac{N}{2}}\sum_{n = 0}^{\frac{N}{2} - 1}A_{t2}^{\lbrack n\rbrack}\frac{)^{2}}{(}\sum_{n = 0}^{\frac{N}{2} - 1}{(A_{t2}^{\lbrack n\rbrack})^{2}} + 0\text{.}\text{0001})}$
(254)

Note that the value of N is different when computing different
time-domain stabilities.

##### 5.1.12.6.2.5 Computation of TF {#computation-of-tf .H6}

The tonality features are computed with the spectrum amplitudes. More
specifically, they are obtained by computing the correlation coefficient
of the amplitude difference of two adjacent frames, or with a further
smoothing of the correlation coefficient, in the following steps:

a\) Compute the spectrum-amplitude difference of two adjacent spectrum
amplitudes in the current frame. If the difference is smaller than 0,
set it to 0.

$D_{\text{sp}}(i) = \left\{ \begin{matrix}
0 \\
A_{\text{sp}}(i + 6) - A_{\text{sp}}(i + 5) \\
\end{matrix}\begin{matrix}
\text{if}A_{\text{sp}}(i + 6) < A_{\text{sp}}(i + 5) \\
\text{otherwise} \\
\end{matrix} \right.\ $ (255)

b\) Compute the correlation coefficient between the non-negative
amplitude difference of the current frame obtained in Step a) and the
non-negative amplitude difference of the previous frame to obtain the
first tonality features as follows:

$F_{\text{TR}} = \frac{\sum_{i = 0}^{N}{D_{\text{sp}}^{\lbrack 0\rbrack}(i)\text{\ D}_{\text{sp}}^{\lbrack - 1\rbrack}(i)}}{\sqrt{\sum_{i = 0}^{N}{(D_{\text{sp}}^{\lbrack 0\rbrack}(i))^{2}(D_{\text{sp}}^{\lbrack - 1\rbrack}(i))^{2}}}}$
(256)

where $D_{\text{sp}}^{\lbrack - 1\rbrack}(i)$ is the amplitude
difference of the previous frame.

Various tonality features can be computed as follows:

$\begin{matrix}
F_{T}(0) = F_{\text{TR}} \\
F_{T}^{\lbrack 0\rbrack}(1) = 0\text{.}\text{96}F_{T}^{\lbrack - 1\rbrack}(1) + 0\text{.}\text{04}F_{\text{TR}} \\
F_{T}^{\lbrack 0\rbrack}(2) = 0\text{.}\text{90}F_{T}^{\lbrack - 1\rbrack}(2) + 0\text{.}\text{10}F_{\text{TR}} \\
\end{matrix}$ (257)

where $F_{T}^{\lbrack - 1\rbrack}$ are tonality features of the previous
frame.

##### 5.1.12.6.3 Computation of SNR parameters 

The SNR parameters of the current frame are computed with the background
energy estimated from the previous frame, the energy parameters and the
energy of the SNR sub-bands of the current frame.

The SNR of all sub-bands is computed by:

$\text{SNR}_{t} = \text{log}_{2}((E_{f}^{\lbrack 0\rbrack} + 0\text{.}\text{0001}\frac{)}{(}E_{f_{\text{bg}}}^{\lbrack - 1\rbrack}))$
(258)

The average total SNR of all sub-bands is computed by:

$\text{SNR}_{\text{flux}} = (\sum_{}^{}{\text{SNR}_{t}(i)\frac{)}{N}}$
(259)

where N is number of the most recent frames and $\text{SNR}_{t}(i)$ is
$\text{SNR}_{t}$of the i^th^ frame.

The frequency-domain SNR is computed by:

$\text{SNR}_{f} = (\sum_{}^{}{\text{SNR}_{\text{sub}}(i)}\frac{)}{N_{\text{snr}}}$
(260)

where $N_{\text{snr}}$ is the number of SNR sub-band and
$\text{SNR}_{\text{sub}}(i)$is the SNR of the i^th^ sub-band by:

$\begin{matrix}
T(i) = \text{log}_{2}((E_{f_{\text{snr}}}^{\lbrack 0\rbrack}(i) + 0\text{.}\text{0001}\frac{)}{(}E_{\text{bg}_{\text{snr}}}^{\lbrack - 1\rbrack}(i) + 0\text{.}\text{0001})) \\
\text{SNR}_{\text{sub}}(i) = \left\{ \begin{matrix}
0\text{\ \ } \\
T(i) \\
\end{matrix} \right.\ \begin{matrix}
\text{if\ }T(i) < - 0\text{.}1 \\
\text{otherwise} \\
\end{matrix} \\
\end{matrix}$ (261)

The first long-time SNR is computed by:

$\text{SNR}_{\text{lt}_{\text{org}}} = \text{log}_{\text{10}}(\frac{E_{\text{lt}_{\text{active}}}^{\lbrack - 1\rbrack}}{E_{\text{lt}_{\text{inactive}}}^{\lbrack - 1\rbrack}})$
(262)

The computation method of
$E_{\text{lt}_{\text{active}}}^{\lbrack - 1\rbrack}$and
$E_{\text{lt}_{\text{inactive}}}^{\lbrack - 1\rbrack}$ can be found in
subclause 5.1.12.6.6.

The second long-time SNR is obtained by accordingly adjusting a
parameter $T_{\text{lt}_{\text{snr}}}$ associated with
$\text{SNR}_{\text{lt}_{\text{org}}}$ as follows:

$\text{SNR}_{\text{lt}} = T_{\text{lt}_{\text{snr}}} + 0\text{.}4(0\text{.}4T_{\text{lt}_{\text{snr}}} + 0\text{.}1)F_{\text{tnSC}0}$
(263)

where:

$F_{\text{tnSC}0} = \left\{ \begin{matrix}
0 \\
F_{\text{nSC}0}^{\lbrack - 1\rbrack} - 1\text{.}4 \\
0\text{.}8 \\
\end{matrix}\text{\ \ \ \ \ \ \ \ }\begin{matrix}
F_{\text{nSC}0}^{\lbrack - 1\rbrack} < 1\text{.}4 \\
1\text{.}4 \leq F_{\text{nSC}0}^{\lbrack - 1\rbrack} \leq 2\text{.}2 \\
F_{\text{nSC}0}^{\lbrack - 1\rbrack} > 2\text{.}2 \\
\end{matrix} \right.\ $ (264)

where $F_{\text{nSC}0}$ is the long-time background spectral centroid.
If the current frame is active frame and the background-update flag is
1, the long-time background spectral centroid of the current frame is
updated as follows:

$F_{\text{nSC}0}^{\lbrack 0\rbrack} = \text{αF}_{\text{nSC}0}^{\lbrack - 1\rbrack} + (1 - \alpha)F_{\text{SC}}^{\lbrack 0\rbrack}(0),\text{\ \ \ }\alpha \in (\text{0,1})$
(265)

where $F_{\text{nSC}0}^{\lbrack - 1\rbrack}$ is the long-time background
spectral centroid of the previous frame.

The initial long-time frequency-domain SNR of the current frame
$\text{SNR}_{l}^{\lbrack 0\rbrack}$ is computed by:

$\text{SNR}_{l}^{\lbrack 0\rbrack} = \frac{S_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack}}{N_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack}} - \frac{S_{\text{ns}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack}}{N_{\text{ns}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack}}$
(266)

where $S_{\text{sp}_{\text{snr}_{f}}}$ and
$N_{\text{sp}_{\text{snr}_{f}}}$ are respectively the frequency-domain
SNR $\text{SNR}_{f}$accumulator and frequency-domain SNR
$\text{SNR}_{f}$ counter when the current frame is pre-decided as active
sound, and $S_{\text{ns}_{\text{snr}_{f}}}$ and
$N_{\text{ns}_{\text{snr}_{f}}}$ are respectively $\text{SNR}_{f}$
accumulator and $\text{SNR}_{f}$ counter when the current frame is
pre-decided as inactive sound. The superscript \[-1\] denotes the
previous frame. The details of computation can be found in Steps e) and
i) of subclause 5.1.12.6.6.

The smoothed average long-time frequency-domain SNR is computed by:

$\text{SNR}_{\text{lf}_{\text{smooth}}}^{\lbrack 0\rbrack} = 0\text{.}9\text{SNR}_{\text{lf}_{\text{smooth}}}^{\lbrack - 1\rbrack} + 0\text{.}1\text{SNR}_{l}^{\lbrack 0\rbrack}$
(267)

The long-time frequency-domain SNR is computed by:

$\begin{matrix}
\text{SNR}_{\text{lf}} = \left\{ \begin{matrix}
0 \\
T_{\text{lf}_{\text{snr}}} \\
\text{MAX\_LF\_SNR} \\
\end{matrix}\text{\ \ \ \ \ \ \ \ \ \ }\begin{matrix}
T_{\text{lf}_{\text{snr}}} < 0 \\
0 \leq T_{\text{lf}_{\text{snr}}} \leq \text{MAX\_LF\_SNR} \\
T_{\text{lf}_{\text{snr}}} > \text{MAX\_LF\_SNR} \\
\end{matrix} \right.\  \\
T_{\text{lf}_{\text{snr}}} = 0\text{.}\text{12}(\text{SNR}_{l}^{\lbrack 0\rbrack} - 3) \\
\end{matrix}$ (268)

where MAX\_LF\_SNR is the maximum of $\text{SNR}_{\text{lf}}$ .

##### 5.1.12.6.4 Decision of background music 

With the energy features, $F_{T}$, $F_{\text{TS}}$, $F_{\text{SSF}}$,
and $F_{\text{SC}}$ of the current frame, the tonality signal flag of
the current frame is computed and used to determine whether the current
frame is tonal signal. If it is a tonal signal, the current frame is
music and the following procedure is carried out:

a\) Suppose the current frame is a non-tonal signal, and a flag
$f_{\text{tonal}_{\text{frame}}}$ is used to indicate whether the
current frame is a tonal frame. If $f_{\text{tonal}_{\text{frame}}}$ =
1, the current frame is a tonal frame. If
$f_{\text{tonal}_{\text{frame}}}$ = 0, the current frame is a non-tonal
frame.

b\) If $F_{T}(0)$\>0.6 or its smoothed value $F_{T}(1)$ is greater than
0.86., go to Step c). Otherwise, go to Step d).

c\) Verify the following three conditions:

> \(1\) The time-domain stability feature $F_{\text{TS}}(5)$ is smaller
> than 0.072;
>
> \(2\) The spectral centroid feature $F_{\text{SC}}(0)$ is greater than
> 1.2;
>
> \(3\) One of three spectral flatness features is smaller than its
> threshold,
> $F_{\text{SSF}}(0) < 0\text{.}\text{76\ OR\ }F_{\text{SSF}}(1) < 0\text{.}88\text{\ \ OR\ \ }F_{\text{SSF}}(2) < 0\text{.}\text{96}$.

If all the above conditions are met, the current frame is considered as
a tonal frame and the flag $f_{\text{tonal}_{\text{frame}}}$ is set to
1. Then go to Step d).

d\) Update the tonal level feature $l_{\text{tonal}}$ according to the
flag $f_{\text{tonal}_{\text{frame}}}$. The initial value of
$l_{\text{tonal}}$ is set in the region \[0, 1\] when the active-sound
detector begins to work.

$l_{\text{tonal}}^{\lbrack 0\rbrack} = \left\{ \begin{matrix}
0\text{.}\text{975}l_{\text{tonal}}^{\lbrack - 1\rbrack} + 0\text{.}\text{025} \\
0\text{.}\text{997}l_{\text{tonal}}^{\lbrack - 1\rbrack} \\
\end{matrix}\text{\ \ \ \ }\begin{matrix}
\text{if\ }f_{\text{tonal}_{\text{frame}}}\text{\ is\ 1\ } \\
\text{otherwise} \\
\end{matrix} \right.\ $ (269)

Where $l_{\text{tonal}}^{\lbrack 0\rbrack}$ and
$l_{\text{tonal}}^{\lbrack - 1\rbrack}$ are respectively the tonal level
of the current frame and the previous frame.

e\) Determine whether the current frame is a tonal signal according to
the updated $l_{\text{tonal}}^{\lbrack 0\rbrack}$ and set the tonality
signal flag $f_{\text{tonal}_{\text{signal}}}$.

If $l_{\text{tonal}}^{\lbrack 0\rbrack}$ is greater than 0.5, the
current frame is determined as a tonal signal. Otherwise, the current
frame is determined as a non-tonal signal.

$f_{\text{tonal}_{\text{signal}}} = \left\{ \begin{matrix}
1 \\
0 \\
\end{matrix}\text{\ \ }\begin{matrix}
\text{if\ }l_{\text{tonal}}^{\lbrack 0\rbrack} > \text{\ 0}\text{.}\text{5\ } \\
\text{otherwise} \\
\end{matrix} \right.\ $ (270)

##### 5.1.12.6.5 Decision of background update flag

The background update flag is used to indicate whether the energy of
background noise is updated and its value is 1 or 0. When this flag is
1, the energy of background noise is updated. Otherwise, it is not
updated.

The initial background update flag of the current frame is computed by
using the energy features, the spectral centroid features, the
time-domain stability features, the spectral flatness features, and the
tonality features of the current frame. The initial background update
flag is updated with the VAD decision, the tonality features, the SNR
parameters, the tonality signal flag, and the time-domain stability
features of the current frame to obtain the final background update
flag. With the obtained background update flag, background noise is
detected.

First, suppose the current frame is background noise. If any one of the
following conditions is met, the current frame is not noise signal.

a\) The time-domain stability $F_{\text{TS}}(5)$ \> 0.12;

b\) The spectral centroid $F_{\text{SC}}(0)$ \> 4.0 and the time-domain
stability $F_{\text{TS}}(5)$ \> 0.04;

c\) The tonality feature $F_{T}(1)$ \> 0.5 and the time-domain stability
$F_{\text{TS}}(5)$ \> 0.1;

d\) The spectral flatness of each sub-band or the average obtained by
smoothing the spectral flatness is smaller than its specified threshold,
or one of three spectral flatness features is smaller than its
threshold: ![](media/image17.wmf){width="2.9305555555555554in"
height="0.20833333333333334in"};

e\) The energy of the current frame $E_{f}$ is greater than a specified
threshold:
$E_{f}^{\lbrack 0\rbrack} > \text{32}E_{\text{sf}}^{\lbrack - 1\rbrack}$,
where $E_{\text{sf}}^{\lbrack - 1\rbrack}$ is the long time smoothed
energy of the previous frame and $E_{\text{sf}}^{\lbrack k\rbrack}$ of
k^th^ frame is computed :
$E_{\text{sf}}^{\lbrack k\rbrack} = 0\text{.}\text{95}E_{\text{sf}}^{\lbrack k - 1\rbrack} + 0\text{.}\text{05}E_{f}^{\lbrack k\rbrack}$;

f\) The tonality features $F_{T}$ are greater than their corresponding
thresholds: $F_{T}(1)$\>0.60 **OR** $F_{T}(0)$\>0.86;

g\) The initial background update flag can be obtained in Steps a) - f).
The initial background update flag is then updated. When the SNR
parameters, the tonality features, and the time-domain stability
features are smaller than their corresponding thresholds :
$\text{SNR}_{f}$ \<0.3 **AND** $\text{SNR}_{t}$\<1.2
**AND**$F_{T}(1)$\<0.5 **AND** $F_{\text{TS}}(3)$\<0.1 and both the
combined $f_{\text{SAD}}$ and $f_{\text{tonal}_{\text{signal}}}$ are set
to 0, the background update flag is updated to 1.

##### 5.1.12.6.6 SAD3 Pre-decision

The SAD3 decision $f_{\text{SAD}3}$is computed with the tonality signal
flag, the SNR parameters, the spectral centroid features, and the energy
features. The SAD3 decision is made in the following steps:

a\) Obtain the second long-time SNR $\text{SNR}_{\text{lt}}$ by
computing and adjusting the ratio of the average energy of long-time
active frames to the average energy of long-time background noise for
the previous frame;

b\) Compute the average of $\text{SNR}_{t}$for a number of recent frames
to obtain $\text{SNR}_{\text{flux}}$;

c\) Compute the SNR threshold for making SAD3 decision, denoted
by$T_{\text{snr}_{f}}$, with the spectral centroid features
$F_{\text{SC}}$ , the second long-time SNR $\text{SNR}_{\text{lt}}$, the
long-time frequency-domain SNR $\text{SNR}_{\text{lf}}$, the number of
previous continuous active frames $N_{\text{continuous}_{\text{sp}}1}$ ,
and the number of previous continuous noise frames
$N_{\text{continuous}_{\text{ns}}}$. Set the initial value of
$T_{\text{snr}_{f}}$to$\text{SNR}_{\text{lt}}$. First, adjust
$T_{\text{snr}_{f}}$ with the spectral centroid features, if the
spectral centroids are located in the different regions, an appropriate
offset may be added to$T_{\text{snr}_{f}}$. Then, $T_{\text{snr}_{f}}$
is further adjusted according to $N_{\text{continuous}_{\text{sp}}1}$ ,
$N_{\text{continuous}_{\text{ns}}}$, $\text{SNR}_{\text{flux}}$, and
$\text{SNR}_{\text{lf}}$. When $N_{\text{continuous}_{\text{sp}}1}$ is
greater than its threshold, the SNR threshold is appropriately
decreased. When $N_{\text{continuous}_{\text{ns}}}$ is greater than its
threshold, the SNR threshold is appropriately increased. If
$\text{SNR}_{\text{lt}}$ is greater than a specified threshold, the SNR
threshold may be accordingly adjusted.

d\) Make an initial VAD decision with the SAD3 decision threshold
$T_{\text{snr}_{f}}$ and the SNR parameters such as $\text{SNR}_{f}$ and
$\text{SNR}_{t}$ of the current frame. First $f_{\text{SAD}3}$ is set to
0. If $\text{SNR}_{f}$ \>$T_{\text{snr}_{f}}$, or
$\text{SNR}_{t} > 4\text{.}0$ , $f_{\text{SAD}3}$ is set to 1. The
initial VAD decision can be used to compute the average energy of
long-time active frames $E_{\text{lt}_{\text{active}}}$ . The value of
$E_{\text{lt}_{\text{active}}}$ is used to make SAD3 decision for the
next frame.

$E_{\text{lt}_{\text{active}}}^{\lbrack 0\rbrack} = \frac{E_{\text{fg}_{\text{sum}}}^{\lbrack 0\rbrack}}{N_{\text{fg}}^{\lbrack 0\rbrack}}$
(271)

where $E_{\text{fg}_{\text{sum}}}^{\lbrack 0\rbrack}$ and
$N_{\text{fg}}^{\lbrack 0\rbrack}$ is computed by:

$E_{\text{fg}_{\text{sum}}}^{\lbrack 0\rbrack} = \left\{ \begin{matrix}
E_{\text{fg}_{\text{sum}}}^{\lbrack - 1\rbrack} + E_{f}^{\lbrack 0\rbrack} \\
E_{\text{fg}_{\text{sum}}}^{\lbrack - 1\rbrack} \\
\end{matrix} \right.\ \begin{matrix}
\text{if}f_{\text{SAD}3} = 1 \\
\text{otherwise} \\
\end{matrix}$ (272)

$N_{\text{fg}}^{\lbrack 0\rbrack} = \left\{ \begin{matrix}
N_{\text{fg}}^{\lbrack - 1\rbrack} + 1 \\
N_{\text{fg}}^{\lbrack - 1\rbrack} \\
\end{matrix}\begin{matrix}
\text{if}f_{\text{SAD}3} = 1 \\
\text{otherwise} \\
\end{matrix} \right.\ $ (273)

e\) Update the initial SAD3 decision according to the tonality signal
flag, the average total SNR of all sub-bands, the spectral centroids,
and the second long-time SNR. If the tonality signal flag
$f_{\text{tonal}_{\text{signal}}}$ is 1, $f_{\text{SAD}3}$ is set to 1.
The parameters $S_{\text{sp}_{\text{snr}_{f}}}$ and are updated by:

$S_{\text{sp}_{\text{snr}_{f}}}^{\lbrack 0\rbrack} = \left\{ \begin{matrix}
S_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack} + \text{SNR}_{f}^{\lbrack 0\rbrack} \\
S_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack} \\
\end{matrix}\text{\ \ }\begin{matrix}
\text{if}\text{\ \ }f_{\text{SAD}3} = 1\text{\ \ }\text{and}\text{\ \ }\text{SNR}_{f}^{\lbrack 0\rbrack} > (\frac{S_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack}}{N_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack}}) \\
\text{otherwise} \\
\end{matrix} \right.\ $ (274)

$N_{\text{sp}_{\text{snr}_{f}}}^{\lbrack 0\rbrack} = \left\{ \begin{matrix}
N_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack} + 1 \\
N_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack} \\
\end{matrix}\text{\ \ }\begin{matrix}
\text{if}\text{\ \ }f_{\text{SAD}3} = 1\text{\ \ }\text{and}\text{\ \ }\text{SNR}_{f}^{\lbrack 0\rbrack} > (\frac{S_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack}}{N_{\text{sp}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack}}) \\
\text{otherwise} \\
\end{matrix} \right.\ $ (275)

If $\text{SNR}_{\text{flux}}$ \>(B+ $\text{SNR}_{\text{lt}}$ \*A), where
A and B are two constants, $f_{\text{SAD}3}$ is set to 1. If any one of
the following conditions is met:

condition 1:
$\text{SNR}_{\text{flux}} > 2\text{.}1 + 0\text{.}\text{24}\text{SNR}_{\text{lt}}$

condition 2:
$\text{SNR}_{\text{flux}} > T_{1}\text{\ and\ F}_{\text{SC}}(3) > T_{2}\text{\ and\ SNR}_{\text{lt\_org}} < T_{3}$

$f_{\text{SAD}3}$ is to 1. Where $T_{1}$, $T_{2}$ and $T_{3}$ are the
thresholds.

f\) Update the number of hangover frames for active sound according to
the decision result, the long-time SNR, and the average total SNR of all
sub-bands for several previous frames, and the SNR parameters and the
SAD3 decision for the current frame; See subclause 5.1.12.6.7 for
details;

g\) Add the active-sound hangover according to the decision result and
the number of hangover frames for active sound of the current frame to
make the SAD3 decision;

h\) Make a combined decision with $f_{\text{SAD}}$ and
$f_{\text{SAD}3}$. The output flag of the combined decision is namely
combined$f_{\text{SAD}}$. See subclause 5.1.12.7;

i\) After Steps g) and h), the average energy of long-time background
noise, denoted by$E_{\text{lt}_{\text{inactive}}}$, can be computed with
the SAD decisions combined $f_{\text{SAD}}$ and
$f_{\text{SAD}}$.$E_{\text{lt}_{\text{inactive}}}$ is used to make the
SAD decision for the next frame. If both combined $f_{\text{SAD}}$ and
$f_{\text{SAD}}$ are 0, $S_{\text{ns}_{\text{snr}_{f}}}$,
$N_{\text{ns}_{\text{snr}_{f}}}$ are updated and
$E_{\text{lt}_{\text{inactive}}}$is computed as follows:

$S_{\text{ns}_{\text{snr}_{f}}}^{\lbrack 0\rbrack} = \left\{ \begin{matrix}
S_{\text{ns}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack} + \text{SNR}_{f}^{\lbrack 0\rbrack} \\
S_{\text{ns}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack} \\
\end{matrix}\text{\ \ }\begin{matrix}
\text{if}f_{\text{SAD}} = 0\text{and}\text{the}\text{combined}f_{\text{SAD}} = 0 \\
\text{otherwise} \\
\end{matrix} \right.\ $ (276)

$N_{\text{ns}_{\text{snr}_{f}}}^{\lbrack 0\rbrack} = \left\{ \begin{matrix}
N_{\text{ns}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack} + 1 \\
N_{\text{ns}_{\text{snr}_{f}}}^{\lbrack - 1\rbrack} \\
\end{matrix}\text{\ \ }\begin{matrix}
\text{if}f_{\text{SAD}} = 0\text{and}\text{the}\text{combined}f_{\text{SAD}} = 0 \\
\text{otherwise} \\
\end{matrix} \right.\ $ (277)

$E_{\text{lt}_{\text{inactive}}}^{\lbrack 0\rbrack} = \frac{E_{\text{bg}_{\text{sum}}}^{\lbrack 0\rbrack}}{N_{\text{bg}}^{\lbrack 0\rbrack}}$
(278)

where $E_{\text{bg}_{\text{sum}}}^{\lbrack 0\rbrack}$ and
$N_{\text{bg}}^{\lbrack 0\rbrack}$ is computed by:

$E_{\text{bg}_{\text{sum}}}^{\lbrack 0\rbrack} = \left\{ \begin{matrix}
E_{\text{bg}_{\text{sum}}}^{\lbrack - 1\rbrack} + E_{f}^{\lbrack 0\rbrack} \\
E_{\text{bg}_{\text{sum}}}^{\lbrack - 1\rbrack} \\
\end{matrix} \right.\ \begin{matrix}
\text{if}f_{\text{SAD}} = 0\text{and}\text{the}\text{combined}f_{\text{SAD}} = 0 \\
\text{otherwise} \\
\end{matrix}$ (279)

$N_{\text{bg}}^{\lbrack 0\rbrack} = \left\{ \begin{matrix}
N_{\text{bg}}^{\lbrack - 1\rbrack} + 1 \\
N_{\text{bg}}^{\lbrack - 1\rbrack} \\
\end{matrix}\begin{matrix}
\text{if}f_{\text{SAD}} = 0\text{and}\text{the}\text{combined}f_{\text{SAD}} = 0 \\
\text{otherwise} \\
\end{matrix} \right.\ $ (280)

The functions of the Pre-decision module are described in Steps a) - e)
in this subclause.

##### 5.1.12.6.7 SAD3 Hangover

The long-time SNR and the average total SNR of all sub-bands are
computed with the sub-band signal (See subclause 5.1.12.6.2.1 and
5.1.12.6.3). The current number of hangover frames for active sound is
updated according to the SAD3 decision of several previous frames,
$\text{SNR}_{\text{lt}_{\text{org}}}$, $\text{SNR}_{\text{flux}}$ ,
other SNR parameters, and the SAD3 decision of the current frame. The
precondition for updating the current number of hangover frames for
active sound is that the flag of active sound indicates that the current
frame is active sound. If both the number of previous continuous active
frames $N_{\text{continuous}_{\text{sp}}2}$\<8 and
$\text{SNR}_{\text{lt}_{\text{org}}}$\<4.0, the curent number of
hangover frames for active sound is updated by subtracting
$N_{\text{continuous}_{\text{sp}}2}$ from the minimum number of
continuous active frames. Suppose the minimum number of continuous
active frames is 8. The updated number of hangover frames for active
sound, denoted by $N_{\text{hang}}$, is computed as follows:

$N_{\text{hang}} = 8 - N_{\text{continuous}_{\text{sp}}2}$ (281)

Otherwise, if both $\text{SNR}_{\text{flux}}$ \> 0.9 and
$N_{\text{continuous}_{\text{sp}}2}$ \> 50, the number of hangover
frames for active sound is set according to the value of
$\text{SNR}_{\text{lt}}$. Otherwise, this number of hangover frames is
not updated.

$N_{\text{continuous}_{\text{sp}}2}$ is set to 0 for the first frame.
When the current frame is the second frame and the subsequent frames,
$N_{\text{continuous}_{\text{sp}}2}$ is updated according to the
previous combined $f_{\text{SAD}}$ as follows:

> If the previous combined $f_{\text{SAD}}$ is 1,
> $N_{\text{continuous}_{\text{sp}}2}$ is increased by 1;
>
> If the previous combined $f_{\text{SAD}}$ is 0,
> $N_{\text{continuous}_{\text{sp}}2}$ is set to 0.

#### 5.1.12.7 Final SAD decision

The feature parameters mentioned above are divided into two categories.
The first feature category includes the number of continuous active
frames$N_{\text{continuous}_{\text{sp}}2}$, the average total SNR of all
sub-bands$\text{SNR}_{\text{flux}}$, and the tonality signal flag
$f_{\text{tonal}_{\text{signal}}}$. $\text{SNR}_{\text{flux}}$ is the
average of SNR over all sub-bands for a predetermined number of frames.
The second feature category includes the flag of noise type, the
smoothed average long-time frequency-domain SNR
$\text{SNR}_{\text{lf}_{\text{smooth}}}$ in a predetermined period of
time, the number of continuous noise frames, frequency-domain SNR.

First, the parameters in the first and second feature categories and
$f_{\text{SAD}}$ and $f_{\text{SAD}3}$ are obtained. The first and
second feature categories are used for the SAD detection.

The combined decision is made in the following steps:

a)  Compute the energy of background noise over all sub-bands for the
    previous frame with the background update flag, the energy
    parameters, and the tonality signal flag of the previous frame and
    the energy of background noise over all sub-bands of the previous 2
    frames. Computing the background update flag is described in
    subclause 5.1.12.6.5.

b)  Compute the above-mentioned $\text{SNR}_{\text{flux}}$ with the
    energy of background noise over all sub-bands of the previous frame
    and the energy parameters of the current frame.

c)  Determine the flag of noise type according to the above-mentioned
    parameters $\text{SNR}_{\text{lt}_{\text{org}}}$ and
    $\text{SNR}_{\text{lf}_{\text{smooth}}}$. First, the noise type is
    set to non-silence. Then, when $\text{SNR}_{\text{lt}_{\text{org}}}$
    is greater than the first preset threshold and
    $\text{SNR}_{\text{lf}_{\text{smooth}}}$ is greater than the second
    preset threshold, the flag of noise type is set to silence.

Then, the features in the first and second feature categories,
$f_{\text{SAD}3}$ and $f_{\text{SAD}}$ are used for active-sound
detection in order to make the combined decision of SAD.

When the input sampling frequency is 16 kHz and 32 kHz, the decision
procedure is carried out as follows:

a\) Select $f_{\text{SAD}3}$ as the initial value of the
combined$f_{\text{SAD}}$;

b\) If the noise type is silence, and the frequency-domain SNR
$\text{SNR}_{f}$ is greater than 0.2 and the combined $f_{\text{SAD}}$
set 0, $f_{\text{SAD}}$ is selected as the output of the SAD, combined
$f_{\text{SAD}}$ . Otherwise, go to Step c).

c\) If the smoothed average long-time frequency-domain SNR is smaller
than 10.5 or the noise type is not silence, go to Step d). Otherwise,
the initial value of the combined $f_{\text{SAD}}$ in Step a) is still
selected as the decision result of the SAD;

d\) If any one of the following conditions is met, the result of a
logical operation **OR** of $f_{\text{SAD}3}$ and $f_{\text{SAD}}$ is
used as the output of the SAD. Otherwise, go to Step e):

Condition 1: The average total SNR of all sub-bands is greater than the
first threshold, e.g. 2.2;

Condition 2: The average total SNR of all sub-bands is greater than the
second threshold, e.g. 1.5 and the number of continuous active frames is
greater than 40;

Condition 3: The tonality signal flag is set to 1.

e\) When the input sampling frequency is 32 kHz: If the noise type is
silence, $f_{\text{SAD}}$ is selected as the output of the SAD and the
decision procedure is completed. Otherwise, the initial value of the
combined $f_{\text{SAD}}$ in Step a) is still selected as the decision
result of the SAD. When the input sampling frequency is 16 kHz:
$f_{\text{SAD}}$ is selected as the output of the SAD and the decision
procedure is completed.

When the input sampling frequency is neither 16 kHz nor 32 kHz, the
procedure of the combined decision is performed as follows:

a\) Select $f_{\text{SAD}3}$ as the initial value of the
combined$f_{\text{SAD}}$;

b\) If the noise type is silence, go to Step c). Otherwise, go to Step
d);

c\) If the smoothed average long-time frequency-domain SNR is greater
than 12.5 and $f_{\text{tonal}_{\text{signal}}}$=0, the combined
$f_{\text{SAD}}$ is set to$f_{\text{SAD}}$. Otherwise, the initial value
of combined $f_{\text{SAD}}$ in Step a) is selected as the decision
result of the SAD;

d\) If any one of the following conditions is met, the result of a
logical operation **OR** of $f_{\text{SAD}3}$ and $f_{\text{SAD}}$ is
used as the output of the final SAD, combined $f_{\text{SAD}}$.
Otherwise, the initial value of combined $f_{\text{SAD}}$ in Step a) is
selected as the decision result of the SAD;

Condition 1: The average total SNR of all sub-bands is greater than 2.0;

Condition 2: The average total SNR of all sub-bands is greater than 1.5
and the number of continuous active frames is greater than 30;

Condition 3: The tonality signal flag is set to 1.

After the combined $f_{\text{SAD}}$ is obtained by using the
above-mentioned method, it needs to be modified as follows:

a\) Compute the number of background-noise updates,
$N_{\text{update\_count}}$ according to the background update flag,
specifically:

When the current frame is indicated as background noise by the
background update flag and $N_{\text{update\_count}}$ is smaller than
1000, $N_{\text{update\_count}}$ increases by 1. Note that
$N_{\text{update\_count}}$ is set to zero at the initialization of the
codec.

b\) Compute number of modified frames for active sound,
$N_{\text{md\_frames}}$ according to the SAD3 decision
$f_{\text{SAD}3}$, the number of background-noise updates
$N_{\text{update\_count}}$, and the number of hangover frames for active
sound $N_{\text{hang}}$, specifically:

When the current frame is indicated as active sound by $f_{\text{SAD}3}$
and $N_{\text{update\_count}}$ is smaller than 12,
$N_{\text{md\_frames}}$ is selected as *max*(20, $N_{\text{hang}}$).

c\) Compute the final decision of SAD for the current frame according to
the number of modified frames for active sound $N_{\text{md\_frames}}$
and the combined $f_{\text{SAD}}$, specifically:

When the current frame is indicated as inactive sound by the combined
$f_{\text{SAD}}$ and $N_{\text{md\_frames}}$ is greater than 0, the
final decision of SAD for the current frame, the combined
$f_{\text{SAD}}$ is modifiedas active sound and $N_{\text{md\_frames}}$
decreases by 1.

#### 5.1.12.8 DTX hangover addition

For better DTX performance a version $f_{\text{SAD}_{\text{DTX}}}$ of
the combined $f_{\text{SAD}}$ is generated through the addition of
hangover. In this case there are two concurrent hangover logics that can
extend the $f_{\text{SAD}_{\text{DTX}}}$ active period. One is for DTX
in general and one specifically to add additional DTX hangover in the
case of music.

During the SAD initialization period the following variables are set as
follows

$\begin{matrix}
\text{ho}_{\text{cnt}} = 0 \\
\text{ho}_{\text{cnt}_{\text{dtx}}} = 0 \\
\text{ho}_{\text{cnt}_{\text{music}}} = 0 \\
\end{matrix}$ (216)

The general DTX hangover works in the same way as the SAD1 hangover the
main difference is in the hangover length. Also here the initial DTX
hangover length depends on $\text{SNR}_{\text{LT}}$, initially the
hangover is set to 2 frames and if the current input bandwidth is NB and
$\text{SNR}_{\text{LT}} < \text{16}$ or
$\text{prim}_{\text{act}_{\text{HE}}} > 0\text{.}\text{95}$it is set to
3, then follows a number of steps that may modify this start value. The
modification depends on other input signal characteristics and codec
mode.

The first two modifications increases the hangover length if there has
already been a high activity, additional activity after a long burst has
little effect on the total activity but can better cover short pauses.
If there has been 12 or more active frames from the primary detector in
SAD1 during the 16 last frames, that is
$f_{\text{LSAD}_{\text{cnt}}} > \text{12}$, the allowed number of
hangover frames is increased with 2 frames. Similarly if there has been
40 or more active frames for the final decision of SAD1 during the last
50 frames , that is $f_{\text{SAD}_{\text{cnt}}} > \text{40}$, the
allowed number of hangover frames is increased with 5 frames. At this
point the allowed number of hangover frames may have been increased with
7 frames over the initial value, and to limit the total number of
hangover frames it is therefore limited to
$\text{HANGOVER}_{\text{LONG}} - 1$. Another condition for limiting the
hangover addition is if the primary activity becomes low there are
different limits for different codec conditions, for AMR\_WB\_IO core
the limit is 2, the same limit is also used for high SNR
$\text{SNR}_{\text{LT}} > \text{25}$ for WB or SWB input in other
conditions the limit is 3 frames. The condition for applying the limit
is if the primary activity $f_{\text{LSAD}_{\text{cnt}}} < 7$ or if the
$\text{SNR}_{\text{LT}} > \text{16}\text{\ and\ }\text{prim}_{\text{act}_{\text{HE}}} < 0\text{.}\text{85}$.

The DTX hangover can also be reduced if the final decision from SAD3
already includes a long hangover.

According to the noise type in SAD3, the decrement of the DTX hangover
is set as shown in Table 13.

Table 13: Setting of the decrement of the DTX hangover

  ----------- -------------------- ------------------------
  Bandwidth   Silence-type noise   Non-silence-type noise
  NB          0                    1
  WB          2                    3
  SWB         2                    1
  ----------- -------------------- ------------------------

As for the hangover in SAD1 the counting of DTX hangover frames is reset
only if at least 3 consecutive active speech frames
($f_{\text{SAD}}\text{==}1$) or if the SAD1 final decision has been
active for over 45 of the 50 latest frames.

For the music hangover to start counting music hangover frames
$\text{prim}_{\text{act}_{\text{HE}}} > 0\text{.}\text{98}$ AND
$E_{t} > \text{40}$ AND $f_{\text{LSAD}_{\text{cnt}}} > \text{14}$ AND
$f_{\text{SAD}_{\text{cnt}}} > \text{48}$ at which point the
$f_{\text{SAD}}\text{==}1$ for the next 15 frames or until hangover is
terminated by the hangover termination logic, which can be triggered by
the flag $f_{\text{hoT}}$ which is described below.

The DTX hangover and the hangover described in subclause 5.1.12.3 when
decisions from SAD1 and SAD2 are combined may be early terminated. The
early hangover termination helps to increase the system capacity by
saving unnecessary hangover frames. At each hangover frame, the comfort
noise which will be produced at the decoder side is estimated at the
encoder side, assuming if the current hangover frame would be encoded as
the first SID frame after active burst. If the estimated comfort noise
is found close to the noise characteristic maintained in the local CNG
module in the encoder side, then no more hangover frame is considered
needed and the hangover is terminated. Otherwise, hangover keeps on as
long as the initial hangover length is not reached.

Specifically, the energy and the LSP spectrum of the comfort noise which
will be produced at the decoder side are estimated at the encoder side.
The energy of the current frame excitation is calculated

$E_{\text{sid}} = \frac{1}{L}\sum_{n = 0}^{L - 1}{r(n)^{2}}$ (217)

which is then converted to log domain

$E_{\text{sid}}^{'} = \text{log}_{2}E_{\text{sid}}$ (218)

where $r(n)$ is the LP excitation of the current frame calculated in
subclause 5.6.2.1.5, $L$ is the frame length,$E_{\text{sid}}^{'}$ is
limited to non-negative value. An age weighted average energy,
$\text{enr}_{\text{hist} - \text{ave} - \text{weighted}}$, is calculated
from hangover frames except the current frame in the same way as
described in sub-clause 6.7.2.1.2. The
$\text{enr}_{\text{hist} - \text{ave} - \text{weighted}}$, together with
the energy of the current frame excitation $E_{\text{sid}}$ are used to
compute the estimated excitation energy for the comfort noise,
$E_{\text{est}}$.

$E_{\text{est}} = \alpha \cdot \text{enr}_{\text{hist} - \text{ave} - \text{weighted}} + (1 - \alpha) \cdot E_{\text{sid}}$
(219)

where $\alpha$ is a smoothing factor, $\alpha$= 0.8 if $m$, the number
of hangover frames used for
$\text{enr}_{\text{hist} - \text{ave} - \text{weighted}}$ calculation is
less than 3, otherwise, $\alpha$= 0.95. The estimated excitation energy
for the comfort noise is then converted to log domain

$E_{\text{est}}^{'} = \text{log}_{2}E_{\text{est}}$ (220)

where $E_{\text{est}}^{'}$ is bounded to non-negative value. An average
LSP vector, $\text{ho}_{\text{lsp} - \text{ave} - \text{weighted}}$, is
calculated over the same hangover frames where the age weighted average
energy $\text{enr}_{\text{hist} - \text{ave} - \text{weighted}}$ is
calculated in the same way as described in sub-clause 6.7.2.1.2. The
$\text{ho}_{\text{lsp} - \text{ave} - \text{weighted}}$, together with
the end-frame LSP vector of the current frame are used to compute the
estimated LSP vector for the comfort noise, $q_{\text{est}}$.

$q_{\text{est}} = 0\text{.}8 \cdot \text{ho}_{\text{lsp} - \text{ave} - \text{weighted}} + 0\text{.}2 \cdot q_{\text{end}}$
(221)

A set of energy and LSP difference parameters are calculated. The
difference between the current frame log excitation energy and the log
hangover average excitation energy is calculated.

$\text{dE}_{s2h} = \left| E_{\text{sid}}^{'} - \text{log}_{2}(\text{enr}_{\text{hist} - \text{ave} - \text{weighted}}) \right|$
(222)

The difference between the current frame end-frame LSP vector and the
hangover average LSP vector is calculated.

$\text{dq}_{s2h} = \sum_{k = 0}^{M - 1}\left| q_{\text{end}}(k) - \text{ho}_{\text{lsp} - \text{ave} - \text{weighted}}(k) \right|$
(223)

where $M$ is the order of LP filter. The difference between the
estimated log excitation energy for the comfort noise and the current
log excitation energy for the comfort noise kept in the local CNG module
is calculated.

$\text{dE} = \left| E_{\text{est}}^{'} - \text{log}_{2}E_{\text{CN}} \right|$
(224)

where $E_{\text{CN}}$ is the comfort noise excitation energy kept in the
local CNG module as calculated in subclause 5.6.2.1.6. The difference
between the estimated LSP vector for the comfort noise and the current
LSP vector for the comfort noise kept in the local CNG module is
calculated.

$\text{dq} = \sum_{k = 0}^{M - 1}\left| q_{\text{est}}(k) - \hat{\overline{q}}(k) \right|$
(225)

where $\hat{\overline{q}}$ is the comfort noise LSP vector kept in the
local CNG module as calculated in subclause 5.6.2.1.4. The maximum
difference per LSP element between the estimated LSP vector for the
comfort noise and the current LSP vector for the comfort noise kept in
the local CNG module is calculated.

$\text{dq}_{\text{max}} = \text{max}\left( \left| q_{\text{est}}(k) - \hat{\overline{q}}(k) \right|,\ k = 0,1,\text{.}\text{.}\text{.},M - 1 \right)$
(226)

The hangover termination flag $f_{\text{hoT}}$ is set to 1 if
$\text{dq} < 0\text{.}4$ and $\text{dE} < 1\text{.}4$ and
$\text{dq}_{s2h} < 0\text{.}4$ and $\text{dE}_{s2h} < 1\text{.}2$ and
$\text{dq}_{\text{max}} < 0\text{.}1$ when operating in VBR mode, or if
$\text{dq} < 0\text{.}4$ and $\text{dE} < 0\text{.}8$ and
$\text{dq}_{s2h} < 0\text{.}4$ and $\text{dE}_{s2h} < 0\text{.}8$ and
$\text{dq}_{\text{max}} < 0\text{.}1$ when operating in non-VBR mode.
Otherwise $f_{\text{hoT}}$ is set to 0. A $f_{\text{hoT}}$ set to 1
means the current frame can be encoded as a SID frame even it is still
in the hangover period. For safety reason of prevent CNG on short pauses
between speech utterances, the actual encoding of SID frame is delayed
by one frame.

### 5.1.13 Coding mode determination

To get the maximum encoding performance, the LP-based core uses a signal
classification algorithm with six distinct coding modes tailored for
each class of signal, namely the Unvoiced Coding (UC) mode, Voiced
Coding (VC) mode, Transition Coding (TC) mode, Audio Coding (AC) mode,
Inactive Coding (IC) mode and Generic Coding (GC) mode. The signal
classification algorithm uses several parameters, some of them being
optimized separately for NB and WB inputs.

Figure 13 shows a simplified high-level diagram of the signal
classification procedure. In the first step, the SAD decision is queried
whether the current frame is active or inactive. In case of inactive
frame, IC mode is selected and the procedure is terminated. In the IC
mode the inactive signal is encoded either in the transform domain by
means of the AVQ technology or in the time/transform domain by means of
the GSC technology, described below. In case of active frames, the
speech/music classification algorithm is run to decide whether the
current frame shall be coded with the AC mode. The AC mode, has been
specifically designed to efficiently encode generic audio signals,
particularly music. It uses a hybrid encoding technique, called the
Generic Signal audio Coder (GSC) which combines both, LP-based coder
operated in the time domain and a transform-domain coder. If the frame
is not classified as "audio", the classification algorithm continues
with selecting unvoiced frames to be encoded with the UC mode. The UC
mode is designed to encode unvoiced frames. In the UC mode, the adaptive
codebook is not used and the excitation is composed of two vectors
selected from a linear Gaussian codebook.

If the frame is not classified as unvoiced, then detection of stable
voiced frames is applied. Quasi-periodic segments are encoded with the
VC mode. VC selection is conditioned by a smooth pitch evolution. It
uses ACELP technology, but given that the pitch evolution is smooth
throughout the frame, more bits are assigned to the algebraic codebook
than in the GC mode.

The TC mode has been designed to enhance the codec performance in the
presence of frame erasures by limiting the usage of past information
\[19\]. To minimize at the same time its impact on a clean channel
performance, it is used only on the most critical frames from a frame
erasure point of view -- these are voiced frames following voiced
onsets.

If a frame is not classified in one of the above coding modes, it is
likely to contain a non-stationary speech segment and is encoded using a
generic ACELP model (GC).

Figure 13: High-level diagram of the coding mode determination procedure

The selection of the coding modes is not uniform across the bitrates and
input signal bandwidth. These differences will be described in detail in
the subsequent sections. The classification algorithm starts with
setting the current mode to GC.

#### 5.1.13.1 Unvoiced signal classification

The unvoiced parts of the signal are characterized by a missing periodic
component. The classification of unvoiced frames exploits the following
parameters:

> -- voicing measures
>
> -- spectral tilt measures
>
> -- sudden energy increase from a low level to detect plosives
>
> -- total frame energy difference
>
> -- energy decrease after spike

##### 5.1.13.1.1 Voicing measure

The normalized correlation, used to determine the voicing measure, is
computed as part of the OL pitch searching module described in clause
5.1.10. The average normalized correlation is then calculated as

${\overline{R}}_{\text{xy}3} = \frac{1}{3}\left( C_{\text{norm}}^{\left\lbrack 0 \right\rbrack} + C_{\text{norm}}^{\left\lbrack 1 \right\rbrack} + C_{\text{norm}}^{\left\lbrack 2 \right\rbrack} \right)$
(293)

where $C_{\text{norm}}^{\left\lbrack i \right\rbrack}$is defined in
subclause 5.1.11.3.2.

##### 5.1.13.1.2 Spectral tilt

The spectral tilt parameter contains information about frequency
distribution of energy. The spectral tilt is estimated in the frequency
domain as a ratio between the energy concentrated in low frequencies and
the energy concentrated in high frequencies, and is computed twice per
frame.

The energy in high frequencies is computed as the average of the
energies in the last two critical bands

${\overline{E}}_{h} = 0\text{.}5\left( E_{\text{CB}}\left( b_{\text{max}} - 1 \right) + E_{\text{CB}}\left( b_{\text{max}} \right) \right)$
(294)

where $E_{\text{CB}}(i)$ are the critical band energies, computed in
subclause 5.1.5.2 and $b_{\text{max}}$is the maximum useful critical
band ($b_{\text{max}}$= 19 for WB inputs and $b_{\text{max}}$= 16 for NB
inputs).

The energy in low frequencies is computed as the average of the energies
in the first 10 critical bands for WB signals and in 9 critical bands
for NB signals. The middle critical bands have been excluded from the
computation to improve the discrimination between frames with
high-energy concentration in low frequencies (generally voiced) and with
high-energy concentration in high frequencies (generally unvoiced). In
between, the energy content is not informative for any of the classes
and increases the decision uncertainty.

The energy in low frequencies is computed differently for voiced
half-frames with short pitch periods and for other inputs. For voiced
female speech segments, the harmonic structure of the spectrum is
exploited to increase the voiced-unvoiced discrimination. These frame
are characterized by the following the condition

$0\text{.}5\left( C_{\text{norm}}^{\lbrack 0\rbrack} + C_{\text{norm}}^{\lbrack 1\rbrack} \right) + r_{e} > 0\text{.}6\ \text{AND}\ T_{\text{OL}}^{\lbrack 2\rbrack} < \text{128}$
(295)

where $C_{\text{norm}}^{\lbrack i\rbrack}$ are computed as defined in
subclause 5.1.10.4 and the noise correction factor $r_{e}$ as defined in
subclause 5.1.10.6. For these frames,${\overline{E}}_{l}$is computed
bin-wise and only frequency bins sufficiently close to the speech
harmonics are taken into account in the summation. That is

${\overline{E}}_{l} = \frac{1}{C}\sum_{k = K_{\text{min}}}^{\text{25}}{E_{\text{BIN}}\left( k \right)w_{h}}\left( k \right)$
(296)

where $K_{\text{min}}$ is the first bin ($K_{\text{min}}$= 1 for WB
inputs and $K_{\text{min}}$= 3 for NB inputs) and $E_{\text{BIN}}(k)$
are the bin energies, as defined in subclause 5.1.5.2, in the first 25
frequency bins (the DC component is not considered). Note that these 25
bins correspond to the first 10 critical bands and that the first 2 bins
not included in the case of NB input constitute the first critical band.
In the summation above, only the terms related to the bins close to the
pitch harmonics are considered. So $w_{h}\left( k \right)$is set to 1,
if the distance between the nearest harmonics is not larger than a
certain frequency threshold (50 Hz) and is set to 0 otherwise. The
counter $C$ is the number of the non-zero terms in the summation. In
other words, only bins closer than 50 Hz to the nearest harmonics are
taken into account. Thus, only high-energy terms will be included in the
sum if the structure is harmonic at low frequencies. On the other hand,
if the structure is not harmonic, the selection of the terms will be
random and the sum will be smaller. Thus, even unvoiced sounds with high
energy content in low frequencies can be detected. This processing
cannot be done for longer pitch periods, as the frequency resolution is
not sufficient. For frames not satisfying the condition (295), the low
frequency energy is computed per critical band as

$\begin{matrix}
{\overline{E}}_{l} = \frac{1}{\text{10}}\sum_{k = 0}^{9}{E_{\text{CB}}\left( k \right),} \\
{\overline{E}}_{l} = \frac{1}{9}\sum_{k = 1}^{9}{E_{\text{CB}}\left( k \right),} \\
\end{matrix}$ (297)

for WB and NB inputs, respectively. The resulting low- and
high-frequency energies are obtained by subtracting the estimated noise
energy from the values${\overline{E}}_{l}$and${\overline{E}}_{h}$
calculated above. That is

$E_{h} = {\overline{E}}_{h} - N_{h}$ (298)

$E_{l} = {\overline{E}}_{l} - N_{l}$ (299)

where $N_{h}$ is the average noise energy in critical bands 18 and 19
for WB inputs, and 15 and 16 for NB inputs and$N_{l}$is the average
noise energy in the first 10 critical bands for WB input and in the
critical bands 1-9 for NB inputs. They are computed similarly as in the
two equations above. The estimated noise energies have been integrated
into the tilt computation to account for the presence of background
noise.

Finally, the spectral tilt is given by

$e_{\text{tilt}} = \frac{E_{l}}{E_{h}}$ (300)

For NB signals, the missing bands are compensated by multiplying
$e_{\text{tilt}}$ by 6. Note that the spectral tilt computation is
performed twice per frame to
obtain$e_{\text{tilt}}^{\left\lbrack 0 \right\rbrack}$and$e_{\text{tilt}}^{\left\lbrack 1 \right\rbrack}$,
corresponding to both spectral analyses per frame. The average spectral
tilt used in unvoiced frame classification is given by

${\overline{e}}_{\text{tilt}} = \frac{1}{3}\left( e_{\text{tilt}}^{\left\lbrack - 1 \right\rbrack} + e_{\text{tilt}}^{\left\lbrack 0 \right\rbrack} + e_{\text{tilt}}^{\left\lbrack 1 \right\rbrack} \right)$
(301)

where $e_{\text{tilt}}^{\left\lbrack - 1 \right\rbrack}$is the tilt in
the second half of the previous frame.

##### 5.1.13.1.3 Sudden energy increase from a low energy level

The maximum energy increase $E_{d}$ from a low signal level is evaluated
on eight short-time segments having the length of 32 samples. The energy
increase is then computed as the ratio of two consecutive segments
provided that the first segment energy was sufficiently low. For better
resolution of the energy analysis, a second pass is computed where the
segmentation is done with a 16 sample offset. The short-time maximum
energies are computed as

$E_{1,\text{st}}^{\left\lbrack j \right\rbrack} = \underset{i = 0}{\overset{\text{31}}{\text{max}}}\left( s_{\text{pre}}^{2}\left( i + \text{32}j \right) \right),\ j = - 1,\ldots,7,$
(302)

where $j = - 1$corresponds to the last segment of the previous frame,
and $j = 0,\ldots,7$corresponds to the current frame. The second set of
maximum energies is computed by shifting the speech indices in equation
(303) by 16 samples. That is

$E_{2,\text{st}}^{\left\lbrack j \right\rbrack} = \underset{i = 0}{\overset{\text{31}}{\text{max}}}\left( s_{\text{pre}}^{2}\left( i + \text{32}j - \text{16} \right) \right),\ j = 0,\ldots,8,$
(304)

$E_{2,\text{st}}^{\left\lbrack j \right\rbrack} = \underset{i = 0}{\overset{\text{31}}{\text{max}}}\left( s_{\text{pre}}^{2}\left( i + \text{32}j + \text{16} \right) \right),\ j = - 1,\ldots,7,$
(305)

The maximum energy variation $E_{d}$is computed as follows:

$E_{d} = \underset{x,j}{\overset{}{\text{max}}}\left\{ \frac{E_{x,\text{st}}^{\left\lbrack j \right\rbrack}}{E_{x,\text{st}}^{\left\lbrack j - 1 \right\rbrack} + 1} \right\},\ \text{for}\ j = 0,\ldots,7,\ x = 1,\ldots,2$
(306)

##### 5.1.13.1.4 Total frame energy difference

The classification of unvoiced frames is further improved by taking into
account the difference of total frame energy. This difference is
calculated as

$\text{dE}_{t} = E_{t} - E_{t}^{\lbrack - 1\rbrack}$

where $E_{t}$ is the total frame energy calculated in subclause 5.1.5.2
and $E_{t}^{\lbrack - 1\rbrack}$ is the total frame energy in the
previous frame.

##### 5.1.13.1.5 Energy decrease after spike

The detection of energy decrease after a spike prevents the UC mode on
significant temporal events followed by relatively rapid energy decay.
Typical examples of such signals are castanets.

The detection of the energy decrease is triggered by detecting a sudden
energy increase from a low level as described in subclause 5.1.13.1.3.
The maximum energy variation $E_{d}$ must be higher than 30 dB. Further,
for NB inputs the mean correlation must not be too high, i.e. the
condition ${\overline{R}}_{\text{xy}3} + r_{e} < 0\text{.}\text{68}$
must be satisfied too.

The energy decrease after a spike is searched within 10 overlapped
short-time segments (of both sets of energies) following the detected
maximum energy variation. Let's call $j_{\text{max}}$ the index $j$for
which $E_{d}$ was found, and the corresponding set of energies
$x_{\text{max}}$. If $x_{\text{max}} = 1$, then the searched interval is
$j = j_{\text{max}},\text{.}\text{.}\text{.},j_{\text{max}} + 4$for both
sets. If $x_{\text{max}} = 2$, then the searched interval is
$j = j_{\text{max}},\text{.}\text{.}\text{.},j_{\text{max}} + 4$for the
2^nd^ set, but
$j = j_{\text{max}} + 1,\text{.}\text{.}\text{.},j_{\text{max}} + 5$ for
the 1^st^ set of energies.

The energy decrease after a spike is then searched as follows. As the
energy can further increase beyond the segment
$\left\lbrack x_{\text{max}},j_{\text{max}} \right\rbrack$ for which
$E_{d}$ was found, the energy increase is tracked beyond that segment to
find the last segment with energy still monotonically increasing. Let's
denote the energy of that segment $E_{d\text{,max}}$. Starting from that
segment until the end of the searched interval, the minimum energy
$E_{d\text{,min}}$ is then determined. The detection of an energy
decrease after spike is based on the ratio of the maximum and minimum
energies

$\text{dE}_{2} = \frac{E_{d\text{,max}}}{E_{d\text{,min}} + \text{10}^{- 5}}$
(307)

This ratio is then compared to a threshold of 21 dB for NB inputs and 30
dB for other inputs.

The detection of energy decrease after a spike further uses a hysteresis
in the sense that UC is prevented not only in the frame where
$\text{dE}_{2}$is above the threshold ($\text{dE}_{2,\text{hyst}} = 0$),
but also in the next frame ($\text{dE}_{2,\text{hyst}} = 1$). In
subsequent frames ($\text{dE}_{2,\text{hyst}} = 2$), the hysteresis is
reset ($\text{dE}_{2,\text{hyst}} = - 1$) only if the following
condition is met:

$\left( \text{dE}_{t} > 5 \right)\ \text{OR}\ \left\lbrack \left( E_{\text{rel}} > - \text{13} \right)\ \text{AND}\ \left( {\overline{R}}_{\text{xy}3} + r_{e} < 0\text{.}\text{695} \right) \right\rbrack$.
(308)

Given that the searched interval of overlapped segments is always 10, it
can happen that the detection cannot be completed in the current frame
if a rapid energy increase happens towards the frame end. In that case,
the detection is completed in the next frame, however, as far as the
hysteresis logic is concerned, the detection of energy decrease after a
spike still pertains to the current frame.

##### 5.1.13.1.6 Decision about UC mode

To classify frames for encoding with UC mode, several conditions need to
be met. As the UC mode does not use the adaptive codebook and no
long-term prediction is thus exploited, it is necessary to make sure
that only frames without periodic content are coded with this mode. The
decision logic is somewhat different for WB and NB inputs and is
described for both cases separately.

For WB inputs, all of the following conditions need to be satisfied to
select the UC mode for the current frame.

1.  Normalized correlation is low:

2.  Energy is concentrated in high frequencies.

3.  The current frame is not in a segment following voiced offset:

where $c_{\text{raw}}^{\lbrack - 1\rbrack}$ is the raw coding mode
selected in the previous frame (described later in this document).

4.  There is no sudden energy increase:

5.  The current frame is not in a decaying segment following sharp
    energy spike:

For NB inputs, the following conditions need to be satisfied to classify
the frame for NB UC coding.

1.  Normalized correlation is low:

2.  Energy is concentrated in high frequencies.

3.  The current frame is not in a segment following voiced offset:

where $\text{CT}_{\text{raw}}^{\lbrack - 1\rbrack}$ is the raw coding
mode selected in the previous frame (described later in this document).

4.  There is no sudden energy increase:

5.  The current frame is not in a decaying segment following sharp
    energy spike:

#### 5.1.13.2 Stable voiced signal classification

The second step in the signal classification algorithm is the selection
of stable voiced frames, i.e. frames with high periodicity and smooth
pitch contour. The classification is mainly based on the results of the
fractional open-loop pitch search described in section 5.1.10.9. As the
fractional open-loop pitch search is done in a similar way as the
closed-loop pitch search, it is assumed that if the open-loop search
gives a smooth pitch contour within predefined limits, the optimal
closed-loop pitch search would give similar results and limited
quantization range can then be used. The frames are classified into the
VC mode if the fractional open-loop pitch analysis yields a smooth
contour of pitch evolution over all four subframes. The pitch smoothness
condition is satisfied if
$d_{\text{fr}}^{\left\lbrack i + 1 \right\rbrack} - d_{\text{fr}}^{\left\lbrack i \right\rbrack} < 3$
, for i = 0, 1, 2, where $d_{\text{fr}}^{\left\lbrack i \right\rbrack}$
is the fractional open-loop pitch lag found in subframe *i* (see section
5.1.10.9 for more details). Furthermore, in order to select VC mode for
the current frame the maximum normalized correlation $C_{\text{fr}}$
must be greater than 0.605 in each of the four subframes. Finally, the
spectral tilt ${\overline{e}}_{\text{tilt}}$ must be higher than 4.0.

The decision about VC mode is further improved for frames with stable
short pitch evolution and high correlation (e.g. female or child voices
or opera voices). Pitch smoothness is again satisfied if
$d_{\text{fr}}^{\left\lbrack i + 1 \right\rbrack} - d_{\text{fr}}^{\left\lbrack i \right\rbrack} < 3$,
for i = 0, 1, 2. High correlation is achieved in frames for which the
mean value of the normalized correlation in all four subframes is higher
than 0.95 and the mean value of the smoothed normalized correlation is
higher than 0.97. That is

$C_{\text{fr}} = \frac{1}{4}\sum_{}^{}C_{\text{fr}}^{\lbrack i\rbrack} > 0\text{.}\text{95}$
(309)

The smoothing of the normalized correlation is done as follows

${{\overline{C}}_{\text{fr}}^{\lbrack 0\rbrack} = 0\text{.}\text{75\ \{}\overline{C}}_{\text{fr}}^{\lbrack - 1\rbrack} + 0\text{.}\text{25}C_{\text{fr}}$
(310)

Finally, VC mode is also selected in frames for which the flag
$f_{\text{spitch}}$ = *Stab\_short\_pitch\_flag = flag\_spitch* has been
previously set to 1 in the module described in sub-clause 5.1.10.8.
Further, when the signal has very high pitch correlation,
$f_{\text{spitch}}$ is also set to 1 so that the VC mode is maintained
to avoid selecting Audio Coding (AC) mode later, as follows,

If (![](media/image20.wmf){width="0.3923611111111111in"
height="0.23333333333333334in"}=1 or

(dpit1 \<= 3 AND dpit2 \<= 3 AND dpit3 \<= 3 AND $\text{Voicing}_{m}$ \>
0.95 AND $\text{Voicing}_{\text{sm}}$ \> 0.97))

{

VC = 1;

![](media/image20.wmf){width="0.3923611111111111in"
height="0.23333333333333334in"}=1

}

wherein
$\text{dpit}1 = \left| T_{\text{OL}}^{\lbrack 0\rbrack} - T_{\text{OL}}^{\lbrack 1\rbrack} \right|$*,*
$\text{dpit}2 = \left| T_{\text{OL}}^{\lbrack 1\rbrack} - T_{\text{OL}}^{\lbrack 2\rbrack} \right|$*,*
$\text{dpit}3 = \left| T_{\text{OL}}^{\lbrack 2\rbrack} - T_{\text{OL}}^{\lbrack 3\rbrack} \right|$*,*
$\text{Voicing}_{m}$ and $\text{Voicing}_{\text{sm}}$ are defined in
subclause 5.1.10.8.

The decision taken so far (i.e. after UC and VC mode selection) is
called the "raw" coding mode, denoted$c_{\text{raw}}$. The value of this
variable from the current frame and from the previous frame is used in
other parts of the codec.

#### 5.1.13.3 Signal classification for FEC

This subclause describes the refinement of the signal classification
algorithm described in the previous section in order to improve the
codec\'s performance for noisy channels. The classification used to
select UC and VC frames cannot be directly used in the FEC as the
purpose of the classification is not the same. Instead, better
performance could be achieved by tuning both classification aspects
separately.

The basic idea behind using a different signal classification approach
for FEC is the fact that the ideal concealment strategy is different for
quasi-stationary speech segments and for speech segments with rapidly
changing characteristics. Whereas the best processing of erased frames
in non-stationary speech segments can be summarized as a rapid drop of
energy, in the case of quasi-stationary signal, the speech-encoding
parameters do not vary dramatically and can be kept practically
unchanged during several adjacent erased frames before being damped.
Also, the optimal method for a signal recovery following an erased block
of frames varies with the classification of the speech signal.

Furthermore, this special classification information is also used to
select frames to be encoded with the TC mode (see subclause 5.1.13.4).

To distinguish the signal classification algorithm for FEC from the
signal classification algorithm for coding mode determination (described
earlier in subclauses 5.1.13.1 and 5.1.13.2), we will refer here to
"signal class" rather than "coding mode" and denote it $c_{\text{FEC}}$.

##### 5.1.13.3.1 Signal classes for FEC

The frame classification is done with the consideration of the
concealment and recovery strategy in mind. In other words, any frame is
classified in such a way that the concealment can be optimal if the
following frame is missing, and that the recovery can be optimal if the
previous frame was lost. Some of the classes used in the FEC do not need
to be transmitted, as they can be deduced without ambiguity at the
decoder. Here, five distinct classes are used and defined as follows:

> • INACTIVE CLASS comprises all inactive frames. Note, that this class
> is used only in the decoder.
>
> • UNVOICED CLASS comprises all unvoiced speech frames and all frames
> without active speech. A voiced offset frame can also be classified as
> UNVOICED CLASS if its end tends to be unvoiced and the concealment
> designed for unvoiced frames can be used for the following frame in
> case it is lost.
>
> • UNVOICED TRANSITION CLASS comprises unvoiced frames with a possible
> voiced onset at the end. The onset is however still too short or not
> built well enough to use the concealment designed for voiced frames.
> The UNVOICED TRANSITION CLASS can only follow a frame classified as
> UNVOICED CLASS or UNVOICED TRANSITION CLASS.
>
> • VOICED TRANSITION CLASS comprises voiced frames with relatively weak
> voiced characteristics. Those are typically voiced frames with rapidly
> changing characteristics (transitions between vowels) or voiced
> offsets lasting the whole frame. The VOICED TRANSITION CLASS can only
> follow a frame classified as VOICED TRANSITION CLASS, VOICED CLASS or
> ONSET CLASS.
>
> • VOICED CLASS comprises voiced frames with stable characteristics.
> This class can only follow a frame classified as VOICED TRANSITION
> CLASS, VOICED CLASS or ONSET CLASS.
>
> • ONSET CLASS comprises all voiced frames with stable characteristics
> following a frame classified as UNVOICED CLASS or UNVOICED TRANSITION
> CLASS. Frames classified as ONSET CLASS correspond to voiced onset
> frames where the onset is already sufficiently built for the use of
> the concealment designed for lost voiced frames. The concealment
> techniques used for frame erasures following the ONSET CLASS are the
> same as those following the VOICED CLASS. The difference is in the
> recovery strategy.
>
> • AUDIO CLASS comprises all frames with harmonic or tonal content,
> especially music. Note that this class is used only in the decoder.

##### 5.1.13.3.2 Signal classification parameters

The following parameters are used for the classification at the encoder:
normalized correlation, ${\overline{R}}_{\text{xy}2}$, spectral tilt
measure, ${\overline{e}}_{\text{tilt},\text{dB}}$, pitch stability
counter, *pc*, relative frame energy, $E_{\text{rel}}$, and zero
crossing counter, *zc*. The computation of these parameters which are
used to classify the signal is explained below.

The normalized correlation, used to determine the voicing measure, is
computed as part of the OL pitch analysis module described in subclause
5.1.10. The average correlation ${\overline{R}}_{\text{xy}2}$is defined
as

${\overline{R}}_{\text{xy}2} = \frac{1}{2}\left( C_{\text{norm}}^{\left\lbrack 1 \right\rbrack} + C_{\text{norm}}^{\left\lbrack 2 \right\rbrack} \right)$
(310)

where$C_{\text{norm}}^{\left\lbrack 1 \right\rbrack}$ and
$C_{\text{norm}}^{\left\lbrack 2 \right\rbrack}$ are the normalized
correlation of the second half-frame and the look ahead, respectively.

The spectral tilt measure, ${\overline{e}}_{\text{tilt},\text{dB}}$, is
computed as the average (in dB) of both frame tilt estimates, as
described in subclause 5.1.13.1.2. That is

${\overline{e}}_{\text{tilt},\text{dB}} = \text{10}\text{log}\left( \text{max}\left\{ e_{\text{tilt}}^{\left\lbrack 0 \right\rbrack}\text{.}e_{\text{tilt}}^{\left\lbrack 1 \right\rbrack},1 \right\} \right)$
(311)

The pitch stability counter, *pc*, assesses the variation of the pitch
period. It is computed as follows:

$\text{pc} = \left| d^{\left\lbrack 1 \right\rbrack} - d^{\left\lbrack 0 \right\rbrack} \right| + \left| d^{\left\lbrack 2 \right\rbrack} - d^{\left\lbrack 1 \right\rbrack} \right|$
(312)

where the values $d^{\left\lbrack 0 \right\rbrack}$,
$d^{\left\lbrack 1 \right\rbrack}$ and
$d^{\left\lbrack 2 \right\rbrack}$correspond to the three OL pitch
estimates evaluated in each frame (see subclause 5.1.10).

The last parameter is the zero-crossing rate, *zc*, computed on the
second half of the current speech frame and the look-ahead. Here, the
zero-crossing counter, *zc*, counts the number of times the signal sign
changes from positive to negative during that interval. The
zero-crossing rate is calculated as follows

$\text{zc} = - \frac{1}{4}\sum_{n = \text{112}}^{\text{368}}{\text{sign}\left\lbrack s_{\text{pre}}(n)\text{.}s_{\text{pre}}(n - 1) \right\rbrack}$
(313)

where the function sign\[.\] returns +1 if the value is positive or -1
it is negative.

##### 5.1.13.3.3 Classification procedure

The classification parameters are used to define a function of merit,
$f_{m}$. For that purpose, the classification parameters are first
scaled between 0 and 1 so that each parameter translates to 0 for an
unvoiced signal and to 1 for a voiced signal. Each parameter, $p_{x}$,
is scaled by a linear function as follows:

$p_{x}^{s} = k_{x}p_{x} + c_{x}$ (314)

and clipped between 0 and 1 (except for the relative energy which is
clipped between 0.5 and 1). The function coefficients, $k_{x}$ and
$c_{x}$, have been found experimentally for each of the parameters so
that the signal distortion due to the concealment and recovery
techniques used in the presence of frame erasures is minimal. The
function coefficients used in the scaling process are summarized in the
following table.

Table 15: Coefficients of the scaling function for FEC signal
classification

  ----------- ------------------------- ---------- --------
  parameter   description                          
              normalized correlation    2.857      -1.286
              spectral tilt             0.04167    0
              pitch stability counter   -0.07143   1.857
              relative frame energy     0.05       0.45
              zero-crossing counter     -0.04      2.4
  ----------- ------------------------- ---------- --------

The function of merit has been defined as

$f_{m} = \frac{1}{6}\left( 2{\overline{R}}_{\text{xy}2}^{s} + {\overline{e}}_{\text{tilt},\text{dB}}^{s} + \text{pc}^{s} + E_{r}^{s} + \text{zc}^{s} \right)$
(315)

where the superscript *s* indicates the scaled version of the
parameters. The classification is then done using the function of merit,
$f_{m}$, and following the rules summarized in the following table.

Table 16: Rules for FEC signal classification

+---------------------------+------+---------------------------+
| previous class            | rule | selected class            |
+---------------------------+------+---------------------------+
| VOICED CLASS              |      | VOICED CLASS              |
|                           |      |                           |
| ONSET CLASS               |      |                           |
|                           |      |                           |
| VOICED TRANSITION CLASS   |      |                           |
+---------------------------+------+---------------------------+
|                           |      | VOICED TRANSITION CLASS   |
+---------------------------+------+---------------------------+
|                           |      | UNVOICED CLASS            |
+---------------------------+------+---------------------------+
| UNVOICED CLASS            |      | ONSET CLASS               |
|                           |      |                           |
| UNVOICED TRANSITION CLASS |      |                           |
+---------------------------+------+---------------------------+
|                           |      | UNVOICED TRANSITION CLASS |
+---------------------------+------+---------------------------+
|                           |      | UNVOICED CLASS            |
+---------------------------+------+---------------------------+

For the purpose of FEC signal classification, all inactive speech
frames, unvoiced speech frames and frames with very low energy are
directly classified as UNVOICED CLASS. This is done by checking the
following condition

$f_{\text{LSAD}} = 0\ \text{OR}\ c_{\text{raw}} = \text{UC}\ \text{OR}\ E_{r} < - 6$
(316)

which has precedence over the rules defined in the above table.

#### 5.1.13.4 Transient signal classification

As a compromise between the clean-channel performance of the codec and
its robustness to channel errors, the use of the TC mode is limited only
to a single frame following voiced onsets and to transitions between two
different voiced segments. Voiced onsets and transitions are the most
problematic parts from the frame erasure point of view. Therefore, the
frame after the voiced onset and voiced transitions must be as robust as
possible. If the transition/onset frame is lost, the following frame is
encoded using the TC mode, without the use of the past excitation
signal, and the error propagation is broken.

The TC mode is selected according to the counter of frames from the last
detected onset/transition $i_{\text{TC}}$. The onset/transition
detection logic is described by the state machine in the following
diagram.

Figure 14 : TC onset/transition state machine

In the above logic, $i_{\text{TC}}$ is set to 0 for all inactive frames,
resp. frames for which the FEC signal class is either UNVOICED CLASS or
UNVOICED TRANSITION CLASS. When the first onset frame is encountered
$i_{\text{TC}}$ is set to 1. This is again determined by the FEC signal
class. The onset/transition frame is always coded with the GC mode, i.e.
the coding mode is set to GC in this frame. The next active frame after
the onset frame increases $i_{\text{TC}}$ to 2 which means that there is
a transition and TC mode is selected. The counter is set to -1 if none
of the above situations happens waiting for the next inactive frame.
Naturally, the GC/TC mode is selected by the above logic only when the
current frame is an active frame, i.e. when $f_{\text{LSAD}} > 0$.

#### 5.1.13.5 Modification of coding mode in special cases

In some special situations, the decision about coding mode is further
modified. This is e.g. due to unsuitability of the selected coding mode
at particular bitrate or due to signal characteristics which make the
selected mode inappropriate. For example, the UC mode is supported only
up to 9.6 kbps after which it is replaced by the GC mode. The reason is
that for bitrates higher than 9.6 kbps the GC mode already has enough
bits to fully represent the random content of an unvoiced signal. The UC
mode is also replaced by the GC mode at 9.6 kbps if the counter of
previous AC frames is bigger than 0. The counter of AC frames is
initialized to the value of 200, incremented by 10 in every AC frame and
decremented by 1 in other frames but not in IC frames. The counter is
upper limited by 1000 and lower limited by 0.

At 32 and 64 kbps, only GC and TC modes are employed, i.e. if the coding
mode has been previously set to UC or VC, it is overwritten to GC.
Finally, for certain low-level signals, it could happen that the gain
quantizer in the NB VC mode goes out of its dynamic range. Therefore,
the coding mode is changed to GC mode if the relative frame energy
$E_{r} < - \text{10}$dB but only at 8.0 kbps and lower bitrates.

The coding mode is also changed to the TC mode in case of mode
switching. If, in the previous frame, 16 kHz ACELP core was used but the
current frame uses 12.8 kHz ACELP core, it is better to prevent
potential switching artefacts resulting from signal discontinuity and
incorrect memory. This modification is done only for frames other than
VC, i.e. if $c_{\text{raw}} \neq \text{VC}$, where $c_{\text{raw}}$ is
the raw coding mode described in subclause 5.1.13.2. Further, the
modification takes place only for active frames in case of DTX
operation.

The coding mode is overridden to the TC mode if MDCT-based core was used
in the last frame but the current frame is encoded with an LP-based
core. Finally, the coding mode is changed to the TC mode if the EVS
codec is operated in the DTX mode and if the last frame was a SID frame
encoded with the FD\_CNG technology.

#### 5.1.13.6 Speech/music classification

Music signals, in general, are more complex than speech and conform less
to any known LP-based model. Therefore, it is of interest to distinguish
music signals (generic audio signals) from speech signals. Speech/music
classification then allows using a different coding approach to such
signals. This new approach has been called the Generic audio Signal
Coding mode (GSC), or the Audio Coding (AC) mode.

The speech/music classification is done in two stages. The first stage
of the speech/music classifier is based on the Gaussian Mixture Model
(GMM) and performs the best statistically based discrimination of speech
from generic audio. The second stage has been optimized directly for the
GSC mode. In other words, the classification in the second stage is done
in such a way that the selected frames are suitable for the AC mode.
Each speech/music classifier stage yields its own binary decision, and
which is either 1 (music) or 0 (speech or background noise). The speech
decision and the background noise decision have been grouped together
only for the purposes of the speech/music classification. The selection
of the IC mode for inactive signals incl. background noise is done later
in the codec and described in subclause 5.1.13.5.7.

The decisions of the first and the second stage are refined and
corrected for some specific cases in the subsequent modules, described
below. The final decision about the AC mode is done based on and but the
two flags are also used for the selection of the coder technology which
is described in subclause 5.1.16.

##### 5.1.13.6.1 First stage of the speech/music classifier

The GMM model has been trained on a large database of speech and music
signals covering several male and female speakers, multiple languages
and various genres of instrumental and vocal music. The statistical
model uses a vector of 12 unique features, all normalized to a unit
interval and derived from the basic parameters that have been calculated
in the pre-processing part of the encoder. There are three statistical
models inside the GMM: speech, music and noise. The statistical model of
the background noise has been added to improve the SAD algorithm
described in subclause 5.1.12. Each statistical model is represented by
a mixture of six normal (Gaussian) distributions, determined by their
relative weight, mean and full covariance matrix. The speech/music
classifier exploits the following characteristics of the input signal:

> -- OL pitch
>
> -- normalized correlation
>
> -- spectral envelope (LSPs)
>
> -- tonal stability
>
> -- signal non-stationarity
>
> -- LP residual error
>
> -- spectral difference
>
> -- spectral stationarity

Figure 15 : Schematic diagram of the first stage of the speech/music
classifier

The OL pitch feature is calculated as the average of the three OL pitch
estimates, i.e.

$\text{FV}_{0} = \frac{1}{3}\left( T_{\text{OL}}^{\lbrack 0\rbrack} + T_{\text{OL}}^{\lbrack 1\rbrack} + T_{\text{OL}}^{\lbrack 2\rbrack} \right)$
(317)

where $T_{\text{OL}}^{\lbrack i\rbrack}$are computed as in subclause
5.1.10.7. In onset/transition frames and in the TC frame after, it is
better to use only the OL pitch estimate of the second analysis window,
i.e. $\text{FV}_{0} = T_{\text{OL}}^{\lbrack 2\rbrack}$.

The normalized correlation feature $\text{FV}_{1}$ used by the
speech/music classifier is the same one as used in the unvoiced signal
classification. See subclause 5.1.13.1.1. for the details of its
computation. In onset/transition frames and in the TC frame after, it is
better to use only the correlation value of the second analysis window,
i.e. $\text{FV}_{1} = C_{\text{norm}}^{\lbrack 2\rbrack}$.

There are five LSF parameters used as features inside the first stage of
the speech/music classifier. These are calculated as follows

$\text{FV}_{i + 1} = \text{arccos}(q_{\text{end},i}) + \text{arccos}(q_{\text{end},i}^{\lbrack - 1\rbrack}),\ i = 1,\text{.}\text{.},5$
(318)

Another feature used by the speech/music classifier is the correlation
map which is calculated as part of the tonal stability measure in
subclause 5.1.11.2.5. However, for the purposes of speech/music
classification, it is not the long-term correlation map which is summed
but rather the correlation map of the current frame. The reason is to
limit the impact of past information on the speech/music decision in the
current frame. That is

$\text{FV}_{7} = \sum_{j = 0}^{\text{127}}{M_{\text{cor}}(j)} + \sum_{j = 0}^{\text{127}}{M_{\text{cor}}^{\lbrack - 1\rbrack}(j)}$
(319)

In case of NB signals, the value of $\text{FV}_{7}$ is multiplied by
1.53.

Signal non-stationarity is also used in the speech/music classifier but
its calculation is slightly different than in the case of background
noise estimation described in subclause 5.1.11.2.1. Firstly, the current
log-energy per band is defined as

$E_{\text{CB}2}(i) = \text{log}(0\text{.}5E_{\text{CB}}^{\left\lbrack 0 \right\rbrack}(i) + 0\text{.}5E_{\text{CB}}^{\left\lbrack 1 \right\rbrack}(i))$,
*i*=2,.,16 (320)

Then,

$\text{FV}_{8} = \sum_{i = 2}^{\text{16}}\left| E_{\text{CB}2}(i) - E_{\text{CB}2}^{\lbrack - 1\rbrack}(i) \right|$
(321)

The LP residual log-energy ratio is calculated as

$\text{FV}_{9} = \text{log}\left( \frac{E(\text{13})}{E(1)} \right) + \text{log}\left( \frac{E^{\lbrack - 1\rbrack}(\text{13})}{E^{\lbrack - 1\rbrack}(1)} \right)$
(322)

where the superscript \[-1\] denotes values from the previous frame. In
case of NB signals, the statistical distribution of $\text{FV}_{9}$ is
significantly different than in case of WB signals. Thus, for NB signals
$\text{FV}_{9} = - 1\text{.}\text{647}$.

For the last two features, the power spectrum must be normalized as
follows:

$\text{PS}_{n}(k) = \frac{\text{PS}(k)}{\sum_{k = 3}^{\text{69}}{\text{PS}(k)}}$,
*k*=3,..,69 (323)

and difference spectrum calculated as follows:

$\text{dPS}_{n}(k) = \text{PS}_{n}(k) - \text{PS}_{n}^{\lbrack - 1\rbrack}(k)$,
*k*=3,..,69 (324)

Then we calculate the spectral difference as the sum of
$\text{dPS}_{n}(k)$ in the log domain. That is

$\text{FV}_{\text{10}} = \text{log}\left( \sum_{k = 3}^{\text{69}}{\text{dPS}_{n}(k)} \right) + \text{log}\left( \sum_{k = 3}^{\text{69}}{\text{dPS}_{n}^{\lbrack - 1\rbrack}(k)} \right)$
(325)

The spectral non-stationarity is calculated as the product of ratios
between power spectrum and the difference spectrum. This is done as
follows

$\text{FV}_{\text{11}} = \text{log}\sum_{k = 3}^{\text{69}}\frac{\text{max}\left( \text{PS}_{n}(k),\text{PS}_{n}^{\lbrack - 1\rbrack}(k) \right)}{\text{dPS}_{n}(k)}$
(326)

##### 5.1.13.6.2 Scaling of features in the first stage of the speech/music classifier

The feature vector *FV~i~, i*=0,..,11 is scaled in such a way that all
its values are approximately in the range \[0;1\]. This is done as

$\text{FV}_{s}(i) = \text{sfa}_{i}\text{FV}_{i} + \text{sfb}_{i}$
*i*=0,..,11 (327)

where the scaling factors *sfa~i~* and *sfb~i~* have been found on a
large training database. The scaling factors are defined in the
following table.

Table 17: Scaling factors for feature vector in the speech/music
classifier

  ----- -------- --------- -------- ---------
  *i*   WB       NB                 
                                    
  0     0.048    -0.0952   0.0041   0
  1     1.0002   0         0.8572   0.1020
  2     0.6226   -0.0695   0.6739   -0.1000
  3     0.5497   -0.1265   0.6257   -0.1678
  4     0.4963   -0.2230   0.5495   -0.2380
  5     0.5049   -0.4103   0.5793   -0.4646
  6     0.5069   -0.5717   0.2502   0
  7     0.0041   0         0.0041   0
  8     0.0022   -0.0029   0.0020   0
  9     0.0630   1.0015f   0.0630   1.0015
  10    0.0684   0.9103f   0.0598   0.8967
  11    0.1159   -0.2931   0.0631   0
  ----- -------- --------- -------- ---------

##### 5.1.13.6.3 Log-probability and decision smoothing

The multivariate Gaussian probability distribution is defined as

$p(\text{FV}) = \frac{1}{\sqrt{\left( 2\pi \right)^{k}\left| \Sigma \right|}}\text{exp}\left( - \frac{1}{2}(\text{FV} - \mu)^{T}\Sigma^{- 1}(\text{FV} - \mu) \right)$
(328)

where **FV** is the feature vector, **µ** is the vector of means and
**Σ** is the variance matrix. As stated before, the dimension of the
feature vector is *k*=12. The means and the variance matrix are found by
the training process of the Gaussian Mixture Model (GMM). This training
is done by means of the EM (Expectation-Maximization) algorithm . The
speech/music classifier is trained with a mixture of 6 Gaussian
distributions. The log-likelihood of each mixture is defined as

$L_{i} = - \frac{1}{2}\text{log}\left( 2\pi \right)^{\text{12}} + \text{log}w_{i} + \text{log}\left| \Sigma_{i} \right| - \frac{1}{2}(\text{FV} - \mu_{i})^{T}\Sigma_{i}^{- 1}(\text{FV} - \mu_{i})$
*i*=1,..,6 (329)

where *w~i~* is the weight of each mixture. The term
$\text{log}w_{i} + \text{log}\left| \Sigma_{i} \right|$ is calculated in
advance and stored in the form of a look-up table. The probability over
the complete set of 6 Gaussians is then calculated in the following way:

$p_{\text{all}} = \sum_{i = 1}^{6}{\text{exp}\left\lbrack \text{log}w_{i} + \text{log}\left| \Sigma_{i} \right| - \frac{1}{2}(\text{FV} - \mu_{i})^{T}\Sigma_{i}^{- 1}(\text{FV} - \mu_{i}) \right\rbrack}$
(330)

and the log-likelihood over the complete set as

$L_{\text{all}} = \text{log}\left( p_{\text{all}} \right) - \frac{1}{2}\text{log}\left( 2\pi \right)^{\text{12}}$
(331)

Since there are three trained classes in the GMM model (speech, music
and noise), three log-likelihood values are obtained by the above
estimation process: $L_{s},L_{m},L_{n}$. Only $L_{s}$ and $L_{m}$ are
used in the subsequent logic. $L_{n}$ is used in the SAD algorithm to
improve detection accuracy. Therefore, in case of inactive signal when
*f~LSAD\_HE~* is 0

$L_{s} = 1\text{.}2L_{n}$ (332)

The difference of log-likelihood is calculated as

$\text{dL}_{\text{sm}} = L_{m} - L_{s}$ (333)

which can be directly interpreted as a speech/music decision without
hangover. This decision has low dynamic range and fluctuates a lot
around zero, especially for mixed signals. To improve the detection
accuracy, the decision is smoothed by means of AR filtering

$\text{wdL}_{\text{sm}} = \gamma_{\text{comb}}\text{dL}_{\text{sm}} + (1 - \gamma_{\text{comb}})\text{wdL}_{\text{sm}}^{\lbrack - 1\rbrack}$
(334)

where the superscript \[-1\] denotes the previous frame and
$\gamma_{\text{comb}}$ is the filtering factor which is adaptively set
on a frame-by-frame basis. The filtering factor is in the range \[0;1\]
and is based on two measures (weighting factors). The first weighting
factor $\gamma_{E}$ is related to the relative frame energy and the
second weighting factor $\gamma_{\text{drop}}$ is designed to emphasize
rapid negative changes of $\text{dL}_{\text{sm}}$.

The energy-based weight $\gamma_{E}$ is calculated as follows

$\gamma_{E} = 1 + \frac{E_{r}}{\text{15}},\ \text{conditioned\ by\ }0\text{.}\text{01} < \gamma_{E} < 1$
(335)

where $E_{r}$ is relative frame energy. The result of the addition means
that the weight has values close to 0.01 in low-energy segments and
close to 1 in high energy, or more important, segments. Therefore, the
smoothed decision follows the current decision more closely if the
signal energy is relatively high and leads to past information being
disregarded more readily. On the other hand, if the signal energy is
low, the smoothed decision puts more emphasis on previous decisions
rather than the current one. This logic is motivated by the observation
that discrimination between speech and music is more difficult when the
SNR of the signal is low.

The second weighting factor $\gamma_{\text{drop}}$ is designed to track
sudden transitions from music to speech. This situation happens only in
frames where $\text{dL}_{\text{sm}} < 0$ and at the same time
$\text{dL}_{\text{sm}} < \text{dL}_{\text{sm}}^{\lbrack - 1\rbrack}$. In
these frames

$\begin{matrix}
{\overline{w}}_{\text{drop}} = - \text{dL}_{\text{sm}} & \text{,if\ }\text{dL}_{\text{sm}}^{\lbrack - 1\rbrack} > 0 \\
{\overline{w}}_{\text{drop}} = {\overline{w}}_{\text{drop}}^{\lbrack - 1\rbrack} + (\text{dL}_{\text{sm}}^{\lbrack - 1\rbrack} - \text{dL}_{\text{sm}}) & \text{,otherwise} \\
\end{matrix}$ (336)

where the parameter ${\overline{w}}_{\text{drop}}$ is a quantitative
measure of sudden falls, or drops, in the value of
$\text{dL}_{\text{sm}}$. This parameter is set to 0 in all frames that
do not fulfil the previous condition. In the first frame when
$\text{dL}_{\text{sm}}$ falls below 0, it is set equal to its negative
value and it is incremented when $\text{dL}_{\text{sm}}$ continues to
fall in consecutive frames. In the first frame when
$\text{dL}_{\text{sm}}$ stops decreasing it is reset back to 0. Thus,
${\overline{w}}_{\text{drop}}$ is positive only during frames of falling
$\text{dL}_{\text{sm}}$ and the bigger the fall the bigger its value.
The weighting factor $\gamma_{\text{drop}}$ is then calculated as

$\gamma_{\text{drop}} = \frac{{\overline{w}}_{\text{drop}}}{\text{20}},\ \text{conditioned\ by\ }0\text{.}1 < \gamma_{\text{drop}} < 1$
(337)

The filtering factor is then calculated by from the product of both
weights, i.e.

$\gamma_{\text{comb}} = \gamma_{E}\text{.}\gamma_{\text{drop}},\ \text{conditioned\ by\ }0\text{.}\text{01} < \gamma_{\text{comb}}$
(338)

##### 5.1.13.6.4 State machine and final speech/music decision

The state machine is an event-based decision system in which the state
of the speech/music classifier is changed from INACTIVE to ACTIVE and
vice-versa. There are two intermediate states: ENTRY and INSTABLE. The
classifier must always go through the ENTRY state in order to be ACTIVE.
During the ENTRY period, there is no relevant past information that
could be exploited by the algorithm for hangover additional described
later in this section. When the classifier is in the ACTIVE state but
the energy of the input signal goes down up to the point when it is
almost equal to the estimated background noise energy level, the
classifier is in an UNSTABLE state. Finally, when SAD goes to 0, the
classifier is in INACTIVE state. The following state-flow diagram shows
the transitions between the states.

Figure 16 : State machine for the first stage of the speech/music
classifier

The conditions for changing the states are described in from of decision
tree in figure 17. The processing starts at the top-left corner and
stops at bottom-right corner. The counter of inactive states
$c_{\text{inact}}$ is initialized to 0 and the state variable
$\text{sm}_{\text{state}}$ is initialized to -8. The state variable
stays within the range \[-8;+8\] where the value of -8 means INACTIVE
state and the value of +8 means ACTIVE STATE. If
$0 < \text{sm}_{\text{state}} < 8$ the classifier is in ENTRY state and
if $- 8 < \text{sm}_{\text{state}} \leq 0$ the classifier is in INSTABLE
state.

If the speech/music classifier is in INACTIVE state, i.e. if
$\text{sm}_{\text{state}} = - 8$ then the smoothed decision is
automatically set to 0, i.e. $\text{wdL}_{\text{sm}} = 0$.

The final decision of the speech/music classifier is binary and it is
characterized by the flag *f~SM~*. The flag is set to 0 if
$f_{\text{LSAD}_{\text{HE}}} = 0$ and the classifier is in INACTIVE
STATE, i.e. when $\text{sm}_{\text{state}} = - 8$. If there is a
transition from the ACTIVE state to the INACTIVE or INSTABLE state,
characterized by $\text{sm}_{\text{state}} \leq 0$, the flag retains its
value from the previous frame. If the classifier is in ENTRY state,
characterized by $0 < \text{sm}_{\text{state}} < 8$, the flag is set
according to weighted average of past non-binary decisions. This is done
as follows

$\text{dec} = \sum_{j = 1}^{8}{g_{\text{entry}}(\text{sm}_{\text{state}},j)\text{dL}_{\text{sm}}^{\lbrack j - 1\rbrack}}$
(339)

where the weighting coefficients $g_{\text{entry}}(i,j)$ are given in
the following table:

Table 18: Weighting coefficients for the ENTRY period of the
speech/music classifier

  --- ------- ------- ------- ------- ------- ------- ------- ------
      1       2       3       4       5       6       7       8
  1   1       0       0       0       0       0       0       0
  2   0.6     0.4     0       0       0       0       0       0
  3   0.47    0.33    0.2     0       0       0       0       0
  4   0.4     0.3     0.2     0.1     0       0       0       0
  5   0.3     0.25    0.2     0.15    0.1     0       0       0
  6   0.233   0.207   0.18    0.153   0.127   0.1     0       0
  7   0.235   0.205   0.174   0.143   0.112   0.081   0.05    0
  8   0.2     0.179   0.157   0.136   0.114   0.093   0.071   0.05
  --- ------- ------- ------- ------- ------- ------- ------- ------

Figure 18 : Decision tree for transitions between INACTIVE and ACTIVE
states of the speech/music classifier

The flag $f_{\text{SM}}$ is set to 1 when $\text{dec}$ \> 2. If the
classifier is in a stable ACTIVE state, the flag retains its value from
the previous frame unless one of the following two situations happens.
If $\text{wdL}_{\text{sm}} > 0$ but the decisions in the previous three
frames were all "speech", i.e. $f_{\text{SM}}^{\lbrack i\rbrack} = 0$for
*i*=-1,-2,-3, there is a transition from speech to music and
$f_{\text{SM}}$ is set to 1. If $\text{wdL}_{\text{sm}} < 0$ but the
decision in the previous frame was "music", i.e.
$f_{\text{SM}}^{\lbrack - 1\rbrack} = 1$, there is a transition from
music to speech and $f_{\text{SM}}$ is set to 0.

The speech/music decision obtained by the algorithm described so far
will be denoted $f_{\text{SM}1}$ in the following text to distinguish it
from the second stage of the speech/music classifier in which the
decision will be denoted $f_{\text{SM}2}$.

##### 5.1.13.6.5 Improvement of the classification for mixed and music content

The speech/music decision $f_{\text{SM}1}$ obtained above is further
refined with the goal of improving the classification rate on music and
mixed content. A set of feature parameters are extracted from the input
signal and buffered. Statistical analysis is performed on each feature
parameter buffer and a binary speech/music decision $f_{\text{SM}^{'}}$
is obtained using a tree-based classification. During the processing the
value '1' indicates music and the value '0' indicates non-music. As a
result of this refinement, the earlier speech/music
decision$f_{\text{SM}1}$ may be adjusted from '0' to '1' if $f_{SM^{'}}$
has a final value of '1' in the situation that the$f_{\text{SM}1}$ and
$f_{SM^{'}}$ are not aligned with each other.

The feature parameters used to form the feature parameter buffers
include a spectral energy fluctuation parameter,$\text{flux}$, a tilt
parameter of the LP analysis residual energies, $\text{tilt}_{R}$, a
high-band spectral peakiness parameter, $\text{pk}_{h}$, a parameter of
correlation map sum, $\text{cor}_{\text{sum}}$, a voicing parameter,
$\text{vm}$, and finally three tonal parameters $\text{NT}$,$\text{NT}2$
and $\text{NT}_{l}$. Since music is assumed to only existing during high
SNR active regions of the input signal, the classification refinement is
only applied for active frames and when the long-term SNR is high. So,
if the SAD flag $f_{\text{LSAD}}$ indicates that the current frame is an
inactive frame or the long-term SNR $\text{SNR}_{\text{LT}}$ is below a
threshold of 25, i.e.
$\text{if}(f_{\text{LSAD}}\text{==}0||\ \text{SNR}_{\text{LT}} < \text{25})$,
then the classification refinement is terminated without executing
fully. In the early termination case, the speech/music
decision$f_{\text{SM}1}$ is kept unchanged and two long-term
speech/music decisions $\text{LTf}_{SM^{'}}$,
${\text{LT\ \{}f}_{SM^{'}}^{'}$, as will be described later in this
subclause, are both initialized to 0.5.

Before computing the various feature parameters, percussive music is
first detected. Percussive music is characterized by temporal spike-like
signals. First the log maximum amplitude of the current frame is found
as

$\text{Am}_{\text{max}} = \text{20}\text{log}_{2}\text{max}(\left| s(i) \right|),\ i = 0,1,\text{.}\text{.}\text{.},\text{255}$
(340)

where $s(i)$ is the time-domain input frame. The difference between the
log maximum amplitude and its moving average from the previous frame is
calculated

$D_{\text{ltA}} = \text{Am}_{\text{max}} - {\overline{\text{Am}_{\text{max}}}}^{\lbrack - 1\rbrack}$
(341)

where the superscript \[-1\] denotes the value from the previous frame.
$\overline{\text{Am}_{\text{max}}}$ is updated at each frame after the
calculation of $D_{\text{ltA}}$, if both the normalized pitch
correlations of the current frame $C_{\text{norm}}^{\lbrack 0\rbrack}$
and $C_{\text{norm}}^{\lbrack 1\rbrack}$ as calculated in defined in
subclause 5.1.11.3.2 are greater than 0.9 as

$\overline{\text{Am}_{\text{max}}} = \alpha \cdot {\overline{\text{Am}_{\text{max}}}}^{\lbrack - 1\rbrack} + (1 - \alpha) \cdot \text{Am}_{\text{max}}$
(342)

where the value $\alpha$is the forgetting factor and is set to 0.75 for
increasing updates
($\text{Am}_{\text{max}} > {\overline{\text{Am}_{\text{max}}}}^{\lbrack - 1\rbrack}$)
and 0.995 for decreasing updates
($\text{Am}_{\text{max}} < {\overline{\text{Am}_{\text{max}}}}^{\lbrack - 1\rbrack}$).
The $D_{\text{ltA}}$, the total frame energy $E_{t}$ calculated in
subclause 5.1.5.2, the normalized pitch correlation
$C_{\text{norm}}^{\lbrack i\rbrack}$ defined in subclause 5.1.11.3.2 and
the long-term active signal energy ${\overline{E}}_{t}$ are used to
identify the temporal spike-like signals. First, certain energy
relationship between several past frames is checked. If
$E_{t}^{\lbrack - 2\rbrack} - E_{t}^{\lbrack - 3\rbrack} > 6$ and
$E_{t}^{\lbrack - 2\rbrack} > E_{t}^{\lbrack - 1\rbrack}$ and
$E_{t}^{\lbrack - 2\rbrack} - E_{t}^{\lbrack 0\rbrack} > 3$ and
$E_{t}^{\lbrack - 2\rbrack} - {\overline{E}}_{t} > 3$ and
$E_{t}^{\lbrack - 1\rbrack} > E_{t}^{\lbrack 0\rbrack}$, where the
superscript $\lbrack - i\rbrack$ denotes the $i$-th frame in the past,
the energy envelope of temporal spike-like signal is considered found.
Then if the voicing is low, that is
if$0\text{.}5C_{\text{norm}}^{\lbrack 0\rbrack} + 0\text{.}\text{25}C_{\text{norm}}^{\lbrack 1\rbrack} + 0\text{.}\text{25}C_{\text{norm}}^{\lbrack 2\rbrack} < 0\text{.}\text{75}$,
the percussive music flag $f_{\text{pc}}$ is set to 1 indicating the
detection of spike-like signal, if the the normalized pitch correlations
for the second half of the previous frame, the first half of the current
frame and the second half of the current frame,
$C_{\text{norm}}^{\lbrack 0\rbrack}$,$C_{\text{norm}}^{\lbrack 1\rbrack}$and$C_{\text{norm}}^{\lbrack 2\rbrack}$
are all less than 0.75 and the $D_{\text{ltA}}$ is greater than 10, or
if simply the long-term speech/music decision $\text{LTf}_{SM^{'}}$ is
greater than 0.8.

Besides the detection of percussive music, sound attacks are also
detected using $E_{t}^{\lbrack i\rbrack}$, ${\overline{E}}_{t}$,
$\text{LTf}_{SM^{'}}$ and $D_{\text{ltA}}^{\lbrack - 1\rbrack}$, where
$D_{\text{ltA}}^{\lbrack - 1\rbrack}$ denotes the $D_{\text{ltA}}$ of
the previous frame. If
$E_{t}^{\lbrack 0\rbrack} - E_{t}^{\lbrack - 1\rbrack} > 6$ and
$E_{t}^{\lbrack 0\rbrack} - {\overline{E}}_{t} > 5$ and
$\text{LTf}_{SM^{'}} > 0\text{.}9$ and
$D_{\text{ltA}}^{\lbrack - 1\rbrack} > 5$, sound attack is detected and
the attack flag $f_{\text{att}}$ is set to 3. The attack flag
$f_{\text{att}}$ is decremeted by 1 in each frame afterthe calculation
and buffering of the spectral energy fluctuation
parameter$\text{flux}$which is claculated from the log energy spectrum
of the current frame as follows: Firstly, all local peaks and valleys in
the log spectrum
$E_{\text{dB}}(k),\ k = 0,1,\text{.}\text{.}\text{.}\text{126}$, as
calculated in equation (127) are identified. A value of
$E_{\text{dB}}(k)$ is considered as a local peak if
$E_{\text{dB}}(k) > E_{\text{dB}}(k - 1)$ and
$E_{\text{dB}}(k) > E_{\text{dB}}(k + 1)$. A value of $E_{\text{dB}}(k)$
is considered as a local valley if
$E_{\text{dB}}(k) < E_{\text{dB}}(k - 1)$ and
$E_{\text{dB}}(k) < E_{\text{dB}}(k + 1)$. Besides, the first local
valley is found as the $E_{\text{dB}}(k)$ with
$E_{\text{dB}}(k) < E_{\text{dB}}(k + 1)$and$E_{\text{dB}}(k) \leq \forall E_{\text{dB}}(i),\ i = 0,\text{.}\text{.}\text{.},k - 1$,
the last local valley is found as the $E_{\text{dB}}(k)$ with
$E_{\text{dB}}(k) < E_{\text{dB}}(k - 1)$and$E_{\text{dB}}(k) \leq \forall E_{\text{dB}}(i),\ i = k + 1,\text{.}\text{.}\text{.},\text{126}$.
For each local peak, its peak to valley distance is calculated as

$p2v(i) = E_{p}(i) - E_{\text{vl}}(i) + E_{p}(i) - E_{\text{vh}}(i),\ i = 0,1,\text{.}\text{.}\text{.},m - 1$
(343)

where $p2v(i)$ denotes the peak to valley distance of the $i$-th local
peak, $E_{p}(i)$ denotes the log energy of the $i$-th local peak and
$E_{\text{vl}}(i)$, $E_{\text{vh}}(i)$ denote the respect log energy of
the local valleys adjacent to the $i$-th local peak at the lower
frequency side and the higher frequency side, $m$ denotes the number of
local peaks. An array called peak to valley distance map is then
obtained as

$\text{MAP}_{p2v}(k) = \begin{matrix}
\left\{ p2v(i)\ \text{if}\ k = \text{idx}_{P}(i) \middle| \right.\  \\
\end{matrix}$ (344)

where $\text{MAP}_{p2v}(k)$ denotes the peak to valley distance map,
$\text{idx}_{P}(i)$ denotes the index (or the location) of the $i$-th
local peak in the log spectrum $E_{\text{dB}}(k)$. The spectral energy
fluctuation parameter $\text{flux}$ is defined as the average energy
deviation between the current frame spectrum and the spectrum two frames
ago at locations of the local spectral peaks $\text{idx}_{P}(i)$. The
$\text{flux}$ is computed as

$\text{flux} = \frac{1}{m} \cdot \sum_{k = 0,\text{MAP}_{p2v}(k) \neq 0}^{\text{127}}\left| E_{\text{dB}}^{\lbrack 0\rbrack}(k) - E_{\text{dB}}^{\lbrack - 2\rbrack}(k) \right|$
(345)

where $E_{\text{dB}}^{\lbrack 0\rbrack}(k)$ and
$E_{\text{dB}}^{\lbrack - 2\rbrack}(k)$ denote respectively the log
energy spectrum of the current frame and the log energy spectrum of the
frame two frames ago, $m$ denotes the number of local peaks. If $m$= 0,
$\text{flux}$ is set to 5. The computed $\text{flux}$ is stored into a
buffer
$\text{BUF}_{\text{flux}}(i),i = 0,1\text{.}\text{.}\text{.}\text{59}$
of 60 frames if there is no sound attack in the past 3 frames (including
the current frame), that is if $f_{\text{att}} \leq 0$. Moreover, if the
long-term speech/music decision $\text{LTf}_{SM^{'}}$is greater than 0.8
meaning a strong music signal in previous classifications, then the
value of$\text{flux}$ is upper limited to 20 before it is stored into
the $\text{BUF}_{\text{flux}}(i)$. The $\text{flux}$ buffer
$\text{BUF}_{\text{flux}}(i)$ is altered at every first active frame
after an inactive segment (flagged by$f_{\text{LSAD}}$) that all values
in the buffer excluding the one just calculated and stored for the
current frame are changed to negative values.

The effective portion of the buffer $\text{BUF}_{\text{flux}}(i)$ is
determined in each frame after the calculation and buffering of the
parameter$\text{flux}$. The effective portion is defined as the portion
in the $\text{flux}$ buffer $\text{BUF}_{\text{flux}}(i)$which contains
continuous non-negative values starting from the value of the latest
frame . If percussive music is detected, that is if the percussive music
flag $f_{\text{pc}}$ is set to 1, each value in the effective portion of
the $\text{flux}$ buffer $\text{BUF}_{\text{flux}}(i)$ is initialized to
5.

The tilt parameter of the LP analysis residual energies
$\text{tilt}_{R}$is calculated as

$\text{tilt}_{R} = \frac{\sum_{i = 1}^{\text{15}}{E(i) \cdot E(i + 1)}}{\sum_{i = 1}^{\text{15}}{E(i) \cdot E(i)}}$
(346)

where $E(i)$ is the LP error energies computed by the Levinson-Durbin
algorithm. The computed $\text{tilt}_{R}$ is stored into a buffer
$\text{BUF}_{\text{tilt}}(i),i = 0,1\text{.}\text{.}\text{.}\text{59}$
of 60 frames.

The high-band spectral peakiness parameter $\text{pk}_{h}$ reflects an
overall tonality of the current frame at its higher frequency band and
is calculated from the peak to valley distance map $\text{MAP}_{p2v}(k)$
as

$\text{pk}_{h} = \sum_{k = \text{64}}^{\text{126}}{\text{MAP}_{p2v}(k)}$
(345)

The calculated $\text{pk}_{h}$ is stored into a buffer
$\text{BUF}_{\text{pk}_{h}}(i),i = 0,1\text{.}\text{.}\text{.}\text{59}$
of 60 frames.

The three tonal parameters $\text{NT}$,$\text{NT}2$ and $\text{NT}_{l}$
are also calculated from the peak to valley distance map
$\text{MAP}_{p2v}(k)$. $\text{NT}$denotes the first number of harmonics
found from the spectrum of the current frame. $\text{NT}$ is calculated
as

$\text{NT} = \sum_{k = 0}^{\text{126}}\left( \text{MAP}_{p2v}(k) > \text{55} \right)$
(346)

$\text{NT}2$ denotes the second number of harmonics also found from the
spectrum of the current frame. $\text{NT}2$ is defined more strictly
than $\text{NT}$ and is calculated as

$\text{NT}2 = \sum_{k = 0}^{\text{126}}\left( \text{MAP}_{p2v}(k) > \text{80} \right)$
(347)

$\text{NT}_{l}$denotes the number of harmonics found only at the low
frequency band of the current frame's spectrum and is calculated as

$\text{NT}_{l} = \sum_{k = 0}^{\text{64}}\left( \text{MAP}_{p2v}(k) > \text{80} \right)$
(348)

The calculated values of $\text{NT}$,$\text{NT}2$ and $\text{NT}_{l}$
are stored into their respective buffers $\text{BUF}_{\text{NT}}(i)$,
$\text{BUF}_{\text{NT}2}(i)$ and $\text{BUF}_{\text{NT}_{l}}(i)$all of
60 frames.

The sum of correlation map $m_{\text{sum}}$ as calculated by

$m_{\text{sum}} = \sum_{j = 0}^{\text{127}}{M_{\text{cor}}(j)}$ (349)

is also stored into a buffer
$\text{BUF}_{m_{\text{sum}}}(i),i = 0,1\text{.}\text{.}\text{.}\text{59}$
of 60 frames, where $M_{\text{cor}}(j)$ is the correlation map
calculated in subclause 5.1.11.2.5.

The voicing parameter $\text{vm}$ is defined as the difference of
log-likelihood between speech class and music class as calculated in
subclause 5.1.13.6.3. The $\text{vm}$ is calculated as

$\text{vm} = L_{s} - L_{m}$ (350)

where $L_{s}$, $L_{m}$ are the log-likelihood of speech class and the
log-likelihood of music class respectively. $\text{vm}$is stored into a
buffer $\text{BUF}_{\text{vm}}(i),i = 0,1\text{.}\text{.}\text{.}9$ of
10 frames.

The speech/music decision $f_{SM^{'}}$ is obtained through a tree-based
classification. The $f_{SM^{'}}$ is first initialized as a hysteresis of
the long-term speech/music decision $\text{LTf}_{SM^{'}}$ from the
previous frame, i.e.

$f_{SM^{'}} = \begin{matrix}
\left\{ 1\ \text{if}\ \text{LTf}_{SM^{'}}^{\lbrack - 1\rbrack} > 0\text{.}5 \middle| \right.\  \\
\end{matrix}$ (351)

where the superscript \[-1\] denotes the value from the previous frame.
Then, the $f_{SM^{'}}$ can be altered through successive
classifications. Let $\text{LEN}$ denotes the length of the effective
portion in$\text{BUF}_{\text{flux}}(i)$. Depending on the actual value
of $\text{LEN}$, different classification procedures are followed. If
$\text{LEN} \leq 5$, insufficient data is considered in the feature
parameter buffers. The classification is terminated and the initialized
$f_{SM^{'}}$ is used as the final $f_{SM^{'}}$. If
$5 < \text{LEN} < \text{10}$, the respective mean values
$M_{\text{pk}_{h}}$, $M_{m_{\text{sum}}}$and $M_{\text{NT}}$are
calculated from $\text{BUF}_{\text{pk}_{h}}(i)$,
$\text{BUF}_{\text{cor}_{\text{sum}}}(i)$ and
$\text{BUF}_{\text{NT}}(i)$ over the effective portion and the variance
$V_{\text{tilt}}$, calculated over the effective portion from
$\text{BUF}_{\text{tilt}}(i)$ is also obtained. In addition, the number
of positive values $N_{\text{vm}6}$ among the 6 latest values in
$\text{BUF}_{\text{vm}}(i)$ is counted. The speech/music decision
$f_{SM^{'}}$ is then set to 1 if $N_{\text{vm}6} < 4$and any of the
following conditions is fulfilled; $M_{\text{pk}_{h}} > \text{1100}$ or
$M_{m_{\text{sum}}} > \text{100}$ or
$V_{\text{tilt}} < 0\text{.}\text{00008}$ or
$M_{\text{NT}} > \text{27}$. Otherwise, if $\text{LEN} > \text{10}$, the
feature buffers are first analysed over the portion
$\text{POR}_{\text{10}}$ containing the latest 10 values. The mean
values $M_{\text{flux}_{\text{10}}}$, $M_{\text{pk}_{h\text{10}}}$and
$M_{m_{\text{sum}\text{10}}}$ are calculated
from$\text{BUF}_{\text{flux}}(i)$, $\text{BUF}_{\text{pk}_{h}}(i)$and
$\text{BUF}_{m_{\text{sum}}}(i)$ over $\text{POR}_{\text{10}}$and for
the same portion the variance $V_{\text{tilt}_{\text{10}}}$ is also
calculated from $\text{BUF}_{\text{tilt}}(i)$.Besides, the mean value
of$\text{BUF}_{\text{flux}}(i)$$M_{\text{flux}_{5}}$, over a shorter
portion of the latest 5 frames is also calculated. The $N_{\text{vm}}$
is found as the number of positive values in$\text{BUF}_{\text{vm}}(i)$.
The speech/music decision $f_{SM^{'}}$ is determined without the need to
analyse any longer portion if strong speech or music characteristics are
found within $\text{POR}_{\text{10}}$, that is, the $f_{SM^{'}}$ and
$\text{LTf}_{SM^{'}}$ are both set to 1 if $N_{\text{vm}} < 3$ and
$M_{\text{flux}_{5}} < \text{15}$ and any of the following conditions is
fulfilled: $M_{\text{flux}_{\text{10}}} < 8\text{.}5$ or
$M_{\text{pk}_{h\text{10}}} > \text{1050}$ or
$M_{m_{\text{sum}\text{10}}} > \text{100}$ or
$V_{\text{tilt}_{\text{10}}} < 0\text{.}\text{001}\ \text{\&\&}\ M_{\text{flux}_{\text{10}}}\text{12}$
. The $f_{SM^{'}}$ and $\text{LTf}_{SM^{'}}$ are both set to 0 if any of
the following conditions is fulfilled:
$M_{\text{flux}_{\text{10}}} > \text{16}$ or
$M_{\text{flux}_{5}} > \text{19}$ or
$M_{\text{flux}_{\text{10}}} > \text{15}\ \text{\&\&}\ N_{\text{vm}}2$
or
$\text{BUF}_{\text{flux}}(\text{59}) \geq \text{20}\ \text{\&\&}\ \text{vm} > 0$.
If no class is determined for $f_{SM^{'}}$ over the
$\text{POR}_{\text{10}}$values, the $f_{SM^{'}}$ is determined
iteratively over portions starting from $\text{POR}_{\text{10}}$ until
the whole effective portion is reached. For each iteration, the
respective mean values$M_{\text{flux}}$, $M_{\text{pk}_{h}}$and
$M_{m_{\text{sum}}}$ are calculated from$\text{BUF}_{\text{flux}}(i)$,
$\text{BUF}_{\text{pk}_{h}}(i)$ and
$\text{BUF}_{\text{cor}_{\text{sum}}}(i)$ over the portion under
analysis and for the same portion the variance $V_{\text{tilt}}$ is also
calculated from $\text{BUF}_{\text{tilt}}(i)$. The mean value
$M_{\text{flux}_{\text{10}}}$is calculated from
$\text{BUF}_{\text{flux}}(i)$ over $\text{POR}_{\text{10}}$, and the
number of positive values in $b_{\text{LQMF}}$,$N_{\text{vm}}$, is also
counted. The value of $f_{SM^{'}}$ is set to 1 if $N_{\text{vm}} < 3$
and any of the following conditions is fulfilled:
$M_{\text{flux}} < \text{12} + 0\text{.}\text{05} \cdot (\text{LEN} - \text{10})\ \text{\&\&}M_{\text{flux}_{\text{10}}} < \text{15}$
or
$V_{\text{tilt}} < 0\text{.}\text{0001} + 0\text{.}\text{000018} \cdot (\text{LEN} - \text{10})$
or $M_{\text{pk}_{h}} > \text{1050} - 5 \cdot (\text{LEN} - \text{10})$
or$M_{m_{\text{sum}}} > \text{95} - 0\text{.}3 \cdot (\text{LEN} - \text{10})$.
If through the above iteration procedure the $f_{SM^{'}}$ is not set and
if the effective portion reaches the maximum of 60 frames, a final
speech/music discrimination is made from $L_{\text{FFT}}$,
$\text{BUF}_{\text{NT}_{l}}(i)$ and $\text{BUF}_{\text{NT}2}(i)$. The
mean value $L_{\text{FFT}}$ of the $L_{\text{FFT}}$, the sum value
$L_{\text{FFT}}$ of the $\text{BUF}_{\text{NT}_{l}}(i)$, and the sum
value $M_{\text{NT}2}$ of the $\text{BUF}_{\text{NT}2}(i)$ are
calculated over the whole buffers. A low frequency tonal ratio
$R_{\text{NT}_{l}}$ is calculated as

$R_{\text{NT}_{l}} = \frac{S_{\text{NT}_{l}}}{S_{\text{NT}2}}$ (352)

The $f_{SM^{'}}$ is set to 1 if $M_{\text{NT}} > \text{18}$ or
$R_{\text{NT}_{l}} < 0\text{.}2$. Otherwise, if $M_{\text{NT}} < 1$, the
$f_{SM^{'}}$is set to 0.

If $\text{LEN}$ is greater than 30, then both the two long-term
speech/music decisions $\text{LTf}_{SM^{'}}$ and
${\text{LT\ \{}f}_{SM^{'}}^{'}$ are updated at each frame with
$f_{SM^{'}}$ as

$\text{LTf}_{SM^{'}} = 0\text{.}\text{97} \cdot \text{LTf}_{SM^{'}}^{\lbrack - 1\rbrack} + (1 - 0\text{.}\text{97}) \cdot f_{SM^{'}}$
(353)

${\text{LT\ \{}f}_{SM^{'}}^{'} = 0\text{.}\text{97} \cdot \text{LT\ \{}f{}_{SM^{'}}^{} + (1 - 0\text{.}\text{97}) \cdot f_{SM^{'}}$
(354)

where the superscript \[-1\] denotes the value from the previous frame.
If the total frame energy $E_{t}$ calculated in subclause 5.1.5.2 is
greater than 1.5 and $\text{BUF}_{\text{NT}2}(\text{59})$ is less than 2
and the raw coding mode $\text{CT}_{\text{raw}}$ is either UNVOICED or
INACTIVE, then an unvoiced counter $\text{CT}_{\text{uv}}$ initialized
to 300 at the first frame is updated by

$\text{CT}_{\text{uv}} = \text{CT}_{\text{uv}} - 8$ (355)

Otherwise, $\text{CT}_{\text{uv}}$ is incremented by 1. The value of
$\text{CT}_{\text{uv}}$ is bounded between \[0, 300\]. The
$\text{CT}_{\text{uv}}$ is further smoothed by an AR filtering as

$\text{LT}_{\text{CT}_{\text{uv}}} = 0\text{.}9 \cdot \text{LT}_{\text{CT}_{\text{uv}}}^{\lbrack - 1\rbrack} + 0\text{.}1 \cdot \text{CT}_{\text{uv}}$
(356)

where $\text{LT}_{\text{CT}_{\text{uv}}}$is the smoothed
$\text{CT}_{\text{uv}}$, the superscript \[-1\] denotes the value from
the previous frame. If $f_{SM^{'}}$ is set to 1 in any previous stage,
the flag $f_{\text{SM}1}$ is overridden by $f_{SM^{'}}$ unless the
long-term speech/music decision ${\text{LT\ \{}f}_{SM^{'}}^{'}$ as
calculated in equation (357) is close to speech and the smoothed
unvoiced counter$\text{LT}_{\text{CT}_{\text{uv}}}$ exhibits strong
unvoiced characteristic, that is, the $f_{\text{SM}1}$ is set to 1 if
$f_{SM^{'}} = 1$ and
${\text{LT\ \{}f}_{SM^{'}}^{'} \geq 0\text{.}2\ \text{or}\ \text{LT}_{\text{CT}_{\text{uv}}} \geq \text{200}$
.

##### 5.1.13.6.6 Second stage of the speech/music classifier

The second stage of the speech/music classifier has been designed and
optimized for the GSC technology. Not all frames classified as music in
the first stage can be encoded directly with the GSC technology due to
its inherent limitations. Therefore, in the second stage of the
speech/music classifier, a subset of frames that have been previously
classified as "music", i.e. for which $f_{\text{SM}1} = 1$, are reverted
to speech and encoded with one of the CELP modes. The decision in the
second stage of the speech/music classifier is denoted $f_{\text{SM}2}$.
The second stage is run only for WB, SWB and FB signals, not for NB. The
reason for this limitation is purely due to the fact that GSC technology
is only applied at bandwidths higher than NB.

The second stage of the speech/music classifier starts with signal
stability estimation which is based on frame-to-frame difference of the
total energy of the input signal. That is

$\text{dE}_{t}(i) = E_{t}^{\lbrack - i\rbrack} - E_{t}^{\lbrack - i - 1\rbrack},\ \text{for\ }i = 1,\text{.}\text{.},\text{40}$
(358)

Then, the mean energy difference is calculated as

${\overline{\text{dE}}}_{t} = \frac{1}{\text{40}}\sum_{i = 1}^{\text{40}}{\text{dE}_{t}(i)}$
(359)

i.e. over the period of the last 40 frames. Then, the statistical
deviation of the delta-energy values around this mean is calculated as

$E_{\text{dev}} = \sqrt{\frac{1}{\text{15}}\sum_{i = 1}^{\text{15}}\left( \text{dE}_{t}(i) - {\overline{\text{dE}}}_{t} \right)^{2}}$
(360)

i.e. over the period of the last 15 frames.

After signal stability estimation, correlation variance is calculated as
follows. First, mean correlation is estimated over the period of the
last 10 frames. This is done as

${\overline{C}}_{\text{norm}2} = \frac{1}{\text{10}}\sum_{i = 1}^{\text{10}}C_{\text{norm}2}^{\lbrack - i\rbrack}$
(361)

where
$C_{\text{norm}2} = 0\text{.}5C_{\text{norm}}^{\lbrack 0\rbrack} + 0\text{.}5C_{\text{norm}}^{\lbrack 1\rbrack} + r_{e}$
and the superscript \[-1\] is used to denote past frames. Then, the
correlation variance is defined as

$E_{\text{dev}} = \frac{1}{\text{10}}\sum_{i = 1}^{\text{10}}\left( C_{\text{norm}2}^{\lbrack - i\rbrack} - {\overline{C}}_{\text{norm}2} \right)^{2}$
(362)

In order to discriminate highly-correlated stable frames, long-term
correlation is calculated as

${\overset{\sim}{C}}_{\text{norm}2} = 0\text{.}9{\overset{\sim}{C}}_{\text{norm}2}^{\lbrack - 1\rbrack} + 0\text{.}1C_{\text{norm}2}^{\lbrack - 1\rbrack}$
(363)

The flag $f_{\text{hscor}}$ is set to 1 if
${\overset{\sim}{C}}_{\text{norm}2}^{\lbrack - 1\rbrack} > 0\text{.}8$
and at the same time $E_{\text{dev}} < 0\text{.}\text{0005}$.

In the next step, attacks are detected in the inputs signal. This is
done by dividing the current frame of the input signal into 32 segments
where each segment has the length of 8 samples. Then, energy is
calculated in each segment as

$E_{\text{seg}}(k) = \sum_{i = 0}^{7}{s_{\text{pre}}^{2}(8k + i)},\ \text{for\ }k = 0,\text{.}\text{.},\text{31}$
(364)

The segment with the maximum energy is then found by

$k_{\text{att}} = \underset{k}{\text{max}}\left( E_{\text{seg}}(k) \right)$
(365)

and this is the position of the candidate attack. In all active frames
where $f_{\text{LSAD}} > 0$ and for which the coding mode was set to GC,
the following logic is executed to eliminate false attacks, i.e. attacks
that are not sufficiently strong. First, the mean energy in the first 3
sub-frames is calculated as

$E_{\text{SF}3} = \frac{1}{\text{24}}\sum_{k = 0}^{\text{23}}{E_{\text{seg}}(k)}$
(366)

and the mean energy after the detected candidate attack is defined

$E_{\text{after}} = \frac{1}{\text{32} - k_{\text{att}}}\sum_{k = k_{\text{att}}}^{\text{31}}{E_{\text{seg}}(k)}$
(367)

and the ratio of these two energies is compared to a certain threshold.
That is

$\text{if\ \ }\frac{E_{\text{after}}}{E_{\text{SF}3}} < 8\text{\ \ then\ \ }k_{\text{att}} = 0$
(368)

Thus, the candidate attack position is set to 0 if the attack is not
sufficiently strong. Further, if the FEC class of the last frame was
VOICED CLASS and if
$\frac{E_{\text{after}}}{E_{\text{SF}3}} < \text{20}$ then
$k_{\text{att}}$ is also set to 0.

To further reduce the number of falsely detected attacks, the segment
with maximum energy is compared to other segments. This comparison is
done regardless of the selected coding mode and $f_{\text{LSAD}}$.

$\text{if\ \ }\frac{E_{\text{seg}}(k_{\text{att}})}{E_{\text{seg}}(k)} < 1\text{.}3\text{\ \ then\ \ }k_{\text{att}} = 0\ \text{for\ }k = 2,\text{.}\text{.},\text{21},\ k \neq k_{\text{att}}$
(369)

Thus, if the energy in any of the above defined segments, other than
$k_{\text{att}}$, is close to that of the candidate attack, the attack
is eliminated by setting $k_{\text{att}}$ to 0.

Initially the speech/music decision in the second stage is set equal to
the speech/music decision from the first stage, i.e.
$f_{\text{SM}2} = f_{\text{SM}1}$. In case the decision is "music", it
could be reverted to "speech" in the following situations.

The decision is reverted from music to speech for highly correlated
stable signals with higher pitch period. These signals are characterized
by

$\text{if\ \ }f_{\text{hscor}} > 0\text{\ \ \ AND\ \ }T_{\text{OL}}^{\lbrack 0\rbrack} > \text{130}\text{\ \ then\ \ }f_{\text{SM}2} = 0$
(370)

Further, if the above condition is fulfilled and the selected coding
mode was TC, it is changed to GC. This is to avoid any transition
artefacts during stable harmonic signal.

In case there is an energetic event characterized by
$\text{dE}_{t}(1) > 4\text{.}5$ and at the same time
$\text{dE}_{t}(1) - \text{dE}_{t}(2) > \text{10}$ it could mean that an
attack has occurred in the input signal and the following logic takes
place. If, in this situation, the counter of frames from the last
detected onset/transition $i_{\text{TC}}$, described in subclause
5.1.13.4, has been set to 1 the attack is confirmed and the decision is
changed to speech, i.e. $f_{\text{SM}2} = 0$. Also, the coding mode is
changed to TC. Otherwise, if there has been an attack found by the
attack tracking algorithm described above, and the position of this
attack is beyond the end of the third sub-frame, the decision is also
changed to speech and the coding mode is changed to TC. That is

$\text{if\ \ }k_{\text{att}} \geq \text{24}\text{\ \ \ then\ \ }f_{\text{SM}2} = 0$
(371)

Furthermore, an attack flag $f_{\text{att}}$ is set to 1 if the detected
attack is located after the first quarter of the first sub-frame, i.e.
when $k_{\text{att}} \geq 4$. This flag is later used by the GSC
technology. Finally, the attack flag $f_{\text{att}}$ is set to 1 in all
active frames ($f_{\text{LSAD}} = 1$) that have been selected for GC
coding and for which the decision in the first stage of the speech/music
classifier was "speech". However, it is restricted only to frames in
which the attack is located in the fourth subframe. In this case, the
coding mode is also changed to TC for better representation of the
attack.

As previously described, if $f_{\text{spitch}}$=flag\_spitch=1, VC mode
is maintained and AC mode is set to 0; that is,

if ($f_{\text{spitch}}$=1 and sampling rate = 16kHz and bit rate \<
13.2kbps )

{

$f_{\text{SM}2}$=0;

}

##### 5.1.13.6.7 Context-based improvement of the classification for stable tonal signals

By using context-based improvement of the classification, an error in
the classification in the previous stage can be corrected. If the
current frame has been provisionally classified as "speech", the
classification result can be corrected to "music", and vice versa. To
determine a possible error in the current frame, the values of 8
consecutive frames including the current frame are considered for some
features.

Figure 19 shows the multiple coding mode signal classification method.
If the current frame has been provisionally classified as "speech" after
the first- and second-stage classification, then the frame is encoded
using the CELP-based coding. On the other hand, if the current frame is
initially classified as "music" after the first- and second-stage
classification, then the frame is further analysed for
fine-classification of "speech" or "music" to select either the
GSC-based coding or MDCT-based transform coding, respectively. The
parameters used to perform the fine-classification in multiple coding
mode selection include:

-   Tonality

-   Voicing

-   Modified correlation

-   Pitch gain, and

-   Pitch difference

The tonality in the sub-bands of 0-1kHz, 1-2 kHz, and 2-4 kHz are
estimated as $\text{tonality}1$, $\text{tonality}2$, and
$\text{tonality}3$ as follows:

$\text{tonality}1 = \frac{\underset{k = \lbrack 0,1,\text{.}\text{.}\text{.}\text{19}\rbrack}{\text{max}}\left( \text{PS}(k) \right)}{\sum_{k = 0}^{\text{19}}{\text{PS}(k)}}$

$\text{tonality}2 = \frac{\underset{k = \lbrack\text{20},\text{21},\text{.}\text{.}\text{.}\text{39}\rbrack}{\text{max}}\left( \text{PS}(k) \right)}{\sum_{k = \text{20}}^{\text{39}}{\text{PS}(k)}}$

$\text{tonality}3 = \frac{\underset{k = \lbrack\text{40},\text{41},\text{.}\text{.}\text{.}\text{79}\rbrack}{\text{max}}\left( \text{PS}(k) \right)}{\sum_{k = \text{40}}^{\text{79}}{\text{PS}(k)}}$

where $\text{PS}$ is the power spectrum. The maximum tonality,
$\text{tonality}$, is estimated as,

$\text{tonality} = \text{max}\left( \text{tonality}1,\text{tonality}2,\text{tonality}3 \right)$

The voicing feature, $\text{voicing}$, is the same one as used in the
unvoiced signal classification. See equation (237) in subclause
5.1.13.1.1. for the details of its computation. The voicing feature from
the first analysis window is used, i.e.

$\text{voicing} = C_{\text{norm}}^{\lbrack 0\rbrack}$

The modified correlation, $\text{old}_{\text{corr}}$, is the normalized
correlation from the previous frame.

The pitch gain, $\text{lowrate}_{\text{pitchGain}}$, is the smoothed
closed-loop pitch gain estimated from the previous frame, i.e.,

$\text{lowrate}_{\text{pitchGain}} = 0\text{.}9 \ast \text{lowrate}_{\text{pitchGain}} + 0\text{.}1 \ast \text{gain}_{\text{pit}}$

where $\text{gain}_{\text{pit}}$ is the ACB gain in each of the
sub-frames from the previous frame.

The pitch deviation is estimated as the sum of pitch differences between
the current frame open-loop pitch , $T_{\text{op}}^{n}$ and the open
loop pitch in the previous three frames,
$T_{\text{op}}^{n - 1},T_{\text{op}}^{n - 2},T_{\text{op}}^{n - 3}$

$\text{pitch}_{\text{diff}} = \sum_{i = 1}^{3}\left| T_{\text{op}}^{n - i} - T_{\text{op}}^{n} \right|$

The features, $\text{voicing}$, $\text{old}_{\text{corr}}$, and
$\text{tonality}$ are smoothed to minimize spurious instantaneous
variations as follows:
$\text{lt}_{\text{voicing}} = \alpha_{1c} \ast \text{lt}_{\text{voicing}} + (1 - \alpha_{1c}) \ast \text{voicing}$

$\text{lt}_{\text{corr}} = \alpha_{2c} \ast \text{lt}_{\text{corr}} + (1 - \alpha_{2c}) \ast \text{old}_{\text{corr}}$

$\text{lt}_{\text{tonality}} = \alpha_{3c} \ast \text{lt}_{\text{tonality}} + (1 - \alpha_{3c}) \ast \text{tonality}$

where $\alpha_{1c}$ and $\alpha_{2c}$are 0.1 in active frames (i.e., SAD
= 1), and 0.7 in background noise and inactive frames. Similarly,
$\alpha_{3c}$is 0.1 in active frames and 0.5 in inactive frames.

Figure 20 : Multiple coding mode signal classification

The following condition is evaluated to select the GSC or MDCT based
coding,

A hangover logic is used to prevent frequent switching between coding
modes of GSC and MDCT-based coding. A hangover period of 6 frames is
used. The coding mode is further modified as per below.

Figure 21 shows two independent state machines, which are defined in the
context-based classifier, SPEECH\_STATE and MUSIC\_STATE. Each state
machine has two states . In each state a hangover of 6 frames is used to
prevent frequent transitions. If there is a change of decision within a
given state, the hangover in each state is set to 6, and the hangover is
then reduced by 1 for each subsequent frame. A state change can only
occur once the hangover has been reduced to zero. The following six
features are used in the context-based classifier (the superscript
\[-*i*\] is used below to denote the past frames).

The tonality in the region of 1\~2 kHz, $\text{ton}_{2}$ is defined as

$\text{ton}_{2} = 0\text{.}2\text{*log}_{\text{10}}\left\lbrack \sqrt{\frac{1}{8}\sum_{i = 0}^{7}\left\{ \text{tonality}2^{\lbrack - i\rbrack} \right\}^{2}} \right\rbrack$
(372)

The tonality in the region of 2\~4 kHz, $\text{ton}_{3}$ is defined as

$\text{ton}_{3} = 0\text{.}2\text{*log}_{\text{10}}\left\lbrack \sqrt{\frac{1}{8}\sum_{i = 0}^{7}\left\{ \text{tonality}3^{\lbrack - i\rbrack} \right\}^{2}} \right\rbrack$
(373)

The long-term tonality in the low band, $\text{ton}_{\text{LT}}$ is
defined as

$\text{ton}_{\text{LT}} = 0\text{.}2\text{*log}_{\text{10}}\left\lbrack \text{lt}_{\text{tonality}} \right\rbrack$
(374)

The difference between the tonality in 1\~2 kHz band and the tonality in
2\~4 kHz band is defined as

$d_{\text{ft}} = 0\text{.}2 \ast \left\{ \text{log}_{\text{10}}(\text{tonality}2(n)) - \text{log}_{\text{10}}(\text{tonality}3(n)) \right\}$
(375)

The linear prediction error $\text{LP}_{\text{err}}$ is defined as

$\text{LP}_{\text{err}} = \sqrt{\frac{1}{8}\sum_{i = 0}^{7}\left\{ \text{FV}_{s}^{\lbrack - i\rbrack}(9) \right\}^{2}}$
(376)

where $\text{FV}_{s}(9)$ has been defined in equation (377).

The difference between the scaled voicing feature $\text{FV}_{s}(1)$
defined equation (378) and the scaled correlation map feature
$\text{FV}_{s}(7)$ defined in equation (379) is defined as

$d_{\text{vcor}} = \text{max}(\text{FV}_{s}(1) - \text{FV}_{s}(7),0)$
(380)

The following two independent state machines are used to correct errors
in the previous stages of the speech/music classification. The are two
state machines are called SPEECH\_STATE and MUSIC\_STATE. There are also
two hangover variables denoted $\text{hang}_{\text{sp}}$ and
$\text{hang}_{\text{mus}}$ which are initialized to the value of 6
frames. The following four conditions are evaluated to determine the
transition of one state to another.

Condition A is defined as

$\begin{matrix}
\text{if\ }d_{\text{vcor}} > 0\text{.}4\text{AND}\text{\ d}_{\text{ft}} < 0\text{.}1\text{AND}\text{\ FV}_{s}(1) > \left( 2\text{*FV}_{s}(7) + 0\text{.}\text{12} \right)\text{AND}\text{\ ton}_{2} < d_{\text{vcor}}\text{AND} \\
\text{ton}_{3} < d_{\text{vcor}}\text{AND}\text{\ ton}_{\text{LT}} < d_{\text{vcor}}\text{AND}\text{\ FV}_{s}(7) < d_{\text{vcor}}\text{AND}\text{\ FV}_{s}(1) > d_{\text{vcor}}\text{AND}\text{\ FV}_{s}(1) > 0\text{.}\text{76} \\
\text{then}\ f_{A} = 1 \\
\end{matrix}$ (381)

Condition B is then defined as

$\text{if\ }d_{\text{vcor}} < 0\text{.}4\text{then}\ f_{B} = 1$ (382)

Condition C is defined as

$\begin{matrix}
\text{if\ 0}\text{.}\text{26} < \text{ton}_{2} < 0\text{.}\text{54}\text{AND\ }\text{ton}_{3} > 0\text{.}\text{22}\text{AND\ \ 0}\text{.}\text{26} < \text{ton}_{\text{LT}} < 0\text{.}\text{54}\text{AND\ \ }\text{LP}_{\text{err}} > 0\text{.}5 \\
\text{then}\ f_{C} = 1 \\
\end{matrix}$ (383)

and finally condition D is defined as

$\text{if\ }\text{ton}_{2} < 0\text{.}\text{34}\text{AND\ }\text{ton}_{3} < 0\text{.}\text{26}\text{AND\ \ 0}\text{.}\text{26} < \text{ton}_{\text{LT}} < 0\text{.}\text{45}\text{\ then}\ f_{D} = 1$
(384)

![](media/image30.wmf){width="6.694444444444445in"
height="2.123611111111111in"}

Figure 22 : State machines for context-based speech/music correction

The decisions from the speech/music classifier, $f_{\text{SM}1}$ and
$f_{\text{SM}2}$ are changed to 0 ("speech") if $f_{\text{SM}1}$ was
previously set to 1 ("music") and if the context-based classifier is in
SPEECH\_STATE. Similarly, the decisions from the speech/music
classifier, $f_{\text{SM}1}$ and $f_{\text{SM}2}$ are changed to 1
("music") if $f_{\text{SM}1}$ was previously set to 0 ("speech") and if
the context-based classifier is in MUSIC\_STATE.

##### 5.1.13.6.8 Detection of sparse spectral content

At 13.2kbps, the coding of music signal benefits from combining the
advantages of MDCT and GSC technologies. For frames classified as music
after the context-based improvement, coding mode producing better
quality is selected between MDCT and GSC based on an analysis of signal
spectral sparseness and linear prediction efficiency (depending on the
input bandwidth).

For each active frame, the sum of the log energy spectrum
$\text{PS}_{\text{log}}(k),\ k = 0,1,\text{.}\text{.}\text{.},\text{127}$
is calculated to determine the spectral sparseness analysis.

$S_{\text{PS}_{\text{log}}} = \sum_{k = 0}^{\text{127}}{\text{PS}_{\text{log}}(k)}$
(385)

Then the log energy spectrum $\text{PS}_{\text{log}}(k)$ is sorted in
descending order of magnitude. Each element in the sorted log energy
spectrum $\text{PS}_{\text{log} \downarrow}(k)$ is accumulated one by
one along in descending order until the accumulated value exceeds 75% of
the $S_{\text{PS}_{\text{log}}}$. The index (or the
position),$I_{\text{spa}}$, of the last element added into the
accumulation can be regarded as a kind of representation of the spectral
sparseness of the frame and is stored into a sparseness buffer
$\text{BUF}_{\text{spa}}(k)$ of 8 frames.

If the input bandwidth is WB, some parameters dedicated to WB are
calculated, including the mean of the sparseness buffer, the long-term
smoothed sparseness, the high-band log energy sum, the high-band high
sparseness flag, the low-band high sparseness flag, the linear
prediction efficiency and the voicing metric. For other input bandwidths
the above parameters are not calculated. The mean of the sparseness
buffer is obtained as

$M_{\text{spa}} = \frac{1}{8} \cdot \sum_{k = 0}^{7}{\text{BUF}_{\text{spa}}(k)}$
(386)

Then the long-term smoothed sparseness $\text{LT}_{\text{spa}}$ is
calculated as

$\text{LT}_{\text{spa}} = 0\text{.}\text{75} \cdot \text{LT}_{\text{spa}}^{\lbrack - 1\rbrack} + 0\text{.}\text{25} \cdot M_{4\text{min}}$
(387)

where $\text{LT}_{\text{spa}}^{\lbrack - 1\rbrack}$denotes the long-term
smoothed sparseness in the previous frame, $M_{4\text{min}}$ denotes the
average of the four smallest values in the sparseness buffer
$\text{BUF}_{\text{spa}}(k)$. The reason of using $M_{4\text{min}}$ is
to reduce the possible negative impact to the $\text{LT}_{\text{spa}}$
from interfering frames. The long-term smoothed sparseness
$\text{LT}_{\text{spa}}$ is initialized to the value of $I_{\text{spa}}$
and the sparseness buffer $\text{BUF}_{\text{spa}}(k)$ is also
initialized to the value of $I_{\text{spa}}$ for all its elements if the
current frame is the first active frame after a pause. The high-band log
energy sum is calculated over
$\text{PS}_{\text{log}}(k),\ k = \text{80},\text{81},\text{.}\text{.}\text{.},\text{127}$

$S_{\text{PS}_{\text{log}}h} = \sum_{k = \text{80}}^{\text{127}}{\text{PS}_{\text{log}}(k)}$
(388)

To obtain the high-band high sparseness flag, the high-band log energy
spectrum
$\text{PS}_{\text{log}}(k),\ k = \text{80},\text{81},\text{.}\text{.}\text{.},\text{127}$
is first sorted in descending order. The ratio of the sum of the first 5
elements (or the 5 largest values) of the sorted high-band log energy
spectrum to the high-band log energy sum is calculated

$R_{\text{sph}} = \frac{\sum_{k = 0}^{4}{\text{PS}_{\text{log}h \downarrow}(k)}}{S_{\text{PS}_{\text{log}}h}}$
(389)

where
$\text{PS}_{\text{log}h \downarrow}(k),\ k = 0,1,\text{.}\text{.}\text{.},\text{47}$
is the sorted high-band log energy spectrum. The ratio $R_{\text{sph}}$
can be regarded as a kind of representation of the high-band spectral
sparseness of the frame and is stored into a high-band sparseness buffer
$\text{BUF}_{\text{spah}}(k)$. The mean of the buffer
$\text{BUF}_{\text{spah}}(k)$ is calculated. If the mean is greater than
0.2, the high-band high sparseness flag $f_{\text{spah}}$ is set to 1
indicating a high sparseness of the high-band spectrum, otherwise set to
0. Similarly, to obtain the low-band high sparseness flag, the low-band
log energy spectrum
$\text{PS}_{\text{log}}(k),\ k = 0,1,\text{.}\text{.}\text{.},\text{59}$
is sorted in descending order and the ratio of the sum of the first 5
elements (or the 5 largest values) of the sorted low-band log energy
spectrum to the low-band log energy sum is calculated

$R_{\text{spl}} = \frac{\sum_{k = 0}^{4}{\text{PS}_{\text{log}l \downarrow}(k)}}{\sum_{k = 0}^{\text{59}}{\text{PS}_{\text{log}}(k)}}$
(390)

where
$\text{PS}_{\text{log}l \downarrow}(k),\ k = 0,1,\text{.}\text{.}\text{.},\text{47}$
is the sorted low-band log energy spectrum. The ratio $R_{\text{spl}}$
can be regarded as a kind of representation of the low-band sparseness
of the frame. If the ratio is greater than 0.18, the low-band high
sparseness flag $f_{\text{spal}}$ is set to 1 indicating a high
sparseness of the low-band spectrum, otherwise set to 0. The LP residual
log-energy ratio of the current frame $\text{epsP}$, as calculated in
subclause 5.1.13.5.1 which is shown again below

$\text{epsP} = \text{log}\left( \frac{E^{\lbrack - 1\rbrack}(\text{13})}{E^{\lbrack - 1\rbrack}(1)} \right)$
(391)

is stored into a LP residual log-energy ratio buffer
$\text{BUF}_{\text{epsP}}(k)$ of 8 frames. The mean of the buffer
$\text{BUF}_{\text{epsP}}(k)$, $M_{\text{epsP}}$, is calculated and used
to represent the short-term linear prediction efficiency at the current
frame. The lower the $M_{\text{epsP}}$ is the higher the short-term
linear prediction efficiency is. The scaled normalized
correlation$\text{FV}_{s}(1)$ as calculated in subclause 5.1.13.5.2 is
stored into a voicing buffer $\text{BUF}_{v}(k)$ of 8 frames. The mean
of the buffer $\text{BUF}_{v}(k)$, $M_{v}$, is calculated and used to
represent the voicing metric at the current frame.

Decision on which coding mode to use (MDCT or GSC) is made for each
frame previously classified as music, that is, for each frame where
$f_{\text{SM}1}$ is set to 1. GSC coding mode is selected by setting
$f_{\text{SM}2}$ to 1 and changing $f_{\text{SM}1}$ to 0. GSC coding
mode is selected for frame with extremely non-sparse spectrum, that is,
when $I_{\text{spa}}$ is greater than 90. In this case, the GSC hangover
flag $f_{H_{\text{GSC}}}$ is also set to 1 meaning that a soft hangover
period will be applied. Otherwise, if $f_{H_{\text{GSC}}}$ is set to 1,
the current frame is in a soft hangover period where the determination
of extremely non-sparse spectrum is slightly relaxed, that is, GSC
coding mode is selected if $I_{\text{spa}}$ is greater than 85. If in
above case, $I_{\text{spa}}$ is not greater than 85, GSC coding mode is
still selected if $I_{\text{spa}}$ of the current frame is deviating
from the average $I_{\text{spa}}$ of its adjacent GSC coded frames by
less than 7. A maximum of 7 frames are used for the averaging. The
selection between MDCT coding mode and GSC coding mode ends here if the
input bandwidth is SWB. For WB input bandwidth, one more step is
applied. In this case, GSC coding mode is also selected if the various
sparseness measures calculated all do not exhibit strong sparseness
characteristics and the linear prediction efficiency is assumed high.
Specifically, GSC coding mode is selected if
$M_{\text{epsP}} < - 1\text{.}3$ and $M_{v} > 0\text{.}\text{85}$ and
$I_{\text{spa}} > \text{50}$ and $\text{LT}_{\text{spa}} > \text{60}$
and $f_{\text{spal}}$ is set to 0 and
$S_{\text{PS}_{\text{log}}h} \leq 0\text{.}\text{15} \ast S_{\text{PS}_{\text{log}}}$
or if condition
$S_{\text{PS}_{\text{log}}h} \leq 0\text{.}\text{15} \ast S_{\text{PS}_{\text{log}}}$
is not met but$f_{\text{spah}}$ is not set to 1. In above case, the GSC
hangover flag $f_{H_{\text{GSC}}}$ is also set to 1. The flag
$f_{H_{\text{GSC}}}$ is set to 0 if GSC coding mode is not selected
through the whole procedure described above.

##### 5.1.13.6.9 Decision about AC mode

The decisions in the first and in the second stage of the speech/music
classifier, refined and corrected by the modules described so far are
used to determine the usage of the AC mode. As mentioned before, in the
AC mode GSC technology is used to encode the input signal. The decision
about the AC mode is done always but the GSC technology is used only at
certain bitrates. This is described in subclause 5.1.16.

Before making decision about the AC mode, the speech/music
classification results are overridden for certain noisy speech signals.
If the level of the background noise is higher than 12dB, i.e. when
${\overline{N}}_{t} > \text{12}$, then
$f_{\text{SM}1} = f_{\text{SM}2} = 0$. This is a protection against
mis-classification of active noisy speech signals.

For certain unvoiced SWB signals, GSC technology is preferred over the
UC or GC mode which would normally be selected. In order to override the
selection of the coding mode, there is a flag denoted
$f_{\text{UV}_{\text{SWB}}}$ which is set to 1 under the following
condition

${\text{if\ }f_{\text{SAD}} = 1\text{AND\ \ \ \{}\overline{N}}_{t} > \text{12}\text{AND\ \ }f_{\text{SM}1} = 0\text{AND\ \ }\text{BW} \geq \text{SWB\ }\text{AND\ \ }c_{\text{raw}} = \text{UC}\text{\ \ then\ }\ f_{\text{UV}_{\text{SWB}}} = 1$
(392)

where $c_{\text{raw}}$ is the raw coding mode, described in subclause
5.1.13.2.

The AC mode is selected if $f_{\text{SM}2} = 1$ or if
$f_{\text{UV}_{\text{SWB}}} = 1$.

##### 5.1.13.6.10 Decision about IC mode

The IC mode has been designed and optimized for inactive signals which
are basically the background noise. Two encoding technologies are used
for the encoding of these frames, the GSC and the AVQ. The GSC
technology is used at bitrates below 32kbps and the AVQ is used
otherwise. The selection of the IC mode at bitrates below 32kbps are
conditioned by $f_{\text{SAD}} = 1$ whereas for higher bitrates, the
condition is changed to $f_{\text{LSAD}} = 1$.

The TC mode and the AC mode are not used at 9.6, 16.4 and 24.4 kbps.
Thus, at these bitrates, the coding mode is changed to the GC mode if it
was previously set to the TC or AC mode. Furthermore, the selection of
the IC mode at the previously mentioned bitrates is conditioned only by
$f_{\text{SAD}} = 1$.

### 5.1.14 Coder technology selection

Multiple coding technologies are employed within the EVS codec, based on
one of the following two generic principles for speech and audio coding,
the LP-based (analysis-by-synthesis) approach and the transform-domain
(MDCT) approach. There is no clearly defined borderline between the two
approaches in the context of this codec. The LP-based coder is
essentially based on the CELP technology, optimized and tuned
specifically for each bitrate. The transform-domain approach is adopted
by the HQ MDCT technology. There are also two hybrid schemes in which
both approaches are combined, the GSC technology and the TCX technology.
The selection of the coder technology depends on the actual bitrate, the
bandwidth, speech/music classification, the selected coding mode and
other parameters. The following table shows the allocation of
technologies based on bitrate, bandwidth and content.

Table 19: Allocation of coder technologies per bitrate, bandwidth and
content

  --------- --------- --------- ------- ----------------- ------------- ------------- ------------- ----- ---------
  bitrate   7.2       8         9.6     13.2              16.4          24.4          32            48    64
  NB                                                                                                      
  speech    ACELP     ACELP     ACELP   ACELP             ACELP         ACELP                             
  audio     HQ MDCT   HQ MDCT   TCX     TCX/HQ MDCT       TCX/HQ MDCT   TCX                               
  noise     GSC       GSC       TCX     GSC               TCX           TCX                               
  WB                                                                                                      
  speech    ACELP     ACELP     ACELP   ACELP             ACELP         ACELP         ACELP         TCX   ACELP
  audio     GSC       GSC       TCX     GSC/TCX/HQ MDCT   TCX/HQ MDCT   TCX           HQ MDCT       TCX   HQ MDCT
  noise     GSC       GSC       TCX     GSC               TCX           TCX           ACELP         TCX   ACELP
  SWB                                                                                                     
  speech                                ACELP             ACELP         ACELP         ACELP         TCX   ACELP
  audio                                 GSC/TCX/HQ MDCT   TCX/HQ MDCT   TCX/HQ MDCT   TCX/HQ MDCT   TCX   HQ MDCT
  noise                                 GSC               TCX           TCX           ACELP         TCX   ACELP
  FB                                                                                                      
  speech                                                  ACELP         ACELP         ACELP         TCX   ACELP
  audio                                                   TCX           TCX/HQ MDCT   TCX/HQ MDCT   TCX   HQ MDCT
  noise                                                   TCX           TCX           ACELP         TCX   ACELP
  --------- --------- --------- ------- ----------------- ------------- ------------- ------------- ----- ---------

The TCX technology is used for any content at bitrates higher than 64
kbps.

At 9.6kbps, 16.4kbps and 24.4kbps a specific technology selector is used
to select either ACELP or an MDCT-based technology (HQ MDCT or TCX).
This selector is described in clause 5.1.14.1.

At all other bitrates, the division into "speech", "audio" and
background "noise" is based on the decision of the SAD and on the
decision of the speech/music classifier.

The decision between the TCX technology and the HQ MDCT technology is
done adaptively on a frame-by-frame basis. There are two selectors, one
for 13.2 and 16.4 kbps and the second for 24.4 and 32 kbps. There is no
adaptive selection beyond these bitrates as shown in the above table.
These two selectors are described in detail in the subclauses 5.1.14.2
and 5.1.14.3.

#### 5.1.14.1 ACELP/MDCT-based technology selection at 9.6kbps, 16.4 and 24.4 kbps

At 9.6kbps, 16.4kbps and 24.4kbps the decision to choose either ACELP or
an MDCT-based technology is not based on the decision of the
speech/music classifier as it is done for other bitrates, but on a
specific technology selector described below.

The technology selector is based on two estimates of the segmental SNR,
one estimate corresponding to the transform-based technology (described
in subclause 5.1.14.1.1), another estimate corresponding to the ACELP
technology (described in subclause 5.1.14.1.2). Based on these two
estimates and on a hysteresis mechanism, a decision is taken (described
in subclause 5.1.14.1.3).

##### 5.1.14.1.1 Segmental SNR estimation of the MDCT-based technology

The segmental SNR estimation of the TCX technology is based on a
simplified TCX encoder. The input audio signal is first filtered using a
LTP filter, then windowed and transformed using a MDCT, the MDCT
spectrum is then shaped using weighted LPC, a global gain is then
estimated, and finally the segmental SNR is derived from the global
gain. All these steps are described in detail in the following clauses.

##### 5.1.14.1.1.1 Long term prediction (LTP) filtering {#long-term-prediction-ltp-filtering .H6}

The LTP filter parameters (pitch lag and gain) are first estimated. The
LTP parameters are not only used for filtering the audio input signal
for estimating the segmental SNR of the transform-based technology. The
LTP parameters are also encoded into the bitstream in case the TCX
coding mode is selected, such that the TCX LTP postfilter described in
subclause 6.9.2.2 can use them. Note that the LTP filter parameter
estimation is also performed at 48kbps, 96kbps and 128kbps even though
the parameters are not used to filter the audio input signal in this
case.

A pitch lag with fractional sample resolution is determined, using the
open-loop pitch lag $T_{\text{OL}}^{\left\lbrack 1 \right\rbrack}$ and
an interpolated autocorrelation. The LTP pitch lag has a minimum value
of $p_{\text{min}}$, a maximum value of $p_{\text{max}}$ and a
fractional pitch resolution $p_{\text{res}}$. Additionally, two
thresholds $p_{\text{fr}1}$ and $p_{\text{fr}2}$ are used. If the pitch
lag is less than $p_{\text{fr}2}$, the full fractional precision
$p_{\text{res}}$ is used. If the pitch lag is greater than
$p_{\text{fr}1}$, no fractional lag is used. For pitch lags in between,
half of the fractional precision $p_{\text{res}}$ is used. These
parameters depend on the bitrate and are given in the table below.

Table 20: LTP parameters vs bitrate

  ---------------- ------------- ------------------- ----------------------------------- --- ---- ----- ----- -----
  Bitrate          Bandwidth     LTP sampling rate   LTP frame length $N_{\text{LTP}}$                        
  9.6 kbps         NB, WB, SWB   12.8kHz             256                                 4   29   231   154   121
  16.4-24.4 kbps   NB            12.8kHz             256                                 4   29   231   154   121
  16.4-24.4 kbps   WB, SWB, FB   16kHz               320                                 6   36   289   165   36
  48 kbps          WB, SWB, FB   25.6kHz             512                                 4   58   463   164   58
  96-128 kbps      WB, SWB, FB   32kHz               640                                 6   72   577   75    72
  ---------------- ------------- ------------------- ----------------------------------- --- ---- ----- ----- -----

First the parameter $\delta$ is initialized depending on the fractional
pitch resolution:

$\delta = \left\{ \begin{matrix}
8 & ,\ \text{if}\ p_{\text{res}} = 6 \\
\text{16} & ,\ \text{if}\ p_{\text{res}} = 4 \\
\end{matrix} \right.\ $. (391)

Then the search range for the pitch lag is determined as follows:

$\begin{matrix}
t_{\text{min}} = \text{min}\left( \text{max}\left( T_{\text{OL}}^{\left\lbrack 1 \right\rbrack} - \frac{\delta}{2},p_{\text{min}} \right),p_{\text{max}} - \delta + 1 \right) \\
t_{\text{max}} = \text{max}\left( \text{min}\left( T_{\text{OL}}^{\left\lbrack 1 \right\rbrack} + \frac{\delta}{2} - 1,p_{\text{max}} \right),p_{\text{min}} + \delta - 1 \right) \\
\end{matrix}$. (392)

For the search range, autocorrelation of the weighted input signal
$s_{h}$ (including the look-ahead part) is computed (note that at
48kbps, 96kbps and 128kbps, the weighted input signal is not available,
so the non-weighted input signal is used instead), extended by 4
additional samples in both directions required for subsequent
interpolation filtering:

$C\left( d \right) = \sum_{i = 0}^{N_{\text{TCX}} - 1}{s_{h}\left( i \right)s_{h}\left( i - d \right)}\ ,\ d = \left( t_{\text{min}} - 4 \right)\text{.}\text{.}\text{.}\left( t_{\text{max}} + 4 \right)$.
(393)

Within the search range, the index and value of the maximum correlation
are determined:

$\begin{matrix}
C_{\text{LTP}} = C\left( t_{\text{min}} \right) \\
d_{\text{LTP}} = t_{\text{min}} \\
 \\
\text{for}\ d = t_{\text{min}}\text{.}\text{.}\text{.}t_{\text{max}} \\
\ \text{if}\ \left( C\left( d \right) > C_{\text{LTP}} \right)\ \text{then} \\
\ C_{\text{LTP}} = C\left( d \right) \\
\ d_{\text{LTP}} = d \\
\end{matrix}$. (394)

The maximum correlation value is normalized as follows:

$C_{\text{LTP},\text{norm}} = \frac{C_{\text{LTP}}}{\sqrt{\left( \sum_{i = 0}^{N_{\text{TCX}} - 1}{s_{h^{2}}\left( i \right)} \right)\left( \sum_{i = 0}^{N_{\text{TCX}} - 1}{s_{h^{2}}\left( i - d_{\text{max}} \right)} \right) + 0\text{.}1}}$.
(395)

The fractional precision of the transmitted pitch lag is determined by
the initial pitch lag $d_{\text{LTP}}$, the maximum fractional
resolution $p_{\text{res}}$, and the thresholds $p_{\text{fr}1}$ and
$p_{\text{fr}2}$.

$s = \left\{ \begin{matrix}
1 & ,\ \text{if}\ d_{\text{LTP}} < p_{\text{fr}2} \\
2 & ,\ \text{if}\ \left( d_{\text{LTP}} \geq p_{\text{fr}2} \right) \land \left( d_{\text{LTP}} < p_{\text{fr}1} \right) \\
p_{\text{res}} & ,\ \text{if}\ d_{\text{LTP}} \geq p_{\text{fr}1} \\
\end{matrix} \right.\ $. (396)

For determining fractional pitch lag the autocorrelation $C$ is
interpolated around the maximum value by FIR filtering:

$h_{\text{int}} = \left\{ \begin{matrix}
\text{inter}6_{1} & ,\ \text{if}\ p_{\text{res}} = 6 \\
\text{inter}4_{1} & ,\ \text{if}\ p_{\text{res}} = 4 \\
\end{matrix} \right.\ $. (397)

$C_{\text{LTP},\text{int}}\left( f \right) = \sum_{i = 0}^{3}{h_{\text{int}}\left( \text{ip}_{\text{res}} + f \right)C\left( d_{\text{LTP}} - i \right) + h_{\text{int}}\left( \left( i + 1 \right)p_{\text{res}} - f \right)C\left( d_{\text{LTP}} + i + 1 \right)}$.
(398)

$f = \text{is}\ ,\ i = \left( - \frac{p_{\text{res}}}{s} + 1 \right)\text{.}\text{.}\text{.}\left( \frac{p_{\text{res}}}{s} - 1 \right)$.
(399)

The integer and fractional parts of the refined pitch lag
($d_{\text{LTP}}$ and $f_{\text{LTP}}$) are then determined by searching
the maximum of the interpolated correlation:

$\begin{matrix}
i_{\text{min}} = \left\{ \begin{matrix}
0 & ,\ \text{if}\ d_{\text{LTP}} = t_{\text{min}} \\
 - \frac{p_{\text{res}}}{s} + 1 & ,\ \text{else} \\
\end{matrix} \right.\  \\
C_{\text{max}} = C_{\text{LTP}\text{,int}}\left( i_{\text{min}}s \right) \\
f_{\text{LTP}} = i_{\text{min}}s \\
 \\
\text{for}\ i = i_{\text{min}}\text{.}\text{.}\text{.}\left( \frac{p_{\text{res}}}{s} - 1 \right) \\
\ \text{if}\ \left( C_{\text{LTP}\text{,int}}\left( \text{is} \right) > C_{\text{max}} \right)\ \text{then} \\
\ C_{\text{max}} = C_{\text{LTP}\text{,int}}\left( \text{is} \right) \\
\ f_{\text{LTP}} = \text{is} \\
 \\
\text{if}\ \left( f_{\text{LTP}} < 0 \right)\ \text{then} \\
\ f_{\text{LTP}} = f_{\text{LTP}} + p_{\text{res}} \\
\ d_{\text{LTP}} = d_{\text{LTP}} - 1 \\
\  \\
\end{matrix}$. (400)

For transmission in the bitstream, the pitch lag is encoded to an
integer index $I_{\text{LTP},\text{lag}}$ (that can be encoded with 9
bits) as follows:

$I_{\text{LTP},\text{lag}} = \left\{ \begin{matrix}
\left( d_{\text{LTP}} - p_{\text{min}} \right)p_{\text{res}} + f_{\text{LTP}} & ,\ \text{if}\ d_{\text{LTP}} < p_{\text{fr}2} \\
\left( d_{\text{LTP}} - p_{\text{fr}2} \right)\frac{p_{\text{res}}}{2} + \left( p_{\text{fr}2} - p_{\text{min}} \right)p_{\text{res}} + \frac{f_{\text{LTP}}}{2} & ,\ \text{if}\ \left( d_{\text{LTP}} \geq p_{\text{fr}2} \right) \land \left( d_{\text{LTP}} < p_{\text{fr}1} \right) \\
\left( d_{\text{LTP}} - p_{\text{fr}1} \right) + \left( p_{\text{fr}1} - p_{\text{fr}2} \right)\frac{p_{\text{res}}}{2} + \left( p_{\text{fr}2} - p_{\text{min}} \right)p_{\text{res}} & ,\ \text{if}\ d_{\text{LTP}} \geq p_{\text{fr}1} \\
\end{matrix} \right.\ $. (401)

The decision if LTP is activated is taken according to the following
condition:

$\begin{matrix}
\text{if}\left( \left( \text{bitrate} < \text{48}\text{kbps} \right) \land \left( \text{mode} = \text{TCX}\text{20} \right) \land \left( C_{\text{LTP},\text{norm}}C_{\text{LTP},\text{norm}}^{\left( \text{prev} \right)} > 0\text{.}\text{25} \right) \land \left( \text{TFM}_{\text{LTP}} < 3\text{.}5 \right) \right) \vee \ \left( \left( \text{bitrate} \geq \text{48}\text{kbps} \right) \land \left( \text{mode} = \text{TCX}\text{10} \right) \land \left( \text{max}\left( C_{\text{LTP},\text{norm}},C_{\text{LTP},\text{norm}}^{\left( \text{prev} \right)} \right) > 0\text{.}5 \right) \land \left( \text{MEC}_{\text{LTP}} < 3\text{.}5 \right) \right) \vee \\
\ \left( \left( \text{bitrate} \geq \text{48}\text{kbps} \right) \land \left( C_{\text{LTP},\text{norm}} > 0\text{.}\text{44} \right) \land \left( L_{\text{celp}}\left( 1\text{.}2 - C_{\text{LTP},\text{norm}} \right) < d_{\text{LTP}} \right) \right) \vee \\
\ \left( \left( \text{bitrate} \geq \text{48}\text{kbps} \right) \land \left( \text{mode} = \text{TCX}\text{20} \right) \land \left( C_{\text{LTP},\text{norm}} > 0\text{.}\text{44} \right) \land \left( \left( \text{TFM}_{\text{LTP}} < 6 \right) \vee \left( \left( \text{TFM}_{\text{LTP}} < 7 \right) \land \left( \text{MEC}_{\text{LTP}} < \text{22} \right) \right) \right) \right) \\
\text{then} \\
\ \text{LTP}_{\text{on}} = 1 \\
\text{else} \\
\ \text{LTP}_{\text{on}} = 0 \\
\end{matrix}$. (402)

with the temporal flatness measure $\text{TFM}_{\text{LTP}}$ and the
maximum energy change $\text{MEC}_{\text{LTP}}$ are computed as
described in clause 5.1.8.

If LTP is activated, the predicted signal $s_{\text{pred}}$ is computed
from the input signal $s$ (including the lookahead part) by
interpolating the past input signal using a polyphase FIR filter. The
polyphase index of the filter is determined by the fractional pitch lag:

$\begin{matrix}
i = \left\{ \begin{matrix}
 - d_{\text{LTP}} - 1 & ,\ \text{if}\ f_{\text{LTP}} = 0 \\
 - d_{\text{LTP}} - 2 & ,\ \text{else} \\
\end{matrix} \right.\  \\
f = \left\{ \begin{matrix}
0 & ,\ \text{if}\ f_{\text{LTP}} = 0 \\
p_{\text{res}} - f_{\text{LTP}} & ,\ \text{else} \\
\end{matrix} \right.\  \\
\end{matrix}$. (403)

$h_{\text{int}} = \left\{ \begin{matrix}
\text{inter}6_{2}\text{tcx}2\left( f \right) & ,\ \text{if}\ p_{\text{res}} = 6 \\
\text{inter}4_{2}\text{tcx}2\left( f \right) & ,\ \text{if}\ p_{\text{res}} = 4 \\
\end{matrix} \right.\ $. (404)

$s_{\text{pred}}\left( n \right) = \sum_{j = 0}^{3}{h_{\text{int}}\left( j \right)s\left( i + j + n \right)}\ ,\ n = 0\text{.}\text{.}\text{.}N_{\text{TCX}} - 1$.
(405)

The LTP gain ${\overset{\sim}{g}}_{\text{LTP}}$ is computed from the
input and predicted signals:

${\overset{\sim}{g}}_{\text{LTP}} = \frac{\sum_{j = 0}^{N_{\text{TCX}} - 1}{s\left( n \right)s_{\text{pred}}\left( n \right)}}{\sum_{j = 0}^{N_{\text{TCX}} - 1}\left( s_{\text{pred}}\left( n \right) \right)^{2}}$.
(406)

For transmission in the bitstream, the gain is quantized to an integer
index $I_{\text{LTP},\text{gain}}$ (that can be encoded with 2 bits)

$I_{\text{LTP},\text{gain}} = \text{min}\left( \left\lfloor 4{\overset{\sim}{g}}_{\text{LTP}} - 0\text{.}5 \right\rfloor,3 \right)$.
(407)

The quantized gain $g_{\text{LTP}}$ is computed as:

$g_{\text{LTP}} = 0\text{.}\text{15625}\left( I_{\text{LTP},\text{gain}} + 1 \right)$.
(408)

If the quantized gain is less than zero, LTP is deactivated:

$\text{if}\ \left( I_{\text{LTP},\text{gain}} < 0 \right)\ \text{then}\ \text{LTP}_{\text{on}} = 0$.
(409)

If LTP is not active, the LTP parameters are set as follows:

$\begin{matrix}
\text{if}\ \left( \text{LTP}_{\text{on}} = 0 \right)\ \text{then} \\
\ d_{\text{LTP}} = N_{\text{TCX}} \\
\ f_{\text{LTP}} = 0 \\
\ g_{\text{LTP}} = 0 \\
\ s_{\text{pred}}\left( n \right) = 0\ ,\ n = 0\text{.}\text{.}\text{.}N_{\text{TCX}} - 1 \\
\end{matrix}$. (410)

The LTP filtered signal is then computed, except at 48kbps, 96kbps and
128kbps. The LTP filtered signal is computed by multiplying the
predicted signal with the LTP gain and subtracting it from the input
signal. To smooth parameter changes, a zero input response is added for
a 5ms transition period. If LTP was not active in the previous frame, a
linear fade-in is applied to the gain over a 5ms transition period.

If LTP was active in the previous frame, the zero input response $z$ is
computed:

$z_{\text{pred}}\left( n \right) = \sum_{j = 0}^{3}{h_{\text{int}}\left( j \right)s\left( j + n \right)}\ ,\ n = - m\text{.}\text{.}\text{.} - 1$.
(411)

$z\left( n \right) = s_{\text{LTP}}\left( n \right) - s\left( n \right) + g_{\text{LTP}}z_{\text{pred}}\left( n \right)\ ,\ n = - m\text{.}\text{.}\text{.} - 1$.
(412)

The zero input response is then computed by LP synthesis filtering with
zero input, and applying a linear fade-out to the second half of the
transition region:

$z\left( n \right) = - \sum_{j = 1}^{m}{a\left( j \right)z\left( n - j \right)\ ,\ n = 0\text{.}\text{.}\text{.}\text{63}}$.
(413)

$z\left( n \right) = \text{min}\left( \frac{\text{64} - n}{\text{32}},1 \right)z\left( n \right),\ n = 0\text{.}\text{.}\text{.}\text{63}$.
(414)

$z\left( n \right) = 0\ ,\ n = \text{64}\text{.}\text{.}\text{.}N_{\text{TCX}} - 1$.
(415)

with the LP coefficients are obtained by converting the mid-frame LSP
vector of the current frame $q_{\text{mid},i}$ using the algorithm
described in subclause 5.1.9.7. Finally the LTP filtered signal is
computed:

$s_{\text{LTP}}\left( n \right) = \left\{ \begin{matrix}
s\left( n \right) - \text{min}\left( \frac{n}{\text{64}},1 \right)g_{\text{LTP}}s_{\text{pred}}\left( n \right) & ,\ \text{if}\ g_{\text{LTP}}^{\left( \text{prev} \right)} = 0 \\
s\left( n \right) - g_{\text{LTP}}s_{\text{pred}}\left( n \right) + z\left( n \right) & ,\ \text{if}\ g_{\text{LTP}}^{\left( \text{prev} \right)} \neq 0 \\
\end{matrix} \right.\ \ ,\ n = 0\text{.}\text{.}\text{.}N_{\text{TCX}} - 1$.
(416)

##### 5.1.14.1.1.2 Windowing and MDCT {#windowing-and-mdct .H6}

The LTP filtered signal $s_{\text{LTP}}$ is windowed using a sine-based
window whose shape depends on the previous mode. If the past frame was
encoded with a MDCT-based coding mode, the window is defined as

$w\left( n \right) = 0$, for
$n = - \frac{N - L}{2},\text{.}\text{.}\text{.}, - 1$. (417)

$w\left( n \right) = \text{sin}\left\lbrack \left( n + \frac{1}{2} \right)\frac{\pi}{2L} \right\rbrack$,
for $n = 0,\text{.}\text{.}\text{.},L - 1$. (418)

$w\left( n \right) = 1$, for $n = L,\text{.}\text{.}\text{.},N - 1$.
(419)

$w\left( n \right) = \text{sin}\left\lbrack \left( n + \frac{1}{2} - N + L \right)\frac{\pi}{2L} \right\rbrack$,
for $n = N,\text{.}\text{.}\text{.},N + L - 1$. (420)

$w\left( n \right) = 0$, for
$n = N + L,\text{.}\text{.}\text{.},\frac{3N + L}{2}$. (421)

If the past frame was encoded with the ACELP coding mode, the window is
defined as

$w\left( n \right) = 0$, for
$n = - \frac{7N}{8} + \frac{L}{2},\text{.}\text{.}\text{.}, - 1$. (422)

$w\left( n \right) = 1$, for $n = 0,\text{.}\text{.}\text{.},N - 1$.
(423)

$w\left( n \right) = \text{sin}\left\lbrack \left( n + \frac{1}{2} - N + L \right)\frac{\pi}{2L} \right\rbrack$,
for $n = N,\text{.}\text{.}\text{.},N + L - 1$. (424)

$w\left( n \right) = 0$, for
$n = N + L,\text{.}\text{.}\text{.},\frac{5N}{8} + \frac{L}{2}$. (425)

with $L = \text{112}$, $N = \text{256}$ at 12.8kHz, and
$L = \text{140}$, $N = \text{320}$ at 16kHz. The total length of the
window is $2N$ (40ms) when the past frame was encoded with a MDCT-based
coding mode and $5\frac{N}{2}$ (50ms) when the past frame was encoded
with the ACELP coding mode.

The windowed LTP-filtered signal is transformed with a MDCT using time
domain aliasing (TDA) and a discrete cosine transform (DCT) IV as
described in subclause 5.3.2.2, producing the MDCT coefficients
$X\left( i \right)$with
$i = 0,\text{.}\text{.}\text{.},L_{\text{TCX}} - 1$, $L_{\text{TCX}}$ is
$N$ when the past frame was encoded with a MDCT-based coding mode and
$L_{\text{TCX}}$ is $5\frac{N}{4}$ when the past frame was encoded with
the ACELP coding mode.

##### 5.1.14.1.1.3 MDCT spectrum shaping {#mdct-spectrum-shaping .H6}

The mid-frame LSP vector of the current frame $q_{\text{mid},i}$ is
converted into LP filter coefficients $A_{\text{TCX}}\left( z \right)$
using the algorithm described in clause 5.1.9.7. The LP filter
coefficients $A_{\text{TCX}}\left( z \right)$ are then weighted as
described in clause 5.1.10.1, producing weighted LP filter coefficients
${\overset{\sim}{A}}_{\text{TCX}}\left( z \right) = A_{\text{TCX}}\left( \frac{z}{\gamma_{1}} \right)$with
$\gamma_{1} = 0\text{.}\text{92}$at 12.8kHz and
$\gamma_{1} = 0\text{.}\text{94}$at 16kHz. The weighted LP filter
coefficients are then transformed into the frequency domain as described
in subclause 5.3.3.2.3.2. The obtained LPC gains are finally applied to
the MDCT coefficients as described in subclause 5.3.3.2.3.3, producing
the LPC shaped MDCT coefficients $\hat{X}\left( i \right)$.

When the encoded bandwidth is NB, the MDCT coefficients corresponding to
the frequencies above 4kHz are set to
zeros:$\hat{X}\left( i \right) = 0$,
$i = 0,\text{.}\text{.}\text{.},\frac{5L_{\text{TCX}}}{8} - 1$.

##### 5.1.14.1.1.4 Global gain estimation {#global-gain-estimation .H6}

A global gain $g_{\text{TCX}}$ is estimated similarly to the first step
described in subclause 5.3.3.2.8.1.1. The energy of each block of 4
coefficients is first computed:

$E\lbrack k\rbrack = 9 + \text{10}\text{log}_{\text{10}}\left( 0\text{.}\text{01} + \sum_{i = 0}^{3}{{\hat{X}}^{2}\lbrack 4k + i\rbrack} \right)$.
(426)

A bisection search is performed with a final resolution of 0.125dB:

**Initialization:** Set *fac* = *offset = 128* and *target = 500 if NB,
target = 850 otherwise*

**Iteration:** Do the following block of operations *10* times

1- *fac=fac/2*

2- *offset = offset -- fac*

2-
$\text{ener} = \sum_{i = 0}^{\frac{L_{\text{TCX}}}{4} - 1}{a\lbrack i\rbrack}\text{,\ where\ }a\lbrack i\rbrack = \left\{ \begin{matrix}
E\lbrack k\rbrack - \text{offset}\text{\ if\ }E\lbrack k\rbrack - \text{offset} > 0\text{.}3 \\
0\text{\ otherwise} \\
\end{matrix} \right.\ $

3- *if(ener\>target) then offset=offset+fac*

If *offset\<=32, then offset=* -128.\
The gain is then given by:

##### 5.1.14.1.1.5 Segmental SNR estimation of the MDCT-based technology {#segmental-snr-estimation-of-the-mdct-based-technology-1 .H6}

The estimated TCX SNR in one subframe is given by

$\text{snr}_{\text{TCX}} = \frac{\sum_{n = 0}^{\text{63}}{\left\lbrack s_{h}\left( n \right) \right\rbrack^{2} + \text{10}^{- 6}}}{\frac{\text{64}g_{\text{TCX}}g_{\text{TCX}}\sqrt{2}}{\text{12}L_{\text{TCX}}}}$.
(427)

Finally, the estimated segmental SNR of the whole encoded TCX frame
$\text{ssnr}_{\text{TCX}}$is obtained by converting the per-subframe
SNRs $\text{snr}_{\text{TCX}}$into dB and averaging them over all
subframes.

##### 5.1.14.1.2 Segmental SNR estimation of the ACELP technology

The segmental SNR estimation of the ACELP technology is based on the
estimated SNR of the adaptive-codebook and the estimated SNR of the
innovative-codebook. This is described in detail in the following
clauses.

##### 5.1.14.1.2.1 SNR estimation of the adaptive-codebook {#snr-estimation-of-the-adaptive-codebook .H6}

An integer pitch-lag per subframe $d_{\text{int}}$ is derived from the
refined open-loop pitch lags $d_{\text{fr}}$ (see clause 5.1.10.9).\
When the sampling-rate is 12.8kHz, the number of subframe is four, and
the integer pitch lags are simply equal to the refined open-loop pitch
lags rounded to the nearest integer.\
When the sampling-rate is 16kHz, the number of subframe is five. The
refined open-loop pitch lags are first scaled by a factor of 1.25, then
they are rounded to the nearest integer and finally the four obtained
integer pitch lags are mapped to the five subframes. The first integer
pitch-lag is mapped to the first subframe, the second integer pitch-lag
is mapped to the second subframe, the third integer pitch-lag is mapped
to the third and fourth subframes, and the fourth integer pitch-lag is
mapped to the fifth subframe.

A gain is then computed for each subframe

$g = \frac{\sum_{n = 0}^{\text{63}}{s_{h}\left( n \right)s_{h}\left( n - d_{\text{int}} \right)}}{\sum_{n = 0}^{\text{63}}{s_{h}\left( n - d_{\text{int}} \right)s_{h}\left( n - d_{\text{int}} \right)} + \text{10}^{- 6}}$.
(428)

The estimated SNR of the adaptive-codebook is then computed for each
subframe

$\text{snr}_{\text{ada}} = \frac{\sum_{n = 0}^{\text{63}}{\left\lbrack s_{h}\left( n \right) \right\rbrack^{2} + \text{10}^{- 6}}}{\sum_{n = 0}^{\text{63}}\left\lbrack s_{h}\left( n \right) - \text{gs}_{h}\left( n - d_{\text{int}} \right) \right\rbrack^{2} + \text{10}^{- 6}}$.
(429)

##### 5.1.14.1.2.2 SNR estimation of the innovative-codebook {#snr-estimation-of-the-innovative-codebook .H6}

The estimated SNR of the innovative-codebook $\text{snr}_{\text{ino}}$
is assumed to be a constant, which depends on the encoded bandwidth and
on the bitrate. $\text{snr}_{\text{ino}} = 0\text{.}\text{15}$ at
9.6kbps NB, $\text{snr}_{\text{ino}} = 0\text{.}\text{059}$ at 9.6kbps
WB and $\text{snr}_{\text{ino}} = 0\text{.}\text{092}$ at 16.4 and
24.4kbps WB and SWB.

##### 5.1.14.1.2.3 Segmental SNR estimation of ACELP {#segmental-snr-estimation-of-acelp .H6}

The estimated SNR of one ACELP encoded subframe is then computed by
combining the adaptive-codebook SNR and the innovative-codebook SNR.

$\text{snr}_{\text{ace}} = \text{snr}_{\text{ada}}\text{snr}_{\text{ino}}$.
(430)

Finally, the estimated segmental SNR of the whole encoded ACELP frame
$\text{ssnr}_{\text{ace}}$is obtained by converting the per-subframe
SNRs $\text{snr}_{\text{ace}}$into dB and averaging them over all
subframes.

##### 5.1.14.1.3 Hysteresis and final decision

The ACELP technology is selected if

$\text{ssnr}_{\text{ace}} + \text{dssnr} > \text{ssnr}_{\text{TCX}}$.
(431)

otherwise the MDCT-based technology is selected.

$\text{dssnr}$adds hysteresis in the decision, in order to avoid
switching back and forth too often between the two coding technologies.
$\text{dssnr}$is computed as described below ($\text{dssnr}$ is 0 by
default). Further, in 12.8 kHz core (i.e., 9.6 kbps and 13.2 kbps), the
dssnr is updated as shown in equation (433a).

$\begin{matrix}
\text{if}\left( \text{ssnr}_{\text{ace}} > \text{ssnr}_{\text{TCX}} \right) \land \ \left( \text{ssnr}_{\text{ace}} < \text{ssnr}_{\text{TCX}} + 2 \right) \land \\
\ \left( \left( \text{TFM}^{(\text{prev})} + \text{TFM} < 3\text{.}\text{25} \right) \vee \left( \text{stabfac} = 1 \right) \right) \land \\
\ \left( \text{num}_{\text{acelp}_{\text{frames}}} \leq 6 \right) \\
\text{then} \\
\ \text{dssnr} = - 2 \\
\end{matrix}$. (432)

$\begin{matrix}
\text{if}\left( \text{ssnr}_{\text{ace}} < \text{ssnr}_{\text{TCX}} \right) \land \ \left( \text{ssnr}_{\text{ace}} > \text{ssnr}_{\text{TCX}} - 2 \right) \land \\
\ \left( \text{TFM}^{(\text{prev})} + \text{TFM} > 3\text{.}\text{25} \right) \land \\
\ \left( \text{num}_{\text{acelp}_{\text{frames}}} \geq 6 \right) \\
\text{then} \\
\ \text{dssnr} = 2 \\
\end{matrix}$. (433)

$\begin{matrix}
\text{if}\left( \text{sr}_{\text{core}} = \text{12800} \right) \land \left( \text{offset} < \text{74} \right) \land \left( \text{nonstat} > 5 \right) \land \ \left( \text{ssnr}_{\text{ace}}\text{>=}\text{ssnr}_{\text{TCX}} - 4 \right) \land \left( \text{num}_{\text{acelp}_{\text{frames}}}\text{>=}1 \right) \land \\
 \\
\end{matrix}\begin{matrix}
\left( \ \left( \left( L_{s} > L_{m} \right) \land (\text{mean}(\text{voicing}) > 0\text{.}3) \right) \vee \middle| \right) \\
 \\
\end{matrix}$. (433a)

where $\text{offset}$ is described in clause 5.1.14.1.1.4, and
$L_{s},\ L_{m},\ f_{\text{SM}}$are described in clause 5.1.13.6, and
$\text{nonstat}$ is described in 5.1.11.2.1.

$\begin{matrix}
\text{if}\left( \text{SNR}_{\text{LT}} < \text{35} \right) \\
\text{then} \\
\ \text{if}\left( \left( \text{vad}_{\text{flag}} = 1 \right) \vee \left( \text{dtx}_{\text{on}} = 1 \right) \right) \\
\ \text{then} \\
\ \text{dssnr} = \text{dssnr} + 2 \\
\ \text{else} \\
\ \text{dssnr} = \text{dssnr} - 2 \\
\end{matrix}$. (434)

with $\text{TFM}$ is the temporal flatness measure described in clause
5.1.8, $\text{stabfac}$ is a stability factor described in subclause
6.1.1.3.2 but using the unquantized LSF parameters estimated at
12.8kHz,$\text{num}_{\text{acelp}_{\text{frames}}}$is the number of
consecutive previous ACELP frames (if the previous frame was not ACELP,
$\text{num}_{\text{acelp}_{\text{frames}}} = 0$),
$\text{SNR}_{\text{LT}}$ is the long-term SNR as described in clause
5.1.12, $\text{vad}_{\text{flag}}$ is the SAD decision as described in
clause 5.1.12, and $\text{dtx}_{\text{on}}$ indicates whether DTX is
enabled or not.

#### 5.1.14.2 TCX/HQ MDCT technology selection at 13.2 and 16.4 kbps

The selection between TCX and HQ MDCT (Low Rate HQ) technology at 13.2
kbps (NB, WB and SWB) and 16.4 kbps (WB and SWB) is done on a
frame-by-frame basis and is based on the following measures.

-- Voicing measures

-- Spectral noise floor

-- SAD decision

-- High-band energy

-- High-band sparseness (with hysteresis)

The boundaries of frequency bands for the purposes of the TCX/HQ
technology selection is set according to the following table.

Table 21: Boundaries of frequency bands for TCX/HQ MDCT (Low Rate HQ)
selection

+------------+-------------+-------------+-------------+-------------+
| Band width | Low band    | High band   | Low band    | High band   |
|            | CLDFB       | CLDFB       | FFT         | FFT         |
+------------+-------------+-------------+-------------+-------------+
| NB         | 8           | 10          | $L_{\te     | $L_{\text{F |
|            |             |             | xt{FFT}}$/4 | FT}}$\*5/16 |
+------------+-------------+-------------+-------------+-------------+
| WB         | 12          | 20          | $L_{\text{  | $L_{\te     |
|            |             |             | FFT}}$\*3/8 | xt{FFT}}$/2 |
+------------+-------------+-------------+-------------+-------------+
| SWB        | 16          | 40          | $L_{\te     | $L_{\te     |
|            |             |             | xt{FFT}}$/2 | xt{FFT}}$/2 |
|            |             |             | for         |             |
|            |             |             | sparseness, |             |
|            |             |             |             |             |
|            |             |             | $L_{\text{  |             |
|            |             |             | FFT}}$\*3/8 |             |
|            |             |             | otherwise   |             |
+------------+-------------+-------------+-------------+-------------+

Voicing measure $V$is defined as the average of pitch gain
$C_{\text{norm}}^{\left\lbrack 0 \right\rbrack}$ of the former
half-frame and$C_{\text{norm}}^{\left\lbrack 1 \right\rbrack}$ of the
latter half-frame defined in (81),

$V = \frac{1}{2}\left( C_{\text{norm}}^{\left\lbrack 0 \right\rbrack} + C_{\text{norm}}^{\left\lbrack 1 \right\rbrack} \right)$.
(432)

Sparseness measure $S$ is defined as

$S = 1\text{.} - \frac{2 \cdot p}{b_{\text{LFFT}}}$, (433)

where$p$is a number of bins which attain following condition within low
band:

$E_{i} > \text{max}(E_{i - 1},\ E_{i + 1},\ 3\text{.}0,\ \text{log}(\text{10}) \cdot (E_{\text{tot}} - \text{MDCT\_SW\_SIG\_PEAK\_THR}))$,
(434)

where $E_{\text{tot}}$is an averaged energy of all spectrum bands.

High energy measure$E_{\text{High}}$is defined in terms of CLDFB energy
as

$E_{\text{High}} = \text{log}_{\text{10}}\left( \left( \frac{1}{(b_{\text{HCLDFB}} - b_{\text{LCLDFB}})} \right)\sum_{j = b}^{b_{\text{HQMF}} - 1}E_{j} + 0\text{.}\text{0001} \right)$.
(435)

Flag indicating the sparseness for high bands,$f_{H_{\text{SPARSE}}}$ =
TRUE when

$N_{\text{peak}} \leq (b_{\text{HFFT}} - b) \cdot \text{HI\_SPARSE\_THR}$,
(436)

where $N_{\text{peak}}$is a number of FFT bins within
$b_{\text{LFFT}}$and $b_{\text{HFFT}} - 1$ which attain

$E_{j} \geq E_{\text{tot}}\text{\ +\ log}(\text{10}) \cdot \text{MDCT\_SW\_SIG\_LINE\_THR}$.
(437)

Otherwise, $f_{H_{\text{SPARSE}}}$=FALSE.

Flag indicating the sparseness for high bands with hysteresis,
$f_{H_{\text{SPARSE}_{\text{HYS}}}}$= TRUE when

$N_{\text{peak}} \leq ((b_{\text{HFFT}} - b_{\text{LFFT}}) \cdot \text{HI\_SPARSE\_THR/HYST\_FAC})$.
(438)

Otherwise, $f_{H_{\text{SPARSE}_{\text{HYS}}}}$=FALSE.

Additionally, $f_{H_{\text{SPARSE}}}$ is set TRUE when following is
satisfied:

$\text{prev\_\ f}_{\text{H\_SPARSE}} > \text{0\ \&\&\ }f_{\text{H\_SPARSE}}\text{\&\&}(\text{min}(C_{\text{norm}}^{\left\lbrack 0 \right\rbrack},C_{\text{norm}}^{\left\lbrack 1 \right\rbrack},C_{\text{norm}}^{\left\lbrack 2 \right\rbrack}) > \text{VOICING\_THR})$.
(439)

$E_{\text{floor}}$is the averaged energy only for the local minima of
the spectrum. With the notation of 5.1.11.2.5, it is defined as:

$E_{\text{floor}} = \frac{1}{N_{\text{min}}}\sum_{}^{}{E_{\text{dB}}(i_{\text{min}}(i))}$.
(440)

Correlation map sum, $m_{\text{sum}}$ is defined in 5.1.11.2.5.

Indication of possible switching,$f_{\text{Switch}}$ =TRUE when previous
core was not Transform coding, or followings are satisfied.

$\begin{matrix}
(\text{prev}_{}\text{<=}\text{HI\_ENER\_LO\_THR})|| \\
(E_{\text{HIGH}}\text{<=}\text{HI\_ENER\_LO\_THR})\ || \\
(\text{prev}_{\text{core}}\text{==}\text{HQ}(\text{total}_{\text{brate}}\text{==}\text{13200}|| \\
\ f_{H_{\text{SPAESE}}}\text{prev}_{} \geq 0\text{prev}_{} \leq 1))|| \\
(\text{prev}_{\text{core}}\text{==}\text{TCX}(!f_{H_{\text{SPARSE}}}\text{prev}_{} > 0)) \\
\end{matrix}$, (444)

where $\text{prev}_{}$and $\text{prev}_{}$ are $f_{\text{HIGH}}$ and
$f_{H_{\text{SPARSE}}}$ at the previous frames. Note that
$\text{prev}_{}$is integer from -1 to 2, while others are all Boolean.

Indication of preference for TCX, $f_{\text{TCX}}$ = TRUE when
followings are satisfied:

$\begin{matrix}
(E_{\text{tot}} - E_{\text{floor}} \geq \text{SIG\_HI\_LEVEL\_THR}) \\
((m_{\text{sum}} \geq \text{COR\_THR})|| \\
\ (V \geq \text{VOICING\_THR})||(S \geq \text{SPARSENESS\_THR}))\  \\
((E_{\text{High}} \leq \text{HI\_ENER\_LO\_THR})||(f_{H_{\text{Sparse}}})) \\
\end{matrix}$ (445)

Indication of preference for HQ MDCT, $f_{\text{HQ}}$ = TRUE when
followings are satisfied:

$\begin{matrix}
(E_{\text{tot}} - E_{\text{floor}} < \text{SIG\_LO\_LEVEL\_THR})|| \\
((m_{\text{sum}} < \text{COR\_THR} \cdot \text{HYST\_FAC}) \\
\ (V < \text{VOICING\_THR} \cdot \text{HYST\_FAC}) \\
\ (S < \text{SPARSENESS\_THR} \cdot \text{HYST\_FAC}))\ || \\
(\text{total}_{\text{brate}}\text{==}\text{13200}\text{!}f_{\text{TCX}}\text{transient}_{\text{frame}}) \\
\end{matrix}$, (441)

where *transient\_frame* is the output of the time-domain transient
detector (see 5.1.8). For 16.4 kbps, $f_{\text{TCX}}$ is set to FALSE
and $f_{\text{HQ}}$ to TRUE when *transient\_frame* is detected.

Based on the above definitions and thresholds listed in the table below,
switching between HQ and MDCT based TCX is carried out as follows.
Switching between HQ and TCX can only occur when $f_{\text{Switch}}$ is
TRUE. In this case, TCX is used if $f_{\text{TCX}}$ is TRUE, or
otherwise HQ is used if $f_{\text{TCX}}$ is TRUE. In any other case, the
same kind of transform coding is applied as in the previous frame. If
the previous frame was not coded by transform coding, HQ is used for the
low rate (13.2 kbps) and TCX for the high rate (16.4 kbps).

In case input signal is noisy speech (*noisy\_speech\_flag*==TRUE &&
*vadflag*== FALSE) , transition from TCX to HQ is prohibited at 16.4
kbps.

$\text{prev}_{}$ is reset to 0 if $f_{H_{\text{SPARSE}}}$ is FALSE,
otherwise it is incremented by one (with a maximum allowed value of 2)

$\text{prev}_{}$ and $\text{prev}_{}$ are reset to FALSE and -1,
respectively, upon encoder initialization or when a non-transform-coded
frame is encountered.

Table 22: List of thresholds used in TCX/HQ MDCT (Low Rate HQ) selection

  -------------------------- ----------------------- ----------- -----------
  Parameter                  Meaning                 13.2 kbps   16.4 kbps
  SIG\_LO\_LEVEL\_THR        Low level signal        22.5        23.5
  SIG\_HI\_LEVEL\_THR        High level signal       28.0        19.0
  COR\_THR                   correlation             80.0        62.5
  VOICING\_THR               voicing                 0.6         0.4
  SPARSENESS\_THR            sparseness              0.65        0.4
  HI\_ENER\_LO\_THR          High energy low limit   9.5         12.5
  HYST\_FAC                  Hysteresis control      0.8         0.8
  MDCT\_SW\_SIG\_LINE\_THR   Significant Spectrum    2.85        2.85
  MDCT\_SW\_SIG\_PEAK\_THR   Significant peak        36.0        36.0
  -------------------------- ----------------------- ----------- -----------

#### 5.1.14.3 TCX/HQ MDCT technology selection at 24.4 and 32 kbps

The decision between using the TCX technology or the HQ MDCT (high rate
HQ) technology at 24.4 kbps and 32 kbps for SWB signals is based on the
average energy values and peak-to-average ratios of different sub-bands,
furthermore, the average energy values and peak-to-average ratios are
calculated by the CLDFB band energy analysis
![](media/image31.wmf){width="0.4166666666666667in"
height="0.21805555555555556in"}, spectral
analysis![](media/image32.wmf){width="0.34375in"
height="0.20833333333333334in"}and the bit-rate.

First, the average energy of three CLDFB sub-bands: 0\~3.2kHz,
3.2\~6.4kHz and 6.4\~9.6kHz $E_{\text{gain}}(i)$, $i = 0,1,2$ are
calculated according to

$E_{\text{gain}}(i) = \sum_{}^{}{{\overline{E}}_{C}(k + 8i\frac{)}{8},\ i = 0,1,2}$
(442)

Second, the spectral peak $\text{peak}(i)$ and spectral average
$\text{avrg}(i)$, $i = 0,1$ of the FFT sub-bands: 1\~2.6kHz and
4.8\~6.4kHz are calculated according to

$\begin{matrix}
\text{peak}(0) = \text{max}(X(\text{20}),X(\text{21}),\text{.}\text{.}\text{.},X(\text{20} + \text{31})) \\
\text{avrg}(0) = \sum_{}^{}{X(\text{20} + k)} \\
\text{peak}(1) = \text{max}(X(\text{96}),X(\text{97}),\text{.}\text{.}\text{.},X(\text{96} + \text{31})) \\
\text{avrg}(1) = \sum_{}^{}{X(\text{96} + k)} \\
\end{matrix}$ (443)

At 24.4kbps, the CLDFB sub-band (4.8\~9.6kHz) average energy
$E_{\text{gain}}(3)$, and the CLDFB sub-band (400-3.2kHz) average energy
$E_{\text{gain}}(4)$ are also calculated according to

$\begin{matrix}
E_{\text{gain}}(3) = \sum_{}^{}{{\overline{E}}_{C}(k + \text{12}\frac{)}{\text{12}}} \\
E_{\text{gain}}(4) = 8 \cdot (E_{\text{gain}}(0) - {\overline{E}}_{C}(0\frac{)}{8}\frac{)}{7} \\
\end{matrix}$ (444)

The peak energy $\text{peak}_{E1}$ and average energy $\text{avrg}_{E1}$
of the CLDFB sub-band (8\~10kHz) are also calculated according to

$\begin{matrix}
\text{peak}_{E1} = \text{max}({\overline{E}}_{C}(\text{20}),{\overline{E}}_{C}(\text{21}),\text{.}\text{.}\text{.},{\overline{E}}_{C}(\text{20} + 4)) \\
\text{avrg}_{E1} = \sum_{}^{}{{\overline{E}}_{C}(\text{20} + k)} \\
\end{matrix}$ (445)

To identify the MDCT coding mode, three conditions are identified:

Condition I:

$\begin{matrix}
\text{if}\ E_{\text{gain}}(3) > 0\text{.}8 \cdot E_{\text{gain}}(4)\ \text{AND} \\
\ 2\text{.}\text{56} \cdot \text{peak}(0) \cdot \text{avrg}(1) > \text{peak}(1) \cdot \text{avrg}(0)\ \text{AND} \\
\ \text{peak}(0) \cdot \text{avrg}(1) < 5\text{.}\text{12} \cdot \text{peak}(1) \cdot \text{avrg}(0)） \\
\text{then}\ \text{ConditionI} = 1 \\
\text{else}\ \text{ConditionI} = 0 \\
\end{matrix}$ (446)

Condition II:

$\begin{matrix}
\text{if}\ E_{\text{gain}}(3) > 0\text{.}4 \cdot E_{\text{gain}}(4)\ \text{AND}\ \text{32} \cdot \text{peak}(1) < 1\text{.}5 \cdot \text{avrg}(1)\ \text{AND}\ 5 \cdot \text{peak}_{E1} < 1\text{.}5 \cdot \text{avrg}_{E1} \\
\text{then}\ \text{ConditionII} = 1\ \text{else}\ \text{ConditionII} = 0 \\
\end{matrix}$ (447)

Condition III:

$\begin{matrix}
\text{if}\ ((2\text{.}\text{56} \cdot \text{peak}(0) \cdot \text{avrg}(1) < \text{peak}(1) \cdot \text{avrg}(0)\ \text{AND}\ \text{32} \cdot \text{peak}(1) > 1\text{.}5 \cdot \text{avrg}(1))\ \text{OR} \\
\ (\text{peak}(0) \cdot \text{avrg}(1) > 2\text{.}\text{56} \cdot \text{peak}(1) \cdot \text{avrg}(0)\ \text{AND}\ \text{32} \cdot \text{peak}(1) < 1\text{.}5 \cdot \text{avrg}(1))) \\
\text{then}\ \text{ConditionIII} = 1 \\
\text{else}\ \text{ConditionIII} = 0 \\
\end{matrix}$ (448)

The primary classifier decision $D_{\text{MDCT}1}$ at 24.4kbps is formed
according to

$\begin{matrix}
\text{if}\ (\text{conditionI}\text{\ OR\ }\text{conditionII}\text{\ OR\ }\text{conditionIII}) \\
\text{then}\ D_{\text{MDCT}1} = 3,\ i\text{.}e\text{.}\ \text{select\ HQ-MDCT} \\
\text{else}\ D_{\text{MDCT}1} = 1,\ i\text{.}e\text{.}\ \text{select\ TCX} \\
\end{matrix}$ (449)

At 32kbps, further spectral analysis is needed. First, a noise-floor
envelope $X_{\text{nf}}(k)$and a peak envelope $X_{p}(k)$are calculated
as

$\begin{matrix}
X_{\text{nf}}(0) = \left| X(0) \right|^{2}\  \\
X_{\text{nf}}\left( k \right) = \alpha_{\text{nf}}X_{\text{nf}}(k - 1) + (1 - \alpha_{\text{nf}})\left| X(k) \right|^{2},\ k = 1,\text{.}\text{.}\text{.},L_{\text{FFT}} - 1 \\
\end{matrix}$ (455)

and

$\begin{matrix}
X_{p}(0) = \left| X(0) \right|^{2}\  \\
X_{p}\left( k \right) = \alpha_{p}X_{p}(k - 1) + (1 - \alpha_{p})\left| X(k) \right|^{2},\ k = 1,\text{.}\text{.}\text{.},L_{\text{FFT}} - 1 \\
\end{matrix}$ (456)

respectively, where the smoothing factors $\alpha_{\text{nf}}$ and
$\alpha_{p}$depend on the instantaneous magnitude spectrum

$\alpha_{\text{nf}} = \left\{ \begin{matrix}
0\text{.}\text{9578},\ \left| X(k) \right|^{2} > X_{\text{nf}}(k - 1) \\
0\text{.}\text{6472},\ \left| X(k) \right|^{2} \leq X_{\text{nf}}(k - 1) \\
\end{matrix} \right.\ $ (450)

$\alpha_{p} = \left\{ \begin{matrix}
0\text{.}\text{4223},\ \left| X(k) \right|^{2} > X_{p}(k - 1) \\
0\text{.}\text{8029},\ \left| X(k) \right|^{2} \leq X_{p}(k - 1) \\
\end{matrix} \right.\ $ (451)

The noise-floor energy $E_{\text{nf}}$and the peak envelope energy
$E_{p}$are formed by averaging the noise-floor and peak envelopes,
respectively. That is,

$E_{\text{nf}} = \frac{1}{L_{\text{FFT}}}\sum_{}^{}{X_{\text{nf}}(k)}$
(452)

$E_{p} = \frac{1}{L_{\text{FFT}}}\sum_{}^{}{X_{p}(k)}$ (453)

Spectral peaks are identified in two steps. First, all $k$for which
$\left| X(k) \right|^{2} > 0\text{.}\text{64} \cdot X_{p}(k)$holds true
are marked as peak candidates. Second, for each sequence of
consecutive$k$, the largest spectral magnitude is kept as a peak
representative for that sequence. Peak sparseness measure $S$is formed
by averaging the peak distances among the peak representatives, with
$S = 0$if less than 2 peaks are identified. Two decision variables are
formed

$\begin{matrix}
\text{isclean} = E_{p}/E_{\text{nf}} > \text{147}\text{.}\text{87276} \\
\text{issparse} = S > \text{12}\  \\
\end{matrix}$ (454)

The peak energy $\text{peak}_{E2}$ and average energy $\text{avrg}_{E2}$
of the CLDFB sub-band at10\~12 kHz are calculated according to

$\begin{matrix}
\text{peak}_{E2} = \text{max}({\overline{E}}_{C}(\text{25}),{\overline{E}}_{C}(\text{26}),\text{.}\text{.}\text{.},{\overline{E}}_{C}(\text{25} + 4)) \\
\text{avrg}_{E2} = \sum_{}^{}{{\overline{E}}_{C}(\text{25} + k)} \\
\end{matrix}$ (455)

Three conditions are then checked.

Condition I:

$\text{if}\ (E_{\text{gain}}(2) > 1\text{.}2 \cdot E_{\text{gain}}(1))\ \text{then}\ \text{ConditionI} = 1\text{\ \ else\ \ }\text{ConditionI} = 0$
(456)

Condition II:

$\text{if}\ E_{\text{gain}}(2) > 0\text{.}8 \cdot E_{\text{gain}}(1)\ \text{AND\ }\ 5 \cdot \text{peak}_{E2} > 2\text{.}0 \cdot \text{avrg}_{E2}\ \text{then}\ \text{ConditionII} = 1\text{\ \ else\ }\text{ConditionII} = 0$
(457)

Condition III:

$\begin{matrix}
\text{if}\ 2\text{.}\text{25} \cdot \text{peak}(0) \cdot \text{avrg}(1) < \text{peak}(1) \cdot \text{avrg}(0)\ \text{OR}\ \text{peak}(0) \cdot \text{avrg}(1) > 2\text{.}\text{25} \cdot \text{peak}(1) \cdot \text{avrg}(0)) \\
\text{then}\ \text{ConditionIII} = 1\text{\ \ else}\ \text{ConditionIII} = 0 \\
\end{matrix}$ (465)

The primary classifier decision $D_{\text{MDCT}1}$ at 32kbps is formed
according to

$\begin{matrix}
\text{if}\ ((\text{isclean} \oplus \text{issparse})\text{\ \ OR\ \ }\text{conditionI}\text{\ \ OR\ \ }\text{conditionII}\text{\ \ OR\ \ }\text{conditionIII}) \\
\text{then}\ D_{\text{MDCT}1} = 3,\ i\text{.}e\text{.}\ \text{select\ HQ\ MDCT\ technnology} \\
\text{else}\ D_{\text{MDCT}1} = 1\ i\text{.}e\text{.}\text{\ select\ TCX\ technology} \\
\end{matrix}$ (466)

To increase the classifier stability for both 24.4kbps and 32kbps, the
primary classifier decision $D_{\text{MDCT}1}$is low-pass filtered from
frame to frame.

${\overline{D}}_{\text{MDCT}1} = 0\text{.}2D_{\text{MDCT}1} + 0\text{.}8{\overline{D}}_{\text{MDCT}1}^{\lbrack - 1\rbrack}$
(467)

Finally, hysteresis is applied such that the classifier decision from
the previous frame is only changed if the decision passes the switching
range $\left\lbrack 1\text{.}1,1\text{.}6 \right\rbrack$

$\begin{matrix}
\text{if}\ (E_{\text{gain}}^{\lbrack - 1\rbrack}(0) > 0\text{.}5 \cdot E_{\text{gain}}(0)\text{\ AND\ }E_{\text{gain}}^{\lbrack - 1\rbrack}(0) < 2\text{.}0 \cdot E_{\text{gain}}(0))\text{\ AND\ } \\
\ (E_{\text{gain}}^{\lbrack - 1\rbrack}(1) > 0\text{.}5 \cdot E_{\text{gain}}(1)\text{\ AND\ }E_{\text{gain}}^{\lbrack - 1\rbrack}(1) < 2\text{.}0 \cdot E_{\text{gain}}(1)) \\
\text{then\ }\ D_{\text{MDCT}}^{\text{final}} = D_{\text{MDCT}}^{\lbrack - 1\rbrack} \\
\text{else}\ \text{if}\ {\overline{D}}_{\text{MDCT}1} > D_{\text{MDCT}}^{\lbrack - 1\rbrack}\text{\ \{}\overline{D} \\
\end{matrix}_{\text{MDCT}1} > 1\text{.}6\ \text{then}\ D_{\text{MDCT}}^{\text{final}} = 3\ \text{else}\ \text{if}\ {\overline{D}}_{\text{MDCT}1} < 1\text{.}1\ \text{then}\ D_{\text{MDCT}}^{\text{final}} = 1$
(468)

If none of these conditions are met, the previous classifier is kept,
i.e.
$D_{\text{MDCT}}^{\text{final}} = D_{\text{MDCT}}^{\lbrack - 1\rbrack}$.and
the buffers are updated as follows

$\begin{matrix}
{\overline{D}}_{\text{MDCT}1}^{\lbrack - 1\rbrack} = {\overline{D}}_{\text{MDCT}1} \\
D_{\text{MDCT}}^{\lbrack - 1\rbrack} = D_{\text{MDCT}}^{\text{final}} \\
E_{\text{gain}}^{\lbrack - 1\rbrack}(1) = E_{\text{gain}}(1) \\
E_{\text{gain}}^{\lbrack - 1\rbrack}(0) = E_{\text{gain}}(0) \\
\end{matrix}$ (469)

#### 5.1.14.4 TD/Multi-mode FD BWE technology selection at 13.2 kbps and 32 kbps

The input WB or SWB signal is divided into low band signal and high band
signal (wideband input) or super higher band signal (super wideband
input). Firstly, the low band signal is classified based on the
characteristics of the low band signal and coded by the LP-based
approach or the transform-domain approach.

The selection between TD BWE and multi-mode FD BWE technology of super
higher band signal or high band signal at 13.2 kbps (WB and SWB) and 32
kbps (SWB) is performed based on the characteristic of the input signal
and coding modes of the low band signal. Except for MDCT mode, if the
input signal is classified as music signal, the high band signal or the
super higher band signal is encoded by multi-mode FD BWE;if the input
signal is classified as speech signal, the high band signal or the super
higher band signal is encoded by TD BWE. In the case that the low band
signal is classified as IC mode, the high band signal or the super
higher band signal is also encoded by multi-mode FD BWE.

If the decision in the first stage of the speech/music
classifier$f_{\text{SM}1} = 1$, i.e. the input signal is classified as
music signal, or the decision in the first stage of the speech/music
classifier$f_{\text{SM}1} = 0$and the decision in the second stage of
the speech/music classifier$f_{\text{SM}2} = 1$, or the low band signal
is classified as IC mode, the high band or the super higher band signal
is encoded by multi-mode FD BWE, otherwise, the high band or super
higher band signal is encoded by TD BWE. It is noted that, when the flag
of the super wideband noisy speech$f_{\text{UV}_{\text{SWB}}} = 1$, the
super higher band is encoded by TD BWE. It is the same TD/multi-mode FD
BWE technology selection for FB inputs.
