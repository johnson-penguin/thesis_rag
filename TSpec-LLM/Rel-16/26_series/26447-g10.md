![](media/image1.jpeg){width="7.0875in" height="1.5215277777777778in"}

  {#section .TT}

Contents {#contents .TT}
========

[5](#foreword)

[6](#scope)

[6](#references)

[6](#definitions-symbols-and-abbreviations)

[6](#definitions)

[6](#symbols)

[7](#abbreviations)

[7](#general)

[8](#detailed-description)

[8](#concealment-operation-related-to-signal-classification)

[8](#overview)

[8](#signal-class-estimation)

[11](#concealment-operation-related-to-spectral-envelope-lpc-representation)

[12](#specifics-to-rates-9.6-16.4-and-24.4kbps)

[12](#specifics-to-amr-wb-io-mode)

[12](#check-for-mid-lsf-stability)

[13](#adaptive-interpolation-of-lsfs)

[14](#lpc-gain-compensation)

[15](#concealment-operation-related-to-acelp-modes)

[15](#general-1)

[15](#extrapolation-of-future-pitch)

[17](#construction-of-the-periodic-part-of-the-excitation)

[18](#particularity-of-rate-5.9-7.2-8.0-and-13.2-kbps)

[18](#glottal-pulse-resynchronization)

[18](#condition-to-perform-resynchronisation)

[18](#performing-glottal-pulse-resynchronization)

[20](#construction-of-the-random-part-of-the-excitation)

[21](#spectral-envelope-concealment-synthesis-and-updates)

[21](#specifics-for-rates-9.6-16.4-and-24.4-kbps)

[21](#gsc-mode-concealment)

[21](#specifics-for-amr-wb-io-modes)

[23](#reconstructed-excitation)

[23](#particularity-of-rate-5.9-7.2-8.0-and-13.2-kbps-1)

[23](#concealment-for-bandwidth-extension-for-acelp-modes)

[23](#time-domain-bandwidth-extension)

[23](#swb-time-domain-bandwidth-extension)

[24](#the-reconstruction-of-the-global-frame-gain)

[25](#the-reconstruction-of-the-gain-attenuation-factor)

[26](#specifics-for-rates-13.2-and-32-kbps)

[28](#guided-concealment-and-recovery)

[28](#specifics-for-rate-24.4-kbps)

[28](#specifics-for-rates-9.6-16.4-and-24.4-kbps-1)

[29](#energy-control-during-recovery)

[32](#specifics-for-rates-32-and-64-kbps)

[32](#adaptive-codebook-resynchronization-and-fast-recovery-wb)

[32](#decoding-glottal-pulse-position)

[32](#performing-glottal-pulse-resynchronization-1)

[33](#artificial-onset-reconstruction)

[34](#handling-of-multiple-frame-losses-and-muting)

[34](#specifics-for-rates-5.9-6.8-8.0-13.2-32-and-64-kbps)

[35](#specifics-for-rates-9.6-16.4-and-24.4-kbps-2)

[35](#fading-to-background-level)

[35](#fading-to-background-spectral-shape)

[36](#fading-speed)

[37](#concealment-operation-related-to-mdct-modes)

[37](#plc-method-selection)

[37](#tcx-mdct)

[37](#plc-method-selection-1)

[38](#tcx-time-domain-concealment)

[39](#construction-of-the-periodic-part-of-the-excitation-1)

[39](#construction-of-the-random-part-of-the-excitation-1)

[40](#construction-of-the-total-excitation-synthesis-and-updates)

[41](#mdct-frame-repetition-with-sign-scrambling)

[41](#tonal-mdct-concealment-using-phase-prediction)

[41](#overview-1)

[41](#peak-detection-of-tonal-components)

[44](#phase-prediction)

[45](#non-tonal-concealment-with-waveform-adjustment)

[45](#preliminary-concealment-in-frequency-domain)

[45](#waveform-adjustment-in-time-domain)

[49](#intelligent-gap-filling)

[49](#hq-mdct)

[49](#preliminary-signal-analysis-of-past-synthesis)

[49](#resampling-to-8-khz)

[50](#pitch-search-by-cross-correlation)

[50](#plc-method-selection-2)

[53](#mdct-frame-repetition-with-random-sign-and-gain-scaling)

[57](#mdct-frame-repetition-with-sign-prediction)

[58](#phase-ecu)

[59](#transient-analysis)

[60](#spectrum-analysis)

[61](#frame-reconstruction)

[62](#mdct-concealment-based-on-sinusoidal-synthesis-and-adaptive-noise-filling)

[62](#fft)

[63](#selection-of-sinusoidal-components)

[63](#sinusoidal-synthesis)

[63](#adaptive-noise-filling)

[64](#synthesis)

[65](#time-domain-plc-and-ola)

[65](#plc-mode-selection)

[68](#phase-matching)

[71](#repetition-and-smoothing)

[76](#void)

[76](#guided-concealment-and-recovery-1)

[76](#transmission-of-the-synthesis-class)

[76](#transmission-of-the-ltp-pitch-lag)

[76](#transmission-of-a-voicing-indicator)

[77](#a-transmission-of-a-tonality-flag)

[77](#acelp-to-mdct-mode-recovery)

[77](#recovery-after-tcx-mdct-concealment)

[77](#handling-of-multiple-frame-losses-and-muting-1)

[77](#tcx-mdct-1)

[77](#background-level-tracing-for-rates-48-96-and-128-kbps)

[78](#tcx-time-domain-concealment-1)

[78](#mdct-frame-repetition-with-sign-scrambling-1)

[80](#fading-speed-1)

[81](#waveform-adjustment)

[81](#hq-mdct-1)

[81](#burst-loss-handling-for-8-khz-audio-output-sampling-rate)

[81](#burst-loss-handling-audio-output-sampling-rates-larger-or-equal-to-16-khz)

[81](#sid-frame-concealment-operation)

[82](#annex-a-informative-change-history)Foreword 1 Scope 2 References 3
Definitions, symbols and abbreviations 3.1 Definitions 3.2 Symbols 3.3
Abbreviations 4 General 5 Detailed description 5.1 Concealment operation
related to signal classification 5.1.1 Overview 5.1.2 Signal class
estimation 5.2 Concealment operation related to spectral envelope (LPC)
representation 5.2.1 Specifics to rates 9.6, 16.4 and 24.4kbps 5.2.2
Specifics to AMR-WB IO mode 5.2.3 Check for Mid LSF stability 5.2.4
Adaptive interpolation of LSFs 5.2.5 LPC gain compensation 5.3
Concealment operation related to ACELP modes 5.3.1 General 5.3.1.1
Extrapolation of future pitch 5.3.1.2 Construction of the periodic part
of the excitation 5.3.1.2.1 Particularity of rate 5.9, 7.2, 8.0 and 13.2
kbps 5.3.1.3 Glottal pulse resynchronization 5.3.1.3.1 Condition to
perform resynchronisation 5.3.1.3.2 Performing glottal pulse
resynchronization 5.3.1.4 Construction of the random part of the
excitation 5.3.1.5 Spectral envelope concealment, synthesis and updates
5.3.1.5.1 Specifics for rates 9.6, 16.4 and 24.4 kbps 5.3.1.6 GSC mode
concealment 5.3.1.7 Specifics for AMR-WB IO modes 5.3.1.8 Reconstructed
excitation 5.3.1.8.1 Particularity of rate 5.9, 7.2, 8.0 and 13.2 kbps
5.3.2 Concealment for bandwidth extension for ACELP modes 5.3.2.1 Time
domain bandwidth extension 5.3.2.1.1 SWB time domain bandwidth extension
5.3.2.1.1.1 The reconstruction of the global frame gain 5.3.2.1.1.2 The
reconstruction of the gain attenuation factor 5.3.2.1.1.3 Specifics for
rates 13.2 and 32 kbps 5.3.3 Guided concealment and recovery 5.3.3.1
Specifics for rate 24.4 kbps 5.3.3.2 Specifics for rates 9.6, 16.4 and
24.4 kbps 5.3.3.3 Energy control during recovery 5.3.3.4 Specifics for
rates 32 and 64 kbps 5.3.3.4.1 Adaptive codebook resynchronization and
fast recovery (WB) 5.3.3.4.1.1 Decoding glottal pulse position
5.3.3.4.1.2 Performing glottal pulse resynchronization 5.3.3.4.2
Artificial onset reconstruction 5.3.4 Handling of multiple frame losses
and muting 5.3.4.1 Specifics for rates 5.9, 6.8, 8.0, 13.2, 32 and 64
kbps 5.3.4.2 Specifics for rates 9.6, 16.4 and 24.4 kbps 5.3.4.2.1
Fading to background level 5.3.4.2.2 Fading to background spectral shape
5.3.4.2.3 Fading speed 5.4 Concealment operation related to MDCT modes
5.4.1 PLC method selection 5.4.2 TCX MDCT 5.4.2.1 PLC method selection
5.4.2.2 TCX time domain concealment 5.4.2.2.1 Construction of the
periodic part of the excitation 5.4.2.2.2 Construction of the random
part of the excitation 5.4.2.2.3 Construction of the total excitation,
synthesis and updates 5.4.2.3 MDCT frame repetition with sign scrambling
5.4.2.4 Tonal MDCT concealment using phase prediction 5.4.2.4.1 Overview
5.4.2.4.2 Peak detection of tonal components 5.4.2.4.3 Phase prediction
5.4.2.5 Non-tonal concealment with waveform adjustment 5.4.2.5.1
Preliminary concealment in frequency domain 5.4.2.5.2 Waveform
adjustment in time domain 5.4.2.6 Intelligent gap filling 5.4.3 HQ MDCT
5.4.3.1 Preliminary signal analysis of past synthesis 5.4.3.1.1
Resampling to 8 kHz 5.4.3.1.2 Pitch search by cross-correlation 5.4.3.2
PLC method selection 5.4.3.3 MDCT frame repetition with random sign and
gain scaling 5.4.3.4 MDCT frame repetition with sign prediction 5.4.3.5
Phase ECU 5.4.3.5.1 Transient analysis 5.4.3.5.2 Spectrum analysis
5.4.3.5.3 Frame reconstruction 5.4.3.6 MDCT concealment based on
sinusoidal synthesis and adaptive noise filling 5.4.3.6.1 FFT 5.4.3.6.2
Selection of sinusoidal components 5.4.3.6.3 Sinusoidal synthesis
5.4.3.6.4 Adaptive noise filling 5.4.3.6.5 Synthesis 5.4.3.7 Time-domain
PLC and OLA 5.4.3.7.1 PLC mode selection 5.4.3.7.2 Phase matching
5.4.3.7.3 Repetition and smoothing 5.4.4 Void 5.4.5 Guided concealment
and recovery 5.4.5.1 Transmission of the synthesis class 5.4.5.2
Transmission of the LTP pitch lag 5.4.5.3 Transmission of a voicing
indicator 5.4.5.3a Transmission of a tonality flag 5.4.5.4 ACELP to MDCT
mode recovery 5.4.5.5 Recovery after TCX MDCT concealment 5.4.6 Handling
of multiple frame losses and muting 5.4.6.1 TCX MDCT 5.4.6.1.1
Background level tracing for rates 48, 96 and 128 kbps 5.4.6.1.2 TCX
time domain concealment 5.4.6.1.3 MDCT frame repetition with sign
scrambling 5.4.6.1.4 Fading speed 5.4.6.1.5 Waveform adjustment 5.4.6.2
HQ MDCT 5.4.6.2.1 Burst loss handling for 8 kHz audio output sampling
rate 5.4.6.2.2 Burst loss handling audio output sampling rates larger or
equal to 16 kHz 5.5 SID frame concealment operation Annex A
(informative): Change history

Foreword
========

This Technical Specification has been produced by the 3^rd^ Generation
Partnership Project (3GPP).

The contents of the present document are subject to continuing work
within the TSG and may change following formal TSG approval. Should the
TSG modify the contents of the present document, it will be re-released
by the TSG with an identifying change of release date and an increase in
version number as follows:

Version x.y.z

where:

x the first digit:

1 presented to TSG for information;

2 presented to TSG for approval;

3 or greater indicates TSG approved document under change control.

y the second digit is incremented for all changes of substance, i.e.
technical enhancements, corrections, updates, etc.

z the third digit is incremented when editorial only changes have been
incorporated in the document.

1 Scope
=======

The present document defines a frame loss concealment procedure, also
termed frame substitution and muting procedure, which is executed by the
Enhanced Voice Services (EVS) decoder when one or more frames (speech or
audio or SID frames) are unavailable for decoding due to e.g. packet
loss, corruption of a packet or late arrival of a packet.

2 References
============

The following documents contain provisions which, through reference in
this text, constitute provisions of the present document.

\- References are either specific (identified by date of publication,
edition number, version number, etc.) or non‑specific.

\- For a specific reference, subsequent revisions do not apply.

\- For a non-specific reference, the latest version applies. In the case
of a reference to a 3GPP document (including a GSM document), a
non-specific reference implicitly refers to the latest version of that
document *in the same Release as the present document*.

\[1\] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\".

\[2\] 3GPP TS 26.441: \"Codec for Enhanced Voice Services (EVS); General
Overview\".

\[3\] 3GPP TS 26.442: \"Codec for Enhanced Voice Services (EVS); ANSI C
code (fixed-point)\".

\[4\] 3GPP TS 26.444: \"Codec for Enhanced Voice Services (EVS); Test
Sequences\".

\[5\] 3GPP TS 26.445: \"Codec for Enhanced Voice Services (EVS);
Detailed Algorithmic Description\".

\[6\] 3GPP TS 26.446: \"Codec for Enhanced Voice Services (EVS); AMR-WB
Backward Compatible Functions\".

\[7\] R. Martin, Noise Power Spectral Density Estimation Based on
Optimal Smoothing and Minimum Statistics, 2001

\[8\] 3GPP TS 26.443: \"Codec for Enhanced Voice Services (EVS); ANSI C
code (floating-point)\"

\[9\] 3GPP TS 26.452: \"Codec for Enhanced Voice Services (EVS); ANSI C
code; Alternative fixed-point using updated basic operators\".

3 Definitions, symbols and abbreviations
========================================

3.1 Definitions
---------------

For the purposes of the present document, the terms and definitions
given in TR 21.905 \[1\] and the following apply. A term defined in the
present document takes precedence over the definition of the same term,
if any, in TR 21.905 \[1\].

Further EVS codec specific definitions are found in clause 3.1 of \[5\].

3.2 Symbols
-----------

For the purposes of the present document, the following symbols apply:

EVS codec specific symbol definitions may be found in clause 3.2 of
\[5\].

3.3 Abbreviations
-----------------

For the purposes of the present document, the abbreviations given in
TR 21.905 \[1\] and the following apply. An abbreviation defined in the
present document takes precedence over the definition of the same
abbreviation, if any, in TR 21.905 \[1\].

AMR Adaptive Multi Rate (codec)

AMR-NB Adaptive Multi Rate Narrowband (codec) = AMR

AMR-WB Adaptive Multi Rate Wideband (codec)

EFR Enhanced Full Rate (codec)

EVS Enhanced Voice Services

FB Fullband

FR (GSM) Full Rate (codec)

HR (GSM) Half Rate (codec)

JBM Jitter Buffer Management

MTSI Multimedia Telephony Service for IMS

NB Narrowband

PLC Packet Loss Concealment

PS Packet Switched

PSTN Public Switched Telephone Network

SWB Super Wideband

WB Wideband

Further EVS codec specific abbreviations may be found in clause 3.3 of
\[5\].

4 General
=========

The purpose of the frame loss concealment procedure is to conceal the
effect of any unavailable EVS frame (speech or audio or SID) for
decoding. The concealment of erased frames covers both the
reconstruction of missing frames and the techniques to ensure smooth and
rapid recovery of normal synthesis after erased segments. The frame loss
concealment procedure also covers proper strategies including muting or
fading to background noise for the case of multiple frame losses in a
row. The purpose of muting the output or fading to background noise in
the case of several lost frames in a row is to indicate the breakdown of
the channel to the user and to avoid generating possible annoying sounds
as a result from the frame loss concealment procedure.

Unless stated differently, fading operations (described in
subclause 5.3.4 and subclause 5.4.6) start already with the first lost
frame.

Given the architecture and features of the EVS codec (details in \[EVS
Codec Detailed Algorithmic Description\]) the frame loss concealment
procedure comprises concealment methods for the various major codec
modules, such as signal classification, spectral envelope (LPC), ACELP,
MDCT and Bandwidth Extension. A particular feature of the EVS codec is
\'guided\' frame loss concealment for which the encoder provides
specific supplementary data guiding the concealment during erased frames
and enhancing the convergence and recovery of the decoder after erased
frames. The description in this specification is limited on how to apply
the \'guided\' frame loss concealment data; the corresponding encoding
operations are described as part of the EVS codec algorithmic
description \[5\].

The procedure of the present document is mandatory for implementation in
all network entities and User Equipment (UE)s supporting the EVS
decoder.

The present document does not describe the ANSI C code of this
procedure. For a description of the two reference fixed-point ANSI C
code implementations, using different sets of basic operators, see \[3\]
and \[9\] respectively; for a description of the reference
floating-point ANSI C code implementation see \[8\].

In the case of discrepancy between the procedure described in the
present document and its ANSI-C code specifications contained in \[3\]
the procedure defined by \[3\] prevails. In the case of discrepancy
between the procedure described in the present document and its ANSI-C
code specifications contained in \[8\] the procedure defined by \[8\]
prevails. In the case of discrepancy between the procedure described in
the present document and its ANSI-C code specifications contained in
\[9\] the procedure defined by \[9\] prevails.

5 Detailed description
======================

5.1 Concealment operation related to signal classification
----------------------------------------------------------

### 5.1.1 Overview

Many concealment methods are based on signal classification. The frame
class is either transmitted and decoded from the bit stream, or
estimated in the decoder. This estimation process is specified
subsequently in subclause 5.1.2; it is performed in the following during
normal decoding, if the decoded frame is ACELP or MDCT based TCX. In the
case of mode or rate switching, the buffer storing the signal history is
resampled appropriately.

### 5.1.2 Signal class estimation

If possible, the class is directly derived from the coding mode in case
of UC or VC modes, i.e. the class is UNVOICED\_CLAS in case of UC frame
and VOICED\_CLAS in case of VC frame. Otherwise, it is estimated at the
decoder as follows.

The frame classification at the decoder is based on the following
parameters: zero-crossing parameter,
![](media/image3.wmf){width="0.25in" height="0.2361111111111111in"},
pitch-synchronous normalized correlation,
![](media/image4.wmf){width="0.20833333333333334in"
height="0.20833333333333334in"}, pitch coherence parameter,
![](media/image5.wmf){width="0.19375in" height="0.20833333333333334in"},
spectral tilt, ![](media/image6.wmf){width="0.1527777777777778in"
height="0.19375in"}, and pitch synchronous relative energy at the end of
the frame, ![](media/image7.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"}.

The zero-crossing parameter, ![](media/image8.wmf){width="0.25in"
height="0.2361111111111111in"}, is averaged over the whole frame. That
is,

![](media/image9.wmf){width="1.0555555555555556in"
height="0.5416666666666666in"} (1)

where ![](media/image10.wmf){width="0.19375in"
height="0.20833333333333334in"}is the number of times the signal sign of
the synthesized signal,
![](media/image11.wmf){width="0.4722222222222222in"
height="0.2777777777777778in"}, changes from positive to negative during
subframe i. The number of subframes
![](media/image12.wmf){width="0.2916666666666667in"
height="0.2222222222222222in"} depends of the internal sampling
frequency which could be 12.8 kHz or 16 kHz. In case of 12.8kHz the
number of subframes is 4 otherwise the number of subframes is 5. In case
the internal sampling frequency is 16 kHz,
![](media/image13.wmf){width="0.19375in"
height="0.20833333333333334in"}is multiplied by 0.8.

The pitch synchronous normalized correlation is computed based on a
pitch lag, T0, where T0 is the integer part of the pitch lag of the last
subframe, or the average of the pitch lag of the last two subframe if it
is larger than ![](media/image14.wmf){width="0.5416666666666666in"
height="0.2222222222222222in"}, where
![](media/image15.wmf){width="0.3055555555555556in"
height="0.2222222222222222in"} = 64 is the subframe size. That is

![](media/image16.wmf){width="2.8194444444444446in"
height="0.5965277777777778in"} (2)

where ![](media/image17.wmf){width="0.24513888888888888in"
height="0.27708333333333335in"} is the fractional pitch lag at subframe
i.

The pitch synchronous normalized correlation computed at the end of the
frame is given by

![](media/image18.wmf){width="3.486111111111111in"
height="0.4861111111111111in"} (3)

where

![](media/image19.wmf){width="3.8333333333333335in"
height="1.1388888888888888in"} (4)

where L is the frame size and
![](media/image20.wmf){width="0.4722222222222222in"
height="0.2777777777777778in"} is the synthesized speech signal.

The pitch coherence parameter is compute only in the case that the
actual frame is not in TCX MDCT mode. The pitch coherence is given by

![](media/image21.wmf){width="1.6111111111111112in"
height="0.3194444444444444in"} (5)

where ![](media/image22.wmf){width="0.24513888888888888in"
height="0.27708333333333335in"} is the fractional pitch lag at subframe
i. In case the internal sampling frequency is 16 kHz,
![](media/image23.wmf){width="0.19375in"
height="0.20833333333333334in"}is multiplied by 0.8.

The spectral tilt parameter,
![](media/image24.wmf){width="0.1527777777777778in" height="0.19375in"},
is estimated based on the last 3 subframes and given by

![](media/image25.wmf){width="1.6111111111111112in"
height="1.0965277777777778in"} (6)

The pitch synchronous relative energy at the end of the frame is given
by

![](media/image26.wmf){width="0.9027777777777778in"
height="0.2222222222222222in"} (7)

where

![](media/image27.wmf){width="2.013888888888889in"
height="0.5416666666666666in"} (8)

and ![](media/image28.wmf){width="0.2222222222222222in"
height="0.2222222222222222in"} is the long-term energy.
![](media/image29.wmf){width="0.2222222222222222in"
height="0.2222222222222222in"} is updated only when a current frame is
classified as VOICED\_CLAS and is of interoperable coding mode or isn\'t
of generic or transition coding mode, and is classified as VOICED\_CLAS
at the same time, using the relation

![](media/image30.wmf){width="1.3194444444444444in"
height="0.2222222222222222in"} (9)

![](media/image31.wmf){width="0.9305555555555556in"
height="0.2222222222222222in"} (10)

The pitch lag value, T\', over which the energy,
![](media/image32.wmf){width="0.2222222222222222in"
height="0.2222222222222222in"}, is computed is given by

![](media/image33.wmf){width="2.94375in" height="0.7638888888888888in"}

![](media/image34.wmf){width="0.9305555555555556in"
height="0.2222222222222222in"} (11)

To make the classification more robust, the classification parameters
are considered together forming a function of merit,
![](media/image35.wmf){width="0.2076388888888889in"
height="0.24583333333333332in"}. For that purpose, the classification
parameters are first scaled so that each parameter\'s typical value for
unvoiced signal translates in 0 and each parameter\'s typical value for
voiced signal translates into 1. A linear function is used between them.
The scaled version, ![](media/image36.wmf){width="0.19236111111111112in"
height="0.24583333333333332in"}, of a certain parameter,
![](media/image37.wmf){width="0.2076388888888889in"
height="0.20555555555555555in"}, is obtained using

![](media/image38.wmf){width="0.9305555555555556in"
height="0.2777777777777778in"} (12)

![](media/image31.wmf){width="0.9305555555555556in"
height="0.2222222222222222in"} (13)

and in case of pc the scaled parameter is constrained
by![](media/image39.wmf){width="0.6666666666666666in"
height="0.25416666666666665in"}.

The function coefficients,
![](media/image40.wmf){width="0.19236111111111112in"
height="0.23194444444444445in"}, and
![](media/image41.wmf){width="0.22152777777777777in"
height="0.23194444444444445in"}, have been found experimentally for each
of the parameters so that the signal distortion due to the concealment
and recovery techniques used in the presence of frame erasures is
minimal. The values used are summarized in Table 1 below.

Table 1: Signal classification parameters at the decoder

  ------------------------------------------------------------------------------------- ------------------------ ---------- --------
  Parameter                                                                             Meaning                  Kp         cp
  ![](media/image42.wmf){width="0.2222222222222222in" height="0.20833333333333334in"}   Normalized correlation   0.8547     0.2479
  ![](media/image6.wmf){width="0.1527777777777778in" height="0.19375in"}                Spectral tilt            0.8333     0.2917
  ![](media/image43.wmf){width="0.19375in" height="0.20833333333333334in"}              Pitch coherence          --0.0357   1.6071
  ![](media/image44.wmf){width="0.2916666666666667in" height="0.20833333333333334in"}   Relative frame energy    0.04       0.56
  ![](media/image8.wmf){width="0.25in" height="0.2361111111111111in"}                   Zero-crossing counter    --0.04     2.52
  ------------------------------------------------------------------------------------- ------------------------ ---------- --------

The merit function has been defined as

![](media/image45.wmf){width="2.138888888888889in"
height="0.3611111111111111in"} (14)

where the superscript s indicates the scaled version of the parameters.
In the case of 8-kHz sampled output and a decoded bit rate of 9.6kbps,
the merit function, f, is further multiplied by 0.9.

In the case that the actual frame is not in TCX MDCT mode, the pitch
coherence is not compute therefore the merit function has been defined
as

![](media/image46.wmf){width="1.7916666666666667in"
height="0.3611111111111111in"} (15)

![](media/image31.wmf){width="0.9305555555555556in"
height="0.2222222222222222in"} (16)

The classification is performed using the merit function,
![](media/image47.wmf){width="0.2222222222222222in" height="0.25in"},
and following the rules summarized in Table 2. The default class is
UNVOICED\_CLAS. Note that the class ARTIFICIAL ONSET is set at the
decoder if the frame follows an erased frame and artificial onset
reconstruction is used as described in subclause 5.3.3.4.2.

Table 2: Signal classification rules at the decoder

+----------------------+----------------------+---------------------+
| Previous frame class | Rule                 | Current frame class |
+----------------------+----------------------+---------------------+
| ONSET                | ![](media/i          | VOICED\_CLAS        |
|                      | mage48.wmf){width="0 |                     |
| ARTIFICIAL ONSET     | .5965277777777778in" |                     |
|                      | height="0.25in"}     |                     |
| VOICED\_CLAS         |                      |                     |
|                      |                      |                     |
| VOICED TRANSITION    |                      |                     |
+----------------------+----------------------+---------------------+
|                      | ![](media/i          | VOICED TRANSITION   |
|                      | mage49.wmf){width="0 |                     |
|                      | .9861111111111112in" |                     |
|                      | height="0.25in"}     |                     |
+----------------------+----------------------+---------------------+
|                      | ![](media/i          | UNVOICED\_CLAS      |
|                      | mage50.wmf){width="0 |                     |
|                      | .6111111111111112in" |                     |
|                      | height="0.25in"}     |                     |
+----------------------+----------------------+---------------------+
| UNVOICED TRANSITION  | ![](media/i          | ONSET               |
|                      | mage51.wmf){width="0 |                     |
| UNVOICED\_CLAS       | .6111111111111112in" |                     |
|                      | height="0.25in"}     |                     |
| INACTIVE\_CLAS       |                      |                     |
+----------------------+----------------------+---------------------+
|                      | ![](media/i          | UNVOICED TRANSITION |
|                      | mage52.wmf){width="0 |                     |
|                      | .9861111111111112in" |                     |
|                      | height="0.25in"}     |                     |
+----------------------+----------------------+---------------------+
|                      | ![](media/i          | UNVOICED\_CLAS      |
|                      | mage53.wmf){width="0 |                     |
|                      | .5965277777777778in" |                     |
|                      | height="0.25in"}     |                     |
+----------------------+----------------------+---------------------+

5.2 Concealment operation related to spectral envelope (LPC) representation
---------------------------------------------------------------------------

When the LSF parameters of the first good frame are not available, the
LSF parameters of the concealed frame are extrapolated using the last
LSF parameters. The general idea is to fade the last LSF parameters
towards an adaptive LSF mean vector. First, an average LSF vector is
calculated from the last 3 known LSF vectors as

![](media/image54.wmf){width="1.5833333333333333in"
height="0.4305555555555556in"} (17)

Then, the adaptive mean LSF vector is calculated by

![](media/image55.wmf){width="1.6666666666666667in"
height="0.2638888888888889in"} (18)

Then the LSF vector used for concealing the lost frame is computed

![](media/image56.wmf){width="1.5555555555555556in" height="0.25in"}
(19)

where ![](media/image57.wmf){width="0.4027777777777778in"
height="0.25in"} is the mean LSF vector defined according to Table 3.

Table 3: Values of LSF mean vector
![](media/image57.wmf){width="0.4027777777777778in" height="0.25in"}

+----------------------------------+----------------------------------+
| LPC Quantization == 0            | ![](media/image57.w              |
|                                  | mf){width="0.4027777777777778in" |
| AVQ                              | height="0.25in"}=                |
+----------------------------------+----------------------------------+
| ![](media/image58.w              | ![](                             |
| mf){width="0.7083333333333334in" | media/image59.wmf){width="4.5in" |
| height="0.20833333333333334in"}  | height="0.4027777777777778in"}   |
+----------------------------------+----------------------------------+
| ![](media/image60.w              | ![](media/image61.               |
| mf){width="0.7916666666666666in" | wmf){width="4.291666666666667in" |
| height="0.20833333333333334in"}  | height="0.4027777777777778in"}   |
+----------------------------------+----------------------------------+
| ![](media/image62.w              | ![](me                           |
| mf){width="0.7777777777777778in" | dia/image63.wmf){width="4.125in" |
| height="0.20833333333333334in"}  | height="0.4027777777777778in"}   |
+----------------------------------+----------------------------------+
| LPC Quantization == 1            | ![](media/image64.w              |
|                                  | mf){width="0.4166666666666667in" |
| ACELP                            | height="0.25in"}=                |
+----------------------------------+----------------------------------+
| ![](media/image62.w              | ![](me                           |
| mf){width="0.7777777777777778in" | dia/image63.wmf){width="4.125in" |
| height="0.20833333333333334in"}  | height="0.4027777777777778in"}   |
+----------------------------------+----------------------------------+
| ![](media/image65.w              | ![](media/image66.w              |
| mf){width="0.7777777777777778in" | mf){width="4.2243055555555555in" |
| height="0.20833333333333334in"}  | height="0.41597222222222224in"}  |
+----------------------------------+----------------------------------+
| ![](media/image67.w              | ![](me                           |
| mf){width="0.7083333333333334in" | dia/image68.wmf){width="4.125in" |
| height="0.20833333333333334in"}  | height="0.4027777777777778in"}   |
+----------------------------------+----------------------------------+

Furthermore, ![](media/image69.wmf){width="0.1527777777777778in"
height="0.19375in"}is defined according to Table 4.

Table 4: Values of LSF interpolation factor
![](media/image70.wmf){width="0.1527777777777778in" height="0.19375in"}

  -------------------------------- ------------------------------------------------------------------------- -------------------------------------------------------------------------
  Bitrates:                        5.9, 6.8, 8.0, 13.2, 32 and 64 kbps                                       9.6, 16.4, 24.4, 48, 96 and 128 kbps
  plcBackgroundNoiseUpdated == 1   ![](media/image71.wmf){width="0.5277777777777778in" height="0.19375in"}   ![](media/image72.wmf){width="0.3611111111111111in" height="0.19375in"}
  plcBackgroundNoiseUpdated == 0   ![](media/image73.wmf){width="0.5277777777777778in" height="0.19375in"}   ![](media/image74.wmf){width="0.5277777777777778in" height="0.19375in"}
  -------------------------------- ------------------------------------------------------------------------- -------------------------------------------------------------------------

![](media/image75.wmf){width="0.1527777777777778in"
height="0.1388888888888889in"}depends on the previous coder type and the
signal class of the last good frame for the first 3 lost frames. It is
determined according to Table5.

Table 5: Values of LSF interpolation factor
![](media/image76.wmf){width="0.1527777777777778in"
height="0.1388888888888889in"}

+---------------------+----------------------+----------------------+
| Last good received\ | Additional criteria  | *α*                  |
| frame (coder\_type) |                      |                      |
+---------------------+----------------------+----------------------+
| UNVOICED            |                      | 1                    |
+---------------------+----------------------+----------------------+
| INACTIVE or         | Last\                | 0.8                  |
|                     | _GSC\_pit\_band\_idx |                      |
| AUDIO               | \> 0 and nbLostCmpt  |                      |
|                     | \> 1                 |                      |
+---------------------+----------------------+----------------------+
|                     | else                 | 0.995                |
+---------------------+----------------------+----------------------+
| UNVOICED\_CLAS      | Successively lost    | ![](media/i          |
|                     | frames = 1           | mage77.wmf){width="0 |
|                     |                      | .6666666666666666in" |
|                     |                      | height="0.1          |
|                     |                      | 6666666666666666in"} |
+---------------------+----------------------+----------------------+
|                     | Successively lost    | 0.6                  |
|                     | frames = 2           |                      |
+---------------------+----------------------+----------------------+
|                     | Successively lost    | 0.4                  |
|                     | frames = 3           |                      |
+---------------------+----------------------+----------------------+
| UNVOICED TRANSITION |                      | 0.8                  |
+---------------------+----------------------+----------------------+
| VOICED\_CLAS        |                      | 1                    |
+---------------------+----------------------+----------------------+
| ONSET               |                      | 1                    |
+---------------------+----------------------+----------------------+
| ARTIFICIAL ONSET    |                      | 0.6                  |
+---------------------+----------------------+----------------------+
| All other cases     |                      | 0.4                  |
+---------------------+----------------------+----------------------+

Starting from the 4^th^ consecutive lost
frame![](media/image78.wmf){width="0.6666666666666666in"
height="0.4027777777777778in"}.

The estimated LSF vector of the concealed frame
![](media/image79.wmf){width="0.2777777777777778in" height="0.25in"} is
converted to LSP representation and interpolated. The interpolation
procedure corresponds to the procedure described in subclause 5.1.9.6 of
\[5\]. The interpolation procedure calculates four or five LSP vectors,
each for a given subframe of the concealed frame. The interpolation is
done between the LSP vector of the last subframe of the last frame (the
one before the concealed frame)and the LSP vector derived from
![](media/image79.wmf){width="0.28125in" height="0.25in"} during
concealment, as described above.

### 5.2.1 Specifics to rates 9.6, 16.4 and 24.4kbps

Additionally to estimating the LSF vector
![](media/image80.wmf){width="0.2777777777777778in"
height="0.25in"}there is another LSF vector
![](media/image81.wmf){width="0.3055555555555556in"
height="0.2777777777777778in"} computed

![](media/image82.wmf){width="1.7083333333333333in"
height="0.2777777777777778in"} (20)

where

![](media/image83.wmf){width="0.3055555555555556in"
height="0.2777777777777778in"} is an estimated LSF vector used in ACELP
concealment,

![](media/image84.wmf){width="0.2916666666666667in"
height="0.2361111111111111in"} is the LSF representation of the CNG
noise estimation on decoder side (see clause 4.3 in \[5\]).

### 5.2.2 Specifics to AMR-WB IO mode

The same procedure is performed, but instead of LSFs, ISFs are used for
the estimation. The mean LSF vector used for interpolation is

![](media/image85.wmf){width="5.041666666666667in"
height="0.6527777777777778in"}

### 5.2.3 Check for Mid LSF stability

The interpolation of the mid-LSF can create unstable LSFs under packet
erasure conditions. Let the
![](media/image86.wmf){width="0.1388888888888889in"
height="0.19375in"}th sub-frame LSFs are given
by![](media/image87.wmf){width="1.0in" height="0.2361111111111111in"}.
*We denote the last sub-frame LSF of*
![](media/image88.wmf){width="0.1388888888888889in"
height="0.1527777777777778in"}*th frame as*
![](media/image89.wmf){width="0.19375in" height="0.2638888888888889in"}
*where* ![](media/image90.wmf){width="0.5277777777777778in"
height="0.2638888888888889in"}*. Let us denote the*
![](media/image91.wmf){width="9.652777777777778e-2in"
height="0.18055555555555555in"}th *LSF dimension of the*
![](media/image92.wmf){width="0.1388888888888889in"
height="0.19375in"}th *sub-frame of frame n as*
![](media/image93.wmf){width="0.25in" height="0.2777777777777778in"}
*where*![](media/image94.wmf){width="0.7430555555555556in"
height="0.19305555555555556in"}*.*

*The end-LSF quantizer
quantizes*![](media/image89.wmf){width="0.19375in"
height="0.2638888888888889in"}*. Then mid-LSF quantizer interpolates the
mid-LSFs as follows.*

![](media/image95.wmf){width="2.013888888888889in"
height="0.2777777777777778in"} (21)

*where i-th dimension of the weighting vector*
![](media/image96.wmf){width="0.20833333333333334in"
height="0.20833333333333334in"} *is given by*
![](media/image97.wmf){width="0.2638888888888889in"
height="0.2222222222222222in"}*. The vector elements*
![](media/image98.wmf){width="0.2604166666666667in"
height="0.21805555555555556in"} *are not constrained. In particular if*
![](media/image99.wmf){width="0.625in" height="0.20833333333333334in"}
*interpolation generates a mid-LSF*
![](media/image100.wmf){width="0.23958333333333334in"
height="0.25in"}*between*
![](media/image101.wmf){width="0.3333333333333333in" height="0.25in"}
*and*![](media/image102.wmf){width="0.23958333333333334in"
height="0.25in"}*. However if*
![](media/image103.wmf){width="0.4888888888888889in"
height="0.21805555555555556in"}*or*
![](media/image104.wmf){width="0.4888888888888889in"
height="0.21805555555555556in"}*interpolation might generate a mid-LSF*
![](media/image105.wmf){width="0.23958333333333334in" height="0.25in"}
*outside*![](media/image106.wmf){width="0.7083333333333334in"
height="0.28125in"}*.* This could potentially create LSF clustering that
result in an unstable LSF synthesis filter. To remedy this situation, a
potential instability is detected as described below.

In the frame that follows the packet loss, the decoder checks whether
the computed mid-LSFs are ordered correctly i.e.
![](media/image107.wmf){width="2.2777777777777777in" height="0.25in"}.
If violation of this rule is detected the LSFs are considered as
potentially unstable. If potential LSF instability is detected, decoder
uses a fixed weighting value
![](media/image108.wmf){width="0.3611111111111111in" height="0.25in"}
(typically 0.6) for mid LSF interpolation as follows.

![](media/image109.wmf){width="2.19375in" height="0.2777777777777778in"}
(22)

The mid LSF interpolation based on equation (22) is continued until
frame ![](media/image110.wmf){width="0.3194444444444444in"
height="0.18055555555555555in"} such that the frame
![](media/image111.wmf){width="0.3194444444444444in"
height="0.18055555555555555in"} is the first frame after frame
![](media/image112.wmf){width="0.125in" height="0.1388888888888889in"}
that uses safety net quantization for quantizing its end LSF.

### 5.2.4 Adaptive interpolation of LSFs

*The sub-frame LSFs are interpolated based
on*![](media/image113.wmf){width="0.34652777777777777in"
height="0.2777777777777778in"}*,* ![](media/image114.wmf){width="0.25in"
height="0.2777777777777778in"} *and*
![](media/image115.wmf){width="0.25in" height="0.2777777777777778in"}
*using fixed interpolation factors given by*

> ![](media/image116.wmf){width="2.9027777777777777in"
> height="0.2777777777777778in"} (23)

where ![](media/image114.wmf){width="0.25in"
height="0.2777777777777778in"} and
![](media/image115.wmf){width="0.25in" height="0.2777777777777778in"}
correspond to the mid and end LSFs of frame n respectively. Note that
![](media/image117.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"}and
![](media/image118.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"}such
that![](media/image119.wmf){width="0.94375in"
height="0.2361111111111111in"}, and those are fixed values known to both
encoder and decoder. If the frame
![](media/image120.wmf){width="0.3888888888888889in"
height="0.20833333333333334in"} is lost its end LSFs are estimated by
the decoder. However the dependence on the estimated end LSFs of the
![](media/image121.wmf){width="0.3888888888888889in"
height="0.20833333333333334in"}th frame may adversely affect the speech
quality if the estimated end LSFs are not well represent the actual one.
This issue is addressed by selecting the interpolation factors
![](media/image117.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"} and
![](media/image118.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"} appropriately by giving more weight to
the end LSF of frame
![](media/image122.wmf){width="0.1388888888888889in"
height="0.1527777777777778in"} which is not lost.

*To adaptively select the LSF interpolation factors, we estimate the
gain of the synthesis filter resulting from the LSF vectors*
![](media/image101.wmf){width="0.3333333333333333in"
height="0.25in"}*and*
![](media/image102.wmf){width="0.2361111111111111in" height="0.25in"}*by
computing the energy of the impulse response of the corresponding
synthesis filters. Let the impulse responses of the synthesis filters
corresponding to* ![](media/image101.wmf){width="0.3333333333333333in"
height="0.25in"}*and*
![](media/image102.wmf){width="0.2361111111111111in"
height="0.25in"}*are given by*
![](media/image123.wmf){width="0.4583333333333333in"
height="0.20833333333333334in"}*and*
![](media/image124.wmf){width="0.375in"
height="0.20833333333333334in"}*. The truncated energy of the impulse
responses are given by*
![](media/image125.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"} *and*
![](media/image126.wmf){width="0.20833333333333334in"
height="0.20833333333333334in"} *where*

![](media/image127.wmf){width="1.0138888888888888in"
height="0.3194444444444444in"} (24)

Note that N is the length of the truncated response. Typically 128
samples are used to compute the truncated impulse response. The
interpolation
factors![](media/image117.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"}and
![](media/image118.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"}are picked based on the energy
ratio![](media/image128.wmf){width="0.8611111111111112in"
height="0.25in"}, coder type, FEC classification and the use of safety
net quantization for LSF quantization.

*These interpolation factors are picked from four different sets of
interpolation factors. For example a largest difference in*
![](media/image129.wmf){width="0.2222222222222222in"
height="0.25in"}*should pick the interpolation factors that give the
very little or zero weight to the previous end LSF in the
interpolation*.

![](media/image130.wmf){width="6.695138888888889in"
height="3.675in"}Figure 1: **Adaptive interpolation of LSFs**

### 5.2.5 LPC gain compensation

At 9.6, 16.4, 24.4, 48, 96 and 128 kbps, the LPC concealment and
interpolation will lead to a change of overall gain of the signal, which
is unwanted when targeting a certain background noise level during
consecutive frame loss. Therefore the energy of the LPC is measured and
stored during decoding of regular frames. In a concealment frame the
energy of the concealed LPC is measured and compared to the LPC energy
of the last correctly received frame and any change is compensated.

To measure the LPC energy, a vector of length 64 is generated and
initialized to all zero. Then the first entry is set to one:

![](media/image131.wmf){width="1.9722222222222223in"
height="0.2361111111111111in"} (25)

![](media/image132.wmf){width="0.5in" height="0.2361111111111111in"}is
fed into the LPC synthesis filter, where the filter memory is
initialized with zeros. The output of the filter (impulse response) is
denoted as ![](media/image133.wmf){width="0.46875in"
height="0.20833333333333334in"}. After filtering, the root mean square
energy is calculated by:

$\text{energ}_{\text{LPC}} = \sqrt{\sum_{i = 0}^{\text{63}}\left( \text{imp}_{\text{LPC}}\left( i \right) \right)^{2}}$
(26)

In correctly received frames the energy is calculated and stored using
the latest LPC available.

In case of concealment the compensation differs for ACELP and TCX:

For ACELP there will be 4 or 5 sets of LPC coefficients, depending on
the number of subframes to be synthesized. For each set of coefficients
the corresponding energy is calculated and divided by the energy derived
in the last good frame. The result of the division is used as a factor
to be multiplied to each element of the excitation vector of the
corresponding subframe. See sub-clause 5.3.4.2.1.

For TCX, there will be one or two sets of coefficients (TCX10/TCX20).
For each set of coefficients the corresponding energy is calculated and
divided by the energy derived in the previous segment. The segment size
equals 10 ms for TCX10 and 20 ms for TCX20. As the fade out is performed
in the time domain, the LPC gain compensation is also done in the time
domain, by linearly fading from the last compensation factor (would be 1
for the first lost frame) to the derived compensation factor at the end
of the segment. See sub-clause 5.4.6.1.3.

5.3 Concealment operation related to ACELP modes
------------------------------------------------

### 5.3.1 General

In case of frame erasures, the concealment strategy can be summarized as
a convergence of the signal energy and the spectral envelope to the
estimated parameters of the background noise. A frame erasure is
signalled to the decoder by setting the bad frame indicator variable for
the current frame active. The periodicity of the signal is converged to
zero. The speed of the convergence is dependent on the parameters of the
last correctly received frame and the number of consecutive erased
frames, and is controlled by an attenuation factor, α. The factor, α, is
further dependent on the stability, θ, of the LP filter for
UNVOICED\_CLAS frames. In general, the convergence is slow if the last
good received frame is in a stable segment and is rapid if the frame is
in a transition segment. The values of α are summarized in subclause
5.3.4.1 for the excitation concealment of rates: 5.9, 7.2, 8.0, 13.2, 32
and 64 kbps and in subclause 5.3.4.2.3 for the rates: 9.6, 16.4 and 24.4
kbps. Similar values are also defined for LSF concealment as described
in subclause 5.2.

#### 5.3.1.1 Extrapolation of future pitch

In case of a frame loss, an estimation of the end-of-frame pitch is done
to help keeping the adaptive codebook in sync to the error free case as
good as possible. If the error free end-of-frame pitch can be predicted
precisely, the recovery after the loss will be a lot quicker. The pitch
extrapolation assumes that the encoder uses a smooth pitch contour. The
information on the estimated end-of-frame pitch is used by the glottal
pulse resynchronization tool described in subclause 5.3.1.2.

The pitch extrapolation is done only if the last good frame was
classified as UNVOICED TRANSITION, VOICED TRANSITION or VOICED\_CLAS.
Also the pitch extrapolation is only performed if the frame before the
loss was a good frame. The extrapolation is done based on the pitch
lags, ![](media/image134.wmf){width="0.2361111111111111in"
height="0.2777777777777778in"}*,* of the last 5 subframes before the
erasure. Also the history of the pitch gains,
![](media/image135.wmf){width="0.2222222222222222in"
height="0.2777777777777778in"}, of the last 6 subframes before the
erasure is needed. The history update of the pitch lags and pitch gains
is done after the synthesis of every frame.

First, the difference between the pitch lags is computed:

![](media/image136.wmf){width="1.0277777777777777in"
height="0.2916666666666667in"}
for![](media/image137.wmf){width="0.6805555555555556in"
height="0.18055555555555555in"} (27)

where ![](media/image138.wmf){width="0.3194444444444444in"
height="0.2916666666666667in"} *denotes the last subframe of the
previous frame,* ![](media/image139.wmf){width="0.3194444444444444in"
height="0.2916666666666667in"} *denotes the second last sub-frame of the
previous frame,* and so on.

In case the last good frame contained information about future pitch
gains and pitch lags,
![](media/image140.wmf){width="0.2638888888888889in"
height="0.2777777777777778in"} is instead calculated by:

![](media/image141.wmf){width="1.1666666666666667in"
height="0.2916666666666667in"} for
![](media/image137.wmf){width="0.6805555555555556in"
height="0.18055555555555555in"} (28)

Also in case of information about future pitch gains and pitch lags was
contained in the previous frame, the history of pitch gains is shifted
by 2 subframes in a way that the ![](media/image142.wmf){width="0.375in"
height="0.20833333333333334in"}-th pitch gain is moved to the
![](media/image143.wmf){width="9.652777777777778e-2in"
height="0.16666666666666666in"}-th pitch gain, for
![](media/image144.wmf){width="0.6805555555555556in"
height="0.18055555555555555in"}.

Future subframe information might be available if the last good frame
was coded with TCX MDCT and there was LTP information available, or the
last good frame was coded with ACELP and there was future pitch
information transmitted in the bitstream (see subclause 5.3.3.1).

The sum of the differences is computed as

![](media/image145.wmf){width="0.7916666666666666in"
height="0.4722222222222222in"} (29)

The position of the maximum absolute difference,
![](media/image146.wmf){width="1.5555555555555556in"
height="0.4583333333333333in"}, is found.

If the criterion ![](media/image147.wmf){width="1.2638888888888888in"
height="0.3055555555555556in"} AND
![](media/image148.wmf){width="1.2361111111111112in"
height="0.3055555555555556in"} is met, pitch prediction is performed.
Else no prediction is performed and
![](media/image149.wmf){width="0.5277777777777778in" height="0.25in"}is
used for building the adaptive codebook during concealment.

Pitch prediction is performed by minimizing this error equation.

![](media/image150.wmf){width="1.9305555555555556in"
height="0.5138888888888888in"} (30)

where:

![](media/image151.wmf){width="0.4166666666666667in"
height="0.1527777777777778in"} is the error function,

![](media/image152.wmf){width="0.2222222222222222in"
height="0.2638888888888889in"} are the past adaptive codebook gains,

![](media/image153.wmf){width="0.1388888888888889in"
height="0.1527777777777778in"} and
![](media/image154.wmf){width="0.1388888888888889in" height="0.19375in"}
are unknown variables which need to be determined,

![](media/image155.wmf){width="0.2361111111111111in"
height="0.2222222222222222in"} are the adaptive codebook lags from the
past frames,

![](media/image156.wmf){width="9.652777777777778e-2in"
height="0.18055555555555555in"} is the subframe index

The past adaptive codebook gains are multiply by a vector {1.25f,
1.125f, 1.f, 0.875f, .75f};

Minimizing of this function is done by deviating the error function by a
and b separately

![](media/image157.wmf){width="4.69375in" height="1.2916666666666667in"}
(31)

By setting the derivatives
![](media/image158.wmf){width="0.8465277777777778in" height="0.25in"}
and ![](media/image159.wmf){width="0.6805555555555556in"
height="0.3611111111111111in"} to zero, this leads to:

![](media/image160.wmf){width="4.263888888888889in"
height="1.5694444444444444in"} (32)

![](media/image161.wmf){width="4.19375in" height="1.5694444444444444in"}
(33)

where

![](media/image162.wmf){width="3.3333333333333335in"
height="1.0965277777777778in"} (34)

The end-of-frame pitch is determined according to this, if no
information about future subframes was available in the previous frame:

$P_{\text{pred}} = a + 4 \cdot b$ (35)

In case there was information about future pitch gains and pitch lags
available the end-of-frame pitch is predicted by:

$P_{\text{pred}} = a + 2 \cdot b$ (36)

After this processing, the predicted pitch
![](media/image163.wmf){width="0.3611111111111111in"
height="0.2361111111111111in"} is limited between
![](media/image164.wmf){width="0.3055555555555556in"
height="0.20833333333333334in"} and
![](media/image165.wmf){width="0.3194444444444444in"
height="0.20833333333333334in"}.

#### 5.3.1.2 Construction of the periodic part of the excitation

For a concealment of erased frames following a correctly received
UNVOICED\_CLAS frame, no periodic part of the excitation is generated.
For a concealment of erased frames following a correctly received frame
other than UNVOICED\_CLAS, the periodic part of the excitation is
constructed by repeating the low-pass filtered last pitch period of the
previous frame. The low-pass filter used is a simple 3-tap linear phase
FIR filter with the coefficients equal to 0.18, 0.64 and 0.18. The pitch
period, Tc, used to select the last pitch pulse, and hence used during
the concealment, is defined so that pitch multiples or submultiples can
be avoided or reduced. The following logic is used in determining the
pitch period, Tc

+-----------------------------------------------------------------+
| if ((T\[--1\] \< 1.8Ts) AND (T\[--1\] \> 0.6Ts)) OR (Tcnt \>=5) |
|                                                                 |
| tmp\_tc = T\[--1\]                                              |
|                                                                 |
| else                                                            |
|                                                                 |
| tmp\_tc = Ts                                                    |
|                                                                 |
| Tc = round(tmp\_tc)                                             |
+-----------------------------------------------------------------+

Here, T\[--1\] = ![](media/image166.wmf){width="0.4166666666666667in"
height="0.2777777777777778in"} is the pitch period of the last subframe
of the last good received frame and Ts is the pitch period of the last
subframe of the last good stable voiced frame with coherent pitch
estimates. A stable voiced frame is defined here as a VOICED\_CLAS
frame, preceded by a frame of voiced type (VOICED TRANSITION,
VOICED\_CLAS, ONSET). The coherence of pitch is verified by examining
whether the closed-loop pitch estimates are reasonably close; i.e.
whether the ratio between the 4th subframe pitch,
$d_{\text{fr}^{\left\lbrack - 1 \right\rbrack}}$ at 12.8 kHz core
sampling frequency or $d_{\text{fr}^{\left\lbrack - 2 \right\rbrack}}$
at 16 kHz core sampling frequency, and the 2nd subframe pitch,
$d_{\text{fr}^{\left\lbrack - 3 \right\rbrack}}$ at 12.8 kHz core
sampling frequency or $d_{\text{fr}^{\left\lbrack - 4 \right\rbrack}}$
at 16 kHz core sampling frequency, is within the interval \[0.7, 1.4\],
and whether the ratio between the 2nd subframe pitch
($d_{\text{fr}^{\left\lbrack - 3 \right\rbrack}}$ or
$d_{\text{fr}^{\left\lbrack - 4 \right\rbrack}}$) and the last subframe
pitch of the preceding frame,
$d_{\text{fr}^{\left\lbrack - y \right\rbrack}}$, is also within that
interval, where *y* = 5 when the core sampling frequency is 12.8 kHz and
*y* = 6 otherwise. The pitch is also assumed cohererent if the coding
type is transition.

This determination of the pitch period, Tc, implies that if the pitch at
the end of the last good frame and the pitch of the last stable frame
are close, the pitch of the last good frame is used. Otherwise, this
pitch is considered unreliable and the pitch of the last stable frame is
used instead to avoid the impact of erroneous pitch estimates at voiced
onsets. This logic is valid only if the last stable segment is not too
far in the past. Hence, a counter, Tcnt, is defined that limits the
effect of the last stable segment. If Tcnt is greater than or equal to
5; i.e. if there are at least 5 frames since the last Ts update, the
last good frame pitch is used systematically. Tcnt is reset to 0 every
time a stable segment is detected and Ts is updated. The period Tc is
then maintained constant during the concealment for the entire erased
block.

##### 5.3.1.2.1 Particularity of rate 5.9, 7.2, 8.0 and 13.2 kbps

On top of UNVOICED\_CLAS, the periodic component of the excitation is
not constructed when the last coding mode was GSC AUDIO without a
temporal contribution or the last class was INACTIVE without a temporal
contribution.

#### 5.3.1.3 Glottal pulse resynchronization 

The construction of the periodic part of the excitation, described in
the subclause 5.3.1.2, may result in a drift of the glottal pulse
position in the concealed frame during voiced segments, since the pitch
period used to build the excitation can be different from the encoder
pitch period. This will cause the adaptive codebook (or past CELP
excitation) to be desynchronized from the actual CELP excitation. Thus,
in case a good frame is received after an erased frame, the pitch
excitation (or adaptive codebook excitation) will have an error which
may persist for several frames and affect the performance of the
correctly received frames.

To overcome this problem and improve the decoder convergence, a
resynchronization method is used which adjusts the position of the
glottal pulses in the concealed frame to be synchronized with the
estimated true glottal pulses positions where the positions of the
glottal pulses are estimated at the decoder based on the pitch
extrapolation performed as in subclause 5.3.1.1. Therefore, this
resynchronization procedure is performed based on the estimation of
phase information and it aligns the maximum pulse in each pitch period
of the concealed frame to the estimated position of the glottal pulse.

The starting point is the constructed periodic part of the excitation
src\_exc, constructed as described in subclause 5.3.1.2. If
![](media/image167.wmf){width="0.94375in" height="0.2361111111111111in"}
then samples are removed from src\_exc and if
![](media/image168.wmf){width="0.94375in" height="0.2361111111111111in"}
then samples are added to src\_exc. The samples are added or removed at
the locations of the minimum energy, between the estimated locations of
the glottal pulses as well as the locations of the minimum energy before
the estimated location of the first and after the estimated location of
the last glottal pulse. The periodic part of the excitation, modified in
such way, is stored into dst\_exc.

##### 5.3.1.3.1 Condition to perform resynchronisation

The glottal pulse resynchronisation is performed only if some
conditions, which describe that a reliable estimation of true pulse
positions is available and is different from the actual pulse positions,
are met. First the extrapolation of the future pitch as performed in
subclause 5.3.1.1 shall have been successful. The pitch period Tc as
defined in subclause 5.3.1.2 shall be different than the rounded
predicted pitch ![](media/image169.wmf){width="0.3611111111111111in"
height="0.2361111111111111in"} as defined in subclause 5.3.1.1. The
absolute difference between the pitch period Tc and the rounded
predicted pitch ![](media/image170.wmf){width="0.3611111111111111in"
height="0.2361111111111111in"} shall be smaller than
![](media/image171.wmf){width="0.5138888888888888in"
height="0.20833333333333334in"}. In order to have enough samples for the
pulse resynchronization in the periodic part of the excitation
constructed by repeating the last pitch period, the relative pitch
change shall be greater than a threshold as described below:

![](media/image172.wmf){width="1.3611111111111112in"
height="0.4583333333333333in"} (37)

where ![](media/image173.wmf){width="0.3611111111111111in"
height="0.2361111111111111in"} is the number of subframes as defined in
subclause 5.1.2.

If the conditions to perform the glottal pulse resynchronization are not
met, the samples from src\_exc are simply copied to dst\_exc. In some
instances, where the glottal pulse resynchronization is used, this is
implemented in a such way that src\_exc points to the final location of
the modified periodic part of the excitation, and that its contents are
first copied to another temporary buffer which is then considered as
src\_exc inside the pulse resynchronization and the final location which
for the caller is src\_exc is considered as dst\_exc inside the pulse
resynchronization.

##### 5.3.1.3.2 Performing glottal pulse resynchronization

First the pitch change per sub-frame
![](media/image174.wmf){width="0.1388888888888889in"
height="0.16666666666666666in"} is calculated as:

![](media/image175.wmf){width="1.19375in" height="0.4722222222222222in"}
(38)

Then the number of samples to be added (to be removed if negative)
![](media/image176.wmf){width="0.1388888888888889in"
height="0.18055555555555555in"} is calculated as:

![](media/image177.wmf){width="2.0694444444444446in"
height="0.4166666666666667in"} (39)

Then the location of the first maximum pulse
![](media/image178.wmf){width="0.2916666666666667in"
height="0.19375in"}, among first
![](media/image179.wmf){width="0.19375in"
height="0.20833333333333334in"} samples in src\_exc is found using
simple search for the maximum absolute value.

The index of the last pulse that will be present in dst\_exc is
calculated as:

$k = \left\lceil \frac{L - d - T\lbrack 0\rbrack}{T_{C}} - 1 \right\rceil$
(40)

The delta of the samples to be added or removed between consecutive
pitch cycles ![](media/image180.wmf){width="0.125in"
height="0.1388888888888889in"} is calculated as:

![](media/image181.wmf){width="1.7777777777777777in"
height="0.6805555555555556in"} (41)

The number of samples to be added or removed before the first pulse is
calculated as:

![](media/image182.wmf){width="1.9305555555555556in"
height="0.4027777777777778in"} (42)

The number of samples to be added or removed before the first pulse is
rounded down and the fractional part is kept in memory:

![](media/image183.wmf){width="0.7777777777777778in"
height="0.5416666666666666in"} (43)

For each region between 2 pulses the number of samples to be added or
removed is calculated as:

![](media/image184.wmf){width="1.6527777777777777in"
height="0.3055555555555556in"}, ![](media/image185.wmf){width="0.5in"
height="0.18055555555555555in"} (44)

The number of samples to be added or removed between 2 pulses, taking
into account the remaining fractional part from the previous rounding,
is rounded down:

![](media/image186.wmf){width="0.8055555555555556in"
height="0.5416666666666666in"} (45)

If, due to the added
![](media/image187.wmf){width="0.1527777777777778in"
height="0.1527777777777778in"}, for some i it happens that
![](media/image188.wmf){width="0.5833333333333334in"
height="0.2777777777777778in"}, then the values for
![](media/image189.wmf){width="0.18055555555555555in"
height="0.2777777777777778in"} and
![](media/image190.wmf){width="0.2916666666666667in"
height="0.2777777777777778in"} are swapped.

The number of samples to be added or removed after the last pulse is
calculated as:

![](media/image191.wmf){width="1.5138888888888888in"
height="0.5138888888888888in"} (46)

The maximum number of samples to be added or removed among the minimum
energy regions is calculated as:

![](media/image192.wmf){width="2.2083333333333335in"
height="0.4861111111111111in"} (47)

The location of the minimum energy segment
![](media/image193.wmf){width="0.44375in" height="0.2777777777777778in"}
between the first two pulses in src\_exc, that has
![](media/image194.wmf){width="0.34652777777777777in" height="0.25in"}
length, is then found by simple search for minimum in the moving average
of length ![](media/image194.wmf){width="0.34652777777777777in"
height="0.25in"}. For every consecutive minimum energy segment between
two pulses, the position is calculated as:

![](media/image195.wmf){width="1.5694444444444444in"
height="0.2777777777777778in"}, ![](media/image196.wmf){width="0.5in"
height="0.18055555555555555in"} (48)

If ![](media/image197.wmf){width="0.7361111111111112in"
height="0.2777777777777778in"} then the location of the minimum energy
segment before the first pulse is calculated using
![](media/image198.wmf){width="1.2916666666666667in"
height="0.2777777777777778in"}. Otherwise the location of the minimum
energy segment ![](media/image199.wmf){width="0.4722222222222222in"
height="0.2777777777777778in"} before the first pulse in src\_exc is
found by simple search for minimum in the moving average of length
![](media/image200.wmf){width="0.20833333333333334in" height="0.25in"}.

If ![](media/image201.wmf){width="1.2638888888888888in"
height="0.2777777777777778in"} then the location of the minimum energy
segment after the last pulse is calculated using
![](media/image202.wmf){width="1.5416666666666667in"
height="0.2777777777777778in"}. Otherwise the location of the minimum
energy segment ![](media/image203.wmf){width="0.6666666666666666in"
height="0.2777777777777778in"} after the last pulse in src\_exc is found
by simple search for minimum in the moving average of length
![](media/image204.wmf){width="0.3194444444444444in" height="0.25in"}.

If there is going to be just one pulse in dst\_exc, that is if
![](media/image205.wmf){width="0.125in" height="0.18055555555555555in"}
is equal to 0, the search for ![](media/image193.wmf){width="0.44375in"
height="0.2777777777777778in"} is limited to
![](media/image206.wmf){width="0.34652777777777777in"
height="0.18055555555555555in"}.
![](media/image193.wmf){width="0.44375in" height="0.2777777777777778in"}
then points to the location of the minimum energy segment after the only
pulse in dst\_exc.

If ![](media/image207.wmf){width="0.34652777777777777in"
height="0.18055555555555555in"} then
![](media/image208.wmf){width="0.18055555555555555in" height="0.25in"}
samples are added at location ![](media/image209.wmf){width="0.44375in"
height="0.2777777777777778in"} for
![](media/image210.wmf){width="0.7083333333333334in"
height="0.18055555555555555in"} to the signal src\_exc and stored in
dst\_exc, otherwise if
![](media/image211.wmf){width="0.34652777777777777in"
height="0.18055555555555555in"} then
![](media/image208.wmf){width="0.18055555555555555in" height="0.25in"}
samples are removed at location
![](media/image209.wmf){width="0.44375in" height="0.2777777777777778in"}
for ![](media/image210.wmf){width="0.7083333333333334in"
height="0.18055555555555555in"} from the signal src\_exc and stored in
dst\_exc. There are ![](media/image212.wmf){width="0.3333333333333333in"
height="0.18055555555555555in"} regions where the samples are added or
removed.

#### 5.3.1.4 Construction of the random part of the excitation

The innovative (non-periodic) part of the excitation is generated
randomly. A simple random generator with approximately uniform
distribution is used. Before adjusting the innovation gain, the randomly
generated innovation is scaled to some reference value, fixed here to
the unitary energy per sample. At the beginning of an erased block, the
innovation gain, *g~s~*, is initialized by using the innovative
excitation gains of each subframe of the last good frame

for 4 subframes:

![](media/image213.wmf){width="2.5833333333333335in" height="0.25in"}
(49)

for 5 subframes:

$g_{s} = \frac{1}{\text{15}}g_{c}^{\lbrack - 5\rbrack} + \frac{2}{\text{15}}g_{c}^{\lbrack - 4\rbrack} + \frac{3}{\text{15}}g_{c}^{\lbrack - 3\rbrack} + \frac{4}{\text{15}}g_{c}^{\lbrack - 2\rbrack} + \frac{5}{\text{15}}g_{c}^{\lbrack - 1\rbrack}$(49a)

where $g_{c}^{\lbrack - 5\rbrack}$,
![](media/image214.wmf){width="0.3333333333333333in" height="0.25in"},
![](media/image215.wmf){width="0.3333333333333333in"
height="0.2388888888888889in"},
![](media/image216.wmf){width="0.3333333333333333in" height="0.25in"}
and ![](media/image217.wmf){width="0.3229166666666667in"
height="0.25in"} are the algebraic codebook gains of the four subframes
of the last correctly received frame. The attenuation strategy of the
random part of the excitation is somewhat different from the attenuation
of the pitch excitation. The reason is that the pitch excitation (and
thus the excitation periodicity) is converging to 0 while the random
excitation is converging to the CNG excitation energy. The innovation
gain attenuation is calculated as

![](media/image218.wmf){width="1.3611111111111112in" height="0.25in"}
(50)

where ![](media/image219.wmf){width="0.25in" height="0.25in"} is the
innovative gain at the beginning of the next frame,
![](media/image220.wmf){width="0.2590277777777778in" height="0.25in"}is
the innovative gain at the beginning of the current frame,
![](media/image221.wmf){width="0.19375in" height="0.25in"}is the gain of
the excitation used during the comfort noise generation and α is as
defined in Table 4. The comfort noise gain,
![](media/image222.wmf){width="0.19375in" height="0.25in"}, is given as
the square root of the energy
![](media/image223.wmf){width="0.1840277777777778in"
height="0.18888888888888888in"} as described in subclause 5.4.3.6.4.
Similarly to the periodic excitation attenuation, the gain is thus
attenuated linearly throughout the frame on a sample-by-sample basis
starting with, ![](media/image224.wmf){width="0.27361111111111114in"
height="0.25in"}, and going to the value of
![](media/image225.wmf){width="0.25in" height="0.25in"} that would be
achieved at the beginning of the next frame.

Finally, if the last correctly received frame is different from
UNVOICED\_CLAS, the innovation excitation is filtered through a linear
phase FIR high-pass filter with coefficients --0.0125, --0.109, 0.7813,\
--0.109, and --0.0125. To decrease the amount of noisy components during
voiced segments, these filter coefficients are multiplied by an adaptive
factor equal to ![](media/image226.wmf){width="0.8611111111111112in"
height="0.20833333333333334in"}, with
![](media/image227.wmf){width="0.1527777777777778in"
height="0.20833333333333334in"} denoting the voicing factor as defined
in equation (1475) in subclause 6.1.1.3.2 of \[5\]. The random part of
the excitation is then added to the adaptive excitation to form the
total excitation signal. If the last good frame is UNVOICED\_CLAS, only
the innovative excitation is used and it is further attenuated by a
factor of 0.8. In this case, the past excitation buffer is updated with
the innovation excitation, as no periodic part of the excitation is
available. If the last good frame is UNVOICED\_CLAS or INACTIVE but it
is not coded with UC mode signalling non‑stationary unvoiced frame, the
innovation excitation is further attenuated by a factor of 0.8.

#### 5.3.1.5 Spectral envelope concealment, synthesis and updates

To synthesize the decoded speech, the LP filter parameters shall be
obtained. The spectral envelope is gradually moved to an estimated
reference envelope, see clause 5.2. The estimated LSF vector is
converted to an LSP vector and interpolated with the last frame\'s LSP
vector for 4 or 5 subframes, depending on the ACELP sampling rate being
12.8 kHz or 16 kHz.

The synthesized signal is obtained by filtering the sum of the adaptive
and the random excitation signal through the LP synthesis filter (see
clause 6.1.3 of \[5\]) and post-processed similar to the steps performed
in clean channel.

As the LSF quantizers uses prediction, their memories would not be up to
date after the normal operation is resumed. To reduce this effect, the
quantizers\' memories (moving average and auto-regressive) are estimated
and updated at the end of each erased frame.

##### 5.3.1.5.1 Specifics for rates 9.6, 16.4 and 24.4 kbps

The coefficients of the filter used in subclause 5.3.1.2 for low pass
filtering of the first pitch cycle are dependent on the sampling rate.
The pitch period, tmp\_tc, is always equal to T\[-1\], where T\[-1\] is
the pitch period of the last sub-frame of the last good received frame,
and Tc, used to select the last pitch pulse is thus equal to
round(T\[-1\]).

The periodic part of the excitation will be generated further by
repeatedly copying the last pitch cycle of the dst\_exc for an
additional half frame, which is used for correctly updating the
overlap-add buffers for MDCT recovery.

In contrast to subclause 5.3.1.5, both excitation signals are not added
up and filtered. The synthesized signal is obtained by filtering the
adaptive excitation through the LP synthesis filter based on the LSF
interpolation according to formula (19). The random part of the
excitation is filtered through the LP filter based on formula (21).
After obtaining two separate synthesis signals, they are added up, post
processed and played out like in a correctly received frame. Note, that
the memories for both of the LP synthesis filters are initialized with
the last known state of the last good frame in the beginning of a frame
loss. For consecutive loss, they are updated and stored separately.

#### 5.3.1.6 GSC mode concealment

When the concealment is performed based on the GSC core, the
construction of the periodic part of the excitation is performed as
described in subclauses 5.3.1.2 and 5.3.1.3. The reconstruction of the
periodic part of the excitation corresponds to the time domain
contribution of the GSC model. Thus, the reconstructed periodic
excitation is converted into the frequency domain using the DCT~IV~ as
described in subclause 5.2.3.5.3.1 of \[5\] and the spectrum above the
last known cut-off frequency is smoothed-out to zero.

Then, the spectral concealment is performed by using the last good band
energies received. In case of INACTIVE content or active SWB UC mode,
the last good decoded spectrum is mixed with random noise at a rate of
4/5 random noise and 1/5 the last decoded spectrum, making the spectrum
to become noisy quite fast. In case the last good frame was AUDIO, no
noise is added, but the spectrum dynamic is attenuated by 25 %.

The next step consists in adding the spectrum of the reconstructed
periodic excitation to the concealed spectrum of the frequency domain
contribution and to perform the inverse DCT~IV~ similarly as done in
subclause 5.2.3.5.3.1 of \[5\] to get the final concealed excitation in
case of GSC mode.

#### 5.3.1.7 Specifics for AMR-WB IO modes

In case of AMR-WB IO the subclause 5.1.2 is complement with a few more
parameters that allow the interoperable decoder to know if the decoded
frame contains more likely speech of generic audio and if the current
frame contains an onset. The generic audio can include music,
reverberant speech and can also include background music. To determine
with good confidence that the current frame can be categorized as
generic audio, two parameters are used. The total frame energy
![](media/image228.wmf){width="0.2222222222222222in"
height="0.20833333333333334in"} as formulated in subclause 5.1.2 and the
statistical deviation of the energy variation
history![](media/image229.wmf){width="0.2222222222222222in"
height="0.20833333333333334in"}.

First, a mean of the past forty (40) total frame energy variations
![](media/image230.wmf){width="0.2777777777777778in"
height="0.2361111111111111in"} is calculated using the following
relation:

![](media/image231.wmf){width="3.5965277777777778in"
height="0.6666666666666666in"} (51)

Then, a statistical deviation of the energy variation history
![](media/image232.wmf){width="0.2222222222222222in"
height="0.20833333333333334in"}over the last fifteen (15) frames is
determined using the following relation:

![](media/image233.wmf){width="2.0277777777777777in"
height="0.5694444444444444in"} (52)

The resulting deviation
![](media/image234.wmf){width="0.2222222222222222in"
height="0.20833333333333334in"} gives an indication on the energy
stability of the decoded synthesis. Typically, music has a higher energy
stability (lower statistical deviation of the energy variation history)
than speech.

Additionally, the first step classification is used to evaluate the
interval between two frames classified as unvoiced
![](media/image235.wmf){width="0.28125in"
height="0.20833333333333334in"} when the coder type is different from
INACTIVE. When a frame is classified as unvoiced and the coder type is
different from INACTIVE, meaning that the signal is unvoiced but not
silence, if the long term active content
energy![](media/image236.wmf){width="0.21805555555555556in"
height="0.21805555555555556in"}, as formulated in subclause 5.1.2, is
below 40 dB the unvoiced interval counter is set to 16, otherwise the
unvoiced interval counter ![](media/image237.wmf){width="0.28125in"
height="0.20833333333333334in"} is decreased by 8 and also limited
between 0 and 300 for active signal and between 0 and 125 for inactive
signal. It is reminded that, the difference between active and inactive
signal is deduced from the voice activity detection VAD information
included in the bitstream.

A long term average is derived from this unvoiced frame counter as
follow for active signal:

![](media/image238.wmf){width="1.625in" height="0.2361111111111111in"}
(53)

And as follows for inactive signal:

![](media/image239.wmf){width="1.0694444444444444in"
height="0.2361111111111111in"} (54)

Furthermore, when the long term unvoiced average
![](media/image240.wmf){width="0.3333333333333333in"
height="0.2361111111111111in"}is greater than 100 and the deviation
![](media/image241.wmf){width="0.2222222222222222in"
height="0.20833333333333334in"} is greater than 5 and the difference
between the current frame energy and the last frame energy
![](media/image242.wmf){width="0.2361111111111111in" height="0.25in"} is
smaller than 12 dB, the long term average is modified as follow:

![](media/image243.wmf){width="1.2916666666666667in"
height="0.2361111111111111in"} (55)

This parameter on long term average of the number of frames between
frames classified as unvoiced is used by the classifier to determine if
the frame should be considered as generic audio or not. The more the
unvoiced frames are close in time, the more likely the frame has speech
characteristics (less probably generic audio). In the illustrative
example, the threshold to decide if a frame is considered as generic
audio ![](media/image244.wmf){width="0.2361111111111111in"
height="0.20833333333333334in"}is defined as follows:

A frame is declared ![](media/image245.wmf){width="0.2361111111111111in"
height="0.20833333333333334in"}if

![](media/image246.wmf){width="1.3055555555555556in"
height="0.2777777777777778in"} (56)

The parameter![](media/image247.wmf){width="0.2361111111111111in"
height="0.25in"}, defined at the beginning of this subclause, is added
to not classify large energy variation as generic audio, but to keep it
as active content. A flag named local attack flag
![](media/image248.wmf){width="0.25in" height="0.2361111111111111in"}and
used in subclause 6.8.1.3.5 of \[6\] is derived from variation of energy
parameter![](media/image247.wmf){width="0.2361111111111111in"
height="0.25in"}. The local attack flag
![](media/image248.wmf){width="0.25in" height="0.2361111111111111in"}is
set to 1 when the energy variation is greater than 6 dB and the frame is
classified as GENERIC AUDIO SOUND or when the energy variation is
greater than 9 dB.

The modification performed on the excitation depends on the
classification of the frame and for some type of frames there is no
modification at all. The next table 3 summarizes the case where a
modification can be performed or not.

Table 6: Signal category for excitation modification

+----------------------+--------------------------+------------------+--------------+
| Frame Classification | Voice activity detected? | Category         | Modification |
|                      |                          |                  |              |
|                      | Y/N                      |                  | Y/N          |
+----------------------+--------------------------+------------------+--------------+
| ONSET                | Y                        | Active voice     | N            |
|                      |                          |                  |              |
| VOICED\_CLAS         | (VAD=1)                  |                  |              |
|                      |                          |                  |              |
| UNVOICED TRANSITION  |                          |                  |              |
|                      |                          |                  |              |
| ARTIFICIAL ONSET     |                          |                  |              |
+----------------------+--------------------------+------------------+--------------+
| GENERIC AUDIO SOUND  | Y                        | Generic audio    | Y            |
+----------------------+--------------------------+------------------+--------------+
| VOICED TRANSITION    | Y                        | Active unvoiced  | Y            |
|                      |                          |                  |              |
| UNVOICED\_CLAS       |                          |                  |              |
+----------------------+--------------------------+------------------+--------------+
| ONSET                | N                        | Inactive content | Y            |
|                      |                          |                  |              |
| VOICED\_CLAS         |                          |                  |              |
|                      |                          |                  |              |
| UNVOICED TRANSITION  |                          |                  |              |
|                      |                          |                  |              |
| ARTIFICIAL ONSET     |                          |                  |              |
|                      |                          |                  |              |
| GENERIC AUDIO SOUND  |                          |                  |              |
|                      |                          |                  |              |
| VOICED TRANSITION    |                          |                  |              |
|                      |                          |                  |              |
| UNVOICED\_CLAS       |                          |                  |              |
+----------------------+--------------------------+------------------+--------------+

The output of the second stage classifier will be used to activate or
not different post processing based on content category.

#### 5.3.1.8 Reconstructed excitation

The total excitation from layer 1 in each subframe is constructed by

![](media/image249.wmf){width="2.8465277777777778in"
height="0.2361111111111111in"} (57)

where ![](media/image250.wmf){width="0.2638888888888889in"
height="0.20833333333333334in"} is the pre-filtered algebraic code
vector. The excitation signal,
![](media/image251.wmf){width="0.3055555555555556in"
height="0.20833333333333334in"}, is used to update the contents of the
adaptive codebook for the next frame. The excitation signal,
![](media/image251.wmf){width="0.3055555555555556in"
height="0.20833333333333334in"}, is then post‑processed as described in
subclause 6.1.1.3 of \[5\] to obtain the post-processed excitation
signal ![](media/image252.wmf){width="0.2777777777777778in"
height="0.20833333333333334in"}, which is finally used as an input to
the synthesis filter
![](media/image253.wmf){width="0.4027777777777778in"
height="0.2361111111111111in"}. The final steps of synthesis,
post‑processing, de-emphasis and resampling are described in
subclauses 6.1.4 of \[5\].

##### 5.3.1.8.1 Particularity of rate 5.9, 7.2, 8.0 and 13.2 kbps

In case of GSC based concealment, with or without a time domain
contribution, the excitation
![](media/image251.wmf){width="0.3055555555555556in"
height="0.20833333333333334in"} corresponds directly to the output of
subclause 5.3.1.6.

### 5.3.2 Concealment for bandwidth extension for ACELP modes

#### 5.3.2.1 Time domain bandwidth extension

##### 5.3.2.1.1 SWB time domain bandwidth extension

The concealment for SWB TD BWE works for 13.2 kbps, 16.4 kbps, 24.4 kbps
and 32 kbps. The algorithm aims to reconstruct the high band of the
current lost frame for SWB TD BWE. The reconstruction of the lost frame
depends on at least one of the following gain adjustment information:
the coder type of the previous frame, the frame class of the last good
received frame, the frame class of the current frame, the number of the
consecutive lost frame, the energies and the tilts of the low band of
both the current frame and the previous frame.

There are gain shapes which are also the subframe gains, global frame
gain and LSF should be reconstructed when the current frame is lost. The
reconstruction of the LSF information is usually copying from the
previous frame. The reconstruction of the subframe gains of the lost
frame is based on the subframe gains and the subframe gain gradients of
at least one frame before the current frame and adjusted by some of the
above gain adjustment information. The reconstruction of the global
frame gain of the lost frame is based on the global frame gain of at
least one frame before the current frame and the global frame gain
gradient of the current frame and adjusted by some of the above gain
adjustment information.

The initial high band signal of the current lost frame is synthesized
according to the decoding parameters of the frame prior to the current
lost frame, specifically it is synthesized by passing the high band
excitation through the synthesis filter, where the high band excitation
is obtained from the low band excitation and synthesis filter is
obtained from the reconstructed LSF parameters. Then the initial
synthesized high band signal is adjusted by the reconstructed global
frame gain and at least two of the reconstructed subframe gains of the
current lost frame. Finally, the high band of the current lost frame is
reconstructed.

###### 5.3.2.1.1.1 The reconstruction of the global frame gain

For single frame loss: determining the frame class of the current frame,
the tilts of the current frame and the previous frame, the energies of
the low parts and high parts from the low band of both the current frame
and the previous frame.

Assuming the three following conditions:

\- Condition 1: the frame class of the current frame is not
UNVOICED\_CLAS and UNVOICED\_TRANSITION.

\- Condition 2: the tilt of the previous frame is less than 8.0.

\- Condition 3: the energy of low parts from the low band of the current
frame![](media/image254.wmf){width="0.375in"
height="0.16666666666666666in"}is more than
![](media/image255.wmf){width="0.8465277777777778in"
height="0.2361111111111111in"} and
![](media/image256.wmf){width="0.375in"
height="0.16666666666666666in"}is less
than![](media/image257.wmf){width="0.8465277777777778in"
height="0.2361111111111111in"}, or, the energy of high parts from the
low band of the current
frame![](media/image258.wmf){width="0.4305555555555556in"
height="0.16666666666666666in"}is more than
![](media/image259.wmf){width="0.9027777777777778in"
height="0.2361111111111111in"} and
![](media/image260.wmf){width="0.4305555555555556in"
height="0.16666666666666666in"}is less
than![](media/image261.wmf){width="0.9166666666666666in"
height="0.2361111111111111in"}. The
![](media/image262.wmf){width="0.5833333333333334in"
height="0.2361111111111111in"}is the energy of low parts from the low
band of the current frame and the
![](media/image263.wmf){width="0.6388888888888888in"
height="0.2361111111111111in"} is the energy of high parts from the low
band of the previous frame.

If all the above mentioned three conditions are met, the global frame
gain of the current lost frame is described as follows:

![](media/image264.wmf){width="3.44375in" height="0.6527777777777778in"}
(58)

where the![](media/image265.wmf){width="0.4305555555555556in"
height="0.20833333333333334in"} is calculated by:

![](media/image266.wmf){width="1.2083333333333333in"
height="0.2361111111111111in"} (59)

![](media/image267.wmf){width="2.4027777777777777in"
height="0.7916666666666666in"} (60)

where ![](media/image268.wmf){width="0.20833333333333334in"
height="0.16666666666666666in"} is the high band excitation energy of
the current frame, ![](media/image269.wmf){width="0.4305555555555556in"
height="0.2361111111111111in"} is the high band excitation energy of the
previous frame.

Then if the tilt of the low band of the current frame
![](media/image270.wmf){width="0.20833333333333334in"
height="0.18055555555555555in"} is more than that of the previous frame
![](media/image271.wmf){width="0.4305555555555556in"
height="0.2361111111111111in"}, the global frame gain is updated as
follows:

![](media/image272.wmf){width="1.9027777777777777in"
height="0.4583333333333333in"} (61)

![](media/image273.wmf){width="1.7361111111111112in"
height="0.2361111111111111in"} (62)

If the above mentioned three conditions are not met, but the following
three conditions are met:

\- Condition 4: the frame class of the current frame is not
UNVOICED\_CLAS or the tilt of the previous frame is more than 8.0,

\- Condition 5: ![](media/image274.wmf){width="0.4305555555555556in"
height="0.20833333333333334in"} is more
than![](media/image275.wmf){width="0.4722222222222222in"
height="0.19375in"},

\- Condition 6: the energy of low parts from the low band of the current
frame![](media/image276.wmf){width="0.375in"
height="0.16666666666666666in"}is more
than![](media/image277.wmf){width="0.8465277777777778in"
height="0.2361111111111111in"}, or the energy of high parts from the low
band of the current
frame![](media/image278.wmf){width="0.4305555555555556in"
height="0.16666666666666666in"}is more
than![](media/image279.wmf){width="0.9027777777777778in"
height="0.2361111111111111in"}. The
![](media/image262.wmf){width="0.5833333333333334in"
height="0.2361111111111111in"}is the energy of low parts from the low
band of the current frame and the
![](media/image263.wmf){width="0.6388888888888888in"
height="0.2361111111111111in"} is the energy of high parts from the low
band of the previous frame.

The global frame gain would be:

![](media/image280.wmf){width="1.5555555555555556in"
height="0.20833333333333334in"} (63)

For multiple frame losses:

For 13.2 kbps and 32 kbps, if
![](media/image281.wmf){width="0.4305555555555556in"
height="0.20833333333333334in"} is more
than![](media/image282.wmf){width="0.4722222222222222in"
height="0.19375in"}, ![](media/image283.wmf){width="0.375in"
height="0.16666666666666666in"}is more than
![](media/image284.wmf){width="0.5833333333333334in"
height="0.2361111111111111in"}and
![](media/image285.wmf){width="0.4305555555555556in"
height="0.16666666666666666in"}is more
than![](media/image286.wmf){width="0.6388888888888888in"
height="0.2361111111111111in"}. For 16.4 kbps and 24.4 kbps if
![](media/image281.wmf){width="0.4305555555555556in"
height="0.20833333333333334in"} is more
than![](media/image282.wmf){width="0.4722222222222222in"
height="0.19375in"}, the global frame gain is as follows:

![](media/image287.wmf){width="4.069444444444445in"
height="0.4861111111111111in"} (64)

Otherwise, for 13.2 kbps and 32 kbps, if
![](media/image281.wmf){width="0.4305555555555556in"
height="0.20833333333333334in"} is more
than![](media/image288.wmf){width="0.19375in"
height="0.20833333333333334in"}, ![](media/image283.wmf){width="0.375in"
height="0.16666666666666666in"}is more than
![](media/image284.wmf){width="0.5833333333333334in"
height="0.2361111111111111in"}and
![](media/image285.wmf){width="0.4305555555555556in"
height="0.16666666666666666in"}is more
than![](media/image286.wmf){width="0.6388888888888888in"
height="0.2361111111111111in"}. For 16.4 kbps and 24.4 kbps if
![](media/image281.wmf){width="0.4305555555555556in"
height="0.20833333333333334in"} is more
than![](media/image289.wmf){width="0.19375in"
height="0.20833333333333334in"}, the global frame gain is as follows:

![](media/image290.wmf){width="3.2083333333333335in"
height="0.4861111111111111in"} (65)

###### 5.3.2.1.1.2 The reconstruction of the gain attenuation factor

Reconstruct the gain attenuation factor according to the following
conditions: the coder type of the previous frame, the frame class of the
last good received frame, and the energies of the low band of both the
current frame and the previous frame, the number of the consecutive lost
frames. The detail processing is as follows:

For single frame loss, judging the following three conditions:

\- Condition 1: the energy of the shaped excitation
![](media/image291.wmf){width="0.3611111111111111in"
height="0.19375in"}of current
frame![](media/image292.wmf){width="0.3194444444444444in"
height="0.20833333333333334in"}is more than the energy of the shaped
excitation ![](media/image293.wmf){width="0.3611111111111111in"
height="0.19375in"}of the previous
frame![](media/image294.wmf){width="0.6388888888888888in"
height="0.2361111111111111in"}.

\- Condition 2: The coder type of the previous frame is not UNVOICED.

\- Condition 3: The frame class of the last good received frame is not
UNVOICED\_CLAS.

If condition1, 2 and 3 are met:

The gain attenuation factor
![](media/image295.wmf){width="0.5138888888888888in"
height="0.20833333333333334in"} to the shaped excitation
![](media/image296.wmf){width="0.3611111111111111in"
height="0.19375in"}is as follows:

![](media/image297.wmf){width="1.6111111111111112in"
height="0.9722222222222222in"} (66)

Otherwise

\- Condition 4: the energy of the shaped excitation
![](media/image298.wmf){width="0.3611111111111111in"
height="0.19375in"}of current
frame![](media/image299.wmf){width="0.3194444444444444in"
height="0.20833333333333334in"}is more than 0.5 times the energy of the
shaped excitation ![](media/image300.wmf){width="0.3611111111111111in"
height="0.19375in"}of the previous
frame![](media/image301.wmf){width="0.9027777777777778in"
height="0.2361111111111111in"}.

\- Condition 5: the energy of low parts from the low band of the current
frame![](media/image283.wmf){width="0.375in"
height="0.16666666666666666in"}is more
than![](media/image277.wmf){width="0.8465277777777778in"
height="0.2361111111111111in"}, or the energy of high parts from the low
band of the current
frame![](media/image278.wmf){width="0.4305555555555556in"
height="0.16666666666666666in"}is more than
![](media/image279.wmf){width="0.9027777777777778in"
height="0.2361111111111111in"}.
The![](media/image262.wmf){width="0.5833333333333334in"
height="0.2361111111111111in"}is the energy of low parts from the low
band of the current frame and the
![](media/image263.wmf){width="0.6388888888888888in"
height="0.2361111111111111in"} is the energy of high parts from the low
band of the previous frame.

\- Condition 6: The coder type of the previous frame is not UNVOICED, or
the type of the last good received is not UNVOICED\_CLAS or the tilt of
the previous frame is more than 5.0.

If condition 4, 5 and 6 are met, the gain attenuation factor
![](media/image302.wmf){width="0.5138888888888888in"
height="0.20833333333333334in"}is calculated as follows:

![](media/image303.wmf){width="1.6111111111111112in"
height="0.9722222222222222in"} (67)

For multiple frame losses:

If the energy of the shaped excitation
![](media/image304.wmf){width="0.3611111111111111in"
height="0.19375in"}of current
frame![](media/image305.wmf){width="0.3194444444444444in"
height="0.20833333333333334in"}is more than the energy of the shaped
excitation ![](media/image304.wmf){width="0.3611111111111111in"
height="0.19375in"}of the previous
frame![](media/image306.wmf){width="0.625in"
height="0.2361111111111111in"}, the gain attenuation factor
![](media/image307.wmf){width="0.5138888888888888in"
height="0.20833333333333334in"}is as follows:

$\begin{matrix}
\text{factor}_{\text{sε}} = \sqrt{\frac{\text{En}_{\text{sε}}}{\text{En}_{\text{sε}_{\text{prev}}}}} \\
 \\
\text{factor}_{\text{sε}_{\text{temp}}} = \left( \text{factor}_{\text{se}} \right)^{0\text{.}\text{125}} \\
\end{matrix}$ (68)

Otherwise if condition4, 5 and 6 are met, the gain attenuation factor
![](media/image308.wmf){width="0.5138888888888888in"
height="0.20833333333333334in"}is as follows:

$\begin{matrix}
\text{factor}_{\text{sε}} = \text{min}\left( 2\text{.}0,\sqrt{\frac{\text{En}_{\text{sε}}}{\text{En}_{\text{sε}_{\text{prev}}}}} \right) \\
 \\
\text{factor}_{\text{sε}_{\text{temp}}} = \left( \text{factor}_{\text{se}} \right)^{0\text{.}\text{125}} \\
\end{matrix}$ (69)

Use the ![](media/image309.wmf){width="0.5138888888888888in"
height="0.20833333333333334in"} and
![](media/image310.wmf){width="0.8194444444444444in"
height="0.2361111111111111in"}to the subframe gains and the shaped
excitation ![](media/image311.wmf){width="0.3611111111111111in"
height="0.19375in"}described as follows:

![](media/image312.wmf){width="3.5in" height="0.875in"} (70)

Use the reconstructed information including subframe gains, global frame
gain and LSFs to reconstruct the high band signal of the lost frame.

###### 5.3.2.1.1.3 Specifics for rates 13.2 and 32 kbps

Calculating the subframe gain gradients of the previous frame and the
frame immediately prior to the previous frame are described as follows:

![](media/image313.wmf){width="3.4027777777777777in"
height="0.7916666666666666in"} (71)

where ![](media/image314.wmf){width="1.0138888888888888in"
height="0.25in"}are the subframe gains of the previous frame,
![](media/image315.wmf){width="1.0in" height="0.25in"}are the subframe
gains of the frame immediately prior to the previous frame.

![](media/image316.wmf){width="6.25in" height="1.1527777777777777in"}
(72)

If the coder type of the previous frame is UNVOICED, or the frame class
of the last good received frame is UNVOICED\_CLASS, and
the![](media/image317.wmf){width="0.7222222222222222in"
height="0.2361111111111111in"}is positive. Then the first subframe gain
template ![](media/image318.wmf){width="0.75in"
height="0.2361111111111111in"}would be:

$\text{gs}_{\text{template}}(0) = gs^{''}(3) + \text{gs}_{\text{gradfec}}(0)$
(73)

Otherwise, if ![](media/image319.wmf){width="0.7361111111111112in"
height="0.2638888888888889in"} is positive, the subframe gain template
![](media/image320.wmf){width="0.7638888888888888in"
height="0.2638888888888889in"}would be:

$\text{gs}_{\text{template}}(0) = gs^{''}(3) + 0\text{.}5 \ast \text{gs}_{\text{gradfec}}(0)$
(74)

Otherwise, the subframe gain template
![](media/image321.wmf){width="0.75in"
height="0.2361111111111111in"}would be:

$\text{gs}_{\text{template}}(0) = gs^{''}(3)$ (75)

The other gain subframe gain templates
![](media/image322.wmf){width="1.375in" height="0.2638888888888889in"}
are determined as follows:

If ![](media/image323.wmf){width="0.6388888888888888in"
height="0.2361111111111111in"}is more than
10\*![](media/image324.wmf){width="0.6111111111111112in"
height="0.2361111111111111in"}and
the![](media/image325.wmf){width="0.6111111111111112in"
height="0.2361111111111111in"} is positive. Then:

![](media/image326.wmf){width="3.4027777777777777in"
height="0.2361111111111111in"} (76)

Otherwise, if ![](media/image327.wmf){width="0.6388888888888888in"
height="0.2361111111111111in"}is more than
![](media/image328.wmf){width="0.8333333333333334in"
height="0.2361111111111111in"}and
![](media/image329.wmf){width="0.6111111111111112in"
height="0.2361111111111111in"} is negative. Then:

![](media/image330.wmf){width="3.4027777777777777in"
height="0.2361111111111111in"} (77)

Otherwise

![](media/image331.wmf){width="3.138888888888889in"
height="0.2361111111111111in"} (78)

Reconstruct the ![](media/image332.wmf){width="0.9583333333333334in"
height="0.19375in"}use the
![](media/image333.wmf){width="1.3611111111111112in"
height="0.2361111111111111in"}according to the coder type of the
previous frame, the frame class of the last good received frame and the
number of consecutive lost frame. The global frame gain
g[radient]{.underline}![](media/image334.wmf){width="0.3194444444444444in"
height="0.20833333333333334in"} is also determined by the upper three
conditions, it is initialized to 1.0:

If the coder type of the previous frame is UNVOICED or the frame class
of the last good received frame is UNVOICED\_CLAS, and there is single
frame loss, then:

![](media/image335.wmf){width="3.013888888888889in"
height="0.2361111111111111in"} (79)

![](media/image336.wmf){width="1.1666666666666667in" height="0.25in"}
(80)

Otherwise if the coder type of the previous frame is UNVOICED or the
frame class of the last good received frame is UNVOICED\_CLAS Then:

![](media/image337.wmf){width="2.75in" height="0.2361111111111111in"}
(81)

![](media/image338.wmf){width="1.1111111111111112in"
height="0.20833333333333334in"} (82)

Otherwise, if there are multiple frame losses, then:

![](media/image339.wmf){width="3.013888888888889in"
height="0.2361111111111111in"} (83)

![](media/image340.wmf){width="1.0138888888888888in"
height="0.20833333333333334in"} (84)

Otherwise then:

![](media/image341.wmf){width="2.75in" height="0.2361111111111111in"}
(85)

![](media/image342.wmf){width="1.1111111111111112in"
height="0.20833333333333334in"} (86)

where ![](media/image343.wmf){width="1.875in"
height="0.20833333333333334in"}are the subframe gains of the current
frame.

The global frame gain of the current frame is calculated with
![](media/image344.wmf){width="0.3194444444444444in"
height="0.20833333333333334in"} and
![](media/image345.wmf){width="0.3888888888888889in"
height="0.2361111111111111in"} described as follows:

![](media/image346.wmf){width="1.0833333333333333in"
height="0.2361111111111111in"} (87)

where the ![](media/image345.wmf){width="0.3888888888888889in"
height="0.2361111111111111in"} is the global frame gain of the previous
frame.

### 5.3.3 Guided concealment and recovery

#### 5.3.3.1 Specifics for rate 24.4 kbps

As described in subclause 5.5.4 of \[5\], the activation flag and
differential pitch lag are transmitted as side information to obtain
better pitch lag estimates and excitation signal for the future frame to
be concealed.

The first 1 bit of the side information is read from the bit-stream
yielding the activation flag. In case the activation flag equals 0, no
further decoding is performed. If the flag equals 1, additional 4 bits
are decoded yielding the differential pitch lag. With 4bits 16 different
states are signalled. 15 states are used to represent the differential
pitch lag, ranging from -7 to 7. The remaining signalling state is used
to signal, that the pitch lag difference was outside the +-7 range on
encoder side.\
In case the pitch lag difference is inside the signalled valid rage of
+-7, the differential pitch lag is added to the pitch lag of the last
sub-frame. The result is used as an initial pitch lag estimate of the
future 1^st^ and 2^nd^ sub-frame. The initial pitch lag estimates are
used as an input to the pitch lag extrapolation procedure described in
subclause 5.3.1.1. If the initial pitch lag estimates are available, the
history of pitch lags used for the pitch extrapolation is updated with
the initial pitch lag estimates. In case the criteria in clause 5.3.1.1
is not met, instead of ![](media/image149.wmf){width="0.53125in"
height="0.25in"}, the initial pitch lag estimate is used for building
the first and second subframe of the adaptive codebook during
concealment .

In case the pitch lag difference indicates that the difference is
outside the valid range of +-7 the pitch extrapolation is performed like
there is no future pitch lag information available in the bitstream.

#### 5.3.3.2 Specifics for rates 9.6, 16.4 and 24.4 kbps

As described in subclause 5.5.5 of \[5\], side information on the
activation of spectral envelope diffuser is transmitted to suppress too
sharp peak at LP spectrum at the decoder side, 1 bit is decoded to
obtain the activation flag. In case the value equals to 1, spectral
envelope diffuser is activated, otherwise de-activated. When spectral
envelope diffuser is active, the following procedure is performed at the
recovery frame.

A modified LSF parameter
![](media/image347.wmf){width="0.34652777777777777in"
height="0.2777777777777778in"} for the previous frame is calculated by
placing the low-order coefficients of the LSF parameter of the concealed
frame ![](media/image348.wmf){width="0.34652777777777777in"
height="0.2777777777777778in"} at equal space.

![](media/image349.wmf){width="1.7916666666666667in"
height="0.4861111111111111in"} (88)

Then the LSF parameter for the current frame is replaced by the sum of
mean vector of the current coder type and the residual LSF vector
obtained in the decoding of the current frame, and bandwidth separation
is applied.

This bandwidth separation is applied to ensure stability and suppress
too sharp peak in LP spectrum. The distances are wider than the distance
used in the normal LSF decoding process. In case the internal sampling
frequency is 12.8 kHz, the distances are as follows:

![](media/image350.wmf){width="2.2083333333333335in"
height="0.7083333333333334in"} (89)

Then, LP coefficients are calculated based on those modified LSF
parameters, and used instead of LP coefficients obtained in the ordinary
decoding process. The procedure for conversion from LSF to LPC is the
same as normal decoding process.

#### 5.3.3.3 Energy control during recovery

Precise control of the speech energy is very important in frame erasure
concealment. The importance of the energy control becomes more evident
when a normal operation is resumed after an erased block of frames.
Since VC and GC modes are heavily dependent on prediction, the actual
energy cannot be properly estimated at the decoder. In voiced speech
segments, the incorrect energy can persist for several consecutive
frames, which can be very annoying, especially when this
incorrect-valued energy increases.

The goal of the energy control is to minimize energy discontinuities by
scaling the synthesized signal to render the energy of the signal at the
beginning of the recovery frame (a first non-erased frame received
following frame erasure) to be similar to the energy of the synthesized
signal at the end of the last frame erased during the frame erasure. The
energy of the synthesized signal in the received first non-erased frame
is further made converging to the energy corresponding to the received
energy parameter toward the end of that frame while limiting an increase
in energy.

If the available bitrate is sufficiently high, the synthesized speech
energy information can be estimated in the encoder and transmitted as a
side information to the decoder. In EVS, the energy information is
transmitted only at 32 and 64 kb/s, using 5 bits. Further, it is
transmitted only in the GC mode. In the TC mode, the energy control is
not needed as the TC mode does not make use of the adaptive codebook,
and memory-less LSF quantization is used. At lower bitrates, the correct
energy is estimated at the decoder.

The energy control for LP-based decoding is triggered in the first
non-erased frame following frame erasure for other than TC modes. At
frames coded at 7.2 and 8 kb/s, in case that this first non-erased frame
is using the Autoregressive (AR) prediction for the LP filter
quantization, the energy control is continued in all subsequent frames
using the AR prediction. The energy control is then maintained in yet
another frame as the synthesis filter can still be affected by the
filter coefficients interpolation.

The energy control is done in the synthesized speech signal domain. Even
if the energy is controlled in the speech domain, it is the LP
excitation signal that is scaled. The synthesis is then repeated to
smooth the transitions.

The energy control in a recovery frame is done as follows. Let
![](media/image351.wmf){width="0.19375in"
height="0.20833333333333334in"} denote the gain used to scale the 1st
sample in the current frame and
![](media/image352.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"} the gain used at the end of the frame.
The excitation signal is then scaled as follows

![](media/image353.wmf){width="2.3055555555555554in"
height="0.20833333333333334in"} (90)

where ![](media/image354.wmf){width="0.3611111111111111in"
height="0.20833333333333334in"} is the scaled excitation,
![](media/image355.wmf){width="0.2916666666666667in" height="0.19375in"}
is the excitation before the scaling,
![](media/image356.wmf){width="0.1388888888888889in"
height="0.1527777777777778in"} is the frame length and
![](media/image357.wmf){width="0.5555555555555556in"
height="0.20833333333333334in"} is the gain starting from
![](media/image351.wmf){width="0.19375in"
height="0.20833333333333334in"} and converging exponentially to
![](media/image352.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"}. That is

![](media/image358.wmf){width="3.6805555555555554in"
height="0.20833333333333334in"} (91)

with the initialization
![](media/image359.wmf){width="0.9027777777777778in"
height="0.20833333333333334in"}. The factor
![](media/image360.wmf){width="0.3611111111111111in"
height="0.20833333333333334in"} is the attenuation factor set to the
value of 0.98. This value has been found experimentally as a compromise
of having a smooth transition from the previous (erased) frame on one
side, and scaling the last pitch period of the current frame as much as
possible to the correct (transmitted) value on the other side. The gains
![](media/image351.wmf){width="0.19375in"
height="0.20833333333333334in"} and
![](media/image352.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"} *are defined as*

![](media/image361.wmf){width="0.7083333333333334in"
height="0.4583333333333333in"} (92)

![](media/image362.wmf){width="0.6388888888888888in"
height="0.4861111111111111in"} (93)

where ![](media/image363.wmf){width="0.2638888888888889in"
height="0.20833333333333334in"} is the energy computed at the end of the
previous (erased) frame, ![](media/image364.wmf){width="0.19375in"
height="0.20833333333333334in"} is the energy at the beginning of the
current (recovered) frame,
![](media/image365.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"} is the energy at the end of the current
frame, and ![](media/image366.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"} is the target energy at the end of the
current frame. At higher
bitrates,![](media/image366.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"}is computed at the encoder, quantized and
transmitted. The energy information is quantized using a 5-bit linear
quantizer in the range of 0 dB to 96 dB with a step of 3 dB. The
quantization index is given by

![](media/image367.wmf){width="1.4861111111111112in"
height="0.4583333333333333in"} (94)

The index is limited to the range \[0, 31\]. At lower bitrates,
![](media/image366.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"} is estimated at the decoder.

The energy ![](media/image365.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"} of the synthesized speech
![](media/image368.wmf){width="0.44375in" height="0.2777777777777778in"}
at the end of the first non erased frame is first computed as follows.
The energy is the maximum of the signal energy for frames classified as
VOICED\_CLAS or ONSET, or the average energy per sample for all other
frames. For VOICED\_CLAS or ONSET frames, the maximum signal energy is
computed pitch-synchronously at the end of the current frame as follows:

![](media/image369.wmf){width="2.5555555555555554in"
height="0.2777777777777778in"} (95)

where *L* is the frame length at internal sampling rate. Signal
![](media/image368.wmf){width="0.44722222222222224in"
height="0.28125in"} is the local synthesis signal sampled at the
internal sampling rate. The integer pitch period length
![](media/image370.wmf){width="0.3229166666666667in"
height="0.20833333333333334in"}is the rounded pitch period of the last
subframe, i.e.
$T^{\text{end}} = \left\lfloor d_{\text{fr}}^{\left\lbrack \text{last} \right\rbrack} + 0\text{.}5 \right\rfloor$.

For all other classes,
![](media/image365.wmf){width="0.17708333333333334in"
height="0.20833333333333334in"} is the average energy per sample of the
last half of the current frame, i.e.

$E_{1} = \frac{1}{\frac{L}{2}}\sum_{n = \frac{L}{2}}^{L - 1}{\hat{s}}_{1}^{2}\left( n \right)$.
(96)

![](media/image363.wmf){width="0.2638888888888889in"
height="0.20833333333333334in"} is computed similarly using the
synthesized speech signal of the previous (last erased) frame. When
![](media/image363.wmf){width="0.2638888888888889in"
height="0.20833333333333334in"} is computed pitch synchronously (i.e. if
the class of the previous frame was VOICED\_CLAS or ONSET), it uses the
concealment pitch period
![](media/image371.wmf){width="0.16666666666666666in"
height="0.20833333333333334in"}.

When ![](media/image364.wmf){width="0.19375in"
height="0.20833333333333334in"} is computed pitch synchronously (the
class of the current frame is VOICED\_CLAS or ONSET), it is done
similarly using the rounded pitch value
![](media/image372.wmf){width="0.2638888888888889in"
height="0.20833333333333334in"} of the first subframe:

![](media/image373.wmf){width="2.0965277777777778in"
height="0.2777777777777778in"} (97)

For other frame classes:

$E_{0} = \frac{1}{\frac{L}{2}}\sum_{n = 0}^{(\frac{L}{2}) - 1}{\hat{s}}_{\text{pre}}^{2}\left( n \right)$.
(98)

As mentioned previously,
![](media/image366.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"}is transmitted from the encoder, but only
at high bitrates. If
![](media/image366.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"} is not available, it is initialized to
![](media/image365.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"} and further limited as described below.

The gains ![](media/image351.wmf){width="0.19375in"
height="0.20833333333333334in"} and
![](media/image352.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"}are further limited to a maximum allowed
value to prevent too strong energy. This value has been set to 1.2 with
the exception of very low energy frames
(![](media/image366.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"} \< 1.1). In this case,
![](media/image352.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"} is limited to 1. If
![](media/image366.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"} is not transmitted, further precautions
shall be taken because of the possible mismatch between the excitation
signal energy and the LP filter gain.

At 7.2 or 8 kb/s, this is done by upper-limiting the energy
![](media/image366.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"} by a value $E_{1\text{max}}$, scaled by a
factor $\alpha_{E_{1}}$.

In the recovery frame or in the scaled frames following the recovery
frame coded by the GC mode using AR prediction,
$\alpha_{E_{1}} = 1\text{.}5$ and $E_{1\text{max}} = E_{- 1}$if the
following conditions are met: 1) the end-frame LP filter is resonant in
low frequencies (measured by means of the filter tilt), and 2) the
evolution of the transmitted pitch is stable within the frame or the
mean of the pitch value over all subframes is lower than 34 samples. In
the remaining scaled frames following the recovery frame, the scaling
factor $\alpha_{E_{1}} = 2$ and $E_{1\text{max}}$ equals to the larger
value between $E_{- 1}$ and an average energy of recent voiced frames
${\overline{E}}_{1}$. If $E_{1}$ is computed pitch synchronously,
${\overline{E}}_{1}$is the running average of pitch-synchronous energy
of previous frames. If $E_{1}$ is computed as average energy per sample,
${\overline{E}}_{1}$ is the running average of average energy per sample
of of previous frames. For other bitrates, when the erasure occurs
during a voiced speech segment (i.e. the last good frame before the
erasure and the first good frame after the erasure are classified as
VOICED TRANSITION, VOICED\_CLAS or ONSET) and the LP filter impulse
response energy of the first frame after an erasure is twice as high as
the LP filter impulse response energy of the last frame before the
erasure, the energy of the excitation is adjusted to the gain of the new
LP filter as follows:

![](media/image374.wmf){width="0.94375in"
height="0.4166666666666667in"}. (99)

Here![](media/image375.wmf){width="0.3333333333333333in"
height="0.20833333333333334in"} is the energy of the LP filter impulse
response of the last good frame before the erasure and
![](media/image376.wmf){width="0.3194444444444444in"
height="0.20833333333333334in"} is the energy of the LP filter of the
first good frame after the erasure. The LP filters of the last subframes
are used. Further, if
![](media/image377.wmf){width="0.5694444444444444in"
height="0.2361111111111111in"}
(![](media/image366.wmf){width="0.20833333333333334in"
height="0.2361111111111111in"}already initialized to
![](media/image378.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"}), it is further limited as follows:

![](media/image379.wmf){width="1.2083333333333333in"
height="0.2361111111111111in"} (100)

At 9.6 and 13.2 kb/s, there is however one exception to this energy
scaling strategy if the LP filter is found resonant in low frequencies
and the frame is classified as UNVOICED\_CLAS or INACTIVE\_CLAS. This
situation indicates a possible error in the classification and the
energy is scaled as in the case of the 7.2 or 8 kb/s recovery frame.

The following exceptions, all related to transitions in speech signal of
good frames following an erasure, further overwrite the computation of
![](media/image351.wmf){width="0.19375in"
height="0.20833333333333334in"}. If artificial onset is used in the
current frame, ![](media/image351.wmf){width="0.19375in"
height="0.20833333333333334in"} is set to
![](media/image380.wmf){width="0.34652777777777777in"
height="0.20833333333333334in"}, to make the onset energy increase
gradually. In the case of a first good frame after an erasure is
classified as ONSET, the gain ![](media/image351.wmf){width="0.19375in"
height="0.20833333333333334in"} is prevented from being higher than
![](media/image352.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"}. This precaution is taken to prevent a
positive gain adjustment at the beginning of the frame from amplifying
the voiced onset at the end of the frame. *Finally, during a transition
from voiced to unvoiced (i.e. the last good frame being classified as
VOICED TRANSITION, VOICED*\_CLAS *or ONSET and the current frame being
classified UNVOICED*\_CLAS*) or during a transition from a non-active
speech period to an active speech period, the value of*
![](media/image351.wmf){width="0.19375in"
height="0.20833333333333334in"} *is set to*
![](media/image352.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"}*.*

Additionally, the synthesis energy control is performed also in the
erased frames following frames coded at 7.2 or 8 kb/s or using the
AMR-WB IO mode. Here the energy control is simpler in the sense that it
is just verified that the gain is not increasing. Energies $E_{- 1}$,
$E_{0}$ and $E_{1}$ are computed similarly as in the recovery frames,
but $E_{- 1}$ is used instead of $E_{q}$, and the gains
![](media/image351.wmf){width="0.19375in"
height="0.20833333333333334in"} and
![](media/image352.wmf){width="0.18055555555555555in"
height="0.20833333333333334in"} *are limited to 1.*

After the energy control, the speech signal is resynthesized by
filtering the scaled excitation signal through the LP synthesis filter.
The running energy average ${\overline{E}}_{1}$ is finally updated in
good voiced frames as
${0\text{.}\text{05}E_{q} + 0\text{.}\text{95\ \{}\overline{E}}_{1}$
with initializion to $E_{q}$.

#### 5.3.3.4 Specifics for rates 32 and 64 kbps

##### 5.3.3.4.1 Adaptive codebook resynchronization and fast recovery (WB)

Fast recovery is an approach where side information with some bit rate
overhead is transmitted to arrest error propagation into future frames,
thereby improving performance under frame erasures. Side information
includes parameters like energy, frame classification information
and phase information. Specifically, the phase side information is used
to align the glottal pulse position at the decoder to that of the
encoder thereby synchronizing the adaptive codebook content. The
information on the lost frame which becomes available on receiving the
future frame is used to correct the excitation (pitch) memory before
synthesizing the correctly received future frame. This helps to
significantly contain the error propagation into future frames and
improves decoder convergence when good frames are received after the
erased frame. The waveform interpolation technique (\[5\], clause 5.2.3)
is used to avoid abrupt changes in the pitch contour between the error
concealed lost frame and the memory corrected future frame.

###### 5.3.3.4.1.1 Decoding glottal pulse position

The glottal pulse position information consists of the position in the
past, ![](media/image381.wmf){width="0.125in"
height="0.1388888888888889in"}, of the absolute maximum pulse from the
beginning of the current frame and its sign. If the first decoded pitch
of the current frame is smaller then 128, the received quantized
position![](media/image381.wmf){width="0.125in"
height="0.1388888888888889in"} is used as is, else the received
quantized position ![](media/image382.wmf){width="0.125in"
height="0.1388888888888889in"}is multiplied by 2.

###### 5.3.3.4.1.2 Performing glottal pulse resynchronization

The goal of the resynchronization is to correct the difference between
the target transmitted position of the last glottal pulse in the
adaptive codebook of the current frame, and its actual position in the
concealed adaptive codebook excitation signal. The position T(0) of the
maximum pulse in the concealed adaptive excitation, *u(n)*, from the
beginning of the frame is determined as described in the previous
subclause. If the decoded maximum pulse position is positive, then the
maximum positive pulse in the concealed adaptive codebook excitation
from the beginning of the frame is determined. If the decoded maximum
pulse position is negative, the maximum negative pulse is determined.

The target position of the absolute maximum pulse with respect to the
beginning of the current frame is given by:

![](media/image383.wmf){width="0.8333333333333334in"
height="0.20833333333333334in"} (101)

where ![](media/image384.wmf){width="0.125in"
height="0.1388888888888889in"} has been defined as a decoded pulse or
estimated as done in subclause 7.11.2.5.2. The error in the pulse
position of the last concealed pulse in the frame is found by searching
for the pulse ![](media/image385.wmf){width="0.2777777777777778in"
height="0.20833333333333334in"} closest to the actual pulse,
![](media/image386.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"}. The error is given by:

![](media/image387.wmf){width="0.9861111111111112in"
height="0.20833333333333334in"} (102)

where ![](media/image388.wmf){width="0.125in"
height="0.18055555555555555in"} is the index of the pulse closest to
![](media/image389.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"} and
![](media/image390.wmf){width="0.16666666666666666in"
height="0.20833333333333334in"}the difference between the actual pulse
and the closest one. If
![](media/image391.wmf){width="0.4027777777777778in"
height="0.20833333333333334in"}, then no resynchronization is required.
If ![](media/image392.wmf){width="0.3888888888888889in"
height="0.20833333333333334in"} then
![](media/image393.wmf){width="0.16666666666666666in"
height="0.20833333333333334in"} samples need to be inserted. If
![](media/image394.wmf){width="0.3888888888888889in"
height="0.20833333333333334in"}, then
![](media/image395.wmf){width="0.16666666666666666in"
height="0.20833333333333334in"} samples need to be removed. Further, the
resynchronization is performed only if
![](media/image396.wmf){width="0.44375in"
height="0.20833333333333334in"} and
![](media/image397.wmf){width="0.9166666666666666in"
height="0.2361111111111111in"}, where
![](media/image398.wmf){width="0.3055555555555556in"
height="0.2361111111111111in"} is the absolute difference between
![](media/image399.wmf){width="0.16666666666666666in"
height="0.20833333333333334in"} and the pitch lag of the first subframe
in the future frame, or its extrapolated value if it is not available.

The samples that need to be added or deleted are distributed across the
pitch cycles in the frame. The minimum energy regions in the different
pitch cycles are determined and the sample deletion or insertion is
performed in those regions. The number of pitch pulses in the frame is
![](media/image400.wmf){width="0.2361111111111111in"
height="0.2361111111111111in"} at
positions![](media/image401.wmf){width="1.2222222222222223in"
height="0.2361111111111111in"}. The number of minimum energy regions is
![](media/image402.wmf){width="0.4305555555555556in"
height="0.2361111111111111in"}. If Tc ≤ 128, there shall be at least 2
minimum energy regions in the current frame. The minimum energy regions
are determined by computing the energy using a sliding 5-sample window.
The minimum energy position is set at the middle of the window at which
the energy is at a minimum. The search performed between two pitch
pulses at position ![](media/image403.wmf){width="0.2777777777777778in"
height="0.20833333333333334in"} and
![](media/image404.wmf){width="0.4583333333333333in"
height="0.20833333333333334in"} is restricted between
![](media/image405.wmf){width="0.69375in"
height="0.20833333333333334in"} and
![](media/image406.wmf){width="0.875in" height="0.20833333333333334in"}.

The sample deletion or insertion is performed around
![](media/image407.wmf){width="0.4583333333333333in"
height="0.20833333333333334in"}, where
![](media/image408.wmf){width="1.4861111111111112in"
height="0.20833333333333334in"} are the minimum positions described
above and ![](media/image409.wmf){width="0.8888888888888888in"
height="0.2361111111111111in"} is the number of minimum energy regions.
The samples to be added or deleted are distributed across the different
pitch cycles as follows.

If ![](media/image410.wmf){width="0.5416666666666666in"
height="0.20833333333333334in"}, then there is only one minimum energy
region and all samples
![](media/image411.wmf){width="0.16666666666666666in"
height="0.20833333333333334in"} are inserted or deleted at
![](media/image412.wmf){width="0.4861111111111111in"
height="0.20833333333333334in"}.

For ![](media/image413.wmf){width="0.5416666666666666in"
height="0.20833333333333334in"}, a simple algorithm is used to determine
the number of samples to be added or removed at each pitch cycle whereby
less samples are added/removed at the beginning and more towards the end
of the frame. If the total number of pulses to be removed/added is
![](media/image414.wmf){width="0.16666666666666666in"
height="0.20833333333333334in"}, and the number of minimum energy
regions is ![](media/image415.wmf){width="0.34652777777777777in"
height="0.20833333333333334in"}, the number of samples to be
removed/added per pitch cycle,
![](media/image416.wmf){width="1.3194444444444444in"
height="0.20833333333333334in"}, is found using the following recursive
relation:

![](media/image417.wmf){width="2.0555555555555554in"
height="0.5416666666666666in"} (103)

where ![](media/image418.wmf){width="0.6805555555555556in"
height="0.44375in"}.

Note that at each stage, if
![](media/image419.wmf){width="0.8465277777777778in"
height="0.20833333333333334in"} then the values of
![](media/image420.wmf){width="0.2777777777777778in"
height="0.20833333333333334in"} and
![](media/image421.wmf){width="0.4583333333333333in"
height="0.20833333333333334in"} are interchanged. The values
![](media/image422.wmf){width="0.2777777777777778in"
height="0.20833333333333334in"} correspond to pitch cycles starting from
the beginning of the frame.
![](media/image423.wmf){width="0.3055555555555556in" height="0.19375in"}
corresponds to ![](media/image424.wmf){width="0.4861111111111111in"
height="0.20833333333333334in"},
![](media/image425.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"} corresponds to
![](media/image426.wmf){width="0.4583333333333333in"
height="0.20833333333333334in"}, ...,
![](media/image427.wmf){width="0.7361111111111112in"
height="0.20833333333333334in"} corresponds to
![](media/image428.wmf){width="0.9166666666666666in"
height="0.20833333333333334in"}. Since
![](media/image429.wmf){width="0.2777777777777778in"
height="0.20833333333333334in"} are in increasing order, more samples
are added/removed towards the cycles at the end of the frame.

Removing samples is straightforward. Adding samples is performed by
copying the last ![](media/image430.wmf){width="0.2777777777777778in"
height="0.20833333333333334in"} samples after dividing by 20 and
inverting the sign. For example, if 5 samples need to be inserted at
position![](media/image431.wmf){width="0.4861111111111111in"
height="0.20833333333333334in"}, the following is performed:

![](media/image432.wmf){width="2.4166666666666665in"
height="0.20833333333333334in"} (104)

Using the above procedure, the last maximum pulse in the concealed
adaptive codebook excitation is forced to be aligned with the actual
maximum pulse position at the end of the adaptive codebook frame which
is transmitted in the current frame.

##### 5.3.3.4.2 Artificial onset reconstruction

If the frame is classified as ARTIFICIAL ONSET, it means that the lost
frame probably contained a voice onset, and the transition mode has not
taken care of it (e.g., several consecutive frames were erased,
containing the voiced onset frame, but also the following frame usually
coded with TC mode). If the position of the glottal pulse of the
previous frame is in the bitstream of the first good frame (i.e. 32 and
64 kbps), the onset is reconstructed artificially inside the adaptive
codebook.

The lost onset case is the most complicated situation related to the use
of the long-term prediction in CELP decoding. The lost onset means that
the voiced speech onset happened somewhere during the erased block. In
this case, the last good received frame was unvoiced and thus no
periodic excitation is found in the excitation buffer. The first good
frame after the erased block is however voiced, the excitation buffer at
the encoder is highly periodic and the adaptive excitation has been
encoded using this periodic past excitation. As this periodic part of
the excitation is completely missing at the decoder, it can several
frames to recover from this loss. It is worth emphasizing that this
problem does not occur in the EVS codec for single frame erasures, as
the frames following frames with voiced onsets are generally coded with
TC mode and, TC mode does not make use of inter-frame long-term
prediction.

If an ONSET frame is lost (i.e. a VOICED\_CLAS good frame arrives after
an erasure), but the last good frame before the erasure was
UNVOICED\_CLAS, a special technique is used to artificially reconstruct
the lost onset and to trigger the voiced synthesis. The position of the
last glottal pulse in the concealed frame can be available from the
first good frame after the erase (in case the phase information related
to the previous frame is transmitted in the bitstream). The artificial
onset reconstruction does not affect the concealment of the erased
frame; it is only matter of recovery. However, the last pulse of the
erased frame is artificially reconstructed based on the position and
sign information available in the first good frame after the erasure.
This information consists of the position,
![](media/image433.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"}, of the maximum pulse from the end of
the frame and its sign. The last glottal pulse in the erased frame is
thus constructed as a low-pass filtered pulse placed in the memory of
the adaptive excitation buffer (previously initialized to zero), and
centred at the decoded position,
![](media/image434.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"}. If the pulse sign is positive, the
low-pass filter used is a simple linear phase FIR filter with the
impulse response![](media/image435.wmf){width="2.5881944444444445in"
height="0.2125in"}. If the pulse sign is negative, the low-pass filter
used is a linear phase FIR filter with the impulse
response![](media/image436.wmf){width="0.3638888888888889in"
height="0.2125in"}.

Placing the low-pass filtered glottal pulse at the proper position at
the end of the concealed frame significantly improves the performance of
the consecutive good frames and accelerates the decoder convergence to
actual decoder states.

The energy of the periodic part of the artificial onset excitation is
then scaled by the gain corresponding to the quantized and transmitted
energy *E~q~*, as described in subclause 5.3.3.3, for frame erasure
concealment and divided by the gain of the LP synthesis filter.

![](media/image437.wmf){width="1.0694444444444444in"
height="0.4861111111111111in"} (105)

The LP synthesis filter gain being computed as:

![](media/image438.wmf){width="1.0555555555555556in"
height="0.5694444444444444in"} (106)

where ![](media/image439.wmf){width="0.29305555555555557in"
height="0.2125in"} is the LP synthesis filter impulse response. Finally,
the artificial onset gain is reduced by multiplying the periodic part by
0.96.

The LP filter for the output speech synthesis is not interpolated in the
case of an artificial onset construction. Instead, the received LP
parameters are used for the synthesis of the whole frame.

### 5.3.4 Handling of multiple frame losses and muting

#### 5.3.4.1 Specifics for rates 5.9, 6.8, 8.0, 13.2, 32 and 64 kbps

The principal of attenuation in case of packet lost has been introduced
in subclause 5.3.1. However, there are exceptions to the general case.
The following three exceptions based on the last good frame coding mode
that take precedence over table below. All apply only up to 3
consecutive lost frames. First, if the last good received frame is coded
with UC mode, α is set to 1. Second, if the last good received frame is
coded with VC or is an ONSET, α is set to 1.0. Finally, A stability
factor, θ, is computed based on a distance measure between the adjacent
LP filters. Here, the factor, θ, is related to the LSF distance measure
and it is bounded by 0 ≤ θ ≤ 1, with larger values of θ corresponding to
more stable signals. This limits energy and spectral envelope
fluctuations when an isolated frame erasure occurs inside a stable
unvoiced segment. Note that the class ARTIFICIAL ONSET is set at the
decoder if the frame follows an erased frame and artificial onset
reconstruction is used as described in subclause 5.3.3.4.2 at bit rate
32 and 64 kbps.

The signal classification is implicit for VC, UC and TC frames. Further,
more precise classification can be decoded from the bitstream depending
of the bit rate.

Table 7: Values of the PLC attenuation factor α

+---------------------+------------------------------------+--------------+
| Last good received\ | Number of successive erased frames | *α*          |
| frame               |                                    |              |
+---------------------+------------------------------------+--------------+
| ARTIFICIAL ONSET    |                                    | 0.6          |
+---------------------+------------------------------------+--------------+
| ONSET, VOICED\_CLAS | ≤ 3                                | 1.0          |
+---------------------+------------------------------------+--------------+
|                     | \> 3                               | 0.4          |
+---------------------+------------------------------------+--------------+
| VOICED TRANSITION   |                                    | 0.4          |
+---------------------+------------------------------------+--------------+
| UNVOICED TRANSITION |                                    | 0.8          |
+---------------------+------------------------------------+--------------+
| UNVOICED\_CLAS      | = 1                                | 0.2*θ* + 0.8 |
+---------------------+------------------------------------+--------------+
|                     | = 2                                | 0.6          |
+---------------------+------------------------------------+--------------+
|                     | \> 2                               | 0.4          |
+---------------------+------------------------------------+--------------+
| AUDIO \|\| INACTVE  | \>1                                | 0.8          |
|                     |                                    |              |
|                     | if GSC had temporal contribution   |              |
+---------------------+------------------------------------+--------------+
|                     | \<=5                               | 0.995        |
+---------------------+------------------------------------+--------------+
|                     | \>5                                | 0.95         |
+---------------------+------------------------------------+--------------+

#### 5.3.4.2 Specifics for rates 9.6, 16.4 and 24.4 kbps

##### 5.3.4.2.1 Fading to background level

The innovative as well as the harmonic excitation fade to individual
target levels by changing the codebook gains.

![](media/image440.wmf){width="2.321527777777778in"
height="0.3020833333333333in"} (107)

where: ![](media/image441.wmf){width="0.2916666666666667in"
height="0.3020833333333333in"} is the gain of the current frame;

![](media/image442.wmf){width="0.40625in" height="0.3020833333333333in"}
is the gain of the previous frame;

![](media/image443.wmf){width="0.40625in" height="0.25in"} is the target
gain;

![](media/image444.wmf){width="0.375in" height="0.19791666666666666in"}
is the fading factor, its derivation is outlined in subclause 5.3.4.2.3.

The fading is performed as follows:

$\text{sig}_{\text{faded}}\lbrack i\rbrack = \left( g^{\lbrack m - 1\rbrack} - \frac{i}{L_{\text{frame}}}\left( g^{\lbrack m - 1\rbrack} - g^{\lbrack m\rbrack} \right) \right) \cdot \text{sig}\lbrack i\rbrack,i = 0\ldots L_{\text{frame}} - 1$
(107a)

Where $\text{sig}\lbrack i\rbrack$ is the input signal, e.g. the
harmonic or the innovative excitation, and
$\text{sig}_{\text{faded}}\lbrack i\rbrack$ is the faded output signal.

The harmonic excitation is faded towards zero:
![](media/image445.wmf){width="0.6145833333333334in"
height="0.3020833333333333in"}.

The innovative excitation is faded towards a target background noise
level: ![](media/image446.wmf){width="0.7916666666666666in"
height="0.3333333333333333in"}. It is derived during the first lost
frame based on the background noise spectrum derived by CNG during clean
channel decoding (see clause 4.3 of \[5\]). Its derivation is performed
as follows:

a\) Derive target level in time domain based on background noise
spectrum ![](media/image447.wmf){width="0.34375in"
height="0.20833333333333334in"}:

![](media/image448.wmf){width="1.613888888888889in"
height="0.5722222222222222in"} (108)

b\) Compensate gain of LPC synthesis / de-emphasis (see also subsection
5.2.5):

$g^{\text{cng}} = g^{\text{cng}} \cdot \frac{1}{n_{\text{subfr}}} \cdot \sum_{i = 0}^{n_{\text{subfr}}\text{-1}}\text{energ}_{\text{LPC}}^{\left\lbrack i \right\rbrack}$
(109)

where $\text{energ}_{\text{LPC}}^{\left\lbrack i \right\rbrack}$ is
derived subframe-wise as stated in equation (26).

##### 5.3.4.2.2 Fading to background spectral shape

Separate LPCs are applied for the innovative and the harmonic excitation
as described in subclause 5.3.1. The innovative and the harmonic
excitations are faded to individual target spectral shapes by altering
the LPC coefficients. The fading from the last good LPC coefficients to
the target LPC coefficients is performed in the LSF domain as follows:

![](media/image449.wmf){width="2.375in" height="0.25in"} (110)

where: ![](media/image450.wmf){width="0.3055555555555556in"
height="0.3055555555555556in"} are LPC coefficients in the LSF domain of
the current frame;

![](media/image451.wmf){width="0.4027777777777778in"
height="0.3055555555555556in"} are LPC coefficients in the LSF domain of
the previous frame;

![](media/image452.wmf){width="0.4166666666666667in" height="0.25in"}
are the target LPC coefficients;

> ![](media/image453.wmf){width="0.375in" height="0.19375in"} is the
> fading factor as described in subclause 5.3.4.2.3. In case of the
> innovative excitation, ![](media/image453.wmf){width="0.375in"
> height="0.19375in"} will be minimal 0.8.

The target spectral shape of the harmonic excitation is the short term
mean of the last three LPC coefficient sets. Its derivation is performed
in the LSF domain as follows:

![](media/image454.wmf){width="2.0965277777777778in"
height="0.4305555555555556in"} (111)

The target spectral shape of the innovative excitation is derived during
the first lost frame based on the background noise spectrum derived by
CNG during clean channel decoding (see 4.3 of \[5\]). Its derivation is
performed as follows:

a\) Compute power spectrum on the background noise spectrum.

b\) Apply an inverse Fourier transform with length 640 on the power
spectrum to obtain the autocorrelation values
![](media/image455.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"}with
![](media/image456.wmf){width="0.5833333333333334in"
height="0.18055555555555555in"}.

c\) Do a normalisation of
![](media/image455.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"} to obtain
![](media/image457.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"}, if
![](media/image458.wmf){width="0.625in"
height="0.20833333333333334in"}set
![](media/image459.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"}to 100 and multiply
![](media/image460.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"} by 1.0005.

d\) Execute the Levinson-Durbin algorithm with the order 16 to obtain
the LP parameters from
![](media/image457.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"}.

e\) Finally, transform the LPC coefficients to the LSF domain to obtain
![](media/image461.wmf){width="0.4583333333333333in" height="0.25in"}

##### 5.3.4.2.3 Fading speed

The damping factor ![](media/image462.wmf){width="0.375in"
height="0.20833333333333334in"} controls the fading speed of the
innovative and the harmonic excitation and depends on a bunch of
parameters. These are: the number of consecutive lost frames, the LSF
stability factor ![](media/image463.wmf){width="0.125in"
height="0.16666666666666666in"}, the coder type, the class of the last
good frame, the pitch gain
![](media/image464.wmf){width="0.2222222222222222in"
height="0.2361111111111111in"} and the current coding mode. With this
set of parameters the damping factor is determined as follows:

\- Firstly, if current coding mode is ACELP\_CORE, then

\- in case the coder type is UNVOICED and the number of consecutive lost
frames is maximally three, then ![](media/image462.wmf){width="0.375in"
height="0.20833333333333334in"}is set to 1

\- else if the last good frame was UNVOICED\_CLAS and

\- if it is the first lost frame, then
![](media/image465.wmf){width="1.1527777777777777in"
height="0.20833333333333334in"}

\- else if exactly two frames are lost,
then![](media/image466.wmf){width="0.69375in"
height="0.20833333333333334in"}

\- otherwise, if three or more frames are lost,
then![](media/image467.wmf){width="0.69375in"
height="0.20833333333333334in"}

\- else if the last good frame was UNVOICED\_TRANSITION,
then![](media/image468.wmf){width="0.69375in"
height="0.20833333333333334in"}

\- else if the last good frame was ONSET and number of lost frames are
maximally three and the coder type is GENERIC,
then![](media/image469.wmf){width="0.69375in"
height="0.20833333333333334in"}

\- else if the last good frame was either VOICED\_CLAS or the last good
frame was ONSET and the number of lost frames is maximally three,
then![](media/image470.wmf){width="0.5694444444444444in"
height="0.20833333333333334in"}

\- otherwise, ![](media/image471.wmf){width="0.69375in"
height="0.20833333333333334in"}

\- besides that, if the last good frame was not one out of the set of {
UNVOICED\_CLAS, UNVOICED\_TRANSITION, VOICED\_TRANSITION }, then

\- in case it is the first erased frame, then
![](media/image472.wmf){width="1.2222222222222223in"
height="0.2916666666666667in"}, whereas
![](media/image473.wmf){width="0.34652777777777777in"
height="0.2916666666666667in"}is limited from 0.85 to 0.98

\- else if the number of lost frames are exactly two, then
![](media/image474.wmf){width="1.5694444444444444in"
height="0.2361111111111111in"}

\- otherwise, if more than two frames are consecutive lost, then the
pitch of gain is changed to the new gain
![](media/image475.wmf){width="1.375in" height="0.2361111111111111in"}
and following the damping factor is calculated
as![](media/image476.wmf){width="1.0965277777777778in"
height="0.2361111111111111in"}

\- Otherwise, if current coding mode is not ACELP\_CORE and

\- if it is the first lost frame, then
![](media/image477.wmf){width="1.1527777777777777in"
height="0.20833333333333334in"}

\- else if exactly two frames are lost,
then![](media/image478.wmf){width="1.2222222222222223in"
height="0.20833333333333334in"}

\- otherwise, if three or more frames are lost,
then![](media/image479.wmf){width="1.2222222222222223in"
height="0.20833333333333334in"}

5.4 Concealment operation related to MDCT modes
-----------------------------------------------

### 5.4.1 PLC method selection

There is a multitude of PLC methods for MDCT coding modes available.
Best possible codec performance in error-prone situations with frame
losses is obtained through selecting the most suitable method for a
given bit rate, coded audio bandwidth, used MDCT mode and signal class.

The main selector is the MDCT mode of the previous frame, i.e. TCX MDCT
or HQ MDCT. Second level criteria are described in the following
subclauses.

### 5.4.2 TCX MDCT

#### 5.4.2.1 PLC method selection

In case the last good frame prior to a loss was coded with the MDCT
based TCX, a range of different specifically optimized PLC methods are
available that are selected based on second level criteria described in
this subclause. The PLC methods are:

\- TCX time domain concealment

\- MDCT frame repetition with sign scrambling

\- tonal MDCT concealment using phase prediction

\- non-tonal concealment with waveform adjustment

The criteria evaluated in this second level PLC method selection are

\- Last MDCT mode: The MDCT mode of the last good frame
![](media/image480.wmf){width="0.53125in"
height="0.17708333333333334in"} is obtained by decoding the bitstream in
every good frame.

\- Number of consecutively lost frames: The number of consecutively lost
frames is increased in case of a frame loss and is reset in a good
received frame.

\- Last unmodified LTP gain: If LTP information is updated in the last
good frame, the variable
![](media/image481.wmf){width="0.9888888888888889in"
height="0.20833333333333334in"} contains the LTP gain, and otherwise it
is zero.

\- Tonal MDCT peak detection flag: The flag
![](media/image482.wmf){width="0.9680555555555556in"
height="0.17708333333333334in"} describes whether tonal MDCT concealment
using phase prediction should be done. It is set to zero by default and
remains zero if one of the following conditions is true:

\- the last core or the second last core is not mode TCX20

\- the last unmodified LTP gain is bigger than 0.4 and the last pitch is
bigger than ![](media/image483.wmf){width="0.29097222222222224in"
height="0.17708333333333334in"}

\- the last pitch differs from the second last pitch

\- TNS was active in the last or second last frame

Otherwise, ![](media/image482.wmf){width="0.9680555555555556in"
height="0.17708333333333334in"} is set to one if the output of the peak
detection of tonal components (see subclause 5.4.2.4.2) matches one of
the following criteria:

\- the number of found peaks is higher than 10; or

\- the number of found peaks is higher than 5 and the difference between
the 3^rd^ and 2^nd^ last pitch is smaller than 0.5 or

\- at least one peak is found and the last good frame was either
UNVOICED\_TRANSITION or UNVOICED\_CLAS and the difference between the
3^rd^ and 2^nd^ last pitch is smaller than 0.5 and the last unmodified
LTP gain is ![](media/image484.wmf){width="0.40625in"
height="0.16666666666666666in"}.

\- Flag enabling non-tonal concealment with waveform adjustment: The
flag ![](media/image485.wmf){width="1.2597222222222222in"
height="0.20833333333333334in"} is set to one if the bit rate is one out
of the set of {48 kbps, 96 kbps, 128 kbps}.

\- Intelligent gap filling:\
The intelligent gap filling flag
![](media/image486.wmf){width="0.23958333333333334in"
height="0.20833333333333334in"}describes whether intelligent gap filling
is active (1) or not (0) (see subclause 5.4.2.6).

\- TCX\_Tonality flag array:\
array of tonality flags of the last ten received frames (see subclause
5.4.5.3a).

The decision logic of the different PLC methods is done with the
criteria shown above. The selection of the PLC is performed only in the
first lost frame after a good frame and pertained in subsequently lost
frames.

**TCX time domain concealment** is selected if:

\- ![](media/image482.wmf){width="0.9722222222222222in"
height="0.18055555555555555in"}flag is zero; and

> \- ![](media/image487.wmf){width="0.5277777777777778in"
> height="0.18055555555555555in"} is TCX\_CORE and
> ![](media/image488.wmf){width="1.3055555555555556in"
> height="0.20833333333333334in"}and the last good frame was neither
> UNVOICED\_TRANSITION nor UNVOICED\_CLAS.

In all other cases, the three MDCT-based concealment methods are
selected as described below.

**MDCT frame repetition with sign scrambling** is selected if:

\- ![](media/image489.wmf){width="0.9680555555555556in"
height="0.17708333333333334in"} is one (in conjunction with tonal MDCT
concealment using phase prediction); or

\- ![](media/image489.wmf){width="0.9722222222222222in"
height="0.18055555555555555in"} is zero and non-tonal concealment with
waveform adjustment is not active.

**Tonal MDCT Concealment using phase prediction** is selected if:

\- ![](media/image490.wmf){width="0.9722222222222222in"
height="0.18055555555555555in"} is one

**Non-tonal concealment with waveform adjustment** is selected if:

\- ![](media/image491.wmf){width="1.2638888888888888in"
height="0.20833333333333334in"} is one,
![](media/image489.wmf){width="0.9722222222222222in"
height="0.18055555555555555in"}is zero and there is no transition having
a larger frame size than a normal TCX20 frame; and

\- the lost frame is considered to be a non-tonal frame, which requires
that the TCX\_Tonality flag array contains five or less ones or one out
of the last three frames is not TCX20.

If a MDCT-based PLC mode is selected and
![](media/image492.wmf){width="0.2361111111111111in"
height="0.20833333333333334in"}is one, some missing information are
added with the intelligent gap filling concealment.

#### 5.4.2.2 TCX time domain concealment

The time domain PLC for TCX is called if the core of the last good frame
was TCX and if in the PLC method selection as describe in subclause
5.4.2.1 the TCX time domain concealment was chosen. This concealment
method has some similarity to the ACELP like concealment described in
subclause 5.3.1. Due to the fact, that this method is operating in the
excitation domain to shape the noise towards the vocal tract and
preventing discontinuities, a local LPC analysis is applied to the
synthesized time domain signal
![](media/image493.wmf){width="0.4722222222222222in"
height="0.20833333333333334in"} of the last frame. To improve the LPC
analysis, first the ![](media/image494.wmf){width="0.4722222222222222in"
height="0.20833333333333334in"} signal is filtered with the pre-emphasis
filter described in subclause 5.1.3 of \[5\] to obtain
![](media/image495.wmf){width="0.6527777777777778in"
height="0.2361111111111111in"}. After that, an LPC analysis is applied
on ![](media/image496.wmf){width="0.6527777777777778in"
height="0.2361111111111111in"} same as in subclause 5.1.5 of \[5\], but
with the frame
length![](media/image497.wmf){width="0.1388888888888889in"
height="0.1527777777777778in"}and the analysis window, which first
three-quarter part is a hamming window and last quarter part is a cosine
window. The residual signal
![](media/image498.wmf){width="0.3611111111111111in"
height="0.20833333333333334in"} is obtained by filtering
![](media/image496.wmf){width="0.6527777777777778in"
height="0.2361111111111111in"} through the inverse filter same as in
subclause 5.2.2.4.1.1 of \[5\]. The local LPC parameters and the
excitation signal ![](media/image499.wmf){width="0.3611111111111111in"
height="0.20833333333333334in"} are stored for multiple frame loss.

##### 5.4.2.2.1 Construction of the periodic part of the excitation

If the last good frame was neither UNVOICED\_CLAS nor
UNVOICED\_TRANSITION in combination with coder type being GENERIC, a
harmonic part and a random part of excitation have to be generated for a
concealment of erased frames. Otherwise, only a random part has to be
generated. The harmonic part of the excitation is constructed by
repeating the last pitch period of the previous frame. If this is the
case of the first erased frame after a good frame and the ISF stability
factor is lower than one, the first pitch cycle is first low-pass
filtered. The filter used is core sampling rate dependant and consists
of an 11-tap linear phase FIR filter. The filter coefficients for core
sampling rates lower or equal then 16 000 Hz are:

![](media/image500.wmf){width="5.083333333333333in"
height="0.20833333333333334in"}, (112)

for core sampling rate equal to 25600 Hz

![](media/image501.wmf){width="5.125in" height="0.20833333333333334in"}
(113)

and for higher core sampling rates

![](media/image502.wmf){width="5.346527777777778in"
height="0.20833333333333334in"}. (114)

The periodic part of the excitation is constructed as described in
subclause 5.3.1 including the pitch extrapolation as described in
subclause 5.3.1.1 and the glottal pulse resynchronization as described
in subclause 5.3.1.3. The pitches used to get the pitch extrapolation
are based on the LTP lag and gains coming from the last TCX frames.

These LTP lag and gain are sent in the bitstream as side information.
The specific handling as described in subclause 5.3.1.5 is used for TCX
time domain concealment at all bitrates, additionally with the specific
low-pass filtering of the first pitch cycle as described above.

The gain of pitch,![](media/image464.wmf){width="0.2222222222222222in"
height="0.2361111111111111in"}, is calculated on
![](media/image503.wmf){width="0.6527777777777778in"
height="0.2361111111111111in"} as follows:

![](media/image504.wmf){width="3.4583333333333335in"
height="1.0965277777777778in"} (115)

where ![](media/image505.wmf){width="0.6666666666666666in"
height="0.2361111111111111in"} are samples of pre-emphased prior time
data,![](media/image506.wmf){width="0.375in"
height="0.2361111111111111in"} is the length of a subframe in samples
and ![](media/image507.wmf){width="0.16666666666666666in"
height="0.20833333333333334in"} is the rounded pitch period equal to the
LTP lag of the last good frame. The gain of pitch is limited between
zero and one to prevent unexpected increase of energy. The formed
adaptive excitation is attenuated sample-by-sample throughout the frame
starting with one and ending with the damping factor calculated same as
in subclause 5.3.4.2.3. To get a proper overlap add in the case the next
good frame is a valid TCX frame, half a frame is additional created the
same as describe above.

The attenuation strategy of the periodic part of the excitation is the
same as done in subclause 5.3.4.2.1.

##### 5.4.2.2.2 Construction of the random part of the excitation

The innovative (non-periodic) part of the excitation is generated by a
simple random generator with approximately uniform distribution. If the
last good frame was VOICED\_CLAS or ONSET, a pre-emphased filtering of
the noise is done same as \[19\] subclause 5.1.3, but with the
pre-emphasis factor of 0.2 for core sampling rates lower or equal then
16 kHz and 0.6 for all other rates. The filtering is applied to decrease
the amount of noisy components in the lower frequencies speech region.
Furthermore, to shift the noise more to higher frequencies, the noise
gets filtered by a 10-order high pass FIR filter in case of the first
erased frame after a good frame and if the last good frame was neither
UNVOICED\_CLAS nor UNVOICED\_TRANSITION. The filter coefficients are

![](media/image508.wmf){width="5.513888888888889in"
height="0.20833333333333334in"} (116)

for core sampling rates lower or equal than 16000 Hz,

![](media/image509.wmf){width="5.638888888888889in"
height="0.20833333333333334in"} (117)

for the core sampling rate of 25600 Hz and

![](media/image510.wmf){width="5.638888888888889in"
height="0.20833333333333334in"} (118)

for all other rates. For the second and further lost frames, the noise
is composed via a linear interpolation between the fullband and a
highpass-filtered version of it as

![](media/image511.wmf){width="4.75in" height="0.2361111111111111in"}
(119)

where ![](media/image512.wmf){width="0.4861111111111111in"
height="0.20833333333333334in"}are noise samples generated as described
in beginning of this subclause,
![](media/image513.wmf){width="0.6111111111111112in"
height="0.2361111111111111in"} are
![](media/image512.wmf){width="0.4861111111111111in"
height="0.20833333333333334in"} filtered with the highpass filter above
and ![](media/image514.wmf){width="1.375in"
height="0.20833333333333334in"}is a frame wise cumulative factor of the
damping factors. This ensures that the noise fades to fullband noise
with the fading speed dependently on the damping factor.

The innovation gain,![](media/image515.wmf){width="0.19375in"
height="0.20833333333333334in"}, which is used for adjusting the noise
level, is calculated as

![](media/image516.wmf){width="3.3465277777777778in"
height="0.8333333333333334in"} (120)

where ![](media/image464.wmf){width="0.2222222222222222in"
height="0.2361111111111111in"}is calculated as in equation (115).
However, if the last good frame was neither UNVOICED\_CLAS nor
UNVOICED\_TRANSITION in combination with coder type being GENERIC,
![](media/image464.wmf){width="0.2222222222222222in"
height="0.2361111111111111in"}is set to zero for
calculating![](media/image515.wmf){width="0.19375in"
height="0.20833333333333334in"} and the pitch buffer get reset.

The attenuation strategy of the random part of the excitation is
somewhat different from the attenuation of the periodic excitation. The
reason is that the pitch excitation is converging to zero while the
random excitation is fading towards the background level
![](media/image517.wmf){width="0.3194444444444444in" height="0.25in"}
described in 5.3.4.2.1. The background level is limited
to![](media/image518.wmf){width="0.3333333333333333in"
height="0.20833333333333334in"}. The random part of the excitation is
attenuated linearly throughout the frame on a sample-by-sample basis
starting with ![](media/image519.wmf){width="0.19375in"
height="0.20833333333333334in"} and going to the end of the frame gain
which is

![](media/image520.wmf){width="2.0833333333333335in" height="0.25in"}
(121)

where ![](media/image521.wmf){width="0.3194444444444444in"
height="0.25in"} is the gain in the last sample of the noise signal and
![](media/image522.wmf){width="0.375in" height="0.20833333333333334in"}
is the damping factor as calculated in subclause 5.3.4.2.3. Due to the
fact that ![](media/image523.wmf){width="0.19375in"
height="0.20833333333333334in"} is a relative component, the noise gets
normalized. If the last good frame was UNVOICED\_CLAS and the coder type
is not UNVOICED, the innovative excitation is further attenuated by a
factor of 0.8. Otherwise, if the last good frame was not UNVOICED\_CLAS
and not UNVOICED\_TRANSITION, the excitation is further attenuated by
![](media/image524.wmf){width="0.7361111111111112in"
height="0.2361111111111111in"}.

To get a proper overlap add in the case the next good frame is a valid
TCX frame, half a frame is additional created the same as describe
above.

##### 5.4.2.2.3 Construction of the total excitation, synthesis and updates

Finally, the random part of the excitation is added to the adaptive
excitation to form the total excitation signal. If the last good frame
is UNVOICED\_CLAS or last good frame is UNVOICED\_TRANSITION and coder
type is GENERIC, only the innovative excitation is used as mentioned
above. The synthesized signal is obtained by filtering the total
excitation signal through the LP synthesis filter (see \[5\] subclause
6.1.3) with the local calculated LPC parameters and post-processed with
the de-emphases filter, which is the inverse of \[5\] subclause 5.1.3.

If LTP information is available in the last good frame and
![](media/image525.wmf){width="0.19375in"
height="0.20833333333333334in"}is equal to zero then the
![](media/image481.wmf){width="0.9861111111111112in"
height="0.20833333333333334in"}is reset to zero. In the end the overlap
and add buffers get updated same as in subclause 5.4.5.

#### 5.4.2.3 MDCT frame repetition with sign scrambling

The excitation of the concealed frame (input to FDNS)
![](media/image526.wmf){width="0.5in" height="0.25in"}is derived by sign
scrambling of the last received excitation spectrum
![](media/image527.wmf){width="0.9861111111111112in"
height="0.2361111111111111in"}:

![](media/image528.wmf){width="4.208333333333333in"
height="0.4305555555555556in"} (122)

![](media/image529.wmf){width="0.7222222222222222in"
height="0.20833333333333334in"} is the IGF cross over frequency. The
![](media/image530.wmf){width="0.8611111111111112in"
height="0.18055555555555555in"} is derived as

$\text{randomVector}(k) = \text{randomVector}(k - 1) \cdot \text{31821} + \text{13849},\text{\ \ for\ }k = \lbrack 1,\text{.}\text{.}\text{.},\text{igfStartLine}\rbrack$
(123)

For any lost frame following a received frame, the initial value is
reset:

$\text{randomVector}(0) = \text{1977}$ (123a)

If the last 2 spectra are coded using TCX5, then the one with smaller
energy is chosen.

The spectrum ![](media/image531.wmf){width="0.5in" height="0.25in"} is
faded towards noise as described in subclause 5.4.6.1.3.2.1.

#### 5.4.2.4 Tonal MDCT concealment using phase prediction

##### 5.4.2.4.1 Overview

The phase prediction described in subclause 5.4.2.4.3 is performed on
the spectral coefficients belonging to tonal components found using the
peak detection described in subclause 5.4.2. For the spectral
coefficients not belonging to the tonal components, the sign scrambling
is applied as described in subclause 5.4.2.3.

##### 5.4.2.4.2 Peak detection of tonal components

Peak detection is performed if the current frame is lost but the
previous frame has been received.

The peaks are first searched in the power spectrum of frame
![](media/image532.wmf){width="0.3229166666666667in"
height="0.16666666666666666in"}, using predefined thresholds. Based on
the location of the peaks in frame
![](media/image533.wmf){width="0.3229166666666667in"
height="0.16666666666666666in"}, the thresholds for the search in the
power spectrum of frame$m - 1\text{.}5$ are adapted, whereas frame
$m - 1\text{.}5$ represents the second 10ms of frame $m - 2$ and the
first 10ms of frame $m - 1$. Thus, peaks existing in both spectra
(![](media/image534.wmf){width="0.3229166666666667in"
height="0.16666666666666666in"} and $m - 1\text{.}5$) are found. Their
exact location is based on the power spectrum of frame $m - 1\text{.}5$.

The power spectra
${\overset{\sim}{P}}^{\lbrack m - 1\text{.}5\rbrack}\left( k \right)$
and ${\overset{\sim}{P}}^{\lbrack m - 1\rbrack}\left( k \right)$ are
obtained as follows:

${\overset{\sim}{P}}^{\lbrack y\rbrack}\left( k \right) = \left| S^{\lbrack y\rbrack}\left( k \right) \right|^{2} + \ \left| C^{\lbrack y\rbrack}\left( k \right) \right|^{2},y \in \left\{ m - 1\text{.}5,m - 1 \right\},k = 0\ldots\text{nSamples} - 1$
(124)

where $S^{\lbrack y\rbrack}\left( k \right)$ represents the MDST
coefficients and $C^{\lbrack y\rbrack}\left( k \right)$represents the
MDCT coefficients and
![](media/image535.wmf){width="0.5833333333333334in"
height="0.20833333333333334in"} being the number of spectral
coefficients. A minimum significant value of a spectral line in the
power spectrum is assured by this operation:

![](media/image536.wmf){width="2.0833333333333335in"
height="0.4888888888888889in"} (125)

$C^{\lbrack m - 1\text{.}5\rbrack}\left( k \right)$ and
$S^{\lbrack m - 1\text{.}5\rbrack}\left( k \right)$ are derived from the
time domain signal via MDCT/MDST.
$C^{\left\lbrack m - 1 \right\rbrack}\left( k \right)$is given and
$S^{\left\lbrack m - 1 \right\rbrack}\left( k \right)$ is estimated:

$\left| S^{\lbrack m - 1\rbrack}(k) \right| = \left| C^{\lbrack m - 1\rbrack}(k + 1) - C^{\lbrack m - 1\rbrack}(k - 1) \right|$
(126)

If the change of the pitch lag between the last and the second last
frame is larger or equal than 0.25 or the pitch lag is smaller than 10ms
(corresponding to $F_{0} < \text{100}\text{Hz}$), the index of the
fundamental frequency is set to zero. Otherwise the index of the
fundamental frequency is determined as:

$F_{0}^{\text{orig}} = F_{0} = \frac{2 \cdot \text{FrameSize}}{\text{PitchLag}}$.
(128)

10 strongest peaks are found at the positions
$n_{i} \cdot F_{0},i \in \left\{ 1,\text{.}\text{.}\text{.},\text{10} \right\},n_{i} \in \left\{ 2,3,4\text{.}\text{.}\text{.} \right\}$.
Distance between peaks are calculated as
$d_{i} = n_{i + 1} - n_{i},i \in \left\{ 1,\text{.}\text{.}\text{.},9 \right\}$.
The most common among differences $d_{i}$ is $d$. If there are at least
3 $d_{i}$ equal to 1 and if $d = 1$; or less than 5 $d_{i}$are equal to
$d \neq 1$, then $F_{0}$ is not changed. If there are more than 5
$d_{i}$equal to $d \neq 1$, then $F_{0}$is set to $d \cdot F_{0}$.
Otherwise $F_{0}$ is set to 0.

An envelope of each power spectrum is calculated using a moving average
filter:

$\text{Envelope}^{\left\lbrack y \right\rbrack}\left( k \right) = \frac{7\text{.}\text{59}}{\text{FL}} \cdot \sum_{i = k - \left\lfloor \frac{\text{FL}}{2} \right\rfloor}^{k + \left\lfloor \frac{\text{FL}}{2} \right\rfloor}{P^{y}\left( i \right)},y \in \left\{ m - 1\text{.}5,m - 1 \right\}$.
(129)

The filter length ![](media/image537.wmf){width="0.2222222222222222in"
height="0.1527777777777778in"} depends on the index of the fundamental
frequency and is limited to the range \[11,23\], as shown in Table 1. If
the fundamental frequency is not available or not reliable, the filter
length *FL* is set to 15, otherwise:

![](media/image538.wmf){width="2.0416666666666665in"
height="0.4861111111111111in"}. (130)

Table 8: Filter length depending on the fundamental frequency

  -------- -------------------------------------------------------------------------------------
  F0       FL
  0        15
  \<= 10   11
  \>= 22   23
  else     ![](media/image539.wmf){width="0.6666666666666666in" height="0.4305555555555556in"}
  -------- -------------------------------------------------------------------------------------

The smoothed power spectra are calculated as follows:

$P_{\text{smoothed}}^{\left\lbrack y \right\rbrack}(k) = 0\text{.}\text{75} \cdot P^{\lbrack y\rbrack}(k - 1) + P^{\lbrack y\rbrack}(k) + 0\text{.}\text{75} \cdot P^{\lbrack y\rbrack}(k + 1),y \in \left\{ m - 1\text{.}5,m - 1 \right\}$
(131)

##### 5.4.2.4.2.1 Detection of the peak candidates {#detection-of-the-peak-candidates .H6}

If the smoothed spectrum
$P_{\text{smoothed}}^{\left\lbrack m - 1 \right\rbrack}$ is above the
envelope ![](media/image540.wmf){width="0.84375in" height="0.25in"} at
bin ![](media/image541.wmf){width="0.125in"
height="0.17708333333333334in"}and the smoothed spectrum at bin
![](media/image542.wmf){width="0.125in" height="0.17708333333333334in"}
is bigger than at bins
![](media/image543.wmf){width="0.2916666666666667in"
height="0.16666666666666666in"} and
![](media/image544.wmf){width="0.3020833333333333in"
height="0.17708333333333334in"}, $k$ is treated as peak candidate
![](media/image545.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"} and the right and left foot of this peak
candidate are searched for.

The right foot is defined as the spectral bin with index
![](media/image546.wmf){width="0.13541666666666666in"
height="0.20833333333333334in"}, for which

![](media/image547.wmf){width="1.5416666666666667in" height="0.25in"}
(132)

and

![](media/image548.wmf){width="2.8222222222222224in" height="0.25in"}
(133)

It is also allowed for an
![](media/image549.wmf){width="1.0930555555555554in" height="0.25in"}
that ![](media/image550.wmf){width="1.5520833333333333in"
height="0.25in"} is true, but only if
![](media/image551.wmf){width="1.6972222222222222in" height="0.25in"}and
if there is a $k < j < i_{r}$for which:

$2 \cdot \frac{P^{\lbrack m - 1\rbrack}(x^{'} + 1)}{P^{\lbrack m - 1\rbrack}(x^{'})} \leq \frac{P^{\lbrack m - 1\rbrack}(x^{'})}{P^{\lbrack m - 1\rbrack}(j)}$
(134)

and

![](media/image552.wmf){width="2.875in" height="0.4861111111111111in"}
(135)

The left foot is defined in the same way as the right foot, but on the
left side of the bin ![](media/image541.wmf){width="0.125in"
height="0.17708333333333334in"}.

**The local maximum**
![](media/image545.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"} **is then found between the left and the
right foot.**

The thresholds for the peak search in
$P^{\lbrack m - 1\text{.}5\rbrack}$ are set at positions
![](media/image553.wmf){width="1.2180555555555554in"
height="0.20833333333333334in"} as:

$\text{Threshold}(k) = \left\{ \begin{matrix}
1\text{.}1\ \text{when}\ P_{\text{smoothed}}^{\left\lbrack m - 1 \right\rbrack}\left( k \right)\  > \ \text{Envelope}^{\lbrack m - 1\rbrack}(k) \\
1\text{.}5\ \text{otherwise}\  \\
\end{matrix} \right.\ $ (136)

If the change of the pitch between the last and the second last frame is
smaller then 0.5, then for each

\- ![](media/image554.wmf){width="0.6666666666666666in"
height="0.20833333333333334in"}, for each
![](media/image555.wmf){width="0.5409722222222222in"
height="0.19791666666666666in"}, $N$being the number of the harmonics of
$F_{0}$, ![](media/image556.wmf){width="0.9583333333333334in"
height="0.20833333333333334in"}

\- $k = \left\lfloor m \cdot F_{0}^{\text{orig}} \right\rfloor$, for
each
$m \in \left\lbrack 1,\left\lfloor F_{0}F_{0}^{\text{orig}} + 0\text{.}5 \right\rfloor \right\rbrack$,$\text{frac} = m \cdot F_{0}^{\text{orig}} - k$

thresholds are updated as follows:

$\begin{matrix}
\text{Threshold}(k) = \text{thresh}_{\text{base}} \\
\text{Threshold}(k - 1) = \text{thresh}_{\text{base}} + 2 \cdot \text{frac} \\
\text{Threshold}(k + 1) = \text{thresh}_{\text{base}} + 2 \cdot (1 - \text{frac}) \\
\end{matrix}$ (137)

with

$\text{thresh}_{\text{base}} = \left\{ \begin{matrix}
0\text{.}\text{70}\ \text{when}\ F_{0}^{\text{orig}} > 0\ \text{and}\ F_{0} = 0 \\
0\text{.}\text{35}\ \text{when}\ F_{0}^{\text{orig}} > 0\ \text{and}\ F_{0} > 0 \\
\end{matrix} \right.\ $ (138)

For all bins not belonging to peaks or harmonics the threshold is set
as:

$\text{Threshold}(k) = \text{16}$. (140)

Note: The base threshold 7.59, as given in equation 129, corresponds to
$8\text{.}8\text{dB}$. All other thresholds, represented by
$\text{Threshold}(k)$, are given relative to this base threshold. Thus,

\- 0.35 corresponds to $4\text{.}\text{24}\text{dB}$

\- 0.7 corresponds to $7\text{.}\text{25}\text{dB}$

\- 1.1 corresponds to $9\text{.}\text{21}\text{dB}$

\- 1.5 correspnds to $\text{10}\text{.}\text{56}\text{dB}$

\- 16 corresponds to $\text{20}\text{.}\text{84}\text{dB}$

##### 5.4.2.4.2.2 Final detection of the tonal components {#final-detection-of-the-tonal-components .H6}

After setting the thresholds
![](media/image557.wmf){width="0.7916666666666666in"
height="0.20833333333333334in"} as described in subclause 5.4.2.4.2.1,
peaks detected in frame $m - 1$ are now searched for in the power
spectrum of frame $m - 1\text{.}5$.

If the following is fulfilled:

$\begin{matrix}
P_{\text{smoothed}}^{\left\lbrack m - 1\text{.}5 \right\rbrack}(k) > \text{Envelope}^{\lbrack m - 1\text{.}5\rbrack}(k) \cdot \text{Threshold}(k) \\
P_{\text{smoothed}}^{\left\lbrack \text{m-1}\text{.}5 \right\rbrack}(k) \geq \text{max}\left( P_{\text{smoothed}}^{\left\lbrack \text{m-1}\text{.}5 \right\rbrack}(k - 1),P_{\text{smoothed}}^{\left\lbrack \text{m-1}\text{.}5 \right\rbrack}(k + 1) \right) \\
\end{matrix}$ (141)

the right and left foot of the peak is searched for in
$P^{\lbrack m - 1\text{.}5\rbrack}$ around
![](media/image542.wmf){width="0.125in" height="0.17708333333333334in"}.
The algorithm for the foot search is the same as the one in subclause
5.4.2.4.2.1.

**The local maximum**
![](media/image558.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"} **is then found between the left and the
right foot.**

**A tonal component is defined as the set of spectral bins**
![](media/image559.wmf){width="1.6354166666666667in"
height="0.20833333333333334in"}. If two neighboring tonal components
would overlap, their surroundings are symmetrically reduced such that
each spectral bin belongs only to one tonal component. All tonal
components then build the set ![](media/image560.wmf){width="0.375in"
height="0.20833333333333334in"}.

##### 5.4.2.4.3 Phase prediction

For all found tonal components ![](media/image561.wmf){width="0.375in"
height="0.20833333333333334in"}, that include spectrum peaks and their
surroundings, as described in subclause 5.4.2.4.2.2, the MDCT phase
prediction is used. For all other spectrum coefficients sign scrambling
described in subclause 5.4.2.3 is used.

The phases are derived for each bin of a tonal component as:

$\phi^{\lbrack m - 1\text{.}5\rbrack}\left( k \right) = \text{arctan}\left( \frac{S^{\lbrack m - 1\text{.}5\rbrack}(k)}{C^{\lbrack m - 1\text{.}5\rbrack}(k)} \right)$,
![](media/image562.wmf){width="1.375in" height="0.20833333333333334in"}
(142)

The fractional part
![](media/image563.wmf){width="0.17708333333333334in"
height="0.16666666666666666in"} is given by:

![](media/image564.wmf){width="1.0541666666666667in"
height="0.4013888888888889in"} (143)

with *a* given in Table 2, depending on the neighboring bins around a
spectral peak ![](media/image565.wmf){width="0.4722222222222222in"
height="0.20833333333333334in"}.

Table 9: Variable a from equation (143)

  ----------------------------------------------------------------------- -------------------------------------------------------------------------------------
  if                                                                      a
  ![](media/image566.wmf){width="1.8590277777777777in" height="0.25in"}   ![](media/image567.wmf){width="0.6243055555555556in" height="0.4013888888888889in"}
  ![](media/image568.wmf){width="1.8729166666666666in" height="0.25in"}   ![](media/image569.wmf){width="0.6243055555555556in" height="0.4013888888888889in"}
  else                                                                    ![](media/image570.wmf){width="2.261111111111111in" height="1.0402777777777779in"}
  ----------------------------------------------------------------------- -------------------------------------------------------------------------------------

Where the bandwidth *b* is 7, the maximum ratio
![](media/image571.wmf){width="0.2222222222222222in"
height="0.1388888888888889in"}is 44.8 and the constant *G* is
![](media/image572.wmf){width="0.45694444444444443in"
height="0.3597222222222222in"}.

The phase shift, being the same for every spectrum bin in
![](media/image573.wmf){width="0.3333333333333333in"
height="0.20833333333333334in"}, is derived as follows

$\text{Δϕ} = \pi \cdot l\text{\%}4 + \text{Δl}$, (144)

where ![](media/image574.wmf){width="0.46875in"
height="0.20833333333333334in"} is the index of the bin closest to the
peak and ![](media/image575.wmf){width="0.17708333333333334in"
height="0.16666666666666666in"}is the fractional part (i.e. distance of
the peak from ![](media/image576.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"} given as the fractional number of bins).

The current phase ![](media/image577.wmf){width="0.46875in"
height="0.25in"} is estimated for each
![](media/image578.wmf){width="0.5416666666666666in"
height="0.20833333333333334in"} using:

$\phi^{\lbrack m\rbrack}\left( k \right) = \phi^{\lbrack m - 1\text{.}5\rbrack}\left( k \right) + n_{\text{frmdist}} \cdot \text{Δϕ}$
(145)

where $n_{\text{frmdist}} = 1\text{.}5$ for the first concealed frame
and $n_{\text{frmdist}}$ is increased for 1 for every consecutive frame
loss. The correspondingt MDCT bins are estimated as:

$C^{\lbrack m\rbrack}\left( k \right) = \sqrt{P^{\lbrack m - 1\text{.}5\rbrack}\left( k \right)} \cdot \text{cos}\left( \phi^{\lbrack m\rbrack}\left( k \right) \right)$.
(146)

#### 5.4.2.5 Non-tonal concealment with waveform adjustment

##### 5.4.2.5.1 Preliminary concealment in frequency domain

The MDCT coefficients of the current lost frame are computed by using
the MDCT coefficients of the frame prior to the current lost frame as
follows:

The MDCT coefficients at all frequency points of the frame prior to the
current lost frame are multiplied by random signs to obtain the MDCT
coefficients of all frequency points of the current lost frame. In other
words, when the current lost frame is the
![](media/image579.wmf){width="0.25in" height="0.25in"} frame,

![](media/image580.wmf){width="2.4305555555555554in" height="0.25in"}
(147)

wherein ![](media/image581.wmf){width="0.44375in" height="0.25in"}is the
MDCT coefficient at the frequency point
![](media/image582.wmf){width="0.18055555555555555in"
height="0.1527777777777778in"} of the
![](media/image579.wmf){width="0.25in" height="0.25in"} frame,
![](media/image583.wmf){width="0.2222222222222222in"
height="0.18055555555555555in"} is the total number of the frequency
points, and ![](media/image584.wmf){width="0.5277777777777778in"
height="0.2222222222222222in"} is the random sign at the frequency point
![](media/image582.wmf){width="0.18055555555555555in"
height="0.1527777777777778in"}.

The obtained MDCT coefficients of the current lost frame are transformed
by an IMDCT to produce the initially compensated signal of the current
lost frame.

##### 5.4.2.5.2 Waveform adjustment in time domain

Waveform adjustment is performed on the initially compensated signal of
the current lost frame to obtain the compensated signal of the current
lost frame. The detailed procedure of the waveform adjustment is
described as follows:

When the first lost frame occurs, the pitch period of the current lost
frame is estimated as follows:

The pitch search is performed over the time-domain signal of the frame
prior to the current lost frame by using the autocorrelation method to
obtain the value of the pitch period of the frame prior to the current
lost frame. The obtained pitch period value is used as the pitch period
value of the current lost frame and to compute the maximum of normalized
autocorrelation of the current lost frame. Detailedly,
![](media/image585.wmf){width="2.1666666666666665in" height="0.25in"} is
searched so that

![](media/image586.wmf){width="1.2638888888888888in"
height="0.7083333333333334in"} (148)

achieves the maximum value, then the resulting
![](media/image587.wmf){width="9.652777777777778e-2in"
height="0.16666666666666666in"} is the value of the pitch period,
denoted by ![](media/image588.wmf){width="0.1527777777777778in"
height="0.18055555555555555in"}, wherein
![](media/image589.wmf){width="0.3055555555555556in" height="0.25in"}
and ![](media/image590.wmf){width="0.2916666666666667in"
height="0.2361111111111111in"} are the upper and lower limits for the
pitch searching, respectively, and
![](media/image591.wmf){width="0.1527777777777778in"
height="0.18055555555555555in"} is the frame length,
![](media/image592.wmf){width="0.2916666666666667in"
height="0.2222222222222222in"} with
![](media/image593.wmf){width="0.8055555555555556in" height="0.19375in"}
is the time-domain signal (the signal before TCX long-time prediction
and post-processing) over which the pitch search is performed.
![](media/image594.wmf){width="0.3055555555555556in" height="0.25in"}
and ![](media/image595.wmf){width="0.2916666666666667in"
height="0.2361111111111111in"}are obtained as follows:

![](media/image596.wmf){width="1.2222222222222223in"
height="0.20833333333333334in"} (149)

![](media/image597.wmf){width="1.3888888888888888in"
height="0.20833333333333334in"} (150)

wherein ![](media/image598.wmf){width="0.5555555555555556in"
height="0.2222222222222222in"} denotes the rounding operation. Define

![](media/image599.wmf){width="1.8333333333333333in"
height="1.0138888888888888in"} (151)

then ![](media/image600.wmf){width="0.3888888888888889in"
height="0.2222222222222222in"} is the maximum of normalized
autocorrelation. When the frame length
![](media/image601.wmf){width="0.1527777777777778in"
height="0.18055555555555555in"} is not greater than 320, define:

![](media/image602.wmf){width="0.6805555555555556in"
height="0.20833333333333334in"} (152)

wherein ![](media/image603.wmf){width="0.19375in" height="0.19375in"}
indicates taking the greatest integer value less than or equal to
![](media/image604.wmf){width="0.1388888888888889in"
height="0.1527777777777778in"}*. Comparing*
![](media/image605.wmf){width="0.3333333333333333in" height="0.19375in"}
with ![](media/image606.wmf){width="0.4305555555555556in"
height="0.20833333333333334in"}*, the pitch period is reset as*
![](media/image607.wmf){width="0.4583333333333333in"
height="0.20833333333333334in"} *in case*
![](media/image608.wmf){width="0.8611111111111112in"
height="0.20833333333333334in"}*.*

When the frame length
![](media/image609.wmf){width="0.1527777777777778in"
height="0.18055555555555555in"} is greater than 320, in the procedure of
estimating pitch period the following processing is carried out before
pitch searching over the time-domain signal of the frame prior to the
current lost frame: the time-domain signal of the frame prior to the
current lost frame is down-sampled towards a half sampling rate, and the
down-sampled time-domain signal is used to replace the original
time-domain signal of the frame prior to the current lost frame for the
pitch estimate. Accordingly, the searching limits
![](media/image610.wmf){width="0.3055555555555556in" height="0.25in"}
and ![](media/image611.wmf){width="0.2916666666666667in"
height="0.2361111111111111in"}herein are obtained specifically as
follows:

![](media/image612.wmf){width="1.375in" height="0.20833333333333334in"}
(153)

![](media/image613.wmf){width="1.3888888888888888in"
height="0.20833333333333334in"} (154)

The following procedure is used to determine whether the pitch period
value of the current lost frame estimated by the above method is usable
regarding subsequent waveform adjustment:

i\. Verify the following conditions to find if any one of them is met.
If so, the obtained pitch period value is unusable.

\(1\) The cross-zero rate of the initially compensated signal of the
first lost frame, denoted by
![](media/image614.wmf){width="0.7222222222222222in"
height="0.18055555555555555in"}, is greater than a threshold
![](media/image615.wmf){width="0.16666666666666666in"
height="0.1527777777777778in"}, wherein
![](media/image616.wmf){width="0.44375in"
height="0.16666666666666666in"} for $L \leq \text{256}$, and
![](media/image617.wmf){width="0.5in" height="0.16666666666666666in"} in
other cases.

\(2\) In the frame prior to the current lost frame, the ratio of
lower-frequency energy to whole-frame energy, denoted by
![](media/image618.wmf){width="0.9722222222222222in"
height="0.20833333333333334in"}, is smaller than a threshold of 0.02.
This ratio is defined as

![](media/image619.wmf){width="2.125in" height="1.0138888888888888in"}
(155)

wherein ![](media/image620.wmf){width="0.5138888888888888in"
height="0.18055555555555555in"} when the current lost frame is TCX20,
![](media/image621.wmf){width="0.5138888888888888in"
height="0.16666666666666666in"} when the current lost frame is TCX10,
![](media/image622.wmf){width="0.19375in" height="0.1527777777777778in"}
is the total number of the frequency points.

\(3\) In the frame prior to the current lost frame, the spectral tilt,
denoted by![](media/image623.wmf){width="0.20833333333333334in"
height="0.16666666666666666in"}, is smaller than a threshold
![](media/image624.wmf){width="0.34652777777777777in"
height="0.1527777777777778in"}, wherein
![](media/image625.wmf){width="0.6666666666666666in"
height="0.16666666666666666in"} for
![](media/image626.wmf){width="0.4861111111111111in"
height="0.16666666666666666in"} and
![](media/image627.wmf){width="0.6666666666666666in"
height="0.16666666666666666in"} otherwise. This spectral tilt is defined
as

![](media/image628.wmf){width="1.5416666666666667in"
height="1.0138888888888888in"} (156)

wherein ![](media/image629.wmf){width="1.1805555555555556in"
height="0.20833333333333334in"} is a low-pass filtered signal of the
time-domain signal of the prior frame. The low-pass filter is given by:

![](media/image630.wmf){width="1.8333333333333333in"
height="0.4027777777777778in"} (157)

\(4\) In the frame prior to the current lost frame, the cross-zero rate
of the second half frame
![](media/image631.wmf){width="0.2638888888888889in" height="0.19375in"}
is greater than that of the first half frame
![](media/image632.wmf){width="0.2361111111111111in" height="0.19375in"}
by four times.

ii\. If none of the above-mentioned conditions (i.e. the conditions
(1)-(4)) is met, verify whether the obtained pitch period value is
usable according to the following criteria:

\(a\) When the current lost frame is within a silence segment, the
obtained pitch period value is considered to be unusable. The silence
segment is identified if the logarithm energy of the frame prior to the
current lost frame is smaller than a threshold of 50 or the following
two conditions are met simultaneously:

\(1\) The maximum of normalized autocorrelation mentioned above in the
pitch estimate procedure is smaller than 0.9.

\(2\) The result of the current long-time logarithm energy minus the
logarithm energy of the frame prior to the current lost frame is greater
than 8.0.

The logarithm energy is defined as:

![](media/image633.wmf){width="1.5965277777777778in"
height="0.5138888888888888in"} (158)

where ![](media/image634.wmf){width="1.0555555555555556in"
height="0.20833333333333334in"} is the time-domain signal used as the
final decoder output.

The long-time logarithm energy is defined as follows:

Set an initial value
![](media/image635.wmf){width="0.3888888888888889in"
height="0.16666666666666666in"}. For each frame, if its logarithm energy
is greater than 50 and its cross-zero rate is smaller than 100, the
long-time logarithm energy is updated as below:

![](media/image636.wmf){width="2.2222222222222223in"
height="0.20833333333333334in"} (159)

where ![](media/image637.wmf){width="0.7083333333333334in"
height="0.16666666666666666in"} and
![](media/image638.wmf){width="0.5138888888888888in"
height="0.16666666666666666in"}.

\(b\) When the current lost frame is not within a silence segment and
the maximum of normalized autocorrelation mentioned above is greater
than 0.8, the obtained pitch period value is considered to be usable.

\(c\) When the criteria (a) and (b) are not met and the cross-zero rate
of the frame prior to the current lost frame is greater than 100, the
obtained pitch period value is considered to be unusable,

\(d\) When the criteria (a), (b), and (c) are not met and the result of
the current long-time logarithm energy minus the logarithm energy of the
frame prior to the current lost frame is greater than 6.0, the obtained
pitch period value is considered to be unusable,

\(e\) When the criteria (a), (b), (c), and (d) are not met, and the
result of the logarithm energy of the frame prior to the current lost
frame minus the current long-time logarithm energy is greater than 1.0
and the maximum of normalized autocorrelation mentioned above is greater
than 0.6, the obtained pitch period value is considered to be usable,

\(f\) When the criteria (a), (b), (c), (d), (e), and (f) are not met,
the harmonic characteristic of the frame prior to the current lost frame
is verified. When a value
![](media/image639.wmf){width="0.4027777777777778in" height="0.19375in"}
representing the harmonic characteristic is smaller than a threshold
![](media/image640.wmf){width="0.19375in"
height="0.18055555555555555in"}, the obtained pitch period value is
considered to be unusable, When the value
![](media/image641.wmf){width="0.34652777777777777in"
height="0.18055555555555555in"} is greater than or equal to the
threshold ![](media/image642.wmf){width="0.19375in"
height="0.18055555555555555in"}, the obtained pitch period value is
considered to be usable, In this case,
![](media/image643.wmf){width="0.4861111111111111in"
height="0.16666666666666666in"}.
![](media/image644.wmf){width="0.34652777777777777in"
height="0.18055555555555555in"} can be computed as follows:

![](media/image645.wmf){width="1.0833333333333333in"
height="1.0138888888888888in"} (160)

wherein ![](media/image646.wmf){width="0.16666666666666666in"
height="0.2361111111111111in"} is the fundamental frequency point,
![](media/image647.wmf){width="0.7222222222222222in"
height="0.20833333333333334in"} is the
![](media/image648.wmf){width="0.19375in" height="0.2222222222222222in"}
harmonic frequency point of
![](media/image649.wmf){width="0.1527777777777778in"
height="0.20833333333333334in"}~,~
![](media/image650.wmf){width="0.3333333333333333in"
height="0.20833333333333334in"} is the MDCT coefficient at the frequency
point ![](media/image651.wmf){width="0.16666666666666666in"
height="0.25in"}. Due to the quantitative relation between the pitch
period and the pitch frequency, the value of
![](media/image652.wmf){width="0.7083333333333334in"
height="0.20833333333333334in"} can be computed with the pitch period
value mentioned above. When
![](media/image653.wmf){width="0.1527777777777778in"
height="0.20833333333333334in"} is not an integer,
![](media/image654.wmf){width="0.32013888888888886in"
height="0.16527777777777777in"} is computed with its adjacent one or
several frequency points by using rounding.

When the current lost frame is not the first lost frame, the pitch
period of the first lost frame is taken as the estimated pitch period of
the current lost frame,

If the pitch period of the current lost frame is not usable, the
initially compensated signal of the current lost frame is taken as the
compensated signal of the current lost frame; if the pitch period is
usable, waveform adjustment is performed on the initially compensated
signal with the time-domain signal of the frame prior to the current
lost frame, that is, the pitch period is adjusted under certain
conditions at first, and then the following are conducted:

It is supposed that the current lost frame is the $x^{\text{th}}$ lost
frame, wherein $x > 0$, and when $x$ is larger than 4, the initially
compensated signal of the current lost frame is taken as the compensated
signal of the current lost frame, otherwise the following steps are
performed;

\(a\) A buffer is established with a length of $L$;

\(b\) When $x$ equals 1, the first $\frac{T}{4}$ samples of the buffer
are configured as a first $\frac{T}{4}$-length signal of the initially
compensated signal of the current lost frame, wherein $T$ is the pitch
period of the current lost frame;

\(c\) When $x$ equals 1, the last pitch period of time-domain signal of
the frame prior to the current lost frame and the first
$\frac{T}{4}$-length signal in the buffer are concatenated, and
repeatedly copied into the buffer, until the buffer is filled up to
obtain a time-domain signal with a length of $L$, and during each copy,
if the length of the existing signal in the buffer is $l$, the signal is
copied to locations from $l - \frac{T}{4}$ to $l + T - 1$ of the buffer,
wherein $l > 0$, and for the resultant overlapped area with a length of
$\frac{T}{4}$, the signal of the overlapped area is obtained by adding
signals of two overlapping parts after windowing respectively; when $x$
is larger than 1, the last pitch period of compensated signal of the
frame prior to the current lost frame is repeatedly copied into the
buffer without overlapping, until the buffer is filled up to obtain a
time-domain signal with a length of $L$;

\(d\) When $x$ is less than 4, the signal in the buffer is taken as the
compensated signal of the current lost frame; when $x$ equals 4,
overlap-add is performed on the signal in the buffer and the initially
compensated signal of the current lost frame, and the obtained signal is
taken as the compensated signal of the current lost frame.

For each lost frame without overlap-add processing, an additional signal
as a noise is added to the compensated signal of the frame after the
compensated signal is obtained. The detailed method of adding additional
signal is as follows: firstly, a past signal, namely, the time-domain
signal of the frame prior to the first lost frame (in the case of the
first lost frame) or the initially compensated signal of the prior lost
frame (in the case of the second, third, or fourth lost frame) is passed
through a high-pass filter given as follows to obtain an additional
signal:

$H_{\text{HP}}(z) = 1 - 0\text{.}\text{68}z^{- 1}$ (160a)

secondly, additional-signal gain values of the lost frame are estimated
as follows:

$\text{NoiseGain} = 0\text{.}\text{99}\text{NoiseGain} + 0\text{.}\text{01}\text{GainBob}$
(160b)

wherein $\text{NoiseGain}$ is updated sample by sample during a series
of consecutively lost frames with an initial value of zero at the
beginning of the first lost frame and

$\text{GainBob} = 1 - \frac{1}{2}f(T)$ (160c)

where $f(T)$ is the maximum of normalized autocorrelation as described
by equation (151); then, the additional signal is multiplied with the
estimated additional-signal gain values sample by sample, and the
additional signal resulting from multiplication is added to the
compensated signal, to obtain a new compensated signal. For each lost
frame with overlap-add processing, overlap-add is performed after the
additional signal is added to the signal in the buffer.

For the first correctly received frame after the frame loss, if the
number of consecutively lost frames is less than 4, a buffer is
established with a length of $L$, the last pitch period of compensated
signal of the frame prior to the first correctly received frame is
repeatedly copied into the buffer without overlapping until the buffer
is filled up, overlap-add is performed on the signal in the buffer and
the time-domain signal obtained by decoding the first correctly received
frame, and the obtained signal is taken as a time-domain signal of the
first correctly received frame. The additional signal described above is
added to the signal in the buffer before overlap-add.

#### 5.4.2.6 Intelligent gap filling

The intelligent gap filling tool is applied on the constructed signal,
generated from one of the three MDCT-based TCX PLC methods, as described
in \[5\], subclause 6.2.2.3.8. However, with increasing number of lost
frames, the tiled IGF signal gets further attenuated by changing the IGF
gain factor for each scale factor band.

In case of a lost frame, the IGF gain factors calculated in \[5\]
subclause 6.2.2.3.8.3.8 firstly get limited to the maximum value of 12.
After that, the gain factors get changes as follows:

![](media/image655.wmf){width="3.2916666666666665in"
height="0.4305555555555556in"} (161)

where ![](media/image656.wmf){width="0.3055555555555556in"
height="0.20833333333333334in"} is the IGF gain factor at scale factor
band ![](media/image657.wmf){width="0.125in"
height="0.18055555555555555in"}and
![](media/image658.wmf){width="0.75in"
height="0.20833333333333334in"}are the number of consecutively lost
frames.

### 5.4.3 HQ MDCT

#### 5.4.3.1 Preliminary signal analysis of past synthesis 

The buffer containing the past decoded signal is analysed in a
preliminary step to prepare the PLC selection method described in clause
5.4.3.2 and the MDCT concealment described in clause 5.4.3.6.

##### 5.4.3.1.1 Resampling to 8 kHz

The last 2 frames of the previous synthesis signal are resampled to 8
kHz using zero-delay low-pass FIR filter with a cutoff frequency at 4
kHz. The FIR filter order is 20, 40, 60 for a sampling frequency of 16,
32, 48 kHz, respectively. The FIR filter coefficients are denoted
![](media/image659.wmf){width="0.5138888888888888in"
height="0.2361111111111111in"} at 16 kHz,
![](media/image660.wmf){width="0.5416666666666666in"
height="0.2361111111111111in"} at 32 kHz and
![](media/image661.wmf){width="0.5416666666666666in"
height="0.2361111111111111in"} at 48 kHz.

Low-pass filtering and downsampling steps are jointly performed with a
polyphase approach; the resampled signal at 8kHz,
![](media/image662.wmf){width="1.3194444444444444in" height="0.25in"},
can be computed using the relationship based on the past synthesis
![](media/image663.wmf){width="0.4305555555555556in"
height="0.2222222222222222in"},
![](media/image664.wmf){width="0.4305555555555556in"
height="0.2222222222222222in"},
![](media/image665.wmf){width="0.4305555555555556in"
height="0.2222222222222222in"} at respectively 16, 32 and 48 kHz:

![](media/image666.wmf){width="3.5in" height="1.3611111111111112in"}
(162)

Note that in the above summations, the past synthesis outside the last 2
frames is by convention considered to be zero. For instance, at 16 kHz,
it is considered that
![](media/image667.wmf){width="0.6388888888888888in"
height="0.2222222222222222in"}when
![](media/image668.wmf){width="0.3611111111111111in"
height="0.18055555555555555in"} or
![](media/image669.wmf){width="0.5138888888888888in"
height="0.18055555555555555in"}.

##### 5.4.3.1.2 Pitch search by cross-correlation

The past synthesis signal resampled to 8 kHz and of length 40 ms,
![](media/image670.wmf){width="1.3194444444444444in" height="0.25in"},
is used to perform an open-loop pitch search as follows:

\- The target signal is defined as the last 6 ms segment from the 40 ms
buffer at 8 kHz: ![](media/image671.wmf){width="2.013888888888889in"
height="0.25in"}

\- A search vector of the same length (6 ms),
![](media/image672.wmf){width="1.4722222222222223in" height="0.25in"},
with sliding starting point ![](media/image673.wmf){width="0.875in"
height="0.2222222222222222in"} is used. The search range
![](media/image674.wmf){width="0.4027777777777778in"
height="0.2222222222222222in"} covers 33 ms when the voicing parameter
indicates a voiced segment (i.e.
![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"}=1) and 28 ms otherwise; therefore the
pitch search range is adapted depending on the voicing indicator
![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"}, to use a longer search range in case of
voiced signals. The cross-correlation is computed for each index
![](media/image676.wmf){width="0.125in" height="0.19375in"} as:

![](media/image677.wmf){width="2.388888888888889in"
height="0.9722222222222222in"} (163)

> To minimize computational complexity the term
> ![](media/image678.wmf){width="0.5694444444444444in"
> height="0.4722222222222222in"} is pre-computed and the term
> ![](media/image679.wmf){width="1.0138888888888888in"
> height="0.4722222222222222in"} is updated incrementally by removing
> the first term and adding a new term in each iteration.
>
> For each index ![](media/image676.wmf){width="0.125in"
> height="0.19375in"}, the maximum correlation
> ![](media/image680.wmf){width="0.12361111111111112in"
> height="0.1486111111111111in"} and maximum location
> ![](media/image681.wmf){width="0.3055555555555556in"
> height="0.2222222222222222in"} are updated as follows: If
> ![](media/image682.wmf){width="0.7777777777777778in"
> height="0.20833333333333334in"},![](media/image683.wmf){width="0.7729166666666667in"
> height="0.20347222222222222in"} and
> ![](media/image684.wmf){width="0.5694444444444444in"
> height="0.2222222222222222in"}, with the initial conditions
> ![](media/image685.wmf){width="0.35833333333333334in"
> height="0.1763888888888889in"} and
> ![](media/image686.wmf){width="0.5694444444444444in"
> height="0.2222222222222222in"}; this loop is stopped whenever
> ![](media/image675.wmf){width="0.12361111111111112in"
> height="0.1486111111111111in"}=0 and
> ![](media/image687.wmf){width="0.9583333333333334in"
> height="0.20833333333333334in"}.

The pitch is then defined as
![](media/image688.wmf){width="0.9861111111111112in"
height="0.2222222222222222in"}, which corresponds to the time offset
with respect to the beginning of the target signal (i.e. 34 ms after the
beginning of the past synthesis
![](media/image689.wmf){width="0.5277777777777778in" height="0.25in"}).

#### 5.4.3.2 PLC method selection

In case the last good frame prior to a loss was coded with HQ MDCT a
range of different specifically optimized PLC methods is available that
are selected based on second level criteria described in this subclause.

The criteria evaluated in this second level PLC method selection are:

\- Output sampling rate\
The output sampling rate
![](media/image690.wmf){width="0.3597222222222222in"
height="0.21666666666666667in"} in which response the second level PLC
method is selected is one out of the set of {8000Hz, 16000Hz, 32000Hz,
48000Hz}.

\- Bit rate\
The bit rate ![](media/image691.wmf){width="0.11041666666666666in"
height="0.12222222222222222in"}in which response the second level PLC
method is selected is one out of the set of the supported bit rates of
the EVS default operation mode \[5\].

\- Voicing\
The voicing parameter
![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"}in which response the second level PLC
method is selected is a binary parameter.

\- Correlation\
The correlation parameter
![](media/image680.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"}computed as in clause 5.4.3.1.2, in which
response the second level PLC method is selected is a correlation
coefficient defined in the number range from \[0...1\].

\- Transient condition\
The transient
condition![](media/image692.wmf){width="0.5541666666666667in"
height="0.20347222222222222in"} in which response the second level PLC
method is selected is a vector of dimension 2 of binary parameters
![](media/image693.wmf){width="0.2916666666666667in"
height="0.20833333333333334in"}indicating a transient condition
![](media/image694.wmf){width="0.1527777777777778in"
height="0.20833333333333334in"}in the last good frame or in the frame
before ![](media/image695.wmf){width="0.125in"
height="0.20833333333333334in"}. The determination of the transient
condition for a given HQ MDCT frame is specified in \[5\], subclause
5.3.2.4.1.1.

\- Spectral envelope stability based speech/music classification\
The Spectral envelope stability based speech/music classification
![](media/image696.wmf){width="0.29097222222222224in"
height="0.2298611111111111in"} in which response the second level PLC
method is selected is a binary parameter. This parameter is a
post-processed instance of the envelope stability parameter
![](media/image697.wmf){width="0.1388888888888889in"
height="0.16597222222222222in"}that is specified in \[5\], subclause
6.2.3.2.1.3.2.3 (Noise level adjustment). The spectral envelope
stability based speech/music classification is calculated during the
decoding of the preceding good HQ MDCT frame and stored for use in the
context of the PLC method selection during a bad frame.

The post-processing of this parameter is a Markov smoother with:

\- {speech, music} as hidden states,

\- the normalized envelope stability parameter,

![](media/image698.wmf){width="2.2083333333333335in"
height="0.3194444444444444in"} (164)

> and its reverse ![](media/image699.wmf){width="0.31666666666666665in"
> height="0.18888888888888888in"}\
> as direct state observation likelihoods for music and, respectively,
> speech,

\- and the transition probabilities\
![](media/image700.wmf){width="1.0215277777777778in"
height="0.20347222222222222in"}for going from speech or, respectively,
music state to speech state, and\
![](media/image701.wmf){width="1.0486111111111112in"
height="0.20347222222222222in"}for going from speech or, respectively,
music state to music state.

For each good HQ MDCT frame the following sequence of operations is
executed:

1\) Calculation of the normalized envelope stability parameter
![](media/image702.wmf){width="0.1527777777777778in"
height="0.20833333333333334in"}and its reverse
![](media/image703.wmf){width="0.31666666666666665in"
height="0.18888888888888888in"}.

2\) Calculation of a priori likelihoods
![](media/image704.wmf){width="0.19375in"
height="0.20833333333333334in"}for speech and music states based on the
state likelihoods for the instant
![](media/image705.wmf){width="0.1527777777777778in"
height="0.20833333333333334in"}of the previous (good) frame and the
transition probabilities:

![](media/image706.wmf){width="1.3611111111111112in"
height="0.4583333333333333in"} (165)

3\) Element-wise multiplication of the vector of a priori likelihoods
![](media/image707.wmf){width="0.19375in"
height="0.20833333333333334in"}with the vector of direct state
observation likelihoods for music and, respectively, speech:

![](media/image708.wmf){width="1.1388888888888888in"
height="0.5277777777777778in"} (166)

Subsequent normalization yield the vector of state likelihoods
![](media/image709.wmf){width="0.125in"
height="0.16666666666666666in"}of the current frame:

$p = \frac{p}{\left| p \right|}$ (167)

4\) Finally, the index of the largest element of the state likelihood
vector ![](media/image710.wmf){width="0.125in"
height="0.16666666666666666in"}is identified and taken as speech/music
classification result
![](media/image711.wmf){width="0.29097222222222224in"
height="0.2298611111111111in"} for the present frame.

![](media/image712.wmf){width="1.0in" height="0.2777777777777778in"}
(168)

5\) The state likelihood vector ![](media/image713.wmf){width="0.125in"
height="0.16666666666666666in"}of the current frame is stored for
subsequent use in the next good HQ MDCT frame.

With the above-specified parameters the second level PLC method
selection is performed as follows:

\- Firstly, if output sampling rate
![](media/image714.wmf){width="0.3597222222222222in"
height="0.21666666666666667in"}equals 8000 Hz, the PLC method specified
in clauses 5.4.3.3, 5.4.3.4 is applied.

\- Otherwise (if output sampling rate
![](media/image715.wmf){width="0.3597222222222222in"
height="0.21666666666666667in"}is equal or exceeds 16000 Hz), then:

\- in case the bit rate
![](media/image716.wmf){width="0.11041666666666666in"
height="0.12222222222222222in"}is less or equal to 48 kbps and

\- if the voicing parameter
![](media/image717.wmf){width="0.11041666666666666in"
height="0.13541666666666666in"}is set or the correlation parameter
![](media/image718.wmf){width="0.11041666666666666in"
height="0.13541666666666666in"}exceeds 0.85, then

> \- the frame loss concealment method specified in subclause 5.4.3.6 is
> applied;
>
> \- otherwise,
>
> \- the frame loss concealment method specified in subclause 5.4.3.5 is
> applied.
>
> \- otherwise (in case the bit rate
> ![](media/image719.wmf){width="0.11041666666666666in"
> height="0.12222222222222222in"}is larger than 48 kbps), then:
>
> \- the frame loss concealment method specified in subclause 5.4.3.6 is
> applied under the same condition as above (for bit rates less or equal
> to 48 kbps) except for the case that the spectral envelope stability
> based speech/music classification
> ![](media/image720.wmf){width="0.29097222222222224in"
> height="0.2298611111111111in"} indicates music, in which case this
> frame loss concealment method is only applied if the correlation
> parameter ![](media/image721.wmf){width="0.11041666666666666in"
> height="0.13541666666666666in"}is below 0.6 or if the voicing
> parameter ![](media/image722.wmf){width="0.11041666666666666in"
> height="0.13541666666666666in"}is set;
>
> \- otherwise, if the above condition is not satisfied the frame loss
> concealment method specified in subclause 5.4.3.5 is applied.

\- However, in addition to the conditions specified above, the frame
loss concealment method specified in subclause 5.4.3.6 is only applied
under the provision that the current frame is the first bad frame
following a good frame and that the transient condition vector does not
indicate a transient in the previous or it indicates a transient in the
frame before the previous frame. If this provision is not satisfied, the
frame loss concealment method specified in subclause 5.4.3.5 is applied.

The decoding of HQ MDCT for NB includes the following modules:

\- a frequency domain packet loss concealment (PLC) block,

\- a spectrum decoding block,

\- a memory update block,

\- an IMDCT block,

\- and a time-domain PLC block.

If it is determined that there is an erased frame, the erased frame is
concealed using a PLC method. The bad frame indicator (BFI) set to 1
indicates that a current frame is erased, or that no useful information
exists for that frame. Similarly, the Prev\_BFI flag set to 1 indicates
that a previous frame has been erased.

Figure 2 shows the block diagram for packet loss concealment of NB
signals for the MDCT mode. A frequency-domain approach operates on the
frequency domain signal such as the input to the IMDCT block in the
figure. A time-domain approach operates on the time domain signal after
the IMDCT block. When a frame erasure occurs, the spectral coefficients
of the current frame are estimated. To accomplish this using the
frequency-domain approach, the synthesized spectral coefficients of the
last good frame are repeated for the current frame with signal
modification such as a gain scaling and a random sign changing. In the
time-domain approach, an additional PLC operation is added to enhance
the performance of the frequency-domain approach depending on the input
signal characteristics. For this additional operation, the appropriate
packet loss concealment tool, either the phase matching tool or the
repetition and smoothing tool is selected.

![](media/image723.wmf){width="3.0659722222222223in"
height="5.583333333333333in"}

Figure 2: **Block diagram for NB PLC for MDCT mode**

#### 5.4.3.3 MDCT frame repetition with random sign and gain scaling

When a first frame erasure occurs, packet loss concealment is performed
as follows. In order to conceal the erasure, the signal characteristics
of a decoded signal are used, which results in a classification of the
characteristics of the decoded signal into a stationary and normal
frame. A current frame is determined to be transient using the frame
type (is\_transient) which is transmitted from the encoder. The energy
difference (energy\_diff) is used to determine if the current frame is
stationary, and is represented by the following equation. The energy
difference indicates the absolute value of a normalized energy
difference between energy *E~curr~* of the current frame and a moving
average *E~MA~* of per-frame energy. *E~MA~* will be updated to
*E~MA\_old~* in the next frame.

![](media/image724.wmf){width="1.2361111111111112in"
height="0.4583333333333333in"} (169)

Where,

![](media/image725.wmf){width="1.9722222222222223in"
height="0.2361111111111111in"} (170)

![](media/image726.wmf){width="1.3333333333333333in"
height="0.7083333333333334in"} (171)

Depending on the frame type and characteristics, scaling and a random
sign are used when the spectral coefficients are repeated for the
current erased frame.

if ( is\_transient == 0 ) {

if(energy\_diff \< ED\_THRES) {

/\* Stationary frame \*/

Repeating the spectral coefficients of the last good frame without
scaling;

}

else{

/\* Non-stationary frame \*/

Repeating the spectral coefficients of the last good frame with 3dB
scale-down;

}

else {

if( st-\>old\_is\_transient\[1\] == 1 ) {

Repeating the spectral coefficients of the last good frame with 3dB
scale-down;

}

else {

Repeating the spectral coefficients of the last good frame with 3dB
scale-down;

Use random sign from the 2^nd^ band (8^th^ spectral coefficient)

}

}

When multiple erasures have occurred, an adaptive fade-out by regression
method is used. In this adaptive fade-out by regression, a grouped
average norm value of an erased frame is predicted using K grouped
average norm values of the previous good frame through regression
analysis.

Figure 3 illustrates the structure of grouped sub-bands when the
regression analysis is applied to a narrowband (supported up to 4.0 KHz)
signal. Grouped average norm values obtained from grouped sub-bands form
a vector, which is referred to as an average vector of grouped norms. K
grouped average norm values of each grouped sub-band (GSb) are used for
the regression analysis.

![](media/image727.wmf){width="5.551388888888889in"
height="2.415277777777778in"}

Figure 3: **Structure of grouped sub-bands**

Figure 4 illustrates the concept of a linear regression analysis and a
non-linear regression analysis. Between the two methods the linear
regression analysis is applied to the adaptive fade-out, wherein the
\'average of norms\' indicates an average norm value obtained by
grouping several bands and is the target the regression analysis is
applied to. A linear regression analysis is performed when the quantized
value of the norm is used for an average norm value of a previous frame.
\'Number of PGF\', which is used for a regression analysis, indicates
the number of the previous good frames and is used for a regression
analysis is a variable. The linear regression analysis is represented by
equations (172) and (173).

![](media/image728.wmf){width="0.5965277777777778in" height="0.19375in"}
(172)

![](media/image729.wmf){width="2.0in" height="0.5694444444444444in"}
(173)

As in equation (172), when a linear equation is used, the upcoming
transition(*y*) is predicted by obtaining
![](media/image730.wmf){width="0.125in" height="0.1388888888888889in"}
and ![](media/image731.wmf){width="0.125in"
height="0.16666666666666666in"}. In this equation,
![](media/image732.wmf){width="0.125in" height="0.1388888888888889in"}
can be a frame index. In equation (173),
![](media/image733.wmf){width="0.125in" height="0.1388888888888889in"}
and ![](media/image734.wmf){width="0.125in"
height="0.16666666666666666in"} are obtained by an inverse matrix.
Gauss-Jordan Elimination is a simple method of obtaining an inverse
matrix.

![](media/image735.wmf){width="4.040972222222222in"
height="1.8930555555555555in"}

Figure 4: **The concept of a linear regression analysis and a non-linear
regression analysis**

Figure 5 is a block diagram of a packet loss concealment block with
adaptive fade-out. Referring to Figure 5, the signal characteristic
determiner determines the characteristics of a signal by using a decoded
signal and classifies the characteristics of the decoded signal into
transient and normal frames. A method of determining a transient frame
is now described. The current frame classification of transient is
determined by two parameters: the frame type (is\_transient) which is
transmitted from the encoder, and the energy difference (energy\_diff),
which is represented by Equation (169).

if(energy\_diff \< ED\_THRES && is\_transient == 0 ) {

/\* Not Transient \*/

num\_pgf = 4;

}

else{

num\_pgf = 2;

}

In the above context, ED\_THRES denotes a threshold and is set to 1.0.
According to the result of the transient determination, the number of
PGFs (num\_pgf), referred to in the subclause on regression analysis,
can be controlled for packet loss concealment.

Another parameter for packet loss concealment is a scaling method of
burst erasure duration. The same energy difference value is used for the
duration of a single burst.

if((energy\_diff\<ED\_THRES) && (is\_transient==0)) {

/\* Not Transient \*/

mute\_start = 5;

random\_start = 2;

}

else {

mute\_start = 2;

random\_start = 2;

}

If it is determined that the current frame is an erasure and is not
transient, then when a burst erasure occurs frames starting from the
fifth frame of the burst are forcibly scaled to a fixed value of 3 dB
regardless of the regression analysis of the decoded spectral
coefficient of the previous frame. Otherwise, if it is determined that
the current frame that is erased is transient, when a burst erasure
occurs, frames starting from the second frame are forcibly scaled to a
fixed value of 3 dB regardless of the regression analysis of the decoded
spectral coefficient of the previous frame.

Because regression analysis is performed only when a burst erasure has
occurred, when nbLostCmpt indicates the number of contiguous erased
frames is two, that is, from the second contiguous erased frame, the
regression analysis is performed.

if (nbLostCmpt==2){

regression\_anaysis();

}

Even though an nth frame is a good frame, if the
![](media/image736.wmf){width="0.4027777777777778in"
height="0.19375in"}th and
![](media/image737.wmf){width="0.4027777777777778in"
height="0.20833333333333334in"}th frames are erased frames, a totally
different signal is generated in an overlapping process. Thus, when
erasures occur in a non-consecutive order (an erasure frame, a good
frame, and an erasure frame), although nbLostCmpt of the third frame
(the second erasure) is 1, nbLostCmpt is forcibly increased by 1. As a
result, nbLostCmpt is 2, and it is determined that a burst erasure has
occurred, and thus the regression analysis will be used.

if( prev\_old\_bfi == 1 && nbLostCmpt == 1 && output\_frame\_org ==
L\_FRAME8k )

{

nbLostCmpt++;

}

In the above context, prev\_old\_bfi denotes frame erasure information
of the second previous frame. This process is applicable when the
current frame is an erased frame. To reduce complexity, the regression
analyzer block forms each group by grouping 8 or 2 bands, and applying
the regression analysis to the mean vector of grouped norms. The number
of previous good frames for the regression analysis is set to either 2
or 4, and is controlled by the result of the signal characteristic
determiner block. In addition, the number of rows of the matrix for the
regression analysis is set to 2. As a result of the regression analysis
by the regression analyzer block, an average norm value of each group is
predicted for an erased frame and is done by calculating the values
![](media/image730.wmf){width="0.125in" height="0.1388888888888889in"}
and ![](media/image731.wmf){width="0.125in"
height="0.16666666666666666in"} from a linear regression analysis
equation (173). In this block the calculated value
![](media/image730.wmf){width="0.125in" height="0.1388888888888889in"}
can be adjusted to the predetermined range as follows. In EVS the range
is always limited to a negative value. In the following pseudo-code,
norm\_values is an average norm value of each group in the previous good
frame and norm\_p is a predicted average norm value of each group.

if( a \> 0 ){

a = 0;

norm\_p\[i\] = norm\_values\[0\];

}

else {

norm\_p\[i\] = (b+a\*(nbLostCmpt-1+num\_pgf);

}

With this modified value of ![](media/image730.wmf){width="0.125in"
height="0.1388888888888889in"}, the average norm value of each group is
predicted. When the predicted norm is larger than zero and the norm of
the previous frame is non-zero, the gain calculator block calculates a
gain between the average norm value of each group that is predicted for
the erased frame and an average norm value of each group in the previous
good frame. Otherwise, the gain is scaled down by 3 dB from the initial
value of 1.0.

The calculated gain is also adjusted to a predetermined range. In EVS,
the maximum value of the gain is 1.0.

The scaler block applies gain scaling to the previous good frame to
predict spectral coefficients of the erased frame. The scaler block also
applies adaptive muting to the erased frame and a random sign to
predicted spectral coefficients according to characteristics of an input
signal, which is also controlled by the results of the signal
characteristic determiner block.

The number indicated by mute\_start indicates that muting forcibly
starts when bfi\_cnt is equal to or greater than mute\_start and when
continuous frame erasures occur. In addition, random\_start, related to
the random sign, is analysed in the same way.

According to a method of applying adaptive muting, spectral coefficients
are forcibly down-scaled by 3dB. In addition, the sign of each of the
spectral coefficients is randomly modified to reduce modulation noise
generated due to repetition of spectral coefficients in each frame.

In addition, the random sign is applied to frequency bands equal to or
higher than the second frequency band, as it should be better to use the
sign of a spectral coefficient that is identical to that of the previous
frame in a very low frequency band (0\~200Hz for the first band).
Accordingly, a sharp change in the signal can be smoothed, and an erased
frame accurately restored to be adaptive to the characteristics of the
signal, in particular, a transient characteristic.

![](media/image738.wmf){width="3.8069444444444445in"
height="4.322222222222222in"}

Figure 5: **Block diagram of a** packet loss **concealment block with
adaptive fade-out**

#### 5.4.3.4 MDCT frame repetition with sign prediction

An analysis of the sign change of the MDCT coefficients in the received
frames is continuously performed. The analysis of
![](media/image739.wmf){width="0.5277777777777778in"
height="0.2638888888888889in"}and
![](media/image740.wmf){width="0.6388888888888888in"
height="0.2638888888888889in"}is performed on 4-dimensional bands up to
1.6 kHz (![](media/image741.wmf){width="0.4027777777777778in"
height="0.16666666666666666in"} MDCT coefficients divided into
![](media/image742.wmf){width="0.4027777777777778in"
height="0.16666666666666666in"} bands).

Two 16-dimensional state variables, used to determine the sign of the
reconstructed MDCT vector,
![](media/image743.wmf){width="0.4722222222222222in" height="0.25in"}and
![](media/image744.wmf){width="0.5694444444444444in"
height="0.25in"}hold the number of sign switches between consecutive
frames. The analysis takes also into account signal dynamics (measured
by a transient detector), to decide on the reliability of past data.
Updates for both state variables are done only
for![](media/image745.wmf){width="0.9722222222222222in"
height="0.16666666666666666in"}, if
![](media/image746.wmf){width="0.94375in"
height="0.16666666666666666in"}the values are set to zero.

Within a sub- band![](media/image747.wmf){width="0.8055555555555556in"
height="0.18055555555555555in"}, first state variable is incremented
whenever the sign of the corresponding MDCT coefficients switches:

![](media/image748.wmf){width="2.1666666666666665in"
height="0.7888888888888889in"} (174)

The second state variable accumulates number of sign switches over
consecutive frames:

![](media/image749.wmf){width="2.25in" height="0.24861111111111112in"}
(175)

When frame ![](media/image750.wmf){width="0.15625in"
height="0.13541666666666666in"}is lost, the missing MDCT vector is
reconstructed by copying the last available coefficients. The sign of
the reconstructed vector can be preserved or changed on a sub-band basis
(every 4 coefficients). Inside a band
![](media/image751.wmf){width="0.125in"
height="0.16666666666666666in"}the decision whether to change the sign
or not is based on comparing the second state variable to a
pre-determined threshold as follows (wherein a sign flip or reversal is
indicated by -1 and preservation of the sign is indicated by +1):

> ![](media/image752.png){width="3.5069444444444446in"
> height="0.5555555555555556in"} (176)

The threshold ![](media/image753.wmf){width="0.13541666666666666in"
height="0.15625in"}is adjusted to the past decision of the transient
detector. The sequential decision logic is illustrated in Table 10.

Table 10: Sign extrapolation decision logic

  -- --
     
     
     
  -- --

+----------------------------------+----------------------------------+
| 1.  If any of frames             | Apply random sign to the copied  |
|     > ![](media/image754.w       | coefficients                     |
| mf){width="0.3229166666666667in" |                                  |
|     >                            |                                  |
|  height="0.16666666666666666in"} |                                  |
|     > or                         |                                  |
|     > ![](media                  |                                  |
| /image755.wmf){width="0.34375in" |                                  |
|     >                            |                                  |
|  height="0.16666666666666666in"} |                                  |
|     > contains transient         |                                  |
+----------------------------------+----------------------------------+
| 2.  If frames                    | Apply sign extrapolation with    |
|     > ![](media/image754.w       | ![](media/image757.w             |
| mf){width="0.3229166666666667in" | mf){width="0.3333333333333333in" |
|     >                            | height="0.16666666666666666in"}  |
|  height="0.16666666666666666in"} |                                  |
|     > or                         |                                  |
|     > ![](media                  |                                  |
| /image755.wmf){width="0.34375in" |                                  |
|     >                            |                                  |
|  height="0.16666666666666666in"} |                                  |
|     > are good, but frame        |                                  |
|     > ![](media/image756.w       |                                  |
| mf){width="0.3333333333333333in" |                                  |
|     >                            |                                  |
|  height="0.16666666666666666in"} |                                  |
|     > contains transient         |                                  |
+----------------------------------+----------------------------------+
| 3.  If frames                    | Apply sign extrapolation with    |
|     > ![](media/image754.w       | ![](media                        |
| mf){width="0.3229166666666667in" | /image759.wmf){width="0.34375in" |
|     > height="0                  | height="0.16666666666666666in"}  |
| .16666666666666666in"},![](media |                                  |
| /image755.wmf){width="0.34375in" |                                  |
|     >                            |                                  |
| height="0.16666666666666666in"}, |                                  |
|     > and                        |                                  |
|     > ![](media/image758.w       |                                  |
| mf){width="0.3333333333333333in" |                                  |
|     >                            |                                  |
|  height="0.16666666666666666in"} |                                  |
|     > are good                   |                                  |
+----------------------------------+----------------------------------+

#### 5.4.3.5 Phase ECU

Phase ECU is a frame loss concealment method especially suitable for
general audio and music signals. It provides a smooth and faithful time
evolution of the reconstructed signal for a lost frame, wherein the
audible impact of a frame loss is minimized.

Phase ECU is a frame loss concealment technique that operates with a
sinusoidal model under the assumption that the audio signal is composed
of a limited number of individual sinusoidal components. The general
principle of Phase ECU comprises sinusoidal analysis of a previously
received good HQ MDCT coded frame of the audio signal (analysis frame),
wherein the sinusoidal analysis involves identifying frequencies of
sinusoidal components of the audio signal. Further, a sinusoidal model
is applied on this previously synthesized frame, wherein it is used as a
prototype frame in order to create a substitution frame for a lost audio
frame. The creation of the substitution frame is done by time-evolving
the identified sinusoidal components of the prototype frame, up to the
time instance of the lost audio frame, in response to the corresponding
identified sinusoidal frequencies.

In more detail Phase ECU operation comprises the steps of sinusoidal
analysis, described in subclause 5.4.3.5.2, and application of the
sinusoidal model based on a prototype frame of the earlier synthesized
signal in order to generate a substitution frame for the lost audio
frame, described in subclause 5.4.3.5.3. In addition and prior to this
basic Phase ECU operation a transient analysis step is carried out,
described in subclause 5.4.3.5.1 with the purpose to detect audio signal
and burst frame loss conditions under which the basic Phase ECU
operation is adapted in order to ensure maximum reconstruction signal
quality.

##### 5.4.3.5.1 Transient analysis

The purpose of the calculations in transient analysis is the detection
of properties of the previously reconstructed good signal frame or the
frame loss statistics that could lead to suboptimal signal
reconstruction quality with the Phase ECU. Upon such detected conditions
phase and magnitude of the substitution frame are selectively adjusted
in order to mitigate potential quality degradations. Conditions under
which such adjustments are carried out are detected transients or burst
losses with several consecutive frame losses. The result of the
transient analysis is phase and magnitude modification factors
corresponding to such adjustments.

Transient analysis is performed on each lost frame, and the following
steps are performed for the first lost frame or for the second lost
frame in case the first lost frame was handled with the method according
to subclause 5.4.3.6. For subsequent lost frames transient analysis
relies on previously calculated and stored parameters (that were
calculated based on the synthesis of the last good HQ MDCT frame). For
these losses transient analysis adjusts magnitude spectrum attenuation
factors and phase dithering degrees in response to detected transient or
burst loss condition.

The transient analysis is performed in the frequency domain. Two FFTs
are performed on a left and a right part of the analysis frame buffer
which contains the previous synthesis

![](media/image760.wmf){width="2.4583333333333335in"
height="0.5118055555555555in"} (177)

where ![](media/image761.wmf){width="0.3194444444444444in"
height="0.2076388888888889in"} is the length of the transient analysis,
set to 64, 128, or 192 for WB, SWB, and FB, and
![](media/image762.wmf){width="0.3888888888888889in"
height="0.2076388888888889in"}is a hamming window of corresponding
length. The resulting FFT spectrum is split into bands according to
Table 11 that are approximately following the size of the human auditory
critical bands, and the energy in each band is calculated.

Table 11: Band start of Phase ECU

  ------------------------------------------------------------------------------------- --- --- --- ---- ---- ---- ---- ----- -----
  ![](media/image763.wmf){width="0.125in" height="0.16597222222222222in"}               0   1   2   3    4    5    6    7     8
  ![](media/image764.wmf){width="0.5138888888888888in" height="0.2076388888888889in"}   1   3   6   10   16   32   64   128   192
  ------------------------------------------------------------------------------------- --- --- --- ---- ---- ---- ---- ----- -----

![](media/image765.wmf){width="1.4722222222222223in"
height="1.0930555555555554in"} (178)

Next the ratio of these energies is calculated as

![](media/image766.wmf){width="1.0138888888888888in"
height="0.4152777777777778in"} (179)

This means that the transient detection is made frequency selectively
for each frequency band![](media/image767.wmf){width="0.125in"
height="0.16597222222222222in"}. The gain
![](media/image768.wmf){width="0.5138888888888888in"
height="0.2076388888888889in"} is then compared with an upper and a
lower threshold for onset or respectively offset detection. If
![](media/image769.wmf){width="0.7916666666666666in"
height="0.2076388888888889in"}or
![](media/image770.wmf){width="0.8194444444444444in"
height="0.2076388888888889in"}is fulfilled, then band
![](media/image771.wmf){width="0.125in"
height="0.17916666666666667in"}contains a transient and
![](media/image772.wmf){width="0.4861111111111111in"
height="0.2076388888888889in"}is set to 1. The gains
![](media/image773.wmf){width="0.5277777777777778in"
height="0.23472222222222222in"}are set to 1. If a band has a transient,
then gain ![](media/image773.wmf){width="0.5277777777777778in"
height="0.23472222222222222in"}is updated to:

![](media/image774.wmf){width="1.625in" height="0.27708333333333335in"}
(180)

The gains ![](media/image773.wmf){width="0.5277777777777778in"
height="0.23472222222222222in"} for the first lost frame are saved
into![](media/image775.wmf){width="0.5277777777777778in"
height="0.23472222222222222in"}.

The derivation of magnitude and phase modification factors in response
to a detected burst loss condition is described in the following. The
variable ![](media/image776.wmf){width="0.3055555555555556in"
height="0.2076388888888889in"}is set to 1,
![](media/image777.wmf){width="0.3194444444444444in"
height="0.2076388888888889in"}is set to 0,
and![](media/image778.wmf){width="0.69375in"
height="0.2076388888888889in"}. An average energy of each band is
calculated:

![](media/image779.wmf){width="1.9861111111111112in"
height="0.45694444444444443in"} (181)

![](media/image780.wmf){width="0.5138888888888888in"
height="0.2361111111111111in"}corresponds to a low-resolution spectrum
of the last good frame. This spectrum is used as part of the burst loss
handling feature of Phase ECU. It is used for a spectrally shaped
additive noise signal to which the substitution signal is pulled in case
of burst frame losses.

For subsequent lost frames, the gain
![](media/image781.wmf){width="0.5277777777777778in"
height="0.23472222222222222in"}is updated according to:

![](media/image782.wmf){width="1.7916666666666667in"
height="0.27708333333333335in"} (182)

where

$\left\{ \begin{matrix}
G_{\text{att}} = 0, \\
G_{\text{att}} = K_{\text{att}}\left( N_{\text{lost}} - T_{\text{att}} \right), \\
G_{\text{att}} = \text{15}K_{\text{att}} + \left( N_{\text{lost}} - T_{\text{att}} - \text{15} \right) \cdot 6\text{.}\text{0206}, \\
K_{\text{att}} = 4 - \text{round}(S) \\
T_{\text{att}} = 2 + \text{round}(S) \\
\end{matrix} \right.\ \begin{matrix}
N_{\text{lost}} < T_{\text{att}} \\
\ T_{\text{att}} < N_{\text{lost}} \leq \text{15} + T_{\text{att}} \\
N_{\text{lost}} > \text{15} + T_{\text{att}} \\
 \\
 \\
\end{matrix}$ (183)

Here ![](media/image783.wmf){width="0.3333333333333333in"
height="0.2076388888888889in"}is the number of consecutive lost frames
and$S \in \left\lbrack 0,1 \right\rbrack$is envelope stability feature
described in \[5\] subclause 6.2.3.2.1.3.3, where the range endpoints 0
and 1 represent speech and music respectively. If
![](media/image784.wmf){width="0.6111111111111112in"
height="0.2076388888888889in"}then
![](media/image785.wmf){width="1.0833333333333333in"
height="0.20833333333333334in"}.

The attenuation factors
![](media/image776.wmf){width="0.3055555555555556in"
height="0.2076388888888889in"} and
![](media/image777.wmf){width="0.3194444444444444in"
height="0.2076388888888889in"}are updated as:

![](media/image786.wmf){width="1.4722222222222223in"
height="0.4840277777777778in"} (184)

Through variable ![](media/image776.wmf){width="0.3055555555555556in"
height="0.2076388888888889in"} the concealment method is modified by
selectively adjusting the magnitude of the substitution frame spectrum,
based on the frequency domain transient detector
status![](media/image787.wmf){width="0.5138888888888888in"
height="0.2076388888888889in"}, see equation (189).

The scaling factor ![](media/image788.wmf){width="0.3194444444444444in"
height="0.20833333333333334in"}is used to scale the spectrally shaped
additive noise signal such that, except for the incorporated gradual
muting behaviour through factor
![](media/image789.wmf){width="0.3611111111111111in"
height="0.20833333333333334in"}, it compensates for the energy loss
caused by the attenuation with factor
![](media/image790.wmf){width="0.3055555555555556in"
height="0.20833333333333334in"}. This is an aspect of the long-term
muting behaviour which is outlined in subclause 5.4.6.2.2.

For ![](media/image791.wmf){width="0.3194444444444444in"
height="0.16597222222222222in"},
![](media/image792.wmf){width="0.3194444444444444in"
height="0.19236111111111112in"} is further adjusted
as![](media/image793.wmf){width="0.9583333333333334in"
height="0.19236111111111112in"} and for
![](media/image794.wmf){width="0.3194444444444444in"
height="0.16597222222222222in"}![](media/image795.wmf){width="0.9583333333333334in"
height="0.2076388888888889in"}. This superimposes a low-pass
characteristic on the additive noise signal, which avoids unpleasant
high-frequency noise in the substitution signal.

The variable![](media/image796.wmf){width="0.8465277777777778in"
height="0.2076388888888889in"} is initialized to 0, and for
![](media/image797.wmf){width="1.1805555555555556in"
height="0.2076388888888889in"}the phase dither is calculated:

![](media/image798.wmf){width="2.9305555555555554in"
height="0.42916666666666664in"} (185)

##### 5.4.3.5.2 Spectrum analysis

The spectrum analysis is carried out in the frequency domain. It is only
done once for the first lost frame after a good HQ MDCT frame. The
buffer with the previous synthesis of the last good HQ MDCT frame
(analysis frame) is windowed and passed through a FFT.

![](media/image799.wmf){width="2.263888888888889in"
height="0.23472222222222222in"} (186)

where ![](media/image800.wmf){width="0.44375in"
height="0.2076388888888889in"}is a hamming-rectangular window, and
![](media/image801.wmf){width="0.34652777777777777in"
height="0.23472222222222222in"}is the length of the FFT set to 512,
1024, or 1536 for WB, SWB, and FB signals,

![](media/image802.wmf){width="3.4583333333333335in"
height="1.0659722222222223in"} (187)

and ![](media/image803.wmf){width="0.19375in"
height="0.2076388888888889in"}is the length of the hamming part, and is
96, 192, or 288 for WB, SWB, and FB.

The spectrum ![](media/image804.wmf){width="0.44375in"
height="0.2076388888888889in"}is saved and used for all consecutive
frame losses. Then the magnitude spectrum
![](media/image805.wmf){width="0.4861111111111111in"
height="0.23472222222222222in"} is calculated. Then the peaks of this
magnitude spectrum are located by a peak picking method. The number of
found peaks is![](media/image806.wmf){width="0.4305555555555556in"
height="0.23472222222222222in"}, and the peaks locations
are![](media/image807.wmf){width="1.4722222222222223in"
height="0.23472222222222222in"}. The frequency resolution of these peak
locations is however still insufficient for good Phase ECU performance,
since the true frequencies of the sinusoidal model components are rather
found in the vicinity of them. Thus, after the peaks in the magnitude
FFT spectrum are found, their positions are further refined to make them
available in highest possible resolution. The refinement is carried out
by using parabolic interpolation, which yields the fractional peak
locations![](media/image808.wmf){width="1.4722222222222223in"
height="0.23472222222222222in"}.

This sinusoidal model is also used in reconstruction of the lost audio
frame.

##### 5.4.3.5.3 Frame reconstruction

The substitution frame for the lost frame is calculated by applying the
sinusoidal model on a frame of the previously synthesized good frame
signal, where this frame serves as a prototype frame. The previously
calculated sinusoidal components of this prototype frame are time
evolved to the time instant of the lost frame. For numerical simplicity,
this prototype frame and its spectrum are chosen to be identical to the
windowed analysis frame and, respectively, its already calculated and
saved spectrum (see subclause 5.4.3.5.2). While the exact time evolution
of the sinusoids of the windowed prototype frame would require a complex
superposition of frequency-shifted, phase-evolved and sampled instances
of the spectrum of the used window function, Phase ECU operates with an
approximation of the window function spectrum such that it comprises
only a region around its main lobe. With this approximation the
substitution frame spectrum is composed of strictly non-overlapping
portions of the approximated window function spectrum and hence the
time-evolution of the sinusoids of the windowed prototype frame reduces
to phase-shifting the sinusoidal components of the prototype spectrum in
![](media/image809.wmf){width="0.1388888888888889in"
height="0.16597222222222222in"}-regions around the corresponding
spectral peaks ![](media/image810.wmf){width="0.125in"
height="0.19236111111111112in"}by an
amount![](media/image811.wmf){width="0.3055555555555556in"
height="0.2076388888888889in"}. Note that this
amount![](media/image811.wmf){width="0.3055555555555556in"
height="0.2076388888888889in"}merely depends on the respective
sinusoidal frequency (peak location)
![](media/image812.wmf){width="1.4861111111111112in"
height="0.23472222222222222in"} and the time shift between the lost
frame and the prototype frame. This is expressed in the following
equation. The phase shift is calculated as:

![](media/image813.wmf){width="3.1805555555555554in"
height="0.45694444444444443in"} (188)

where ![](media/image814.wmf){width="0.2916666666666667in"
height="0.23472222222222222in"}is the offset in number of samples since
the last good frame.
![](media/image815.wmf){width="0.2916666666666667in"
height="0.23472222222222222in"} is a variable incremented by
![](media/image816.wmf){width="0.1388888888888889in"
height="0.15138888888888888in"}for each lost frame,
and![](media/image817.wmf){width="0.16666666666666666in"
height="0.15138888888888888in"}equals 40, 80, or 120 for WB, SWB, or FB
signals.

Note, that if either of the last two frames have the
![](media/image818.wmf){width="0.6805555555555556in"
height="0.16666666666666666in"}flag set, then the number of peaks is set
to 0.

Next the spectrum around the spectral peaks is updated and random noise
component related to burst loss handling is added

![](media/image819.wmf){width="3.19375in"
height="0.24861111111111112in"} (189)

where![](media/image820.wmf){width="1.0965277777777778in"
height="0.2076388888888889in"}, ![](media/image821.wmf){width="0.125in"
height="0.16597222222222222in"}is set according to Table 11,
![](media/image822.wmf){width="0.3055555555555556in"
height="0.17916666666666667in"}is a random number between -1 and 1, and

![](media/image823.wmf){width="1.9305555555555556in"
height="0.8722222222222222in"} (190)

If ![](media/image796.wmf){width="0.8465277777777778in"
height="0.2076388888888889in"}is non-zero, the amplitude is adjusted,
and a small random component is added to the phase

![](media/image824.wmf){width="1.9166666666666667in"
height="0.19236111111111112in"} (191)

![](media/image825.wmf){width="2.6805555555555554in"
height="0.2076388888888889in"} (192)

The spectral coefficients which have not been updated are also updated
in a similar manner but with a randomized phase.

For clarity it is to be noted that the first additive term in equation
(189) relates to phase shifting the sinusoidal components of the
prototype spectrum. In addition, if
![](media/image796.wmf){width="0.8465277777777778in"
height="0.2076388888888889in"}is non-zero, the phase is modified with a
random component. This avoids quality degrading tonal sounds due to too
strong periodicity and is useful both in case of transients and burst
frame loss. In addition, for the same reason the magnitude of the
prototype frame spectral coefficients is attenuated with the scaling
factor![](media/image790.wmf){width="0.3055555555555556in"
height="0.20833333333333334in"}. The second additive term in equation
(189) modifies the substitution frame spectral coefficients by an
additive noise component, where the magnitude of the additive noise
component corresponds to the scaled coefficient of the low-resolution
magnitude spectrum of the previous good frame,
![](media/image826.wmf){width="0.3333333333333333in"
height="0.2361111111111111in"}, which derivation is described in
subclause 5.4.3.5.1. The scaling factor
![](media/image788.wmf){width="0.3194444444444444in"
height="0.20833333333333334in"}is chosen such that, except for the
incorporated gradual muting behaviour, it compensates for the energy
loss caused by the attenuation with factor
![](media/image790.wmf){width="0.3055555555555556in"
height="0.20833333333333334in"}. This is an aspect of the long-term
muting behaviour which is outlined in subclause 5.4.6.2.2.

The reconstructed substitution frame spectrum is passed through the IFFT
to create a time domain substitution frame.

![](media/image827.wmf){width="1.3333333333333333in"
height="0.23472222222222222in"} (193)

Where ![](media/image828.wmf){width="0.8055555555555556in"
height="0.23472222222222222in"}.The signal
![](media/image829.wmf){width="0.4583333333333333in"
height="0.23472222222222222in"}is zero extended outside of this range.
This signal ![](media/image830.wmf){width="1.44375in"
height="0.23472222222222222in"} is then windowed and time-domain aliased
as described in \[5\], clause 5.3.2.2
(![](media/image831.wmf){width="0.3194444444444444in"
height="0.2076388888888889in"}is the number of zero samples in the ALDO
window). The resulting windowed and time-domain aliased signal is then
overlap-added with the previous frame as described in \[5\], clause
6.2.4.1.

#### 5.4.3.6 MDCT concealment based on sinusoidal synthesis and adaptive noise filling

The MDCT concealment based on sinusoidal synthesis and adaptive noise
injection is illustrated in Figure 6. Note that the resampling to 8 kHz
and pitch search are already described in clause 5.4.3.1.

![](media/image832.wmf){width="6.685416666666667in"
height="0.8555555555555555in"}

Figure 6: **Block diagram of MDCT concealment** based on sinusoidal
synthesis\
and adaptive noise filling

##### 5.4.3.6.1 FFT

The pitch cycle of length
![](media/image833.wmf){width="0.16666666666666666in"
height="0.2222222222222222in"} is extracted from the resampled past
synthesis ![](media/image689.wmf){width="0.5277777777777778in"
height="0.25in"} of length 320 as:
![](media/image834.wmf){width="3.0833333333333335in"
height="0.2777777777777778in"}. This pitch cycle is analyzed in
frequency domain using the following steps:

\- The signal ![](media/image835.wmf){width="1.5in" height="0.25in"} is
linearly interpolated to a length corresponding to a power of 2 to
obtain the segment ![](media/image836.wmf){width="0.625in"
height="0.25in"} of length
![](media/image837.wmf){width="0.2222222222222222in"
height="0.2222222222222222in"} such that
![](media/image838.wmf){width="0.875in" height="0.25in"} where
![](media/image839.wmf){width="0.18055555555555555in"
height="0.2222222222222222in"} is the rounding upward to the nearest
integer. A linear interpolation is applied as follows:

![](media/image840.wmf){width="5.180555555555555in"
height="0.7472222222222222in"} (194)

> where ![](media/image841.wmf){width="0.20833333333333334in"
> height="0.2222222222222222in"} is the rounding downward to the nearest
> integer and ![](media/image842.wmf){width="1.1805555555555556in"
> height="0.2222222222222222in"}.

\- The segment ![](media/image836.wmf){width="0.625in" height="0.25in"}
is decomposed in frequency domain by FFT of length
![](media/image843.wmf){width="0.7083333333333334in"
height="0.2222222222222222in"} to obtain the spectrum
![](media/image844.wmf){width="0.3333333333333333in"
height="0.20833333333333334in"},
![](media/image845.wmf){width="1.1527777777777777in"
height="0.2222222222222222in"}

\- The amplitude spectrum ![](media/image846.wmf){width="0.375in"
height="0.25in"}is computed for
![](media/image847.wmf){width="1.3194444444444444in"
height="0.2222222222222222in"} and the overall amplitude is also
computed as:

![](media/image848.wmf){width="1.19375in" height="0.4701388888888889in"}
(195)

##### 5.4.3.6.2 Selection of sinusoidal components

Sinusoidal components are selected by first detecting the number
![](media/image849.wmf){width="0.375in" height="0.25in"} of spectral
peaks following condition:
![](media/image850.wmf){width="1.0555555555555556in" height="0.25in"}
and ![](media/image851.wmf){width="1.0694444444444444in"
height="0.25in"} . When the binary voicing indication has the value
![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"}=1, the peak selection is extended to
select not only the peak at index
![](media/image852.wmf){width="0.1388888888888889in"
height="0.18055555555555555in"} meeting the preceding condition but also
neighboring peaks at index
![](media/image853.wmf){width="0.3194444444444444in"
height="0.18055555555555555in"} and
![](media/image854.wmf){width="0.3194444444444444in"
height="0.18055555555555555in"}; this allows capturing a larger portion
of the overall spectral energy and lowering the noise to be re-injected
for voiced signals.

The final number of peaks to be kept is
![](media/image855.wmf){width="1.6805555555555556in" height="0.25in"}to
reduce the computational load of the subsequent sinusoidal synthesis.
This final selection of peaks is performed by iteratively selecting the
peak maximizing ![](media/image856.wmf){width="0.375in" height="0.25in"}
among peaks that are not yet selected as long as the conditions
![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"}=1 or
![](media/image857.wmf){width="1.7083333333333333in"
height="0.3194444444444444in"} is still met, where the latter condition
ensures that 70% of the amplitude spectrum is covered.

For each *i*-th peak that gets selected, the amplitude
![](media/image858.wmf){width="0.7222222222222222in" height="0.25in"},
phase ![](media/image859.wmf){width="0.8055555555555556in"
height="0.2222222222222222in"} and normalized frequency
![](media/image860.wmf){width="0.9305555555555556in"
height="0.2222222222222222in"} are computed.

##### 5.4.3.6.3 Sinusoidal synthesis

A segment of length ![](media/image861.wmf){width="0.2638888888888889in"
height="0.2222222222222222in"} corresponding to 2 frames of 20 ms (40
ms) and 8 kHz to resampling delay is generated from the
![](media/image862.wmf){width="0.6111111111111112in" height="0.25in"}
selected frequency bins as:

![](media/image863.wmf){width="2.0555555555555554in"
height="0.4840277777777778in"}, ![](media/image864.wmf){width="0.125in"
height="0.22152777777777777in"}![](media/image865.wmf){width="1.0277777777777777in"
height="0.2222222222222222in"} (196)

This sinusoidal synthesis is implemented using an autoregressive of
order 2. The extra segment length (after the current frame) is used for
crossfading with the next decoded frame and to compensate for resampling
delay.

##### 5.4.3.6.4 Adaptive noise filling

Frequency components that do not correspond to selected sinusoids below
4 kHz or that are above 4 kHz are re-injected by adaptive noise filling,
in particular to compensate for energy loss.

The pitch computed according to clause 5.4.3.1.2 is mapped to the output
sampling rate ![](media/image866.wmf){width="0.3333333333333333in"
height="0.2361111111111111in"} as![](media/image867.wmf){width="0.25in"
height="0.2222222222222222in"}, where
![](media/image868.wmf){width="0.1388888888888889in"
height="0.18055555555555555in"} is the decimation factor used in
sub-clause 5.4.3.1.1 with
![](media/image869.wmf){width="0.1388888888888889in"
height="0.18055555555555555in"}=2, 4, 6 for
![](media/image866.wmf){width="0.3333333333333333in"
height="0.2361111111111111in"}=16, 32 or 48 kHz respectively. For a 20
ms frame length ![](media/image870.wmf){width="0.3888888888888889in"
height="0.25in"} at ![](media/image866.wmf){width="0.3333333333333333in"
height="0.2361111111111111in"}, a residual signal is computed as:

![](media/image871.wmf){width="1.6805555555555556in"
height="0.27708333333333335in"}, ![](media/image864.wmf){width="0.125in"
height="0.22152777777777777in"}![](media/image872.wmf){width="1.1111111111111112in"
height="0.2222222222222222in"} (197)

where the residual length is
![](media/image873.wmf){width="0.4861111111111111in"
height="0.2222222222222222in"} ![](media/image874.wmf){width="0.25in"
height="0.2222222222222222in"} if ![](media/image875.wmf){width="0.25in"
height="0.2222222222222222in"}\<![](media/image876.wmf){width="0.3888888888888889in"
height="0.25in"} and
![](media/image877.wmf){width="0.4861111111111111in"
height="0.2222222222222222in"}![](media/image876.wmf){width="0.3888888888888889in"
height="0.25in"} otherwise. Then, if the binary voicing indicator has
the value ![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"}=1, the residual is further scaled down by
a factor of 0.25 as ![](media/image878.wmf){width="1.4305555555555556in"
height="0.22152777777777777in"},
![](media/image872.wmf){width="1.1111111111111112in"
height="0.2222222222222222in"}.

This residual signal is repeated iteratively by adding blocks of
variable length until the length of 2 frames (40 ms) is reached. The
start index for the residual repetition is initialized to
![](media/image879.wmf){width="0.6111111111111112in"
height="0.2222222222222222in"}. In the
![](media/image880.wmf){width="0.16666666666666666in"
height="0.1388888888888889in"}-th iteration:

\- A block length ![](media/image881.wmf){width="0.5138888888888888in"
height="0.25in"} is pseudo-randomly computed by alternating between
![](media/image882.wmf){width="1.94375in" height="0.25in"} and
![](media/image883.wmf){width="1.94375in" height="0.25in"}, where
![](media/image884.wmf){width="0.3611111111111111in"
height="0.18055555555555555in"} is a random number between 0 and 1.

\- A sine window![](media/image885.wmf){width="0.7222222222222222in"
height="0.25in"} of length
![](media/image886.wmf){width="0.3333333333333333in"
height="0.2222222222222222in"} is computed as:

![](media/image887.wmf){width="1.8611111111111112in"
height="0.5270833333333333in"}, ![](media/image864.wmf){width="0.125in"
height="0.22152777777777777in"}![](media/image888.wmf){width="1.2638888888888888in"
height="0.25in"} (198)

This calculation is performed by running an autoregressive filter of
order 2.

\- Two blocks are extracted from the residual
signal:![](media/image889.wmf){width="2.0555555555555554in"
height="0.25in"}, ![](media/image888.wmf){width="1.2638888888888888in"
height="0.25in"} and
![](media/image890.wmf){width="1.4861111111111112in" height="0.25in"},
![](media/image888.wmf){width="1.2638888888888888in" height="0.25in"}.
Note that the blocks overlap with each other and the length of the
overlap depends on the value of
![](media/image891.wmf){width="0.5138888888888888in" height="0.25in"} in
the current iteration.

\- These two blocks are overlap-added to update the noise vector
![](media/image892.wmf){width="0.5277777777777778in"
height="0.2222222222222222in"} from the current start index
![](media/image893.wmf){width="0.5965277777777778in"
height="0.2222222222222222in"}:

![](media/image894.wmf){width="5.736111111111111in" height="0.25in"}
![](media/image864.wmf){width="0.125in" height="0.22152777777777777in"}
(199)

> Note that the upper limit
> ![](media/image895.wmf){width="1.1805555555555556in" height="0.25in"}
> of the time interval is actually saturated to
> ![](media/image896.wmf){width="1.94375in"
> height="0.2777777777777778in"}.

\- The start index is updated:
![](media/image897.wmf){width="1.8055555555555556in"
height="0.3194444444444444in"}

The iterations stop as soon as
![](media/image898.wmf){width="0.9583333333333334in" height="0.25in"}.

##### 5.4.3.6.5 Synthesis

The signal is synthesized as:

![](media/image899.wmf){width="1.4722222222222223in"
height="0.2222222222222222in"}, ![](media/image864.wmf){width="0.125in"
height="0.22152777777777777in"}![](media/image900.wmf){width="1.0277777777777777in"
height="0.2222222222222222in"} (200)

Note that when the binary voicing indicator has the value
![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"}=1, the noise vector
![](media/image901.wmf){width="0.5277777777777778in"
height="0.2222222222222222in"} has been scaled down by a factor of 0.25,
to avoid artefacts for voiced signals.

This signal is overlap-added with the previously decoded synthesis to
ensure signal continuity between frames.

#### 5.4.3.7 Time-domain PLC and OLA

##### 5.4.3.7.1 PLC mode selection

The frequency domain PLC block includes a frequency domain erasure
concealment algorithm and operates when the BFI flag is set to 1 and the
decoding mode of the previous frame is the frequency domain mode. The
frequency domain PLC block generates spectral coefficients of the erased
frame by repeating the synthesized spectral coefficients of the previous
good frame stored in memory. With these coefficients the IMDCT block
generates the time domain signal by performing a time-frequency inverse
transform. The conventional OLA block performs a general OLA processing
by using the time domain signal of the previous frame, and generates a
final time domain signal of the current frame as a result of the general
OLA processing.

To achieve an additional quality enhancement taking into account the
input signal characteristics, the time-domain PLC introduces two
concealment tools, consisting of a phase matching tool and a repetition
and smoothing tool. With these tools, an appropriate concealment method
is selected by checking the stationarity of the input signal.

Figure 7 shows the two concealment tools and the conventional OLA for
the time-domain PLC.

The phase matching block in the figure will be introduced in subclause
5.4.3.7.2 and the repetition and smoothing block in the figure will be
introduced in subclause 5.4.3.7.3.

![](media/image902.wmf){width="5.488888888888889in"
height="4.242361111111111in"}

Figure 7: **Block diagram of a Time-domain PLC module**

Table 12 summarizes the PLC modes that are used for time-domain PLC.
There are two tools for the time-domain PLC. Each of these tools has
several modes representing the erased frame types. The erased frame
types are classified as single erasure frame, burst erasure frame, next
good frame after erasure frame, and next good frame after burst erasure.

Table 12: Used PLC modes for Time-domain PLC

  ---------------------------- ---------------------------------------- ---------------------------------------- ------------------------------------------- --------------------------------------
  Name of tools                Single erasure frame                     Burst erasure frame                      Next good frame                             Next good frame after burst erasures
  **Phase matching**           Phase matching for erased frame          Phase matching for burst erasures        Phase matching for next good frame          Phase matching for next good frame
  **Repetition & Smoothing**   Repetition &smoothing for erased frame   Repetition &smoothing for erased frame   Repetition &smoothing for next good frame   Next good frame after burst erasures
  ---------------------------- ---------------------------------------- ---------------------------------------- ------------------------------------------- --------------------------------------

Table 13 summarizes the PLC mode selection method for the PLC mode
selection block in Figure.7.

Table 13: PLC mode selection

+-------+-------+-------+-------+-------+-------+-------+-------+
| **Pa  | **S   | **Def |       |       |       |       |       |
| ramet | tatus | initi |       |       |       |       |       |
| ers** | of    | ons** |       |       |       |       |       |
|       | Pa    |       |       |       |       |       |       |
|       | ramet |       |       |       |       |       |       |
|       | ers** |       |       |       |       |       |       |
+-------+-------+-------+-------+-------+-------+-------+-------+
| BFI   | 1     | 0     | 1     | 1     | 0     | 0     | Bad   |
|       |       |       |       |       |       |       | frame |
|       |       |       |       |       |       |       | indi  |
|       |       |       |       |       |       |       | cator |
|       |       |       |       |       |       |       | for   |
|       |       |       |       |       |       |       | the   |
|       |       |       |       |       |       |       | cu    |
|       |       |       |       |       |       |       | rrent |
|       |       |       |       |       |       |       | frame |
+-------+-------+-------+-------+-------+-------+-------+-------+
| Prev  | \-    | 1     | 1     | \-    | 1     | 1     | BFI   |
| \_BFI |       |       |       |       |       |       | for   |
|       |       |       |       |       |       |       | the   |
|       |       |       |       |       |       |       | pre   |
|       |       |       |       |       |       |       | vious |
|       |       |       |       |       |       |       | frame |
+-------+-------+-------+-------+-------+-------+-------+-------+
| nbLos | 1     | \-    | \-    | \-    | \-    | \>1   | The   |
| tCmpt |       |       |       |       |       |       | n     |
|       |       |       |       |       |       |       | umber |
|       |       |       |       |       |       |       | of    |
|       |       |       |       |       |       |       | conti |
|       |       |       |       |       |       |       | guous |
|       |       |       |       |       |       |       | e     |
|       |       |       |       |       |       |       | rased |
|       |       |       |       |       |       |       | f     |
|       |       |       |       |       |       |       | rames |
+-------+-------+-------+-------+-------+-------+-------+-------+
| P     | 1     | \-    | \-    | 0     | 0     | 0     | The   |
| hase\ |       |       |       |       |       |       | flag  |
| _mat\ |       |       |       |       |       |       | for   |
| _flag |       |       |       |       |       |       | the   |
|       |       |       |       |       |       |       | Phase |
|       |       |       |       |       |       |       | mat   |
|       |       |       |       |       |       |       | ching |
|       |       |       |       |       |       |       | pr    |
|       |       |       |       |       |       |       | ocess |
|       |       |       |       |       |       |       |       |
|       |       |       |       |       |       |       | (1:   |
|       |       |       |       |       |       |       | used, |
|       |       |       |       |       |       |       | 0:    |
|       |       |       |       |       |       |       | not   |
|       |       |       |       |       |       |       | used) |
+-------+-------+-------+-------+-------+-------+-------+-------+
| P     | 0     | 1     | 1     | 0     | 0     | 0     | The   |
| hase\ |       |       |       |       |       |       | flag  |
| _mat\ |       |       |       |       |       |       | for   |
| _next |       |       |       |       |       |       | the   |
|       |       |       |       |       |       |       | Phase |
|       |       |       |       |       |       |       | mat   |
|       |       |       |       |       |       |       | ching |
|       |       |       |       |       |       |       | pr    |
|       |       |       |       |       |       |       | ocess |
|       |       |       |       |       |       |       | for   |
|       |       |       |       |       |       |       | burst |
|       |       |       |       |       |       |       | era   |
|       |       |       |       |       |       |       | sures |
|       |       |       |       |       |       |       | or    |
|       |       |       |       |       |       |       | next  |
|       |       |       |       |       |       |       | good  |
|       |       |       |       |       |       |       | frame |
|       |       |       |       |       |       |       |       |
|       |       |       |       |       |       |       | (1:   |
|       |       |       |       |       |       |       | used, |
|       |       |       |       |       |       |       | 0:    |
|       |       |       |       |       |       |       | not   |
|       |       |       |       |       |       |       | used) |
+-------+-------+-------+-------+-------+-------+-------+-------+
| stat\ | \-    | \-    | \-    | (1    | \(1\) | 0     | The   |
| _mode |       |       |       | )^\*^ | ^\*^  |       | flag  |
| \_out |       |       |       |       |       |       | for   |
|       |       |       |       |       |       |       | Repet |
|       |       |       |       |       |       |       | ition |
|       |       |       |       |       |       |       | &smoo |
|       |       |       |       |       |       |       | thing |
|       |       |       |       |       |       |       | pr    |
|       |       |       |       |       |       |       | ocess |
|       |       |       |       |       |       |       |       |
|       |       |       |       |       |       |       | (1:   |
|       |       |       |       |       |       |       | used, |
|       |       |       |       |       |       |       | 0:    |
|       |       |       |       |       |       |       | not   |
|       |       |       |       |       |       |       | used) |
+-------+-------+-------+-------+-------+-------+-------+-------+
| di    | \-    | \-    | \-    | (\    | (\    | ![](  | E     |
| ff\_e |       |       |       | <0.15 | <0.15 | media | nergy |
| nergy |       |       |       | 9063) | 9063) | /imag | diffe |
|       |       |       |       | ^\*^  | ^\*^  | e903. | rence |
|       |       |       |       |       |       | wmf){ |       |
|       |       |       |       |       |       | width |       |
|       |       |       |       |       |       | ="0.1 |       |
|       |       |       |       |       |       | 25in" |       |
|       |       |       |       |       |       | hei   |       |
|       |       |       |       |       |       | ght=" |       |
|       |       |       |       |       |       | 0.152 |       |
|       |       |       |       |       |       | 77777 |       |
|       |       |       |       |       |       | 77777 |       |
|       |       |       |       |       |       | 778in |       |
|       |       |       |       |       |       | "}0.1 |       |
|       |       |       |       |       |       | 59063 |       |
+-------+-------+-------+-------+-------+-------+-------+-------+
| Sel   | Phase | Phase | Phase | Repet | Repet | Next  |       |
| ected | mat   | mat   | mat   | ition | ition | good  |       |
| PLC   | ching | ching | ching | &smoo | &smoo | frame |       |
| mode  | for   | for   | for   | thing | thing | after |       |
|       | e     | next  | burst | for   | for   | burst |       |
|       | rased | good  | era   | e     | next  | era   |       |
|       | frame | frame | sures | rased | good  | sures |       |
|       |       |       |       | frame | frame |       |       |
+-------+-------+-------+-------+-------+-------+-------+-------+
| Name  | Phase | Repet |       |       |       |       |       |
| of    | mat   | ition |       |       |       |       |       |
| tools | ching | and   |       |       |       |       |       |
|       |       | Smoo  |       |       |       |       |       |
|       |       | thing |       |       |       |       |       |
+-------+-------+-------+-------+-------+-------+-------+-------+
| NOTE: |       |       |       |       |       |       |       |
| ^\    |       |       |       |       |       |       |       |
| *^The |       |       |       |       |       |       |       |
| ()    |       |       |       |       |       |       |       |
| means |       |       |       |       |       |       |       |
| \     |       |       |       |       |       |       |       |
| "OR\" |       |       |       |       |       |       |       |
| co    |       |       |       |       |       |       |       |
| nnect |       |       |       |       |       |       |       |
| ions. |       |       |       |       |       |       |       |
+-------+-------+-------+-------+-------+-------+-------+-------+

The pseudo code to select a PLC mode for the phase matching tool is as
follows.

if( (nbLostCmpt==1)&&(phase\_mat\_flag==1)&&(phase\_mat\_next==0) ) {

Phase matching for erased frame ();

}

else if((prev\_bfi == 1)&&(bfi == 0) &&(phase\_mat\_next == 1)) {

Phase matching for next good frame ();

}

else if((prev\_bfi == 1)&&(bfi == 1) &&(phase\_mat\_next == 1)) {

Phase matching for burst erasures ();

}

Using this selection method, the phase matching flag (phase\_mat\_flag)
determines at the point of the memory update block in the previous good
frame whether phase matching erasure concealment processing is used for
every good frame when an erasure occurs in a next frame. To this end,
energy and spectral coefficients of each sub-band are used. The energy
is obtained from the norm value. More specifically, when a sub-band
having the maximum energy in a current frame belongs to a predetermined
low frequency band, and the inter-frame energy change is not large, the
phase matching flag is set to 1.

The detailed method is as follows. When a sub-band having the maximum
energy in the current frame is within the range of 75 Hz to 1000 Hz, a
difference between the index of the current frame and the index of a
previous frame with respect to a corresponding sub-band is 1 or less,
and the current frame is a stationary frame of which an energy change is
less than the threshold (ED\_THRES\_90P), and three past frames stored
in the buffer are not transient frames, then phase matching erasure
concealment processing will be applied to a next frame to which an
erasure has occurred.

> if ((Min\_ind\<5) && ( abs(Min\_ind - old\_Min\_ind)\< 2) &&
> (diff\_energy\<ED\_THRES\_90P) && (!bfi) && (!prev\_bfi) &&
> (!prev\_old\_bfi) && (!is\_transient) && (!old\_is\_transient\[1\])) {

if((Min\_ind==0) && (Max\_ind\<3)) {

phase\_mat\_flag = 0;

}

else {

phase\_mat\_flag = 1;

}

}

else {

phase\_mat\_flag = 0;

}

The PLC mode selection method for the repetition and smoothing tool and
the conventional OLA is as follows.

The result of the stationarity detection of an erased frame is performed
by a memory update block. In this detection we introduce a hysteresis in
order to prevent a frequent change of the detected result. The
stationarity detection of the erased frame determines whether the
current erased frame is stationary by receiving information including a
stationary mode stat\_mode\_old of the previous frame, an energy
difference diff\_energy, and the like. Specifically, the stationary mode
flag stat\_mode\_curr of the current frame is set to 1 when the energy
difference diff\_energy is less than 0.032209. The energy
difference(*E~d~*) is given by the Equation (169).

If it is determined that the current frame is stationary, the hysteresis
application generates a final stationarity parameter, stat\_mode\_out
from the current frame by applying the stationarity mode parameter
stat\_mode\_old of the previous frame to prevent a frequent change in
stationarity information of the current frame. The pseudo code for the
hysteresis application is as follows.

/\* Apply Hysteresis to prevent frequent mode changing \*/

if(stat\_mode\_old == stat\_mode\_curr)

{

stat\_mode\_out = stat\_mode\_curr;

}

stat\_mode\_old = stat\_mode\_curr;

First, the operation of the PLC mode selection depends on whether the
current frame is an erased frame or the next good frame after an erased
frame. Referring to Table 13, for an erased frame, a determination is
made whether the input signal is stationary by using various parameters.
More specifically, when the previous good frame is stationary and the
energy difference is less than the threshold, it is concluded that the
input signal is stationary. In this case, the repetition and smoothing
processing is performed. If it is determined that the input signal is
not stationary, then the general OLA processing is be performed.

Referring to Table 13, a determination whether the input signal is
stationary is made by using the same parameters and same method. If the
input signal is not stationary, then for the next good frame after an
erased frame a determination is made whether the previous frame is a
burst erasure frame by checking whether the number of consecutive erased
frames is greater than one. If this is the case, then erasure
concealment processing on the next good frame is performed in response
to the previous frame that is a burst erasure frame. If it is determined
that the input signal is not stationary and the previous frame is a
random erasure, then the conventional OLA processing is performed.

If the input signal is stationary, then the erasure concealment
processing, i.e. repetition and smoothing processing, on the next good
frame is performed in response to the previous frame that is erased.
This repetition and smoothing for next good frame has two types of
concealment methods. One is **repetition and smoothing method for the
next good frame after an erased frame, and the other is repetition and
smoothing method for the next good frame after burst erasures.**

The pseudo code to select a PLC mode for the Repetition and Smoothing
tool and the conventional OLA is as follows.

if(BFI == 0 && st-\>prev\_ BFI == 1) {

if((stat\_mode\_out==1) \|\| (diff\_energy\<0.032209) ) {

Repetition &smoothing for next good frame ();

}

else if(nbLostCmpt \> 1) {

Next good frame after burst erasures ();

}

else {

Conventional OLA ();

}

}

else { /\* if(BFI == 1) \*/

if( (stat\_mode\_out==1) \|\| (diff\_energy\<0.032209) ) {

if(Repetition &smoothing for erased frame () ) {

Conventional OLA ();

}

}

else {

Conventional OLA ();

}

}

##### 5.4.3.7.2 Phase matching

Figure 8 is a block diagram of the phase matching PLC module. The phase
matching tool includes a PLC mode selection block and three phase
matching packet loss concealment blocks.

Basically the phase matching error concealment performs phase matching
packet loss concealment processing on a current erased frame when the
previous good frame has the maximum energy in a predetermined low
frequency band and the change in energy is less than a predetermined
threshold.

The phase matching tool does not use the conventional OLA block but
generates the time domain signal for the current erased frame by copying
the phase-matched time domain signal obtained from the previous good
frames. Once the phase matching tool is used for an erased frame, the
tool shall also be used for the next good frame or subsequent burst
erasures. For the next good frame, the phase matching for next good
frame tool is used. For subsequent burst erasures, the phase matching
tool for burst erasures is used.

The phase matching tool for the next good frame performs phase matching
packet loss concealment processing on the current frame when the
previous frame is an erasure and when phase matching error concealment
processing on the previous frame has been performed.

The phase matching function for burst erasures performs phase matching
packet loss concealment processing on the current frame that is part of
a burst erasure when the previous frame is an erasure and phase matching
error concealment processing on the previous frame has been performed.

![](media/image904.wmf){width="4.727777777777778in"
height="3.0659722222222223in"}

Figure 8: **Block diagram of a phase matching PLC module**

Figure 9 shows a block diagram of the phase matching for erased frame
block in Figure 8. In order to use the phase matching tool, the
phase\_mat\_flag shall be set to 1. Even though this condition is
satisfied, a second condition shall be satisfied. As a second condition,
a correlation scale accA is obtained, and either phase matching erasure
concealment processing or general OLA processing is selected. The
selection depends on whether the correlation scale accA is within a
predetermined range. That is, phase matching packet loss concealment
processing is conditionally performed depending on whether a correlation
between segments exists in a search range and a cross-correlation
between a search segment and the segments exists in the search range.
The correlation scale
![](media/image905.wmf){width="0.3194444444444444in"
height="0.16666666666666666in"} is given by Equation (201).
![](media/image906.wmf){width="0.125in" height="0.19375in"}

![](media/image907.wmf){width="1.9027777777777777in"
height="0.5138888888888888in"} (201)

In Equation (201), ![](media/image908.wmf){width="0.1388888888888889in"
height="0.18055555555555555in"} denotes the number of segments existing
in the search range, ![](media/image909.wmf){width="0.25in"
height="0.2361111111111111in"} denotes a cross-correlation used to
search for the matching segment having the same length as the search
segment (![](media/image910.wmf){width="0.125in"
height="0.1388888888888889in"} signal) with respect to the
![](media/image911.wmf){width="0.16666666666666666in"
height="0.16666666666666666in"} past good frames
(![](media/image912.wmf){width="0.1388888888888889in"
height="0.16666666666666666in"} signal) stored in the buffer, and
![](media/image913.wmf){width="0.2638888888888889in"
height="0.2361111111111111in"} denotes a correlation between segments
existing in the ![](media/image914.wmf){width="0.16666666666666666in"
height="0.16666666666666666in"} past good frames stored in the buffer.
Next, it is be determined whether the correlation scale
![](media/image905.wmf){width="0.3194444444444444in"
height="0.16666666666666666in"} is within the predetermined range. If
this is the case phase matching erasure concealment processing takes
place on the current erased frame. Otherwise, the conventional OLA
processing on the current frame is performed. If the correlation scale
![](media/image905.wmf){width="0.3194444444444444in"
height="0.16666666666666666in"} is less than 0.5 or greater than 1.5,
the conventional OLA processing is performed. Otherwise, phase matching
erasure concealment processing is performed.

The phase matching packet loss concealment processing includes a maximum
correlation search block, a copying block, a smoothing block, and a
memory update block. The maximum correlation search block searches for a
matching segment, which has the maximum correlation to, i.e. is most
similar to, a search segment adjacent to a current frame, from a decoded
signal in a previous good frame from among N past good frames stored in
a buffer. A position index of the matching segment obtained as a result
of the search is provided to the copying block.

The copying block copies a predetermined duration starting from an end
of the matching segment to the current frame that is an erasure frame by
referring to the location index of the matching segment. At this time, a
duration corresponding to a window length is copied to the current
frame. When the copy starting from the end of the matching segment is
shorter than the window length, the copy, starting from the end of the
matching segment will be repeatedly copied into the current frame.

The smoothing block generates a time domain signal on the -concealed
current frame by performing smoothing processing through OLA to minimize
the discontinuity between the current frame and adjacent frames. After
smoothing, the memory update for the phase matching will be performed in
the memory update block.

![](media/image915.wmf){width="3.902083333333333in"
height="3.859722222222222in"}

Figure 9: **Block** diagram of the phase matching for erased frame

Figure 10 illustrates the operation of phase matching erasure
concealment described in Figure 9. Referring to Figure 10, the decoded
signal from a previous frame from among the N past good frames stored in
a buffer is searched for a matching segment. When the copy process is
completed, the overlapping process on a copied signal and on an Oldauout
signal stored in the previous frame n-1 for overlapping is performed at
the beginning part of the current frame n by a first overlap duration.
The length of the overlap duration is 2 ms. This results in the
generation of the final repeated signal.

![](media/image916.wmf){width="5.450694444444444in" height="2.09375in"}

Figure 10: **The operation of phase matching erasure concealment**

Phase matching for burst erasures as shown in Figure 8 is described as
follows. This method utilizes a smoothing process similar to that of
phase matching for the first erased frame. Phase matching for burst
erasures does not have maximum correlation search block nor the copying
block, as all information needed for these blocks can be reused by phase
matching for the erased frame. The only difference for the smoothing
block is the smoothing that is done between the signal corresponding to
the overlap duration of the copied signal and the Oldauout signal stored
in the current frame n for overlapping purposes. The Oldauout is
actually a copied signal by the phase matching process in the previous
frame.

The phase matching for next good frame in Figure 8 is described as
follows.

This method utilizes the mean\_en\_high parameter, denoting a mean
energy of high bands and indicating the similarity of the last good
frames. This parameter is calculated by following equation,

![](media/image917.wmf){width="3.375in" height="0.7361111111111112in"}
(202)

where ![](media/image918.wmf){width="0.125in"
height="0.18055555555555555in"} is start band index of the determined
high bands.

If ![](media/image919.wmf){width="0.9722222222222222in"
height="0.19375in"} is larger than 2.0 or smaller than 0.5,
oldout\_pha\_idx is set to 1. oldout\_pha\_idx is used as a switch using
the Oldauout memory. The two sets of Oldauout were saved at the both the
phase matching for erased frame block and the phase matching for burst
erasures block. The 1st Oldauout is generated from a copied signal by a
phase matching process, and the 2nd Oldauout is generated by the time
domain signal resulting from the IMDCT. If the oldout\_pha\_idx is set
to 1, it indicates that the high band signal is unstable and the 2nd
Oldauout will be used for the OLA process in the next good frame. If the
oldout\_pha\_idx is set to 0, it indicates that the high band signal is
stable and the 1st Oldauout will be used for OLA process in the next
good frame.

if((mean\_en\_high\>2.0)\|\|(mean\_en\_high\<0.5)) {

oldout\_pha\_idx = 1;

}

else {

oldout\_pha\_idx = 0;

}

##### 5.4.3.7.3 Repetition and smoothing

Figure 11 depicts the repetition and smoothing tool (OLA modes for
time-domain PLC).

![](media/image920.wmf){width="5.309722222222222in"
height="2.6645833333333333in"}

Figure 11: **Repetition and smoothing**

Each tool in the block diagram is described as follows. Figure 12 is a
block diagram of conventional OLA method. The conventional OLA method
includes a windowing block and an OLA block. Referring to Figure 12, the
windowing block performs a windowing process on an IMDCT signal of the
current frame to remove time domain aliasing. The case of a window
having an overlap duration less than 50% will be described below with
reference to Figure 13. The OLA block performs OLA processing on the
windowed IMDCT signal.

Figure 13 illustrates the general OLA method with the window format for
concealing an erased frame. When an erasure occurs in frequency domain
encoding, past spectral coefficients are usually repeated, and thus, it
may be impossible to remove time domain aliasing in the erased frame.

![](media/image921.wmf){width="1.5104166666666667in"
height="1.8229166666666667in"}

Figure 12: **Block diagram of conventional OLA**

![](media/image922.wmf){width="4.245833333333334in"
height="1.3506944444444444in"}

Figure 13: **Diagram for describing a windowing of conventional OLA**

Figure 14 is a block diagram of the repetition and smoothing method for
an erased frame. When the current frame is an erasure, and if a method
of repeating past spectral coefficients obtained in the frequency domain
is used, and if OLA processing is performed after IMDCT and windowing, a
time domain aliasing component in the beginning part of the current
frame is modified. Thus perfect reconstruction is not possible, thereby
resulting in unexpected noise. The repetition and smoothing method is
used to minimize the occurrence of noise even though the original
repetition method is used.

The repetition and smoothing method includes a windowing block, a
repetition block, and a smoothing block. Referring to Figure 14, the
windowing block performs the same operation as that of the windowing
block of Figure 12. The repetition block applies an IMDCT signal of a
frame that is two frames previous to the current frame (referred to as
\"previous old\" in figure 15) to a beginning part of the current erased
frame. The smoothing block consists of the OLA unit and the smoothing
unit. The OLA unit performs OLA processing on the signal repeated by the
repetition block and the IMDCT signal of the current frame. As a result,
the audio output signal of the current frame is generated, and the
occurrence of noise in a beginning part of the audio output signal is
reduced. When scaling is applied together with the repetition of the
spectrum of the previous frame in the frequency domain, the likelihood
of noise occurring in the beginning part of the current frame is greatly
reduced. The smoothing unit applies a smoothing window between the
signal of the previous frame (old audio output) and the signal of the
current frame (referred to as \"current audio output\") and performs OLA
processing. The smoothing window is formed such that the sum of overlap
durations between adjacent windows is equal to one. In the EVS codec,
the sine wave window is used, and in this case, the window function
![](media/image923.wmf){width="0.3194444444444444in" height="0.19375in"}
is represented by Equation (203).

![](media/image924.wmf){width="2.9722222222222223in"
height="0.4305555555555556in"} (203)

In Equation (203), ![](media/image925.wmf){width="0.6666666666666666in"
height="0.19375in"} denotes the duration of the overlap to be used in
the smoothing processing. By performing smoothing processing as
described above, when the current frame is an erasure, the discontinuity
between the previous frame and the current frame, which may occur by
using an IMDCT signal copied from the frame that is two frames previous
to the current frame instead of an IMDCT signal stored in the previous
frame, is prevented.

After completion of the repetition and smoothing, the energy
![](media/image926.wmf){width="0.34652777777777777in"
height="0.16666666666666666in"} of an overlapping region is compared
with the energy ![](media/image927.wmf){width="0.375in"
height="0.16666666666666666in"} of a non-overlapping region. When the
energy of the overlapping region decreases after the packet loss
concealment processing, conventional OLA processing is performed. The
comparison is made by the operation depicted in Figure 14.

If the energy difference between the overlapping region
(![](media/image928.wmf){width="0.34652777777777777in"
height="0.16666666666666666in"}) and the non-overlapping region
(![](media/image929.wmf){width="0.375in"
height="0.16666666666666666in"}) is large as a result of the comparison
in the block, conventional OLA processing is performed.

Figure 15 illustrates the repetition and smoothing method with an
example window for concealing an erased frame.

![](media/image930.wmf){width="2.6506944444444445in"
height="3.213888888888889in"}

Figure14: **Block diagram of repetition & smoothing method for erased
frame**

![](media/image931.wmf){width="5.063194444444444in"
height="2.0340277777777778in"}

Figure 15: **Diagram for describing a windowing of repetition &
smoothing method for erased frame**

Figure 16 is a block diagram of the repetition and smoothing method for
the next good frame after an erased frame. This method only includes the
smoothing block. The smoothing block applies the smoothing window to the
old IMDCT signal and to a current IMDCT signal and performs OLA
processing. Likewise, the smoothing window is formed such that a sum of
overlap durations between adjacent windows is equal to one. That is,
when the previous frame is a first erased frame and a current frame is a
good frame, it is difficult to remove time domain aliasing in the
overlap duration between an IMDCT signal of the previous frame and an
IMDCT signal of the current frame. Thus, noise can be minimized by
performing the smoothing processing based on the smoothing window
instead of the conventional OLA processing. Figure 17 illustrates the
repetition and smoothing method with an example of a window for
smoothing the next good frame after an erased frame.

![](media/image932.wmf){width="1.4722222222222223in"
height="1.3173611111111112in"}

Figure 16: **Block diagram of repetition and smoothing method for the
next good frame after an erased frame**

![](media/image933.wmf){width="4.041666666666667in"
height="1.0972222222222223in"}

Figure 17: **Diagram for describing a windowing of repetition and
smoothing method for the next good frame after an erased frame**

If the input signal is stationary and the previous frame is a burst
erasure frame, then the repetition and smoothing method for the next
good frame after the multiple erased frames as depicted in Figure 18 is
used.

This method includes a repetition block, a scaling block, a first
smoothing block, and a second smoothing block. Referring to Figure18,
the repetition block copies, to a beginning part of the current frame, a
part used for the next frame of the IMDCT signal of the current frame.
The scaling block adjusts the scale of the current frame to prevent a
sudden signal increase. In the EVS codec, the scaling block performs
down-scaling by 3 dB. The first smoothing block applies a smoothing
window to the IMDCT signal of the previous frame and the copied IMDCT
signal from a future frame and performs OLA processing. Likewise, the
smoothing window is formed such that a sum of overlap durations between
adjacent windows is equal to one. That is, when the copied signal is
used, windowing is necessary to remove the discontinuity which may occur
between the previous frame and the current frame, and an old IMDCT
signal may be replaced with a signal obtained by OLA processing of the
first smoothing block. The second smoothing block performs the OLA
processing while removing the discontinuity by applying a smoothing
window between the old IMDCT signal that is a replaced signal and a
current IMDCT signal that is the current frame signal. Likewise, the
smoothing window is formed such that the sum of overlap durations
between adjacent windows is equal to one. That is, when the previous
frame is a burst erasure and the current frame is a good frame, time
domain aliasing in the overlap duration between the IMDCT signal of the
previous frame and the IMDCT signal of the current frame cannot be
removed. In the burst erasure frame, since noise may occur due to a
decrease in energy or continuous repetitions, the method of copying a
signal from the future frame for overlapping with the current frame is
applied. In this case, smoothing processing is performed twice to remove
the noise which may occur in the current frame and simultaneously remove
the discontinuity which occurs between the previous frame and the
current frame. Figure 19 illustrates the repetition and smoothing method
with an example window for smoothing the next good frame after burst
erasures.

![](media/image934.wmf){width="1.5743055555555556in"
height="2.9034722222222222in"}

Figure 18: **Block diagram of repetition and smoothing method for the
next good frame after burst erasures**

![](media/image935.wmf){width="4.809027777777778in"
height="1.2979166666666666in"}

Figure 19: **Diagram for describing a windowing of repetition and
smoothing method for the next good frame after burst erasures**

Figure 20 is the block diagram of the next good frame after burst
erasures shown in Figure 11. Regarding the usage of the future signal
the main operation is same as that of the repetition and smoothing
method for the next good frame after burst erasures shown in Figure 18.

This method includes a repetition block, a scaling block, a smoothing
block, and an OLA block. Referring to Figure 20, the repetition block,
scaling block, and smoothing block are exactly the same as that of
Figure 18. Instead of the second smoothing block, the next good frame
after burst erasures uses the OLA between the replaced OldauOut signal
and the current IMDCT signal. Figure 21 illustrates the next good frame
after burst erasures.

![](media/image936.wmf){width="1.5034722222222223in"
height="2.7743055555555554in"}

Figure 20: **Block diagram of the next good frame after burst erasures**

![](media/image937.wmf){width="4.430555555555555in"
height="1.3909722222222223in"}

Figure 21: **Diagram for describing a windowing of the next good frame
after burst erasures**

### 5.4.4 Void

### 5.4.5 Guided concealment and recovery

#### 5.4.5.1 Transmission of the synthesis class

Instead of performing the signal classification in the decoder (see
clause 5.1.2 Signal classification), the synthesis class is transmitted
in the bitstream for the rates 48, 96 and 128 kbps.

#### 5.4.5.2 Transmission of the LTP pitch lag

Despite of the fact that no LTP post processing is performed for the
rates 96 and 128 kbps, the LTP pitch lag is transmitted in the bitstream
to allow reliable functioning of the decoder concealment modules which
depend on this LTP lag.

#### 5.4.5.3 Transmission of a voicing indicator

A flag ![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"} is used in the decoder for the
concealment method described in clause 5.4.3.6, to adapt several
parameters (pitch search range, sinusoid selection, noise level to be
re-injected).

At the encoder, the flag
![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"} is set to 1 when the current frame is
classified as GENERIC or VOICED, otherwise the flag
![](media/image675.wmf){width="0.12361111111111112in"
height="0.1486111111111111in"} is set to 0 (for all other signal
classes: UNVOICED, TRANSIENT, INACTIVE, AUDIO).

#### 5.4.5.3a Transmission of a tonality flag

A flag indicating the frame as tonal type (1) or non-tonal type (0) is
transmitted in the bitsteam for the rates 48, 96 and 128 kbps. It is
used in the decision criterion to select the concealment method of
non-tonal concealment with waveform adjustment.

#### 5.4.5.4 ACELP to MDCT mode recovery

For the ACELP concealment at 9.6, 16.4 and 24.4 kbps, as well as for the
TCX time domain concealment, an additional segment (half frame) of
signal is generated by predictive decoding from the previous frame and
stored in a temporary buffer. This additional segment is used to recover
from the loss of a transition frame between ACELP to MDCT (HQ MDCT or
non-transition TCX 20) and it is generated in advance without prior
knowledge that the transition frame will be lost, before receiving the
next frame. The extra complexity associated with generating this
additional segment has been found to be outside the critical path of
complexity of the EVS decoder, therefore this extra processing does not
impact worst-case decoding complexity.

To create this additional segment, the parameters used to generate the
half frame of signal are predicted based on the parameters in the
previous frame. The bit indicating the sampling frequency of the ACELP
core is implicitly repeated; the excitation decoding done in the
previous ACELP frame is extended in the additional segment.

When the current frame is MDCT, the additional segment (half frame) is
then overlap and added to the MDCT frame decoded in the current frame,
being HQ MDCT or non-transition TCX 20, using a symmetric sine window of
length 8.75 milliseconds.

For the recovery in the TCX20 transition frame (TCX20 after lost ACELP
frame):

\- If the ACELP PLC was used, the same ACELP to TCX transition as if the
previous ACELP frame would have been received is used, but with the
samples of the past frame replaced with the concealed frame.

\- If the TD TCX PLC was used, the additional half frame constructed in
TD TCX PLC is overlap and added to the transition TCX frame, using
HALF\_OVERLAP (the symmetric sine window of length 3.75 milliseconds).

#### 5.4.5.5 Recovery after TCX MDCT concealment

During recovery after TCX MDCT concealment fading the background level
as described in 5.4.6.1.3.1, the overlap-add buffer is rescaled by
multiplying each element of it with the latest target background noise
level $g^{\text{cng}}$(see equation 109).

### 5.4.6 Handling of multiple frame losses and muting 

#### 5.4.6.1 TCX MDCT

##### 5.4.6.1.1 Background level tracing for rates 48, 96 and 128 kbps

A background noise level is traced in the time domain using a simplified
version of the minimum statistics algorithm \[7\]. The tracing depends
on the class being transmitted in the bitstream: It is performed for UC
only.

In contrast to the FD-CNG - which also makes use of the minimum
statistics approach (see \[5\], subclause 4.4.3) - the noise level
estimation is not carried for each spectral band separately, but
directly in the time domain. The background level tracing delivers
therefore an estimate of the total noise level. Furthermore, the bias
compensation is disregarded in this application. Tracing of the noise
level is hence achieved by computing a smoothed version of the decoder
output frame amplitude and by searching for the minimum smoothed
amplitude over a sliding temporal window.

If![](media/image938.wmf){width="0.3611111111111111in"
height="0.2777777777777778in"}denotes the frame size in
samples,![](media/image939.wmf){width="0.125in"
height="0.16666666666666666in"}denotes the sample
index,![](media/image940.wmf){width="0.1388888888888889in"
height="0.16666666666666666in"}denotes the frame index,
and![](media/image941.wmf){width="0.6666666666666666in"
height="0.2777777777777778in"}is the output frame of the core decoder at
the TCX sampling rate, the current total frame level is computed as
follows:

![](media/image942.wmf){width="2.0277777777777777in"
height="0.6111111111111112in"}. (204)

It is first lower-limited by 0.01 and smoothed with a first-order
recursive low-pass process, i.e.

![](media/image943.wmf){width="3.375in" height="0.25in"}, (205)

where

![](media/image944.wmf){width="2.0416666666666665in"
height="0.4166666666666667in"} (206)

is an optimal smoothing parameter which depends on the signal
level![](media/image945.wmf){width="0.5555555555555556in"
height="0.20833333333333334in"}and the background tracing
level![](media/image946.wmf){width="0.5694444444444444in"
height="0.20833333333333334in"} in the previous frame. The tracing
level![](media/image947.wmf){width="0.4027777777777778in"
height="0.20833333333333334in"}for the current
frame![](media/image948.wmf){width="0.1388888888888889in"
height="0.16666666666666666in"}is obtained by searching for the minimum
in a buffer containing the last 50 values of the smoothed
level![](media/image949.wmf){width="0.3888888888888889in"
height="0.2222222222222222in"}:

![](media/image950.wmf){width="2.5in" height="0.2222222222222222in"}.
(207)

At initialization, the buffer is filled with the value 0.01 and the
smooth signal level is initialized as
![](media/image951.wmf){width="0.7916666666666666in"
height="0.2361111111111111in"}

##### 5.4.6.1.2 TCX time domain concealment

In the case of TCX time domain concealment as stated in subclause
5.4.2.2, the following applies.

##### 5.4.6.1.2.1 Fading to background level {#fading-to-background-level-1 .H6}

At rates 9.6, 16.4 and 24.4kbps the fading is identical to what is
described in subclause 5.3.4.2.1.

At rates 48, 96 and 128kbps the fading is identical to what is described
in subclause 5.3.4.2.1 with the exception, that the target level in the
time domain is not derived from the FFT provided by CNG, but that it is
gained from the background level tracing as described in subclause
5.4.6.1.

##### 5.4.6.1.2.2 Fading to background spectral shape {#fading-to-background-spectral-shape-1 .H6}

No fading of the LPC is applied.

##### 5.4.6.1.3 MDCT frame repetition with sign scrambling

In the case of TCX frequency domain concealment, i.e. frame repetition
with sign scrambling as stated in subclause 5.4.2.3 and/or tonal
concealment using phase prediction as stated in subclause 5.4.2.4, the
following applies.

##### 5.4.6.1.3.1 Fading to background level {#fading-to-background-level-2 .H6}

The time domain signal is faded towards a target background noise level
as described in equation (107) and (107a) . The initial gain is 1. The
derivation of ![](media/image952.wmf){width="0.3854166666666667in"
height="0.20833333333333334in"} is outlined in subclause 5.4.6.1.4.

At rates 9.6, 16.4 and 24.4kbps the target level $g^{\text{cng}}$ is
derived during the first lost frame based on the background noise
spectrum derived by CNG during clean channel decoding (section 4.3 of
\[5\]) as stated in subclause 5.3.4.2.1 under a).

At rates 48, 96 and 128kbps the target level $g^{\text{cng}}$ is gained
from the background level tracing as described in subclause 5.4.6.4.

The gain compensation for the LPC synthesis / de-emphasis as given in
equation (109) is applied, see also subsection 5.2.5.

##### 5.4.6.1.3.2 Fading to background spectral shape {#fading-to-background-spectral-shape-2 .H6}

The fading to background spectral shape is achieved by the following
fading procedures, taking place in parallel:

a\) The excitation itself is faded towards white noise in the frequency
domain prior to the FDNS, on which a tilt is applied.

> b\) The excitation is shaped by FDNS towards a previously measured
> background shape.

c\) The LTP is faded out.

##### 5.4.6.1.3.2.1 Fading the excitation to noise {#fading-the-excitation-to-noise .H6}

For 9.6, 16.4 and 24.4kbps, the sign scrambled excitation (input to
FDNS, see subclause 5.4.2.3) is faded towards a white noise, on which a
tilt is applied prior to the fading procedure. The method is based on
the following parameters: the last received excitation spectrum
![](media/image527.wmf){width="0.9861111111111112in"
height="0.2361111111111111in"}, a noise tilt compensation factor
![](media/image953.wmf){width="0.94375in"
height="0.20833333333333334in"} (derived similar to the clean channel
operation) and a damping factor
![](media/image954.wmf){width="0.7638888888888888in"
height="0.20833333333333334in"}.

The tilt factor is given by

![](media/image955.wmf){width="2.9027777777777777in"
height="0.4166666666666667in"} (208)

Subsequently a tilt vector is derived as

$\begin{matrix}
\text{tilt}(0) = 1 \\
\text{tilt}(k) = \text{tilt}(k - 1) \cdot \text{tiltFactor},k = \lbrack 1,\text{.}\text{.}\text{.},\text{igfStartLine} - 1\rbrack \\
\end{matrix}$ (209)

The![](media/image956.wmf){width="0.8958333333333334in"
height="0.19791666666666666in"}given by equation (123) then gets
multiplied with the tilt to achieve a target noise vector with the
desired tilt:

$C_{\text{noise}_{\text{tilt}}}(k) = \text{tilt}(k) \cdot \text{randomVector}(k)\text{,\ \ \ \ \ \ k=}\lbrack\text{0,}\ldots\text{,igfStartLine-1}\rbrack$
(210)

The energy of this target noise vector is derived

$E_{\text{noise}} = \sum_{k = 0}^{\text{igfStartLine} - 1}\left( C_{\text{noise}_{\text{tilt}}}(k) \right)^{2}$
(211)

and the energy of the last excitation is derived

$E_{C} = \sum_{k = 0}^{\text{igfStartLine} - 1}\left( C_{\text{exc}_{\text{lastGood}}}(k) \right)^{2}$.
(212)

The excitation is then derived as follows:

$C_{\text{exc}}^{\lbrack m\rbrack}(k) = \text{gain} \cdot C_{\text{noise}_{\text{tilt}}}(k) + \text{dampingFac} \cdot C_{\text{exc}}^{\lbrack m\rbrack}(k),\text{for\ k\ =\ }\lbrack\text{0,}\ldots\text{,igfStartLine-1}\rbrack$
(213)

with ![](media/image957.wmf){width="2.0in"
height="0.4583333333333333in"} and
![](media/image958.wmf){width="0.3229166666666667in" height="0.25in"}is
given by equation (122). The fading speed controlled by
![](media/image959.wmf){width="0.7597222222222222in"
height="0.19791666666666666in"} as described in subclause 5.4.6.1.4.

##### 5.4.6.1.3.2.2 Shaping the excitation towards the background shape {#shaping-the-excitation-towards-the-background-shape .H6}

The excitation is shaped towards a target spectral shape by altering the
LPC coefficients. The fading from the last good LPC coefficients to the
target LPC coefficients is performed in the LSF domain as follows:

$f^{\lbrack m\rbrack} = \text{alpha} \cdot f^{\lbrack m - 1\rbrack} + (1 - \text{alpha}) \cdot f^{\text{target}}$
(214)

where: ![](media/image450.wmf){width="0.3020833333333333in"
height="0.3020833333333333in"} are LPC coefficients in the LSF domain of
the current frame;

![](media/image451.wmf){width="0.40625in" height="0.3020833333333333in"}
are LPC coefficients in the LSF domain of the previous frame;

$f^{\text{target}}$ are the target LPC coefficients, derived according
to formula 111

![](media/image453.wmf){width="0.375in" height="0.19791666666666666in"}
is the fading factor as described in subclause 5.3.4.2.3, but limited to
the minimum value of 0.8.

void (215)

For 9.6, 16.4 and 24.4kbps, the target spectral shape of the excitation
is derived during the first lost frame based on the background noise
spectrum derived by CNG during clean channel decoding (see section 4.3
of \[5\]). Its derivation is performed as described in subclause
5.3.4.2.2 for the harmonic excitation.

For 48, 96 and 128kbps, the target spectral shape of the excitation is
the short term mean of the last three LPC coefficient sets. Its
derivation is performed as described in subclause 5.3.4.2.2 for the
innovative excitation.

The achieved LPC is converted into FDNS parameters as follows:

![](media/image960.wmf){width="2.3333333333333335in" height="0.40625in"}
(216)

![](media/image961.wmf){width="2.4166666666666665in" height="0.40625in"}
(217)

where ![](media/image962.wmf){width="0.19791666666666666in"
height="0.20833333333333334in"} are the LPC coefficients. The two
signals ![](media/image963.wmf){width="0.16666666666666666in"
height="0.13541666666666666in"} and
![](media/image964.wmf){width="0.19791666666666666in"
height="0.16666666666666666in"} get zero filled to the length of 128
before a complex Fourier transform of length 128 will be applied on them
to receive the real part
![](media/image965.wmf){width="0.20833333333333334in"
height="0.16666666666666666in"} and the imaginary part
![](media/image966.wmf){width="0.20833333333333334in"
height="0.15625in"}(see \[5\], subsection 5.1.4). The FDNS parameters
will finally be obtained as:

![](media/image967.wmf){width="2.625in" height="0.3020833333333333in"}
(218)

##### 5.4.6.1.3.2.3 LTP fade-out {#ltp-fade-out .H6}

The LTP continues to run during concealment. The LTP lag is kept
constant. The LTP gain is faded towards zero as follows:

![](media/image968.wmf){width="1.5965277777777778in"
height="0.2916666666666667in"} (219)

where: ![](media/image969.wmf){width="0.2916666666666667in"
height="0.2916666666666667in"} is the LTP gain of the current frame;

![](media/image970.wmf){width="0.4027777777777778in"
height="0.2916666666666667in"} is the LTP gain of the previous frame;

![](media/image971.wmf){width="0.7638888888888888in" height="0.19375in"}
is the damping factor, its derivation is outlined in subclause
5.4.6.1.4.

##### 5.4.6.1.4 Fading speed

Several algorithms use a time-varying damping factor for fade-out,
cross-fade etc. Depending on the application, either the damping factor
or the cumulative damping factor is needed.

The damping factor, here described
as![](media/image972.wmf){width="0.7638888888888888in"
height="0.20833333333333334in"}, depends on the number of lost frames
and the ISF stability factor. The ISF stability factor is already
computed in the clean channel. With the lost frame having the index 0,
it is derived as follows

![](media/image973.wmf){width="2.0833333333333335in" height="0.25in"}
(220)

![](media/image974.wmf){width="2.111111111111111in" height="0.25in"}
(221)

![](media/image975.wmf){width="2.272222222222222in"
height="0.2534722222222222in"} (222)

The cumulative damping factor, here described
as![](media/image976.wmf){width="1.15625in"
height="0.20833333333333334in"}, is initialized with 1 during
clean-channel decoding and derived as follows during concealment:

![](media/image977.wmf){width="3.821527777777778in"
height="0.2534722222222222in"} (223)

##### 5.4.6.1.5 Waveform adjustment

The fade out is performed as described in section 5.4.6.1.3, just that
no lpc gain compensation (see section 5.2.5) takes place.

#### 5.4.6.2 HQ MDCT

##### 5.4.6.2.1 Burst loss handling for 8 kHz audio output sampling rate

The burst loss handling for 8 kHz audio sampling rate is described as
part of the HQ MDCT PLC method description for 8 kHz signals, see
clauses 5.4.3.3 and 5.4.3.4.

##### 5.4.6.2.2 Burst loss handling audio output sampling rates larger or equal to 16 kHz

In case the audio output signal frequency exceeds 8 kHz and the current
frame loss is the first loss after a good HQ MDCT frame the PLC method
is selected according to the method described in subclause 5.4.3.2. If
however the current frame loss is at least the second consecutive loss
after a preceding good HQ MDCT frame, then the procedure described in
this clause applies.

In case the current frame loss is the second loss in a row and the PLC
method according to subclause 5.4.3.6 was applied for the first bad
frame, Phase ECU according to subclause 5.4.3.5 is applied with the
following adaptations: Transient analysis and spectrum analysis are
carried out with the previous synthesis signal of the last good HQ MDCT
frame. The offset ![](media/image978.wmf){width="0.2916666666666667in"
height="0.23472222222222222in"}in number of samples since the last good
frame is accordingly incremented
by![](media/image979.wmf){width="0.1388888888888889in"
height="0.15138888888888888in"}.

Otherwise, in case the current frame loss is the second loss in a row
and if Phase ECU was applied for the first frame loss, Phase ECU
according to subclause 5.4.3.5 is applied with the adaptation that no
spectral analysis is carried out and that transient analysis relies on
previously calculated and stored parameters. Details are described in
subclause 5.4.3.5.1.

In case the current frame loss is the third or more in a row Phase ECU
is applied according to subclause 5.4.3.5 with the adaptation that no
spectral analysis is carried out and that transient analysis relies on
previously calculated and stored parameters (that were calculated based
on the synthesis of the last good HQ MDCT frame). The operation of the
Phase ECU is modified in response to the frame loss burst condition.
Specifically, magnitude and phase of the substitution frame spectrum are
adjusted in order to mitigate potential quality losses that might
otherwise arise from too periodic or tonal sounds. With increasing loss
burst length, the magnitude spectrum is adjusted by gradually increasing
attenuation. At the same time the phase spectrum is dithered with an
increasing degree. Further details are described in subclause 5.4.3.5.1.

A special feature is the long-term muting behaviour in case of long loss
bursts with many consecutive lost frames. In that case, the quality of
the audio signal that is reconstructed by Phase ECU might still suffer
from tonal artefacts, despite the performed phase randomization. Too
strong magnitude attenuation could at the same time lead to quality
impairments, as this could be perceived as signal drop-outs. The feature
avoids such impairments to a large degree by gradually superposing the
substitution signal of the Phase ECU with a noise signal, where the
frequency characteristic of the noise signal is a low-resolution
spectral representation of a previously received good frame. With
increasing number of frame losses in a row, the substitution signal of
the Phase ECU is gradually attenuated. At the same time, the frame
energy loss is compensated for through the addition of a noise signal
with similar spectral characteristics like the last received good frame
but with a certain degree of low-pass behaviour. For very long frame
loss bursts (![](media/image784.wmf){width="0.6111111111111112in"
height="0.2076388888888889in"}) the additional noise contribution faded
out in order to enforce a muting characteristic of the decoder. Further
details of the long-term muting feature are described in subclauses
5.4.3.5.1 and 5.4.3.5.3.

5.5 SID frame concealment operation
-----------------------------------

In the case of the loss of an SID frame, the comfort noise will be
generated based on the last received SID frame.

######## Annex A (informative): Change history

  -------------------- ------------- ----------- -------- --------- --------- ------------------------------------------------------------------------- -----------------
  **Change history**                                                                                                                                    
  **Date**             **Meeting**   **TDoc**    **CR**   **Rev**   **Cat**   **Subject/Comment**                                                       **New version**
  2014-09              SA\#65        SP-140462                                Presented at TSG SA\#65 for approval                                      1.0.0
  2014-09              SA\#65                                                 Approved at TSG SA\#65                                                    12.0.0
  2014-12              SA\#66        SP-140727   0001     4                   Corrections to the description of the packet loss concealment algorithm   12.1.0
  2015-03              SA\#67        SP-150087   0002     \-                  Corrections to the description of the packet loss concealment algorithm   12.2.0
  2015-06              SA\#68        SP-150204   0003     \-                  Corrections to the description of the packet loss concealment algorithm   12.3.0
  2015-09              SA\#69        SP-150434   0004     1                   Corrections to the Algorithmic Description                                12.4.0
  2015-12              SA\#70        SP-150639   0005     2                   Corrections to the Algorithmic Description                                12.5.0
  2015-12              SA\#70                                                 Version for Release 13                                                    13.0.0
  2016-06              SA\#72        SP-160257   0007     \-        A         Corrections to the Algorithmic Description                                13.1.0
  -------------------- ------------- ----------- -------- --------- --------- ------------------------------------------------------------------------- -----------------

  -------------------- ------------- ----------- -------- --------- --------- --------------------------------------------------------------------- -----------------
  **Change history**                                                                                                                                
  **Date**             **Meeting**   **TDoc**    **CR**   **Rev**   **Cat**   **Subject/Comment**                                                   **New version**
  2017-03              SA\#75                                                 Version for Release 14                                                14.0.0
  2017-06              SA\#76        SP-170316   0010     \-        A         Corrections to the Algorithmic Description                            14.1.0
  2018-06              SA\#80                                                 Version for Release 15                                                15.0.0
  2019-03              SA\#83        SP-190036   0011     1         B         Correction and addition of reference to Alt\_FX\_EVS implementation   16.0.0
  2020-06              SA\#88-e      SP-200386   0017     0         A         Corrections to the Algorithmic Description                            16.1.0
  -------------------- ------------- ----------- -------- --------- --------- --------------------------------------------------------------------- -----------------
